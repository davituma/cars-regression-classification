2025-12-04 17:59:08,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-04 17:59:08,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-04 17:59:08,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-04 17:59:08,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-04 17:59:08,720:INFO:PyCaret RegressionExperiment
2025-12-04 17:59:08,720:INFO:Logging name: reg-default-name
2025-12-04 17:59:08,720:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-04 17:59:08,720:INFO:version 3.3.2
2025-12-04 17:59:08,722:INFO:Initializing setup()
2025-12-04 17:59:08,722:INFO:self.USI: 7439
2025-12-04 17:59:08,722:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_n_jobs_param', 'data', 'X', 'gpu_param', 'y', 'idx', 'exp_id', 'fold_generator', 'pipeline', 'memory', '_ml_usecase', 'n_jobs_param', 'y_test', 'fold_groups_param', 'transform_target_param', 'html_param', 'X_test', 'y_train', 'X_train', 'seed', 'target_param', 'exp_name_log', '_available_plots', 'logging_param', 'fold_shuffle_param'}
2025-12-04 17:59:08,722:INFO:Checking environment
2025-12-04 17:59:08,722:INFO:python_version: 3.10.19
2025-12-04 17:59:08,722:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-04 17:59:08,722:INFO:machine: AMD64
2025-12-04 17:59:08,722:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-04 17:59:08,722:INFO:Memory: svmem(total=33699516416, available=14965436416, percent=55.6, used=18734080000, free=14965436416)
2025-12-04 17:59:08,722:INFO:Physical Core: 8
2025-12-04 17:59:08,722:INFO:Logical Core: 16
2025-12-04 17:59:08,723:INFO:Checking libraries
2025-12-04 17:59:08,723:INFO:System:
2025-12-04 17:59:08,723:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-04 17:59:08,723:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-04 17:59:08,723:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-04 17:59:08,723:INFO:PyCaret required dependencies:
2025-12-04 17:59:08,725:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:08,793:INFO:                 pip: 25.3
2025-12-04 17:59:08,793:INFO:          setuptools: 80.9.0
2025-12-04 17:59:08,793:INFO:             pycaret: 3.3.2
2025-12-04 17:59:08,793:INFO:             IPython: 8.37.0
2025-12-04 17:59:08,793:INFO:          ipywidgets: 8.1.8
2025-12-04 17:59:08,793:INFO:                tqdm: 4.67.1
2025-12-04 17:59:08,793:INFO:               numpy: 1.26.4
2025-12-04 17:59:08,793:INFO:              pandas: 2.1.4
2025-12-04 17:59:08,793:INFO:              jinja2: 3.1.6
2025-12-04 17:59:08,793:INFO:               scipy: 1.11.4
2025-12-04 17:59:08,793:INFO:              joblib: 1.3.2
2025-12-04 17:59:08,793:INFO:             sklearn: 1.4.2
2025-12-04 17:59:08,795:INFO:                pyod: 2.0.6
2025-12-04 17:59:08,795:INFO:            imblearn: 0.14.0
2025-12-04 17:59:08,795:INFO:   category_encoders: 2.7.0
2025-12-04 17:59:08,795:INFO:            lightgbm: 4.6.0
2025-12-04 17:59:08,795:INFO:               numba: 0.62.1
2025-12-04 17:59:08,795:INFO:            requests: 2.32.5
2025-12-04 17:59:08,795:INFO:          matplotlib: 3.7.5
2025-12-04 17:59:08,795:INFO:          scikitplot: 0.3.7
2025-12-04 17:59:08,795:INFO:         yellowbrick: 1.5
2025-12-04 17:59:08,795:INFO:              plotly: 6.5.0
2025-12-04 17:59:08,795:INFO:    plotly-resampler: Not installed
2025-12-04 17:59:08,795:INFO:             kaleido: 1.2.0
2025-12-04 17:59:08,795:INFO:           schemdraw: 0.15
2025-12-04 17:59:08,795:INFO:         statsmodels: 0.14.5
2025-12-04 17:59:08,795:INFO:              sktime: 0.26.0
2025-12-04 17:59:08,795:INFO:               tbats: 1.1.3
2025-12-04 17:59:08,796:INFO:            pmdarima: 2.0.4
2025-12-04 17:59:08,796:INFO:              psutil: 7.1.3
2025-12-04 17:59:08,796:INFO:          markupsafe: 3.0.3
2025-12-04 17:59:08,796:INFO:             pickle5: Not installed
2025-12-04 17:59:08,796:INFO:         cloudpickle: 3.1.2
2025-12-04 17:59:08,796:INFO:         deprecation: 2.1.0
2025-12-04 17:59:08,796:INFO:              xxhash: 3.6.0
2025-12-04 17:59:08,796:INFO:           wurlitzer: Not installed
2025-12-04 17:59:08,796:INFO:PyCaret optional dependencies:
2025-12-04 17:59:08,819:INFO:                shap: Not installed
2025-12-04 17:59:08,819:INFO:           interpret: Not installed
2025-12-04 17:59:08,819:INFO:                umap: Not installed
2025-12-04 17:59:08,819:INFO:     ydata_profiling: Not installed
2025-12-04 17:59:08,819:INFO:  explainerdashboard: Not installed
2025-12-04 17:59:08,819:INFO:             autoviz: Not installed
2025-12-04 17:59:08,820:INFO:           fairlearn: Not installed
2025-12-04 17:59:08,820:INFO:          deepchecks: Not installed
2025-12-04 17:59:08,820:INFO:             xgboost: Not installed
2025-12-04 17:59:08,820:INFO:            catboost: Not installed
2025-12-04 17:59:08,820:INFO:              kmodes: Not installed
2025-12-04 17:59:08,820:INFO:             mlxtend: Not installed
2025-12-04 17:59:08,820:INFO:       statsforecast: Not installed
2025-12-04 17:59:08,820:INFO:        tune_sklearn: Not installed
2025-12-04 17:59:08,820:INFO:                 ray: Not installed
2025-12-04 17:59:08,820:INFO:            hyperopt: Not installed
2025-12-04 17:59:08,820:INFO:              optuna: Not installed
2025-12-04 17:59:08,820:INFO:               skopt: Not installed
2025-12-04 17:59:08,820:INFO:              mlflow: Not installed
2025-12-04 17:59:08,821:INFO:              gradio: Not installed
2025-12-04 17:59:08,821:INFO:             fastapi: Not installed
2025-12-04 17:59:08,821:INFO:             uvicorn: Not installed
2025-12-04 17:59:08,823:INFO:              m2cgen: Not installed
2025-12-04 17:59:08,823:INFO:           evidently: Not installed
2025-12-04 17:59:08,824:INFO:               fugue: Not installed
2025-12-04 17:59:08,824:INFO:           streamlit: Not installed
2025-12-04 17:59:08,824:INFO:             prophet: Not installed
2025-12-04 17:59:08,824:INFO:None
2025-12-04 17:59:08,826:INFO:Set up data.
2025-12-04 17:59:08,846:INFO:Set up folding strategy.
2025-12-04 17:59:08,846:INFO:Set up train/test split.
2025-12-04 17:59:08,857:INFO:Set up index.
2025-12-04 17:59:08,858:INFO:Assigning column types.
2025-12-04 17:59:08,871:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-04 17:59:08,873:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-04 17:59:08,885:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-04 17:59:08,900:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:09,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:09,177:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,201:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:09,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:09,468:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-04 17:59:09,480:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,491:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,640:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:09,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:09,768:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,781:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-04 17:59:09,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:10,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:10,046:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-04 17:59:10,069:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,340:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:10,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:10,365:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:10,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:10,632:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-04 17:59:10,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,918:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 17:59:10,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:10,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:11,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:11,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 17:59:11,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:11,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:11,208:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-04 17:59:11,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:11,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:11,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:11,704:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-04 17:59:11,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:11,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:11,817:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-04 17:59:12,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:12,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:12,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:12,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:12,446:INFO:Preparing preprocessing pipeline...
2025-12-04 17:59:12,447:INFO:Set up simple imputation.
2025-12-04 17:59:12,447:INFO:Set up feature normalization.
2025-12-04 17:59:12,449:INFO:Set up column name cleaning.
2025-12-04 17:59:12,550:INFO:Finished creating preprocessing pipeline.
2025-12-04 17:59:12,566:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'transmission_encoded',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner_Test Drive Car',
                                             'owner_Third Owner'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-12-04 17:59:12,567:INFO:Creating final display dataframe.
2025-12-04 17:59:12,867:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 17)
4        Transformed data shape        (7906, 17)
5   Transformed train set shape        (5534, 17)
6    Transformed test set shape        (2372, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              7439
2025-12-04 17:59:13,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:13,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:13,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:13,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 17:59:13,453:INFO:setup() successfully completed in 4.77s...............
2025-12-04 17:59:13,453:INFO:Initializing compare_models()
2025-12-04 17:59:13,453:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-04 17:59:13,454:INFO:Checking exceptions
2025-12-04 17:59:13,460:INFO:Preparing display monitor
2025-12-04 17:59:13,529:INFO:Initializing Linear Regression
2025-12-04 17:59:13,529:INFO:Total runtime is 1.0542074839274089e-05 minutes
2025-12-04 17:59:13,538:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:13,539:INFO:Initializing create_model()
2025-12-04 17:59:13,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:13,539:INFO:Checking exceptions
2025-12-04 17:59:13,539:INFO:Importing libraries
2025-12-04 17:59:13,539:INFO:Copying training dataset
2025-12-04 17:59:13,566:INFO:Defining folds
2025-12-04 17:59:13,566:INFO:Declaring metric variables
2025-12-04 17:59:13,584:INFO:Importing untrained model
2025-12-04 17:59:13,598:INFO:Linear Regression Imported successfully
2025-12-04 17:59:13,635:INFO:Starting cross validation
2025-12-04 17:59:13,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:23,076:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,097:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,097:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,105:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,116:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,120:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,122:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,132:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,136:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,138:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:23,756:INFO:Calculating mean and std
2025-12-04 17:59:23,762:INFO:Creating metrics dataframe
2025-12-04 17:59:23,768:INFO:Uploading results into container
2025-12-04 17:59:23,770:INFO:Uploading model into container now
2025-12-04 17:59:23,771:INFO:_master_model_container: 1
2025-12-04 17:59:23,771:INFO:_display_container: 2
2025-12-04 17:59:23,773:INFO:LinearRegression(n_jobs=-1)
2025-12-04 17:59:23,774:INFO:create_model() successfully completed......................................
2025-12-04 17:59:23,971:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:23,971:INFO:Creating metrics dataframe
2025-12-04 17:59:23,988:INFO:Initializing Lasso Regression
2025-12-04 17:59:23,988:INFO:Total runtime is 0.17432361046473185 minutes
2025-12-04 17:59:23,996:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:23,996:INFO:Initializing create_model()
2025-12-04 17:59:23,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:23,998:INFO:Checking exceptions
2025-12-04 17:59:23,998:INFO:Importing libraries
2025-12-04 17:59:23,998:INFO:Copying training dataset
2025-12-04 17:59:24,015:INFO:Defining folds
2025-12-04 17:59:24,016:INFO:Declaring metric variables
2025-12-04 17:59:24,025:INFO:Importing untrained model
2025-12-04 17:59:24,035:INFO:Lasso Regression Imported successfully
2025-12-04 17:59:24,051:INFO:Starting cross validation
2025-12-04 17:59:24,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:30,572:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:30,578:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:30,588:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:30,592:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:30,597:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:30,611:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 17:59:31,189:INFO:Calculating mean and std
2025-12-04 17:59:31,194:INFO:Creating metrics dataframe
2025-12-04 17:59:31,201:INFO:Uploading results into container
2025-12-04 17:59:31,202:INFO:Uploading model into container now
2025-12-04 17:59:31,205:INFO:_master_model_container: 2
2025-12-04 17:59:31,206:INFO:_display_container: 2
2025-12-04 17:59:31,207:INFO:Lasso(random_state=123)
2025-12-04 17:59:31,207:INFO:create_model() successfully completed......................................
2025-12-04 17:59:31,373:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:31,373:INFO:Creating metrics dataframe
2025-12-04 17:59:31,390:INFO:Initializing Ridge Regression
2025-12-04 17:59:31,392:INFO:Total runtime is 0.2977158069610596 minutes
2025-12-04 17:59:31,401:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:31,402:INFO:Initializing create_model()
2025-12-04 17:59:31,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:31,403:INFO:Checking exceptions
2025-12-04 17:59:31,403:INFO:Importing libraries
2025-12-04 17:59:31,403:INFO:Copying training dataset
2025-12-04 17:59:31,419:INFO:Defining folds
2025-12-04 17:59:31,421:INFO:Declaring metric variables
2025-12-04 17:59:31,430:INFO:Importing untrained model
2025-12-04 17:59:31,440:INFO:Ridge Regression Imported successfully
2025-12-04 17:59:31,460:INFO:Starting cross validation
2025-12-04 17:59:31,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:31,691:INFO:Calculating mean and std
2025-12-04 17:59:31,695:INFO:Creating metrics dataframe
2025-12-04 17:59:31,699:INFO:Uploading results into container
2025-12-04 17:59:31,701:INFO:Uploading model into container now
2025-12-04 17:59:31,702:INFO:_master_model_container: 3
2025-12-04 17:59:31,703:INFO:_display_container: 2
2025-12-04 17:59:31,704:INFO:Ridge(random_state=123)
2025-12-04 17:59:31,704:INFO:create_model() successfully completed......................................
2025-12-04 17:59:31,853:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:31,853:INFO:Creating metrics dataframe
2025-12-04 17:59:31,870:INFO:Initializing Elastic Net
2025-12-04 17:59:31,871:INFO:Total runtime is 0.30569625298182174 minutes
2025-12-04 17:59:31,879:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:31,880:INFO:Initializing create_model()
2025-12-04 17:59:31,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:31,880:INFO:Checking exceptions
2025-12-04 17:59:31,880:INFO:Importing libraries
2025-12-04 17:59:31,880:INFO:Copying training dataset
2025-12-04 17:59:31,899:INFO:Defining folds
2025-12-04 17:59:31,900:INFO:Declaring metric variables
2025-12-04 17:59:31,911:INFO:Importing untrained model
2025-12-04 17:59:31,920:INFO:Elastic Net Imported successfully
2025-12-04 17:59:31,940:INFO:Starting cross validation
2025-12-04 17:59:31,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:32,188:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+12, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-04 17:59:32,227:INFO:Calculating mean and std
2025-12-04 17:59:32,229:INFO:Creating metrics dataframe
2025-12-04 17:59:32,234:INFO:Uploading results into container
2025-12-04 17:59:32,235:INFO:Uploading model into container now
2025-12-04 17:59:32,237:INFO:_master_model_container: 4
2025-12-04 17:59:32,237:INFO:_display_container: 2
2025-12-04 17:59:32,238:INFO:ElasticNet(random_state=123)
2025-12-04 17:59:32,240:INFO:create_model() successfully completed......................................
2025-12-04 17:59:32,395:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:32,395:INFO:Creating metrics dataframe
2025-12-04 17:59:32,411:INFO:Initializing Least Angle Regression
2025-12-04 17:59:32,412:INFO:Total runtime is 0.3147253473599752 minutes
2025-12-04 17:59:32,419:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:32,421:INFO:Initializing create_model()
2025-12-04 17:59:32,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:32,422:INFO:Checking exceptions
2025-12-04 17:59:32,422:INFO:Importing libraries
2025-12-04 17:59:32,422:INFO:Copying training dataset
2025-12-04 17:59:32,441:INFO:Defining folds
2025-12-04 17:59:32,443:INFO:Declaring metric variables
2025-12-04 17:59:32,452:INFO:Importing untrained model
2025-12-04 17:59:32,462:INFO:Least Angle Regression Imported successfully
2025-12-04 17:59:32,482:INFO:Starting cross validation
2025-12-04 17:59:32,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:32,708:INFO:Calculating mean and std
2025-12-04 17:59:32,710:INFO:Creating metrics dataframe
2025-12-04 17:59:32,715:INFO:Uploading results into container
2025-12-04 17:59:32,717:INFO:Uploading model into container now
2025-12-04 17:59:32,717:INFO:_master_model_container: 5
2025-12-04 17:59:32,718:INFO:_display_container: 2
2025-12-04 17:59:32,720:INFO:Lars(random_state=123)
2025-12-04 17:59:32,720:INFO:create_model() successfully completed......................................
2025-12-04 17:59:32,872:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:32,872:INFO:Creating metrics dataframe
2025-12-04 17:59:32,890:INFO:Initializing Lasso Least Angle Regression
2025-12-04 17:59:32,890:INFO:Total runtime is 0.3226932048797608 minutes
2025-12-04 17:59:32,899:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:32,901:INFO:Initializing create_model()
2025-12-04 17:59:32,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:32,901:INFO:Checking exceptions
2025-12-04 17:59:32,901:INFO:Importing libraries
2025-12-04 17:59:32,902:INFO:Copying training dataset
2025-12-04 17:59:32,923:INFO:Defining folds
2025-12-04 17:59:32,923:INFO:Declaring metric variables
2025-12-04 17:59:32,935:INFO:Importing untrained model
2025-12-04 17:59:32,946:INFO:Lasso Least Angle Regression Imported successfully
2025-12-04 17:59:32,986:INFO:Starting cross validation
2025-12-04 17:59:32,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:33,249:INFO:Calculating mean and std
2025-12-04 17:59:33,252:INFO:Creating metrics dataframe
2025-12-04 17:59:33,255:INFO:Uploading results into container
2025-12-04 17:59:33,256:INFO:Uploading model into container now
2025-12-04 17:59:33,257:INFO:_master_model_container: 6
2025-12-04 17:59:33,257:INFO:_display_container: 2
2025-12-04 17:59:33,259:INFO:LassoLars(random_state=123)
2025-12-04 17:59:33,259:INFO:create_model() successfully completed......................................
2025-12-04 17:59:33,409:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:33,412:INFO:Creating metrics dataframe
2025-12-04 17:59:33,433:INFO:Initializing Orthogonal Matching Pursuit
2025-12-04 17:59:33,433:INFO:Total runtime is 0.3317357103029887 minutes
2025-12-04 17:59:33,441:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:33,442:INFO:Initializing create_model()
2025-12-04 17:59:33,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:33,444:INFO:Checking exceptions
2025-12-04 17:59:33,444:INFO:Importing libraries
2025-12-04 17:59:33,444:INFO:Copying training dataset
2025-12-04 17:59:33,461:INFO:Defining folds
2025-12-04 17:59:33,462:INFO:Declaring metric variables
2025-12-04 17:59:33,471:INFO:Importing untrained model
2025-12-04 17:59:33,480:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-04 17:59:33,501:INFO:Starting cross validation
2025-12-04 17:59:33,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:33,724:INFO:Calculating mean and std
2025-12-04 17:59:33,727:INFO:Creating metrics dataframe
2025-12-04 17:59:33,732:INFO:Uploading results into container
2025-12-04 17:59:33,734:INFO:Uploading model into container now
2025-12-04 17:59:33,734:INFO:_master_model_container: 7
2025-12-04 17:59:33,734:INFO:_display_container: 2
2025-12-04 17:59:33,736:INFO:OrthogonalMatchingPursuit()
2025-12-04 17:59:33,736:INFO:create_model() successfully completed......................................
2025-12-04 17:59:33,885:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:33,885:INFO:Creating metrics dataframe
2025-12-04 17:59:33,902:INFO:Initializing Bayesian Ridge
2025-12-04 17:59:33,903:INFO:Total runtime is 0.3395692825317383 minutes
2025-12-04 17:59:33,911:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:33,912:INFO:Initializing create_model()
2025-12-04 17:59:33,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:33,912:INFO:Checking exceptions
2025-12-04 17:59:33,913:INFO:Importing libraries
2025-12-04 17:59:33,913:INFO:Copying training dataset
2025-12-04 17:59:33,931:INFO:Defining folds
2025-12-04 17:59:33,932:INFO:Declaring metric variables
2025-12-04 17:59:33,941:INFO:Importing untrained model
2025-12-04 17:59:33,951:INFO:Bayesian Ridge Imported successfully
2025-12-04 17:59:33,973:INFO:Starting cross validation
2025-12-04 17:59:33,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:34,235:INFO:Calculating mean and std
2025-12-04 17:59:34,237:INFO:Creating metrics dataframe
2025-12-04 17:59:34,241:INFO:Uploading results into container
2025-12-04 17:59:34,243:INFO:Uploading model into container now
2025-12-04 17:59:34,244:INFO:_master_model_container: 8
2025-12-04 17:59:34,244:INFO:_display_container: 2
2025-12-04 17:59:34,246:INFO:BayesianRidge()
2025-12-04 17:59:34,247:INFO:create_model() successfully completed......................................
2025-12-04 17:59:34,390:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:34,390:INFO:Creating metrics dataframe
2025-12-04 17:59:34,410:INFO:Initializing Passive Aggressive Regressor
2025-12-04 17:59:34,410:INFO:Total runtime is 0.3480213165283203 minutes
2025-12-04 17:59:34,418:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:34,420:INFO:Initializing create_model()
2025-12-04 17:59:34,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:34,421:INFO:Checking exceptions
2025-12-04 17:59:34,421:INFO:Importing libraries
2025-12-04 17:59:34,421:INFO:Copying training dataset
2025-12-04 17:59:34,441:INFO:Defining folds
2025-12-04 17:59:34,441:INFO:Declaring metric variables
2025-12-04 17:59:34,454:INFO:Importing untrained model
2025-12-04 17:59:34,464:INFO:Passive Aggressive Regressor Imported successfully
2025-12-04 17:59:34,484:INFO:Starting cross validation
2025-12-04 17:59:34,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:35,817:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,823:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,828:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,832:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,842:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,849:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,882:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,890:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,904:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-04 17:59:35,938:INFO:Calculating mean and std
2025-12-04 17:59:35,941:INFO:Creating metrics dataframe
2025-12-04 17:59:35,945:INFO:Uploading results into container
2025-12-04 17:59:35,947:INFO:Uploading model into container now
2025-12-04 17:59:35,948:INFO:_master_model_container: 9
2025-12-04 17:59:35,948:INFO:_display_container: 2
2025-12-04 17:59:35,948:INFO:PassiveAggressiveRegressor(random_state=123)
2025-12-04 17:59:35,949:INFO:create_model() successfully completed......................................
2025-12-04 17:59:36,109:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:36,125:INFO:Creating metrics dataframe
2025-12-04 17:59:36,148:INFO:Initializing Huber Regressor
2025-12-04 17:59:36,148:INFO:Total runtime is 0.3769901672999064 minutes
2025-12-04 17:59:36,157:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:36,159:INFO:Initializing create_model()
2025-12-04 17:59:36,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:36,159:INFO:Checking exceptions
2025-12-04 17:59:36,161:INFO:Importing libraries
2025-12-04 17:59:36,161:INFO:Copying training dataset
2025-12-04 17:59:36,179:INFO:Defining folds
2025-12-04 17:59:36,180:INFO:Declaring metric variables
2025-12-04 17:59:36,188:INFO:Importing untrained model
2025-12-04 17:59:36,199:INFO:Huber Regressor Imported successfully
2025-12-04 17:59:36,216:INFO:Starting cross validation
2025-12-04 17:59:36,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:36,590:INFO:Calculating mean and std
2025-12-04 17:59:36,592:INFO:Creating metrics dataframe
2025-12-04 17:59:36,597:INFO:Uploading results into container
2025-12-04 17:59:36,598:INFO:Uploading model into container now
2025-12-04 17:59:36,599:INFO:_master_model_container: 10
2025-12-04 17:59:36,600:INFO:_display_container: 2
2025-12-04 17:59:36,600:INFO:HuberRegressor()
2025-12-04 17:59:36,600:INFO:create_model() successfully completed......................................
2025-12-04 17:59:36,748:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:36,749:INFO:Creating metrics dataframe
2025-12-04 17:59:36,768:INFO:Initializing K Neighbors Regressor
2025-12-04 17:59:36,770:INFO:Total runtime is 0.3873510996500651 minutes
2025-12-04 17:59:36,780:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:36,781:INFO:Initializing create_model()
2025-12-04 17:59:36,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:36,781:INFO:Checking exceptions
2025-12-04 17:59:36,781:INFO:Importing libraries
2025-12-04 17:59:36,781:INFO:Copying training dataset
2025-12-04 17:59:36,801:INFO:Defining folds
2025-12-04 17:59:36,801:INFO:Declaring metric variables
2025-12-04 17:59:36,815:INFO:Importing untrained model
2025-12-04 17:59:36,826:INFO:K Neighbors Regressor Imported successfully
2025-12-04 17:59:36,849:INFO:Starting cross validation
2025-12-04 17:59:36,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:37,129:INFO:Calculating mean and std
2025-12-04 17:59:37,131:INFO:Creating metrics dataframe
2025-12-04 17:59:37,136:INFO:Uploading results into container
2025-12-04 17:59:37,137:INFO:Uploading model into container now
2025-12-04 17:59:37,139:INFO:_master_model_container: 11
2025-12-04 17:59:37,139:INFO:_display_container: 2
2025-12-04 17:59:37,140:INFO:KNeighborsRegressor(n_jobs=-1)
2025-12-04 17:59:37,140:INFO:create_model() successfully completed......................................
2025-12-04 17:59:37,284:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:37,284:INFO:Creating metrics dataframe
2025-12-04 17:59:37,307:INFO:Initializing Decision Tree Regressor
2025-12-04 17:59:37,307:INFO:Total runtime is 0.3962990403175354 minutes
2025-12-04 17:59:37,317:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:37,318:INFO:Initializing create_model()
2025-12-04 17:59:37,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:37,319:INFO:Checking exceptions
2025-12-04 17:59:37,319:INFO:Importing libraries
2025-12-04 17:59:37,319:INFO:Copying training dataset
2025-12-04 17:59:37,338:INFO:Defining folds
2025-12-04 17:59:37,338:INFO:Declaring metric variables
2025-12-04 17:59:37,347:INFO:Importing untrained model
2025-12-04 17:59:37,358:INFO:Decision Tree Regressor Imported successfully
2025-12-04 17:59:37,382:INFO:Starting cross validation
2025-12-04 17:59:37,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:37,690:INFO:Calculating mean and std
2025-12-04 17:59:37,692:INFO:Creating metrics dataframe
2025-12-04 17:59:37,697:INFO:Uploading results into container
2025-12-04 17:59:37,698:INFO:Uploading model into container now
2025-12-04 17:59:37,699:INFO:_master_model_container: 12
2025-12-04 17:59:37,699:INFO:_display_container: 2
2025-12-04 17:59:37,701:INFO:DecisionTreeRegressor(random_state=123)
2025-12-04 17:59:37,701:INFO:create_model() successfully completed......................................
2025-12-04 17:59:37,861:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:37,862:INFO:Creating metrics dataframe
2025-12-04 17:59:37,887:INFO:Initializing Random Forest Regressor
2025-12-04 17:59:37,887:INFO:Total runtime is 0.405971097946167 minutes
2025-12-04 17:59:37,896:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:37,896:INFO:Initializing create_model()
2025-12-04 17:59:37,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:37,896:INFO:Checking exceptions
2025-12-04 17:59:37,897:INFO:Importing libraries
2025-12-04 17:59:37,897:INFO:Copying training dataset
2025-12-04 17:59:37,917:INFO:Defining folds
2025-12-04 17:59:37,919:INFO:Declaring metric variables
2025-12-04 17:59:37,932:INFO:Importing untrained model
2025-12-04 17:59:37,945:INFO:Random Forest Regressor Imported successfully
2025-12-04 17:59:37,990:INFO:Starting cross validation
2025-12-04 17:59:37,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:41,369:INFO:Calculating mean and std
2025-12-04 17:59:41,372:INFO:Creating metrics dataframe
2025-12-04 17:59:41,379:INFO:Uploading results into container
2025-12-04 17:59:41,380:INFO:Uploading model into container now
2025-12-04 17:59:41,380:INFO:_master_model_container: 13
2025-12-04 17:59:41,381:INFO:_display_container: 2
2025-12-04 17:59:41,382:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-12-04 17:59:41,383:INFO:create_model() successfully completed......................................
2025-12-04 17:59:41,528:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:41,528:INFO:Creating metrics dataframe
2025-12-04 17:59:41,549:INFO:Initializing Extra Trees Regressor
2025-12-04 17:59:41,549:INFO:Total runtime is 0.46700824896494547 minutes
2025-12-04 17:59:41,558:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:41,560:INFO:Initializing create_model()
2025-12-04 17:59:41,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:41,560:INFO:Checking exceptions
2025-12-04 17:59:41,560:INFO:Importing libraries
2025-12-04 17:59:41,560:INFO:Copying training dataset
2025-12-04 17:59:41,577:INFO:Defining folds
2025-12-04 17:59:41,577:INFO:Declaring metric variables
2025-12-04 17:59:41,587:INFO:Importing untrained model
2025-12-04 17:59:41,597:INFO:Extra Trees Regressor Imported successfully
2025-12-04 17:59:41,614:INFO:Starting cross validation
2025-12-04 17:59:41,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:44,078:INFO:Calculating mean and std
2025-12-04 17:59:44,081:INFO:Creating metrics dataframe
2025-12-04 17:59:44,087:INFO:Uploading results into container
2025-12-04 17:59:44,088:INFO:Uploading model into container now
2025-12-04 17:59:44,090:INFO:_master_model_container: 14
2025-12-04 17:59:44,090:INFO:_display_container: 2
2025-12-04 17:59:44,092:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-04 17:59:44,092:INFO:create_model() successfully completed......................................
2025-12-04 17:59:44,259:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:44,260:INFO:Creating metrics dataframe
2025-12-04 17:59:44,285:INFO:Initializing AdaBoost Regressor
2025-12-04 17:59:44,285:INFO:Total runtime is 0.512596337000529 minutes
2025-12-04 17:59:44,294:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:44,296:INFO:Initializing create_model()
2025-12-04 17:59:44,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:44,296:INFO:Checking exceptions
2025-12-04 17:59:44,296:INFO:Importing libraries
2025-12-04 17:59:44,296:INFO:Copying training dataset
2025-12-04 17:59:44,327:INFO:Defining folds
2025-12-04 17:59:44,328:INFO:Declaring metric variables
2025-12-04 17:59:44,336:INFO:Importing untrained model
2025-12-04 17:59:44,347:INFO:AdaBoost Regressor Imported successfully
2025-12-04 17:59:44,368:INFO:Starting cross validation
2025-12-04 17:59:44,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:45,227:INFO:Calculating mean and std
2025-12-04 17:59:45,229:INFO:Creating metrics dataframe
2025-12-04 17:59:45,233:INFO:Uploading results into container
2025-12-04 17:59:45,234:INFO:Uploading model into container now
2025-12-04 17:59:45,236:INFO:_master_model_container: 15
2025-12-04 17:59:45,236:INFO:_display_container: 2
2025-12-04 17:59:45,237:INFO:AdaBoostRegressor(random_state=123)
2025-12-04 17:59:45,237:INFO:create_model() successfully completed......................................
2025-12-04 17:59:45,391:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:45,392:INFO:Creating metrics dataframe
2025-12-04 17:59:45,422:INFO:Initializing Gradient Boosting Regressor
2025-12-04 17:59:45,422:INFO:Total runtime is 0.5315511504809062 minutes
2025-12-04 17:59:45,433:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:45,435:INFO:Initializing create_model()
2025-12-04 17:59:45,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:45,435:INFO:Checking exceptions
2025-12-04 17:59:45,436:INFO:Importing libraries
2025-12-04 17:59:45,436:INFO:Copying training dataset
2025-12-04 17:59:45,463:INFO:Defining folds
2025-12-04 17:59:45,463:INFO:Declaring metric variables
2025-12-04 17:59:45,473:INFO:Importing untrained model
2025-12-04 17:59:45,488:INFO:Gradient Boosting Regressor Imported successfully
2025-12-04 17:59:45,508:INFO:Starting cross validation
2025-12-04 17:59:45,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:46,762:INFO:Calculating mean and std
2025-12-04 17:59:46,765:INFO:Creating metrics dataframe
2025-12-04 17:59:46,769:INFO:Uploading results into container
2025-12-04 17:59:46,770:INFO:Uploading model into container now
2025-12-04 17:59:46,771:INFO:_master_model_container: 16
2025-12-04 17:59:46,771:INFO:_display_container: 2
2025-12-04 17:59:46,773:INFO:GradientBoostingRegressor(random_state=123)
2025-12-04 17:59:46,773:INFO:create_model() successfully completed......................................
2025-12-04 17:59:46,914:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:46,914:INFO:Creating metrics dataframe
2025-12-04 17:59:46,939:INFO:Initializing Light Gradient Boosting Machine
2025-12-04 17:59:46,939:INFO:Total runtime is 0.556834097703298 minutes
2025-12-04 17:59:46,951:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:46,951:INFO:Initializing create_model()
2025-12-04 17:59:46,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:46,951:INFO:Checking exceptions
2025-12-04 17:59:46,951:INFO:Importing libraries
2025-12-04 17:59:46,953:INFO:Copying training dataset
2025-12-04 17:59:46,973:INFO:Defining folds
2025-12-04 17:59:46,973:INFO:Declaring metric variables
2025-12-04 17:59:46,988:INFO:Importing untrained model
2025-12-04 17:59:47,002:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 17:59:47,021:INFO:Starting cross validation
2025-12-04 17:59:47,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:49,095:INFO:Calculating mean and std
2025-12-04 17:59:49,099:INFO:Creating metrics dataframe
2025-12-04 17:59:49,105:INFO:Uploading results into container
2025-12-04 17:59:49,107:INFO:Uploading model into container now
2025-12-04 17:59:49,109:INFO:_master_model_container: 17
2025-12-04 17:59:49,109:INFO:_display_container: 2
2025-12-04 17:59:49,111:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-04 17:59:49,111:INFO:create_model() successfully completed......................................
2025-12-04 17:59:49,275:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:49,275:INFO:Creating metrics dataframe
2025-12-04 17:59:49,302:INFO:Initializing Dummy Regressor
2025-12-04 17:59:49,303:INFO:Total runtime is 0.5962356249491374 minutes
2025-12-04 17:59:49,314:INFO:SubProcess create_model() called ==================================
2025-12-04 17:59:49,315:INFO:Initializing create_model()
2025-12-04 17:59:49,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812874E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:49,315:INFO:Checking exceptions
2025-12-04 17:59:49,315:INFO:Importing libraries
2025-12-04 17:59:49,315:INFO:Copying training dataset
2025-12-04 17:59:49,339:INFO:Defining folds
2025-12-04 17:59:49,341:INFO:Declaring metric variables
2025-12-04 17:59:49,354:INFO:Importing untrained model
2025-12-04 17:59:49,365:INFO:Dummy Regressor Imported successfully
2025-12-04 17:59:49,386:INFO:Starting cross validation
2025-12-04 17:59:49,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 17:59:49,605:INFO:Calculating mean and std
2025-12-04 17:59:49,607:INFO:Creating metrics dataframe
2025-12-04 17:59:49,613:INFO:Uploading results into container
2025-12-04 17:59:49,614:INFO:Uploading model into container now
2025-12-04 17:59:49,615:INFO:_master_model_container: 18
2025-12-04 17:59:49,615:INFO:_display_container: 2
2025-12-04 17:59:49,615:INFO:DummyRegressor()
2025-12-04 17:59:49,615:INFO:create_model() successfully completed......................................
2025-12-04 17:59:49,756:INFO:SubProcess create_model() end ==================================
2025-12-04 17:59:49,757:INFO:Creating metrics dataframe
2025-12-04 17:59:49,788:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-04 17:59:49,810:INFO:Initializing create_model()
2025-12-04 17:59:49,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 17:59:49,811:INFO:Checking exceptions
2025-12-04 17:59:49,813:INFO:Importing libraries
2025-12-04 17:59:49,815:INFO:Copying training dataset
2025-12-04 17:59:49,832:INFO:Defining folds
2025-12-04 17:59:49,832:INFO:Declaring metric variables
2025-12-04 17:59:49,832:INFO:Importing untrained model
2025-12-04 17:59:49,832:INFO:Declaring custom model
2025-12-04 17:59:49,835:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 17:59:49,839:INFO:Cross validation set to False
2025-12-04 17:59:49,839:INFO:Fitting Model
2025-12-04 17:59:49,884:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:59:49,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000787 seconds.
2025-12-04 17:59:49,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:59:49,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:59:49,888:INFO:[LightGBM] [Info] Total Bins 874
2025-12-04 17:59:49,889:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-04 17:59:49,890:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-04 17:59:50,106:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-04 17:59:50,106:INFO:create_model() successfully completed......................................
2025-12-04 17:59:50,340:INFO:_master_model_container: 18
2025-12-04 17:59:50,341:INFO:_display_container: 2
2025-12-04 17:59:50,343:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-04 17:59:50,343:INFO:compare_models() successfully completed......................................
2025-12-04 17:59:50,348:INFO:Initializing tune_model()
2025-12-04 17:59:50,348:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>)
2025-12-04 17:59:50,348:INFO:Checking exceptions
2025-12-04 17:59:50,399:INFO:Copying training dataset
2025-12-04 17:59:50,412:INFO:Checking base model
2025-12-04 17:59:50,413:INFO:Base model : Light Gradient Boosting Machine
2025-12-04 17:59:50,422:INFO:Declaring metric variables
2025-12-04 17:59:50,433:INFO:Defining Hyperparameters
2025-12-04 17:59:50,601:INFO:Tuning with n_jobs=-1
2025-12-04 17:59:50,601:INFO:Initializing RandomizedSearchCV
2025-12-04 18:00:17,464:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-04 18:00:17,466:INFO:Hyperparameter search completed
2025-12-04 18:00:17,466:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:17,469:INFO:Initializing create_model()
2025-12-04 18:00:17,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280FFE39A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-04 18:00:17,470:INFO:Checking exceptions
2025-12-04 18:00:17,470:INFO:Importing libraries
2025-12-04 18:00:17,472:INFO:Copying training dataset
2025-12-04 18:00:17,495:INFO:Defining folds
2025-12-04 18:00:17,495:INFO:Declaring metric variables
2025-12-04 18:00:17,506:INFO:Importing untrained model
2025-12-04 18:00:17,506:INFO:Declaring custom model
2025-12-04 18:00:17,523:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 18:00:17,548:INFO:Starting cross validation
2025-12-04 18:00:17,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:19,470:INFO:Calculating mean and std
2025-12-04 18:00:19,476:INFO:Creating metrics dataframe
2025-12-04 18:00:19,501:INFO:Finalizing model
2025-12-04 18:00:19,552:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-04 18:00:19,552:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-04 18:00:19,552:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 18:00:19,560:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 18:00:19,560:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-04 18:00:19,560:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-04 18:00:19,561:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 18:00:19,564:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001366 seconds.
2025-12-04 18:00:19,564:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-04 18:00:19,564:INFO:[LightGBM] [Info] Total Bins 874
2025-12-04 18:00:19,565:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-04 18:00:19,565:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-04 18:00:19,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 18:00:19,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 18:00:19,813:INFO:Uploading results into container
2025-12-04 18:00:19,816:INFO:Uploading model into container now
2025-12-04 18:00:19,817:INFO:_master_model_container: 19
2025-12-04 18:00:19,817:INFO:_display_container: 3
2025-12-04 18:00:19,820:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005)
2025-12-04 18:00:19,820:INFO:create_model() successfully completed......................................
2025-12-04 18:00:19,982:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:19,982:INFO:choose_better activated
2025-12-04 18:00:19,991:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:19,995:INFO:Initializing create_model()
2025-12-04 18:00:19,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002280FFE3970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:19,995:INFO:Checking exceptions
2025-12-04 18:00:19,999:INFO:Importing libraries
2025-12-04 18:00:19,999:INFO:Copying training dataset
2025-12-04 18:00:20,019:INFO:Defining folds
2025-12-04 18:00:20,019:INFO:Declaring metric variables
2025-12-04 18:00:20,019:INFO:Importing untrained model
2025-12-04 18:00:20,019:INFO:Declaring custom model
2025-12-04 18:00:20,022:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 18:00:20,024:INFO:Starting cross validation
2025-12-04 18:00:20,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:22,394:INFO:Calculating mean and std
2025-12-04 18:00:22,394:INFO:Creating metrics dataframe
2025-12-04 18:00:22,399:INFO:Finalizing model
2025-12-04 18:00:22,448:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 18:00:22,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001677 seconds.
2025-12-04 18:00:22,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-04 18:00:22,452:INFO:[LightGBM] [Info] Total Bins 874
2025-12-04 18:00:22,452:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-04 18:00:22,452:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-04 18:00:22,698:INFO:Uploading results into container
2025-12-04 18:00:22,700:INFO:Uploading model into container now
2025-12-04 18:00:22,701:INFO:_master_model_container: 20
2025-12-04 18:00:22,701:INFO:_display_container: 4
2025-12-04 18:00:22,703:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-04 18:00:22,703:INFO:create_model() successfully completed......................................
2025-12-04 18:00:22,864:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:22,865:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9584
2025-12-04 18:00:22,868:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005) result for R2 is 0.9462
2025-12-04 18:00:22,869:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-12-04 18:00:22,869:INFO:choose_better completed
2025-12-04 18:00:22,869:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-04 18:00:22,896:INFO:_master_model_container: 20
2025-12-04 18:00:22,897:INFO:_display_container: 3
2025-12-04 18:00:22,898:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-04 18:00:22,899:INFO:tune_model() successfully completed......................................
2025-12-04 18:00:23,088:INFO:PyCaret ClassificationExperiment
2025-12-04 18:00:23,088:INFO:Logging name: clf-default-name
2025-12-04 18:00:23,088:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-04 18:00:23,088:INFO:version 3.3.2
2025-12-04 18:00:23,088:INFO:Initializing setup()
2025-12-04 18:00:23,089:INFO:self.USI: b0bf
2025-12-04 18:00:23,089:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_n_jobs_param', 'data', 'X', 'gpu_param', 'y', 'idx', 'exp_id', 'fold_generator', 'pipeline', 'memory', '_ml_usecase', 'n_jobs_param', 'y_test', 'fold_groups_param', 'is_multiclass', 'fix_imbalance', 'html_param', 'X_test', 'y_train', 'X_train', 'seed', 'target_param', 'exp_name_log', '_available_plots', 'logging_param', 'fold_shuffle_param'}
2025-12-04 18:00:23,089:INFO:Checking environment
2025-12-04 18:00:23,089:INFO:python_version: 3.10.19
2025-12-04 18:00:23,089:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-04 18:00:23,089:INFO:machine: AMD64
2025-12-04 18:00:23,089:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-04 18:00:23,089:INFO:Memory: svmem(total=33699516416, available=13075017728, percent=61.2, used=20624498688, free=13075017728)
2025-12-04 18:00:23,089:INFO:Physical Core: 8
2025-12-04 18:00:23,089:INFO:Logical Core: 16
2025-12-04 18:00:23,089:INFO:Checking libraries
2025-12-04 18:00:23,089:INFO:System:
2025-12-04 18:00:23,091:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-04 18:00:23,091:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-04 18:00:23,091:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-04 18:00:23,091:INFO:PyCaret required dependencies:
2025-12-04 18:00:23,091:INFO:                 pip: 25.3
2025-12-04 18:00:23,091:INFO:          setuptools: 80.9.0
2025-12-04 18:00:23,092:INFO:             pycaret: 3.3.2
2025-12-04 18:00:23,092:INFO:             IPython: 8.37.0
2025-12-04 18:00:23,092:INFO:          ipywidgets: 8.1.8
2025-12-04 18:00:23,092:INFO:                tqdm: 4.67.1
2025-12-04 18:00:23,092:INFO:               numpy: 1.26.4
2025-12-04 18:00:23,092:INFO:              pandas: 2.1.4
2025-12-04 18:00:23,092:INFO:              jinja2: 3.1.6
2025-12-04 18:00:23,092:INFO:               scipy: 1.11.4
2025-12-04 18:00:23,092:INFO:              joblib: 1.3.2
2025-12-04 18:00:23,092:INFO:             sklearn: 1.4.2
2025-12-04 18:00:23,092:INFO:                pyod: 2.0.6
2025-12-04 18:00:23,092:INFO:            imblearn: 0.14.0
2025-12-04 18:00:23,092:INFO:   category_encoders: 2.7.0
2025-12-04 18:00:23,092:INFO:            lightgbm: 4.6.0
2025-12-04 18:00:23,093:INFO:               numba: 0.62.1
2025-12-04 18:00:23,093:INFO:            requests: 2.32.5
2025-12-04 18:00:23,093:INFO:          matplotlib: 3.7.5
2025-12-04 18:00:23,093:INFO:          scikitplot: 0.3.7
2025-12-04 18:00:23,093:INFO:         yellowbrick: 1.5
2025-12-04 18:00:23,093:INFO:              plotly: 6.5.0
2025-12-04 18:00:23,093:INFO:    plotly-resampler: Not installed
2025-12-04 18:00:23,093:INFO:             kaleido: 1.2.0
2025-12-04 18:00:23,093:INFO:           schemdraw: 0.15
2025-12-04 18:00:23,093:INFO:         statsmodels: 0.14.5
2025-12-04 18:00:23,093:INFO:              sktime: 0.26.0
2025-12-04 18:00:23,093:INFO:               tbats: 1.1.3
2025-12-04 18:00:23,093:INFO:            pmdarima: 2.0.4
2025-12-04 18:00:23,093:INFO:              psutil: 7.1.3
2025-12-04 18:00:23,093:INFO:          markupsafe: 3.0.3
2025-12-04 18:00:23,093:INFO:             pickle5: Not installed
2025-12-04 18:00:23,093:INFO:         cloudpickle: 3.1.2
2025-12-04 18:00:23,093:INFO:         deprecation: 2.1.0
2025-12-04 18:00:23,095:INFO:              xxhash: 3.6.0
2025-12-04 18:00:23,095:INFO:           wurlitzer: Not installed
2025-12-04 18:00:23,095:INFO:PyCaret optional dependencies:
2025-12-04 18:00:23,095:INFO:                shap: Not installed
2025-12-04 18:00:23,095:INFO:           interpret: Not installed
2025-12-04 18:00:23,095:INFO:                umap: Not installed
2025-12-04 18:00:23,095:INFO:     ydata_profiling: Not installed
2025-12-04 18:00:23,095:INFO:  explainerdashboard: Not installed
2025-12-04 18:00:23,095:INFO:             autoviz: Not installed
2025-12-04 18:00:23,095:INFO:           fairlearn: Not installed
2025-12-04 18:00:23,095:INFO:          deepchecks: Not installed
2025-12-04 18:00:23,095:INFO:             xgboost: Not installed
2025-12-04 18:00:23,095:INFO:            catboost: Not installed
2025-12-04 18:00:23,095:INFO:              kmodes: Not installed
2025-12-04 18:00:23,095:INFO:             mlxtend: Not installed
2025-12-04 18:00:23,095:INFO:       statsforecast: Not installed
2025-12-04 18:00:23,095:INFO:        tune_sklearn: Not installed
2025-12-04 18:00:23,095:INFO:                 ray: Not installed
2025-12-04 18:00:23,097:INFO:            hyperopt: Not installed
2025-12-04 18:00:23,097:INFO:              optuna: Not installed
2025-12-04 18:00:23,097:INFO:               skopt: Not installed
2025-12-04 18:00:23,097:INFO:              mlflow: Not installed
2025-12-04 18:00:23,097:INFO:              gradio: Not installed
2025-12-04 18:00:23,097:INFO:             fastapi: Not installed
2025-12-04 18:00:23,097:INFO:             uvicorn: Not installed
2025-12-04 18:00:23,097:INFO:              m2cgen: Not installed
2025-12-04 18:00:23,097:INFO:           evidently: Not installed
2025-12-04 18:00:23,097:INFO:               fugue: Not installed
2025-12-04 18:00:23,097:INFO:           streamlit: Not installed
2025-12-04 18:00:23,097:INFO:             prophet: Not installed
2025-12-04 18:00:23,097:INFO:None
2025-12-04 18:00:23,097:INFO:Set up data.
2025-12-04 18:00:23,115:INFO:Set up folding strategy.
2025-12-04 18:00:23,115:INFO:Set up train/test split.
2025-12-04 18:00:23,136:INFO:Set up index.
2025-12-04 18:00:23,136:INFO:Assigning column types.
2025-12-04 18:00:23,152:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-04 18:00:23,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 18:00:23,267:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 18:00:23,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:23,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:23,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 18:00:23,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 18:00:23,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:23,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:23,545:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-04 18:00:23,664:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 18:00:23,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:23,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:23,854:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 18:00:23,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:23,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:23,927:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-04 18:00:24,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:24,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:24,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:24,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:24,315:INFO:Preparing preprocessing pipeline...
2025-12-04 18:00:24,317:INFO:Set up simple imputation.
2025-12-04 18:00:24,319:INFO:Set up imbalanced handling.
2025-12-04 18:00:24,320:INFO:Set up column name cleaning.
2025-12-04 18:00:24,411:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] O sistema no pode encontrar o arquivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-12-04 18:00:24,487:INFO:Finished creating preprocessing pipeline.
2025-12-04 18:00:24,504:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'selling_price',
                                             'km_driven', 'mileage', 'engine',
                                             'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Sec...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-04 18:00:24,504:INFO:Creating final display dataframe.
2025-12-04 18:00:24,953:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 17)
4        Transformed data shape           (11982, 17)
5   Transformed train set shape            (9610, 17)
6    Transformed test set shape            (2372, 17)
7              Numeric features                    16
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                Fix imbalance                  True
13         Fix imbalance method                 SMOTE
14               Fold Generator       StratifiedKFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment                 False
19              Experiment Name      clf-default-name
20                          USI                  b0bf
2025-12-04 18:00:25,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:25,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:25,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:25,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 18:00:25,338:INFO:setup() successfully completed in 2.25s...............
2025-12-04 18:00:25,339:INFO:Initializing compare_models()
2025-12-04 18:00:25,339:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-04 18:00:25,339:INFO:Checking exceptions
2025-12-04 18:00:25,350:INFO:Preparing display monitor
2025-12-04 18:00:25,415:INFO:Initializing Logistic Regression
2025-12-04 18:00:25,415:INFO:Total runtime is 0.0 minutes
2025-12-04 18:00:25,425:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:25,427:INFO:Initializing create_model()
2025-12-04 18:00:25,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:25,428:INFO:Checking exceptions
2025-12-04 18:00:25,428:INFO:Importing libraries
2025-12-04 18:00:25,428:INFO:Copying training dataset
2025-12-04 18:00:25,451:INFO:Defining folds
2025-12-04 18:00:25,451:INFO:Declaring metric variables
2025-12-04 18:00:25,462:INFO:Importing untrained model
2025-12-04 18:00:25,470:INFO:Logistic Regression Imported successfully
2025-12-04 18:00:25,517:INFO:Starting cross validation
2025-12-04 18:00:25,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:27,113:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-04 18:00:27,160:INFO:Calculating mean and std
2025-12-04 18:00:27,163:INFO:Creating metrics dataframe
2025-12-04 18:00:27,168:INFO:Uploading results into container
2025-12-04 18:00:27,168:INFO:Uploading model into container now
2025-12-04 18:00:27,171:INFO:_master_model_container: 1
2025-12-04 18:00:27,171:INFO:_display_container: 2
2025-12-04 18:00:27,172:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 18:00:27,172:INFO:create_model() successfully completed......................................
2025-12-04 18:00:27,327:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:27,327:INFO:Creating metrics dataframe
2025-12-04 18:00:27,342:INFO:Initializing K Neighbors Classifier
2025-12-04 18:00:27,344:INFO:Total runtime is 0.032152275244394936 minutes
2025-12-04 18:00:27,353:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:27,354:INFO:Initializing create_model()
2025-12-04 18:00:27,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:27,354:INFO:Checking exceptions
2025-12-04 18:00:27,354:INFO:Importing libraries
2025-12-04 18:00:27,354:INFO:Copying training dataset
2025-12-04 18:00:27,379:INFO:Defining folds
2025-12-04 18:00:27,379:INFO:Declaring metric variables
2025-12-04 18:00:27,391:INFO:Importing untrained model
2025-12-04 18:00:27,400:INFO:K Neighbors Classifier Imported successfully
2025-12-04 18:00:27,418:INFO:Starting cross validation
2025-12-04 18:00:27,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:27,921:INFO:Calculating mean and std
2025-12-04 18:00:27,923:INFO:Creating metrics dataframe
2025-12-04 18:00:27,928:INFO:Uploading results into container
2025-12-04 18:00:27,930:INFO:Uploading model into container now
2025-12-04 18:00:27,930:INFO:_master_model_container: 2
2025-12-04 18:00:27,930:INFO:_display_container: 2
2025-12-04 18:00:27,933:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-04 18:00:27,933:INFO:create_model() successfully completed......................................
2025-12-04 18:00:28,074:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:28,074:INFO:Creating metrics dataframe
2025-12-04 18:00:28,092:INFO:Initializing Naive Bayes
2025-12-04 18:00:28,092:INFO:Total runtime is 0.0446089506149292 minutes
2025-12-04 18:00:28,099:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:28,101:INFO:Initializing create_model()
2025-12-04 18:00:28,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:28,102:INFO:Checking exceptions
2025-12-04 18:00:28,102:INFO:Importing libraries
2025-12-04 18:00:28,102:INFO:Copying training dataset
2025-12-04 18:00:28,118:INFO:Defining folds
2025-12-04 18:00:28,118:INFO:Declaring metric variables
2025-12-04 18:00:28,128:INFO:Importing untrained model
2025-12-04 18:00:28,139:INFO:Naive Bayes Imported successfully
2025-12-04 18:00:28,158:INFO:Starting cross validation
2025-12-04 18:00:28,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:28,429:INFO:Calculating mean and std
2025-12-04 18:00:28,432:INFO:Creating metrics dataframe
2025-12-04 18:00:28,435:INFO:Uploading results into container
2025-12-04 18:00:28,435:INFO:Uploading model into container now
2025-12-04 18:00:28,437:INFO:_master_model_container: 3
2025-12-04 18:00:28,437:INFO:_display_container: 2
2025-12-04 18:00:28,439:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-04 18:00:28,439:INFO:create_model() successfully completed......................................
2025-12-04 18:00:28,580:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:28,582:INFO:Creating metrics dataframe
2025-12-04 18:00:28,599:INFO:Initializing Decision Tree Classifier
2025-12-04 18:00:28,599:INFO:Total runtime is 0.05305941502253214 minutes
2025-12-04 18:00:28,607:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:28,609:INFO:Initializing create_model()
2025-12-04 18:00:28,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:28,609:INFO:Checking exceptions
2025-12-04 18:00:28,609:INFO:Importing libraries
2025-12-04 18:00:28,610:INFO:Copying training dataset
2025-12-04 18:00:28,628:INFO:Defining folds
2025-12-04 18:00:28,628:INFO:Declaring metric variables
2025-12-04 18:00:28,638:INFO:Importing untrained model
2025-12-04 18:00:28,647:INFO:Decision Tree Classifier Imported successfully
2025-12-04 18:00:28,666:INFO:Starting cross validation
2025-12-04 18:00:28,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:28,970:INFO:Calculating mean and std
2025-12-04 18:00:28,974:INFO:Creating metrics dataframe
2025-12-04 18:00:28,978:INFO:Uploading results into container
2025-12-04 18:00:28,979:INFO:Uploading model into container now
2025-12-04 18:00:28,980:INFO:_master_model_container: 4
2025-12-04 18:00:28,980:INFO:_display_container: 2
2025-12-04 18:00:28,981:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-04 18:00:28,981:INFO:create_model() successfully completed......................................
2025-12-04 18:00:29,127:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:29,128:INFO:Creating metrics dataframe
2025-12-04 18:00:29,146:INFO:Initializing SVM - Linear Kernel
2025-12-04 18:00:29,146:INFO:Total runtime is 0.06218229929606119 minutes
2025-12-04 18:00:29,155:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:29,156:INFO:Initializing create_model()
2025-12-04 18:00:29,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:29,157:INFO:Checking exceptions
2025-12-04 18:00:29,158:INFO:Importing libraries
2025-12-04 18:00:29,158:INFO:Copying training dataset
2025-12-04 18:00:29,184:INFO:Defining folds
2025-12-04 18:00:29,184:INFO:Declaring metric variables
2025-12-04 18:00:29,195:INFO:Importing untrained model
2025-12-04 18:00:29,204:INFO:SVM - Linear Kernel Imported successfully
2025-12-04 18:00:29,224:INFO:Starting cross validation
2025-12-04 18:00:29,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:29,704:INFO:Calculating mean and std
2025-12-04 18:00:29,706:INFO:Creating metrics dataframe
2025-12-04 18:00:29,710:INFO:Uploading results into container
2025-12-04 18:00:29,713:INFO:Uploading model into container now
2025-12-04 18:00:29,714:INFO:_master_model_container: 5
2025-12-04 18:00:29,714:INFO:_display_container: 2
2025-12-04 18:00:29,716:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-04 18:00:29,717:INFO:create_model() successfully completed......................................
2025-12-04 18:00:29,856:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:29,857:INFO:Creating metrics dataframe
2025-12-04 18:00:29,876:INFO:Initializing Ridge Classifier
2025-12-04 18:00:29,876:INFO:Total runtime is 0.07435563802719115 minutes
2025-12-04 18:00:29,885:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:29,886:INFO:Initializing create_model()
2025-12-04 18:00:29,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:29,886:INFO:Checking exceptions
2025-12-04 18:00:29,886:INFO:Importing libraries
2025-12-04 18:00:29,886:INFO:Copying training dataset
2025-12-04 18:00:29,905:INFO:Defining folds
2025-12-04 18:00:29,907:INFO:Declaring metric variables
2025-12-04 18:00:29,918:INFO:Importing untrained model
2025-12-04 18:00:29,927:INFO:Ridge Classifier Imported successfully
2025-12-04 18:00:29,945:INFO:Starting cross validation
2025-12-04 18:00:29,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:30,098:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.07985e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,103:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97415e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,112:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.12855e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,114:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.22879e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,117:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.76553e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,119:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.25459e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,122:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97653e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,134:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.18612e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,137:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.84536e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,139:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.27127e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-04 18:00:30,208:INFO:Calculating mean and std
2025-12-04 18:00:30,210:INFO:Creating metrics dataframe
2025-12-04 18:00:30,215:INFO:Uploading results into container
2025-12-04 18:00:30,216:INFO:Uploading model into container now
2025-12-04 18:00:30,217:INFO:_master_model_container: 6
2025-12-04 18:00:30,219:INFO:_display_container: 2
2025-12-04 18:00:30,219:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-04 18:00:30,219:INFO:create_model() successfully completed......................................
2025-12-04 18:00:30,360:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:30,360:INFO:Creating metrics dataframe
2025-12-04 18:00:30,378:INFO:Initializing Random Forest Classifier
2025-12-04 18:00:30,378:INFO:Total runtime is 0.08271174430847167 minutes
2025-12-04 18:00:30,387:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:30,387:INFO:Initializing create_model()
2025-12-04 18:00:30,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:30,388:INFO:Checking exceptions
2025-12-04 18:00:30,388:INFO:Importing libraries
2025-12-04 18:00:30,388:INFO:Copying training dataset
2025-12-04 18:00:30,408:INFO:Defining folds
2025-12-04 18:00:30,409:INFO:Declaring metric variables
2025-12-04 18:00:30,419:INFO:Importing untrained model
2025-12-04 18:00:30,429:INFO:Random Forest Classifier Imported successfully
2025-12-04 18:00:30,448:INFO:Starting cross validation
2025-12-04 18:00:30,449:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:32,721:INFO:Calculating mean and std
2025-12-04 18:00:32,725:INFO:Creating metrics dataframe
2025-12-04 18:00:32,728:INFO:Uploading results into container
2025-12-04 18:00:32,730:INFO:Uploading model into container now
2025-12-04 18:00:32,732:INFO:_master_model_container: 7
2025-12-04 18:00:32,732:INFO:_display_container: 2
2025-12-04 18:00:32,733:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-04 18:00:32,733:INFO:create_model() successfully completed......................................
2025-12-04 18:00:32,885:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:32,886:INFO:Creating metrics dataframe
2025-12-04 18:00:32,907:INFO:Initializing Quadratic Discriminant Analysis
2025-12-04 18:00:32,908:INFO:Total runtime is 0.1248895009358724 minutes
2025-12-04 18:00:32,917:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:32,917:INFO:Initializing create_model()
2025-12-04 18:00:32,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:32,918:INFO:Checking exceptions
2025-12-04 18:00:32,918:INFO:Importing libraries
2025-12-04 18:00:32,919:INFO:Copying training dataset
2025-12-04 18:00:32,952:INFO:Defining folds
2025-12-04 18:00:32,952:INFO:Declaring metric variables
2025-12-04 18:00:32,973:INFO:Importing untrained model
2025-12-04 18:00:32,989:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-04 18:00:33,012:INFO:Starting cross validation
2025-12-04 18:00:33,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:33,176:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,176:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,188:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,188:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,189:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,199:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,199:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,201:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,201:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,207:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,207:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,207:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,207:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,210:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,210:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,214:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,215:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,216:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,216:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,217:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,217:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 18:00:33,218:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,218:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,220:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,225:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,228:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,229:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,229:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,231:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,231:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,232:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,238:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,239:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,240:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,240:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,240:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,240:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,241:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,241:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,242:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,242:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,242:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,242:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,243:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,243:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,248:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,248:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,248:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-04 18:00:33,251:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,258:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,259:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,259:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,266:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,267:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,267:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,269:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,272:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-04 18:00:33,278:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,287:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,287:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,291:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,291:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:33,319:INFO:Calculating mean and std
2025-12-04 18:00:33,322:INFO:Creating metrics dataframe
2025-12-04 18:00:33,327:INFO:Uploading results into container
2025-12-04 18:00:33,328:INFO:Uploading model into container now
2025-12-04 18:00:33,329:INFO:_master_model_container: 8
2025-12-04 18:00:33,329:INFO:_display_container: 2
2025-12-04 18:00:33,330:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-04 18:00:33,330:INFO:create_model() successfully completed......................................
2025-12-04 18:00:33,476:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:33,476:INFO:Creating metrics dataframe
2025-12-04 18:00:33,497:INFO:Initializing Ada Boost Classifier
2025-12-04 18:00:33,498:INFO:Total runtime is 0.13471340735753376 minutes
2025-12-04 18:00:33,506:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:33,507:INFO:Initializing create_model()
2025-12-04 18:00:33,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:33,507:INFO:Checking exceptions
2025-12-04 18:00:33,507:INFO:Importing libraries
2025-12-04 18:00:33,508:INFO:Copying training dataset
2025-12-04 18:00:33,528:INFO:Defining folds
2025-12-04 18:00:33,528:INFO:Declaring metric variables
2025-12-04 18:00:33,539:INFO:Importing untrained model
2025-12-04 18:00:33,550:INFO:Ada Boost Classifier Imported successfully
2025-12-04 18:00:33,571:INFO:Starting cross validation
2025-12-04 18:00:33,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:33,728:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,734:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,736:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,737:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,741:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,747:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,754:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,761:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,768:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:33,769:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-04 18:00:34,907:INFO:Calculating mean and std
2025-12-04 18:00:34,910:INFO:Creating metrics dataframe
2025-12-04 18:00:34,914:INFO:Uploading results into container
2025-12-04 18:00:34,916:INFO:Uploading model into container now
2025-12-04 18:00:34,917:INFO:_master_model_container: 9
2025-12-04 18:00:34,917:INFO:_display_container: 2
2025-12-04 18:00:34,917:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-04 18:00:34,917:INFO:create_model() successfully completed......................................
2025-12-04 18:00:35,064:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:35,066:INFO:Creating metrics dataframe
2025-12-04 18:00:35,087:INFO:Initializing Gradient Boosting Classifier
2025-12-04 18:00:35,087:INFO:Total runtime is 0.16120522022247313 minutes
2025-12-04 18:00:35,099:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:35,100:INFO:Initializing create_model()
2025-12-04 18:00:35,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:35,100:INFO:Checking exceptions
2025-12-04 18:00:35,100:INFO:Importing libraries
2025-12-04 18:00:35,101:INFO:Copying training dataset
2025-12-04 18:00:35,120:INFO:Defining folds
2025-12-04 18:00:35,120:INFO:Declaring metric variables
2025-12-04 18:00:35,131:INFO:Importing untrained model
2025-12-04 18:00:35,140:INFO:Gradient Boosting Classifier Imported successfully
2025-12-04 18:00:35,162:INFO:Starting cross validation
2025-12-04 18:00:35,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:38,623:INFO:Calculating mean and std
2025-12-04 18:00:38,626:INFO:Creating metrics dataframe
2025-12-04 18:00:38,630:INFO:Uploading results into container
2025-12-04 18:00:38,631:INFO:Uploading model into container now
2025-12-04 18:00:38,632:INFO:_master_model_container: 10
2025-12-04 18:00:38,632:INFO:_display_container: 2
2025-12-04 18:00:38,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-04 18:00:38,635:INFO:create_model() successfully completed......................................
2025-12-04 18:00:38,781:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:38,781:INFO:Creating metrics dataframe
2025-12-04 18:00:38,802:INFO:Initializing Linear Discriminant Analysis
2025-12-04 18:00:38,802:INFO:Total runtime is 0.22311723232269287 minutes
2025-12-04 18:00:38,813:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:38,814:INFO:Initializing create_model()
2025-12-04 18:00:38,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:38,814:INFO:Checking exceptions
2025-12-04 18:00:38,814:INFO:Importing libraries
2025-12-04 18:00:38,814:INFO:Copying training dataset
2025-12-04 18:00:38,832:INFO:Defining folds
2025-12-04 18:00:38,832:INFO:Declaring metric variables
2025-12-04 18:00:38,841:INFO:Importing untrained model
2025-12-04 18:00:38,852:INFO:Linear Discriminant Analysis Imported successfully
2025-12-04 18:00:38,870:INFO:Starting cross validation
2025-12-04 18:00:38,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:39,161:INFO:Calculating mean and std
2025-12-04 18:00:39,163:INFO:Creating metrics dataframe
2025-12-04 18:00:39,166:INFO:Uploading results into container
2025-12-04 18:00:39,168:INFO:Uploading model into container now
2025-12-04 18:00:39,170:INFO:_master_model_container: 11
2025-12-04 18:00:39,170:INFO:_display_container: 2
2025-12-04 18:00:39,170:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-04 18:00:39,170:INFO:create_model() successfully completed......................................
2025-12-04 18:00:39,322:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:39,322:INFO:Creating metrics dataframe
2025-12-04 18:00:39,349:INFO:Initializing Extra Trees Classifier
2025-12-04 18:00:39,349:INFO:Total runtime is 0.23224108219146727 minutes
2025-12-04 18:00:39,358:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:39,360:INFO:Initializing create_model()
2025-12-04 18:00:39,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:39,360:INFO:Checking exceptions
2025-12-04 18:00:39,360:INFO:Importing libraries
2025-12-04 18:00:39,360:INFO:Copying training dataset
2025-12-04 18:00:39,378:INFO:Defining folds
2025-12-04 18:00:39,378:INFO:Declaring metric variables
2025-12-04 18:00:39,389:INFO:Importing untrained model
2025-12-04 18:00:39,399:INFO:Extra Trees Classifier Imported successfully
2025-12-04 18:00:39,418:INFO:Starting cross validation
2025-12-04 18:00:39,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:41,260:INFO:Calculating mean and std
2025-12-04 18:00:41,262:INFO:Creating metrics dataframe
2025-12-04 18:00:41,267:INFO:Uploading results into container
2025-12-04 18:00:41,269:INFO:Uploading model into container now
2025-12-04 18:00:41,269:INFO:_master_model_container: 12
2025-12-04 18:00:41,269:INFO:_display_container: 2
2025-12-04 18:00:41,271:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-04 18:00:41,272:INFO:create_model() successfully completed......................................
2025-12-04 18:00:41,461:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:41,461:INFO:Creating metrics dataframe
2025-12-04 18:00:41,486:INFO:Initializing Light Gradient Boosting Machine
2025-12-04 18:00:41,486:INFO:Total runtime is 0.26784232060114543 minutes
2025-12-04 18:00:41,497:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:41,498:INFO:Initializing create_model()
2025-12-04 18:00:41,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:41,499:INFO:Checking exceptions
2025-12-04 18:00:41,499:INFO:Importing libraries
2025-12-04 18:00:41,499:INFO:Copying training dataset
2025-12-04 18:00:41,518:INFO:Defining folds
2025-12-04 18:00:41,519:INFO:Declaring metric variables
2025-12-04 18:00:41,530:INFO:Importing untrained model
2025-12-04 18:00:41,540:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 18:00:41,558:INFO:Starting cross validation
2025-12-04 18:00:41,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:44,405:INFO:Calculating mean and std
2025-12-04 18:00:44,410:INFO:Creating metrics dataframe
2025-12-04 18:00:44,415:INFO:Uploading results into container
2025-12-04 18:00:44,416:INFO:Uploading model into container now
2025-12-04 18:00:44,418:INFO:_master_model_container: 13
2025-12-04 18:00:44,418:INFO:_display_container: 2
2025-12-04 18:00:44,420:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 18:00:44,420:INFO:create_model() successfully completed......................................
2025-12-04 18:00:44,601:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:44,601:INFO:Creating metrics dataframe
2025-12-04 18:00:44,627:INFO:Initializing Dummy Classifier
2025-12-04 18:00:44,627:INFO:Total runtime is 0.3201991637547811 minutes
2025-12-04 18:00:44,636:INFO:SubProcess create_model() called ==================================
2025-12-04 18:00:44,637:INFO:Initializing create_model()
2025-12-04 18:00:44,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022812959FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:44,637:INFO:Checking exceptions
2025-12-04 18:00:44,637:INFO:Importing libraries
2025-12-04 18:00:44,637:INFO:Copying training dataset
2025-12-04 18:00:44,659:INFO:Defining folds
2025-12-04 18:00:44,659:INFO:Declaring metric variables
2025-12-04 18:00:44,671:INFO:Importing untrained model
2025-12-04 18:00:44,684:INFO:Dummy Classifier Imported successfully
2025-12-04 18:00:44,703:INFO:Starting cross validation
2025-12-04 18:00:44,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:00:44,902:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,909:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,916:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,918:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,930:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,932:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,937:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,938:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,945:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,948:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-04 18:00:44,969:INFO:Calculating mean and std
2025-12-04 18:00:44,972:INFO:Creating metrics dataframe
2025-12-04 18:00:44,978:INFO:Uploading results into container
2025-12-04 18:00:44,980:INFO:Uploading model into container now
2025-12-04 18:00:44,981:INFO:_master_model_container: 14
2025-12-04 18:00:44,981:INFO:_display_container: 2
2025-12-04 18:00:44,983:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-04 18:00:44,983:INFO:create_model() successfully completed......................................
2025-12-04 18:00:45,143:INFO:SubProcess create_model() end ==================================
2025-12-04 18:00:45,144:INFO:Creating metrics dataframe
2025-12-04 18:00:45,173:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-04 18:00:45,196:INFO:Initializing create_model()
2025-12-04 18:00:45,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:00:45,196:INFO:Checking exceptions
2025-12-04 18:00:45,200:INFO:Importing libraries
2025-12-04 18:00:45,202:INFO:Copying training dataset
2025-12-04 18:00:45,220:INFO:Defining folds
2025-12-04 18:00:45,221:INFO:Declaring metric variables
2025-12-04 18:00:45,221:INFO:Importing untrained model
2025-12-04 18:00:45,221:INFO:Declaring custom model
2025-12-04 18:00:45,222:INFO:Logistic Regression Imported successfully
2025-12-04 18:00:45,225:INFO:Cross validation set to False
2025-12-04 18:00:45,225:INFO:Fitting Model
2025-12-04 18:00:46,956:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 18:00:46,957:INFO:create_model() successfully completed......................................
2025-12-04 18:00:47,179:INFO:_master_model_container: 14
2025-12-04 18:00:47,180:INFO:_display_container: 2
2025-12-04 18:00:47,180:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 18:00:47,180:INFO:compare_models() successfully completed......................................
2025-12-04 18:00:47,183:INFO:Initializing tune_model()
2025-12-04 18:00:47,183:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>)
2025-12-04 18:00:47,184:INFO:Checking exceptions
2025-12-04 18:00:47,240:INFO:Copying training dataset
2025-12-04 18:00:47,254:INFO:Checking base model
2025-12-04 18:00:47,254:INFO:Base model : Logistic Regression
2025-12-04 18:00:47,265:INFO:Declaring metric variables
2025-12-04 18:00:47,277:INFO:Defining Hyperparameters
2025-12-04 18:00:47,482:INFO:Tuning with n_jobs=-1
2025-12-04 18:00:47,483:INFO:Initializing RandomizedSearchCV
2025-12-04 18:00:52,125:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-04 18:00:52,799:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-04 18:00:59,371:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-04 18:01:00,051:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-04 18:01:00,154:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-04 18:01:00,155:INFO:Hyperparameter search completed
2025-12-04 18:01:00,157:INFO:SubProcess create_model() called ==================================
2025-12-04 18:01:00,159:INFO:Initializing create_model()
2025-12-04 18:01:00,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228126D4460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-04 18:01:00,160:INFO:Checking exceptions
2025-12-04 18:01:00,160:INFO:Importing libraries
2025-12-04 18:01:00,160:INFO:Copying training dataset
2025-12-04 18:01:00,180:INFO:Defining folds
2025-12-04 18:01:00,180:INFO:Declaring metric variables
2025-12-04 18:01:00,188:INFO:Importing untrained model
2025-12-04 18:01:00,188:INFO:Declaring custom model
2025-12-04 18:01:00,199:INFO:Logistic Regression Imported successfully
2025-12-04 18:01:00,218:INFO:Starting cross validation
2025-12-04 18:01:00,222:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:01:02,176:INFO:Calculating mean and std
2025-12-04 18:01:02,179:INFO:Creating metrics dataframe
2025-12-04 18:01:02,192:INFO:Finalizing model
2025-12-04 18:01:04,508:INFO:Uploading results into container
2025-12-04 18:01:04,511:INFO:Uploading model into container now
2025-12-04 18:01:04,512:INFO:_master_model_container: 15
2025-12-04 18:01:04,513:INFO:_display_container: 3
2025-12-04 18:01:04,513:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 18:01:04,514:INFO:create_model() successfully completed......................................
2025-12-04 18:01:04,663:INFO:SubProcess create_model() end ==================================
2025-12-04 18:01:04,663:INFO:choose_better activated
2025-12-04 18:01:04,672:INFO:SubProcess create_model() called ==================================
2025-12-04 18:01:04,674:INFO:Initializing create_model()
2025-12-04 18:01:04,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002287F908BB0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 18:01:04,675:INFO:Checking exceptions
2025-12-04 18:01:04,680:INFO:Importing libraries
2025-12-04 18:01:04,680:INFO:Copying training dataset
2025-12-04 18:01:04,699:INFO:Defining folds
2025-12-04 18:01:04,699:INFO:Declaring metric variables
2025-12-04 18:01:04,700:INFO:Importing untrained model
2025-12-04 18:01:04,700:INFO:Declaring custom model
2025-12-04 18:01:04,702:INFO:Logistic Regression Imported successfully
2025-12-04 18:01:04,702:INFO:Starting cross validation
2025-12-04 18:01:04,703:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 18:01:06,389:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-04 18:01:06,434:INFO:Calculating mean and std
2025-12-04 18:01:06,435:INFO:Creating metrics dataframe
2025-12-04 18:01:06,439:INFO:Finalizing model
2025-12-04 18:01:08,006:INFO:Uploading results into container
2025-12-04 18:01:08,006:INFO:Uploading model into container now
2025-12-04 18:01:08,008:INFO:_master_model_container: 16
2025-12-04 18:01:08,009:INFO:_display_container: 4
2025-12-04 18:01:08,009:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 18:01:08,009:INFO:create_model() successfully completed......................................
2025-12-04 18:01:08,158:INFO:SubProcess create_model() end ==================================
2025-12-04 18:01:08,160:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-04 18:01:08,161:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-04 18:01:08,162:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-04 18:01:08,162:INFO:choose_better completed
2025-12-04 18:01:08,162:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-04 18:01:08,192:INFO:_master_model_container: 16
2025-12-04 18:01:08,193:INFO:_display_container: 3
2025-12-04 18:01:08,195:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 18:01:08,195:INFO:tune_model() successfully completed......................................
2025-12-08 15:08:54,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-08 15:08:54,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-08 15:08:54,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-08 15:08:54,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-08 15:08:55,492:INFO:PyCaret RegressionExperiment
2025-12-08 15:08:55,492:INFO:Logging name: reg-default-name
2025-12-08 15:08:55,492:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-08 15:08:55,492:INFO:version 3.3.2
2025-12-08 15:08:55,492:INFO:Initializing setup()
2025-12-08 15:08:55,492:INFO:self.USI: 34ae
2025-12-08 15:08:55,492:INFO:self._variable_keys: {'X', 'X_test', 'exp_name_log', 'USI', 'idx', 'fold_generator', 'fold_groups_param', 'memory', 'gpu_n_jobs_param', '_ml_usecase', 'n_jobs_param', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'y', '_available_plots', 'y_test', 'transform_target_param', 'data', 'gpu_param', 'logging_param', 'X_train', 'target_param', 'seed', 'pipeline', 'exp_id'}
2025-12-08 15:08:55,492:INFO:Checking environment
2025-12-08 15:08:55,492:INFO:python_version: 3.10.19
2025-12-08 15:08:55,492:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-08 15:08:55,492:INFO:machine: AMD64
2025-12-08 15:08:55,492:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-08 15:08:55,494:INFO:Memory: svmem(total=33699516416, available=16767791104, percent=50.2, used=16931725312, free=16767791104)
2025-12-08 15:08:55,494:INFO:Physical Core: 8
2025-12-08 15:08:55,494:INFO:Logical Core: 16
2025-12-08 15:08:55,494:INFO:Checking libraries
2025-12-08 15:08:55,494:INFO:System:
2025-12-08 15:08:55,494:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-08 15:08:55,494:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-08 15:08:55,494:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-08 15:08:55,494:INFO:PyCaret required dependencies:
2025-12-08 15:08:55,498:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:08:55,588:INFO:                 pip: 25.3
2025-12-08 15:08:55,588:INFO:          setuptools: 80.9.0
2025-12-08 15:08:55,590:INFO:             pycaret: 3.3.2
2025-12-08 15:08:55,590:INFO:             IPython: 8.37.0
2025-12-08 15:08:55,590:INFO:          ipywidgets: 8.1.8
2025-12-08 15:08:55,590:INFO:                tqdm: 4.67.1
2025-12-08 15:08:55,590:INFO:               numpy: 1.26.4
2025-12-08 15:08:55,590:INFO:              pandas: 2.1.4
2025-12-08 15:08:55,590:INFO:              jinja2: 3.1.6
2025-12-08 15:08:55,590:INFO:               scipy: 1.11.4
2025-12-08 15:08:55,590:INFO:              joblib: 1.3.2
2025-12-08 15:08:55,590:INFO:             sklearn: 1.4.2
2025-12-08 15:08:55,590:INFO:                pyod: 2.0.6
2025-12-08 15:08:55,590:INFO:            imblearn: 0.14.0
2025-12-08 15:08:55,590:INFO:   category_encoders: 2.7.0
2025-12-08 15:08:55,590:INFO:            lightgbm: 4.6.0
2025-12-08 15:08:55,590:INFO:               numba: 0.62.1
2025-12-08 15:08:55,590:INFO:            requests: 2.32.5
2025-12-08 15:08:55,590:INFO:          matplotlib: 3.7.5
2025-12-08 15:08:55,591:INFO:          scikitplot: 0.3.7
2025-12-08 15:08:55,591:INFO:         yellowbrick: 1.5
2025-12-08 15:08:55,591:INFO:              plotly: 6.5.0
2025-12-08 15:08:55,591:INFO:    plotly-resampler: Not installed
2025-12-08 15:08:55,591:INFO:             kaleido: 1.2.0
2025-12-08 15:08:55,591:INFO:           schemdraw: 0.15
2025-12-08 15:08:55,591:INFO:         statsmodels: 0.14.5
2025-12-08 15:08:55,591:INFO:              sktime: 0.26.0
2025-12-08 15:08:55,591:INFO:               tbats: 1.1.3
2025-12-08 15:08:55,591:INFO:            pmdarima: 2.0.4
2025-12-08 15:08:55,591:INFO:              psutil: 7.1.3
2025-12-08 15:08:55,591:INFO:          markupsafe: 3.0.3
2025-12-08 15:08:55,591:INFO:             pickle5: Not installed
2025-12-08 15:08:55,593:INFO:         cloudpickle: 3.1.2
2025-12-08 15:08:55,593:INFO:         deprecation: 2.1.0
2025-12-08 15:08:55,593:INFO:              xxhash: 3.6.0
2025-12-08 15:08:55,593:INFO:           wurlitzer: Not installed
2025-12-08 15:08:55,593:INFO:PyCaret optional dependencies:
2025-12-08 15:08:55,618:INFO:                shap: Not installed
2025-12-08 15:08:55,618:INFO:           interpret: Not installed
2025-12-08 15:08:55,618:INFO:                umap: Not installed
2025-12-08 15:08:55,618:INFO:     ydata_profiling: Not installed
2025-12-08 15:08:55,618:INFO:  explainerdashboard: Not installed
2025-12-08 15:08:55,618:INFO:             autoviz: Not installed
2025-12-08 15:08:55,618:INFO:           fairlearn: Not installed
2025-12-08 15:08:55,618:INFO:          deepchecks: Not installed
2025-12-08 15:08:55,618:INFO:             xgboost: Not installed
2025-12-08 15:08:55,618:INFO:            catboost: Not installed
2025-12-08 15:08:55,618:INFO:              kmodes: Not installed
2025-12-08 15:08:55,618:INFO:             mlxtend: Not installed
2025-12-08 15:08:55,618:INFO:       statsforecast: Not installed
2025-12-08 15:08:55,618:INFO:        tune_sklearn: Not installed
2025-12-08 15:08:55,618:INFO:                 ray: Not installed
2025-12-08 15:08:55,618:INFO:            hyperopt: Not installed
2025-12-08 15:08:55,618:INFO:              optuna: Not installed
2025-12-08 15:08:55,618:INFO:               skopt: Not installed
2025-12-08 15:08:55,618:INFO:              mlflow: Not installed
2025-12-08 15:08:55,618:INFO:              gradio: Not installed
2025-12-08 15:08:55,618:INFO:             fastapi: Not installed
2025-12-08 15:08:55,618:INFO:             uvicorn: Not installed
2025-12-08 15:08:55,618:INFO:              m2cgen: Not installed
2025-12-08 15:08:55,618:INFO:           evidently: Not installed
2025-12-08 15:08:55,618:INFO:               fugue: Not installed
2025-12-08 15:08:55,618:INFO:           streamlit: Not installed
2025-12-08 15:08:55,618:INFO:             prophet: Not installed
2025-12-08 15:08:55,618:INFO:None
2025-12-08 15:08:55,618:INFO:Set up data.
2025-12-08 15:08:55,636:INFO:Set up folding strategy.
2025-12-08 15:08:55,636:INFO:Set up train/test split.
2025-12-08 15:08:55,653:INFO:Set up index.
2025-12-08 15:08:55,653:INFO:Assigning column types.
2025-12-08 15:08:55,672:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-08 15:08:55,672:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-08 15:08:55,684:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 15:08:55,697:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:08:55,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:55,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:08:55,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:55,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:55,963:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-08 15:08:55,987:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,268:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:56,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:56,268:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-08 15:08:56,288:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:56,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:56,588:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,601:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,754:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:08:56,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:56,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:56,900:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-08 15:08:56,923:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:08:57,068:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:57,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:08:57,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:57,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:57,208:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:08:57,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:57,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:08:57,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:57,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:57,488:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-08 15:08:57,672:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:57,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:08:57,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:57,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:57,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:58,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:08:58,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:58,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:58,109:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-08 15:08:58,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:58,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:58,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:58,598:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:08:58,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:58,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:58,709:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-08 15:08:59,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:59,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:59,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:59,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:08:59,315:INFO:Preparing preprocessing pipeline...
2025-12-08 15:08:59,315:INFO:Set up simple imputation.
2025-12-08 15:08:59,315:INFO:Set up feature normalization.
2025-12-08 15:08:59,315:INFO:Set up column name cleaning.
2025-12-08 15:08:59,472:INFO:Finished creating preprocessing pipeline.
2025-12-08 15:08:59,552:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'transmission_encoded',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner_Test Drive Car',
                                             'owner_Third Owner'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-12-08 15:08:59,552:INFO:Creating final display dataframe.
2025-12-08 15:08:59,903:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 17)
4        Transformed data shape        (7906, 17)
5   Transformed train set shape        (5534, 17)
6    Transformed test set shape        (2372, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              34ae
2025-12-08 15:09:00,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:09:00,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:09:00,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:09:00,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:09:00,519:INFO:setup() successfully completed in 5.03s...............
2025-12-08 15:09:00,519:INFO:Initializing compare_models()
2025-12-08 15:09:00,519:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-08 15:09:00,519:INFO:Checking exceptions
2025-12-08 15:09:00,525:INFO:Preparing display monitor
2025-12-08 15:09:00,607:INFO:Initializing Linear Regression
2025-12-08 15:09:00,608:INFO:Total runtime is 1.9601980845133464e-05 minutes
2025-12-08 15:09:00,616:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:00,616:INFO:Initializing create_model()
2025-12-08 15:09:00,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:00,616:INFO:Checking exceptions
2025-12-08 15:09:00,616:INFO:Importing libraries
2025-12-08 15:09:00,616:INFO:Copying training dataset
2025-12-08 15:09:00,637:INFO:Defining folds
2025-12-08 15:09:00,639:INFO:Declaring metric variables
2025-12-08 15:09:00,649:INFO:Importing untrained model
2025-12-08 15:09:00,661:INFO:Linear Regression Imported successfully
2025-12-08 15:09:00,682:INFO:Starting cross validation
2025-12-08 15:09:00,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:09,891:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,900:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,902:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,916:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,928:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,947:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,950:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,963:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,967:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:09,969:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:10,549:INFO:Calculating mean and std
2025-12-08 15:09:10,552:INFO:Creating metrics dataframe
2025-12-08 15:09:10,563:INFO:Uploading results into container
2025-12-08 15:09:10,566:INFO:Uploading model into container now
2025-12-08 15:09:10,567:INFO:_master_model_container: 1
2025-12-08 15:09:10,567:INFO:_display_container: 2
2025-12-08 15:09:10,570:INFO:LinearRegression(n_jobs=-1)
2025-12-08 15:09:10,570:INFO:create_model() successfully completed......................................
2025-12-08 15:09:10,766:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:10,769:INFO:Creating metrics dataframe
2025-12-08 15:09:10,783:INFO:Initializing Lasso Regression
2025-12-08 15:09:10,783:INFO:Total runtime is 0.16960038741429648 minutes
2025-12-08 15:09:10,790:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:10,792:INFO:Initializing create_model()
2025-12-08 15:09:10,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:10,792:INFO:Checking exceptions
2025-12-08 15:09:10,792:INFO:Importing libraries
2025-12-08 15:09:10,792:INFO:Copying training dataset
2025-12-08 15:09:10,809:INFO:Defining folds
2025-12-08 15:09:10,809:INFO:Declaring metric variables
2025-12-08 15:09:10,817:INFO:Importing untrained model
2025-12-08 15:09:10,829:INFO:Lasso Regression Imported successfully
2025-12-08 15:09:10,844:INFO:Starting cross validation
2025-12-08 15:09:10,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:17,618:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:17,650:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:17,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:17,708:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:17,758:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:17,770:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:09:18,334:INFO:Calculating mean and std
2025-12-08 15:09:18,337:INFO:Creating metrics dataframe
2025-12-08 15:09:18,343:INFO:Uploading results into container
2025-12-08 15:09:18,346:INFO:Uploading model into container now
2025-12-08 15:09:18,346:INFO:_master_model_container: 2
2025-12-08 15:09:18,348:INFO:_display_container: 2
2025-12-08 15:09:18,349:INFO:Lasso(random_state=123)
2025-12-08 15:09:18,349:INFO:create_model() successfully completed......................................
2025-12-08 15:09:18,475:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:18,475:INFO:Creating metrics dataframe
2025-12-08 15:09:18,491:INFO:Initializing Ridge Regression
2025-12-08 15:09:18,491:INFO:Total runtime is 0.29807706673940026 minutes
2025-12-08 15:09:18,503:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:18,503:INFO:Initializing create_model()
2025-12-08 15:09:18,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:18,503:INFO:Checking exceptions
2025-12-08 15:09:18,503:INFO:Importing libraries
2025-12-08 15:09:18,503:INFO:Copying training dataset
2025-12-08 15:09:18,525:INFO:Defining folds
2025-12-08 15:09:18,525:INFO:Declaring metric variables
2025-12-08 15:09:18,537:INFO:Importing untrained model
2025-12-08 15:09:18,549:INFO:Ridge Regression Imported successfully
2025-12-08 15:09:18,570:INFO:Starting cross validation
2025-12-08 15:09:18,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:18,826:INFO:Calculating mean and std
2025-12-08 15:09:18,826:INFO:Creating metrics dataframe
2025-12-08 15:09:18,833:INFO:Uploading results into container
2025-12-08 15:09:18,834:INFO:Uploading model into container now
2025-12-08 15:09:18,836:INFO:_master_model_container: 3
2025-12-08 15:09:18,836:INFO:_display_container: 2
2025-12-08 15:09:18,837:INFO:Ridge(random_state=123)
2025-12-08 15:09:18,837:INFO:create_model() successfully completed......................................
2025-12-08 15:09:18,961:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:18,961:INFO:Creating metrics dataframe
2025-12-08 15:09:18,979:INFO:Initializing Elastic Net
2025-12-08 15:09:18,980:INFO:Total runtime is 0.30621435642242434 minutes
2025-12-08 15:09:18,989:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:18,989:INFO:Initializing create_model()
2025-12-08 15:09:18,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:18,989:INFO:Checking exceptions
2025-12-08 15:09:18,989:INFO:Importing libraries
2025-12-08 15:09:18,989:INFO:Copying training dataset
2025-12-08 15:09:19,007:INFO:Defining folds
2025-12-08 15:09:19,009:INFO:Declaring metric variables
2025-12-08 15:09:19,020:INFO:Importing untrained model
2025-12-08 15:09:19,026:INFO:Elastic Net Imported successfully
2025-12-08 15:09:19,048:INFO:Starting cross validation
2025-12-08 15:09:19,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:19,302:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+12, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-08 15:09:19,349:INFO:Calculating mean and std
2025-12-08 15:09:19,350:INFO:Creating metrics dataframe
2025-12-08 15:09:19,356:INFO:Uploading results into container
2025-12-08 15:09:19,357:INFO:Uploading model into container now
2025-12-08 15:09:19,360:INFO:_master_model_container: 4
2025-12-08 15:09:19,360:INFO:_display_container: 2
2025-12-08 15:09:19,360:INFO:ElasticNet(random_state=123)
2025-12-08 15:09:19,360:INFO:create_model() successfully completed......................................
2025-12-08 15:09:19,481:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:19,481:INFO:Creating metrics dataframe
2025-12-08 15:09:19,496:INFO:Initializing Least Angle Regression
2025-12-08 15:09:19,496:INFO:Total runtime is 0.31481299002965296 minutes
2025-12-08 15:09:19,508:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:19,509:INFO:Initializing create_model()
2025-12-08 15:09:19,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:19,510:INFO:Checking exceptions
2025-12-08 15:09:19,510:INFO:Importing libraries
2025-12-08 15:09:19,510:INFO:Copying training dataset
2025-12-08 15:09:19,527:INFO:Defining folds
2025-12-08 15:09:19,530:INFO:Declaring metric variables
2025-12-08 15:09:19,539:INFO:Importing untrained model
2025-12-08 15:09:19,550:INFO:Least Angle Regression Imported successfully
2025-12-08 15:09:19,566:INFO:Starting cross validation
2025-12-08 15:09:19,573:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:19,816:INFO:Calculating mean and std
2025-12-08 15:09:19,816:INFO:Creating metrics dataframe
2025-12-08 15:09:19,823:INFO:Uploading results into container
2025-12-08 15:09:19,824:INFO:Uploading model into container now
2025-12-08 15:09:19,824:INFO:_master_model_container: 5
2025-12-08 15:09:19,826:INFO:_display_container: 2
2025-12-08 15:09:19,826:INFO:Lars(random_state=123)
2025-12-08 15:09:19,826:INFO:create_model() successfully completed......................................
2025-12-08 15:09:19,950:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:19,952:INFO:Creating metrics dataframe
2025-12-08 15:09:19,969:INFO:Initializing Lasso Least Angle Regression
2025-12-08 15:09:19,969:INFO:Total runtime is 0.3226963877677918 minutes
2025-12-08 15:09:19,979:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:19,979:INFO:Initializing create_model()
2025-12-08 15:09:19,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:19,979:INFO:Checking exceptions
2025-12-08 15:09:19,979:INFO:Importing libraries
2025-12-08 15:09:19,979:INFO:Copying training dataset
2025-12-08 15:09:20,001:INFO:Defining folds
2025-12-08 15:09:20,001:INFO:Declaring metric variables
2025-12-08 15:09:20,013:INFO:Importing untrained model
2025-12-08 15:09:20,023:INFO:Lasso Least Angle Regression Imported successfully
2025-12-08 15:09:20,041:INFO:Starting cross validation
2025-12-08 15:09:20,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:20,283:INFO:Calculating mean and std
2025-12-08 15:09:20,285:INFO:Creating metrics dataframe
2025-12-08 15:09:20,290:INFO:Uploading results into container
2025-12-08 15:09:20,293:INFO:Uploading model into container now
2025-12-08 15:09:20,293:INFO:_master_model_container: 6
2025-12-08 15:09:20,295:INFO:_display_container: 2
2025-12-08 15:09:20,296:INFO:LassoLars(random_state=123)
2025-12-08 15:09:20,296:INFO:create_model() successfully completed......................................
2025-12-08 15:09:20,416:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:20,418:INFO:Creating metrics dataframe
2025-12-08 15:09:20,435:INFO:Initializing Orthogonal Matching Pursuit
2025-12-08 15:09:20,437:INFO:Total runtime is 0.3304957588513693 minutes
2025-12-08 15:09:20,445:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:20,445:INFO:Initializing create_model()
2025-12-08 15:09:20,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:20,445:INFO:Checking exceptions
2025-12-08 15:09:20,449:INFO:Importing libraries
2025-12-08 15:09:20,449:INFO:Copying training dataset
2025-12-08 15:09:20,471:INFO:Defining folds
2025-12-08 15:09:20,471:INFO:Declaring metric variables
2025-12-08 15:09:20,483:INFO:Importing untrained model
2025-12-08 15:09:20,496:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-08 15:09:20,520:INFO:Starting cross validation
2025-12-08 15:09:20,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:20,760:INFO:Calculating mean and std
2025-12-08 15:09:20,764:INFO:Creating metrics dataframe
2025-12-08 15:09:20,769:INFO:Uploading results into container
2025-12-08 15:09:20,771:INFO:Uploading model into container now
2025-12-08 15:09:20,771:INFO:_master_model_container: 7
2025-12-08 15:09:20,771:INFO:_display_container: 2
2025-12-08 15:09:20,771:INFO:OrthogonalMatchingPursuit()
2025-12-08 15:09:20,771:INFO:create_model() successfully completed......................................
2025-12-08 15:09:20,896:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:20,896:INFO:Creating metrics dataframe
2025-12-08 15:09:20,913:INFO:Initializing Bayesian Ridge
2025-12-08 15:09:20,915:INFO:Total runtime is 0.33847275972366336 minutes
2025-12-08 15:09:20,924:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:20,924:INFO:Initializing create_model()
2025-12-08 15:09:20,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:20,926:INFO:Checking exceptions
2025-12-08 15:09:20,926:INFO:Importing libraries
2025-12-08 15:09:20,926:INFO:Copying training dataset
2025-12-08 15:09:20,944:INFO:Defining folds
2025-12-08 15:09:20,945:INFO:Declaring metric variables
2025-12-08 15:09:20,955:INFO:Importing untrained model
2025-12-08 15:09:20,966:INFO:Bayesian Ridge Imported successfully
2025-12-08 15:09:20,987:INFO:Starting cross validation
2025-12-08 15:09:20,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:21,230:INFO:Calculating mean and std
2025-12-08 15:09:21,233:INFO:Creating metrics dataframe
2025-12-08 15:09:21,237:INFO:Uploading results into container
2025-12-08 15:09:21,237:INFO:Uploading model into container now
2025-12-08 15:09:21,240:INFO:_master_model_container: 8
2025-12-08 15:09:21,240:INFO:_display_container: 2
2025-12-08 15:09:21,242:INFO:BayesianRidge()
2025-12-08 15:09:21,242:INFO:create_model() successfully completed......................................
2025-12-08 15:09:21,365:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:21,366:INFO:Creating metrics dataframe
2025-12-08 15:09:21,386:INFO:Initializing Passive Aggressive Regressor
2025-12-08 15:09:21,388:INFO:Total runtime is 0.34634969631830853 minutes
2025-12-08 15:09:21,396:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:21,399:INFO:Initializing create_model()
2025-12-08 15:09:21,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:21,399:INFO:Checking exceptions
2025-12-08 15:09:21,400:INFO:Importing libraries
2025-12-08 15:09:21,400:INFO:Copying training dataset
2025-12-08 15:09:21,420:INFO:Defining folds
2025-12-08 15:09:21,422:INFO:Declaring metric variables
2025-12-08 15:09:21,433:INFO:Importing untrained model
2025-12-08 15:09:21,444:INFO:Passive Aggressive Regressor Imported successfully
2025-12-08 15:09:21,465:INFO:Starting cross validation
2025-12-08 15:09:21,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:22,661:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,681:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,749:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,751:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,765:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,783:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,792:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,799:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,866:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:09:22,893:INFO:Calculating mean and std
2025-12-08 15:09:22,893:INFO:Creating metrics dataframe
2025-12-08 15:09:22,901:INFO:Uploading results into container
2025-12-08 15:09:22,901:INFO:Uploading model into container now
2025-12-08 15:09:22,901:INFO:_master_model_container: 9
2025-12-08 15:09:22,904:INFO:_display_container: 2
2025-12-08 15:09:22,906:INFO:PassiveAggressiveRegressor(random_state=123)
2025-12-08 15:09:22,906:INFO:create_model() successfully completed......................................
2025-12-08 15:09:23,028:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:23,030:INFO:Creating metrics dataframe
2025-12-08 15:09:23,052:INFO:Initializing Huber Regressor
2025-12-08 15:09:23,052:INFO:Total runtime is 0.3740785559018453 minutes
2025-12-08 15:09:23,060:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:23,060:INFO:Initializing create_model()
2025-12-08 15:09:23,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:23,060:INFO:Checking exceptions
2025-12-08 15:09:23,064:INFO:Importing libraries
2025-12-08 15:09:23,064:INFO:Copying training dataset
2025-12-08 15:09:23,083:INFO:Defining folds
2025-12-08 15:09:23,083:INFO:Declaring metric variables
2025-12-08 15:09:23,094:INFO:Importing untrained model
2025-12-08 15:09:23,103:INFO:Huber Regressor Imported successfully
2025-12-08 15:09:23,125:INFO:Starting cross validation
2025-12-08 15:09:23,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:23,482:INFO:Calculating mean and std
2025-12-08 15:09:23,485:INFO:Creating metrics dataframe
2025-12-08 15:09:23,485:INFO:Uploading results into container
2025-12-08 15:09:23,485:INFO:Uploading model into container now
2025-12-08 15:09:23,485:INFO:_master_model_container: 10
2025-12-08 15:09:23,485:INFO:_display_container: 2
2025-12-08 15:09:23,485:INFO:HuberRegressor()
2025-12-08 15:09:23,485:INFO:create_model() successfully completed......................................
2025-12-08 15:09:23,610:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:23,613:INFO:Creating metrics dataframe
2025-12-08 15:09:23,632:INFO:Initializing K Neighbors Regressor
2025-12-08 15:09:23,632:INFO:Total runtime is 0.38375922838846843 minutes
2025-12-08 15:09:23,644:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:23,644:INFO:Initializing create_model()
2025-12-08 15:09:23,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:23,644:INFO:Checking exceptions
2025-12-08 15:09:23,644:INFO:Importing libraries
2025-12-08 15:09:23,644:INFO:Copying training dataset
2025-12-08 15:09:23,666:INFO:Defining folds
2025-12-08 15:09:23,668:INFO:Declaring metric variables
2025-12-08 15:09:23,678:INFO:Importing untrained model
2025-12-08 15:09:23,689:INFO:K Neighbors Regressor Imported successfully
2025-12-08 15:09:23,711:INFO:Starting cross validation
2025-12-08 15:09:23,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:23,999:INFO:Calculating mean and std
2025-12-08 15:09:24,001:INFO:Creating metrics dataframe
2025-12-08 15:09:24,005:INFO:Uploading results into container
2025-12-08 15:09:24,007:INFO:Uploading model into container now
2025-12-08 15:09:24,009:INFO:_master_model_container: 11
2025-12-08 15:09:24,009:INFO:_display_container: 2
2025-12-08 15:09:24,009:INFO:KNeighborsRegressor(n_jobs=-1)
2025-12-08 15:09:24,009:INFO:create_model() successfully completed......................................
2025-12-08 15:09:24,133:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:24,133:INFO:Creating metrics dataframe
2025-12-08 15:09:24,156:INFO:Initializing Decision Tree Regressor
2025-12-08 15:09:24,156:INFO:Total runtime is 0.39248055617014566 minutes
2025-12-08 15:09:24,165:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:24,166:INFO:Initializing create_model()
2025-12-08 15:09:24,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:24,167:INFO:Checking exceptions
2025-12-08 15:09:24,167:INFO:Importing libraries
2025-12-08 15:09:24,167:INFO:Copying training dataset
2025-12-08 15:09:24,183:INFO:Defining folds
2025-12-08 15:09:24,183:INFO:Declaring metric variables
2025-12-08 15:09:24,195:INFO:Importing untrained model
2025-12-08 15:09:24,201:INFO:Decision Tree Regressor Imported successfully
2025-12-08 15:09:24,216:INFO:Starting cross validation
2025-12-08 15:09:24,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:24,499:INFO:Calculating mean and std
2025-12-08 15:09:24,500:INFO:Creating metrics dataframe
2025-12-08 15:09:24,504:INFO:Uploading results into container
2025-12-08 15:09:24,507:INFO:Uploading model into container now
2025-12-08 15:09:24,507:INFO:_master_model_container: 12
2025-12-08 15:09:24,507:INFO:_display_container: 2
2025-12-08 15:09:24,509:INFO:DecisionTreeRegressor(random_state=123)
2025-12-08 15:09:24,509:INFO:create_model() successfully completed......................................
2025-12-08 15:09:24,633:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:24,633:INFO:Creating metrics dataframe
2025-12-08 15:09:24,653:INFO:Initializing Random Forest Regressor
2025-12-08 15:09:24,653:INFO:Total runtime is 0.40077635049819943 minutes
2025-12-08 15:09:24,661:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:24,665:INFO:Initializing create_model()
2025-12-08 15:09:24,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:24,665:INFO:Checking exceptions
2025-12-08 15:09:24,665:INFO:Importing libraries
2025-12-08 15:09:24,665:INFO:Copying training dataset
2025-12-08 15:09:24,683:INFO:Defining folds
2025-12-08 15:09:24,683:INFO:Declaring metric variables
2025-12-08 15:09:24,690:INFO:Importing untrained model
2025-12-08 15:09:24,704:INFO:Random Forest Regressor Imported successfully
2025-12-08 15:09:24,722:INFO:Starting cross validation
2025-12-08 15:09:24,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:28,091:INFO:Calculating mean and std
2025-12-08 15:09:28,093:INFO:Creating metrics dataframe
2025-12-08 15:09:28,099:INFO:Uploading results into container
2025-12-08 15:09:28,100:INFO:Uploading model into container now
2025-12-08 15:09:28,102:INFO:_master_model_container: 13
2025-12-08 15:09:28,102:INFO:_display_container: 2
2025-12-08 15:09:28,102:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-12-08 15:09:28,102:INFO:create_model() successfully completed......................................
2025-12-08 15:09:28,238:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:28,238:INFO:Creating metrics dataframe
2025-12-08 15:09:28,258:INFO:Initializing Extra Trees Regressor
2025-12-08 15:09:28,264:INFO:Total runtime is 0.4609500726064046 minutes
2025-12-08 15:09:28,274:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:28,274:INFO:Initializing create_model()
2025-12-08 15:09:28,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:28,274:INFO:Checking exceptions
2025-12-08 15:09:28,274:INFO:Importing libraries
2025-12-08 15:09:28,274:INFO:Copying training dataset
2025-12-08 15:09:28,285:INFO:Defining folds
2025-12-08 15:09:28,296:INFO:Declaring metric variables
2025-12-08 15:09:28,306:INFO:Importing untrained model
2025-12-08 15:09:28,316:INFO:Extra Trees Regressor Imported successfully
2025-12-08 15:09:28,333:INFO:Starting cross validation
2025-12-08 15:09:28,338:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:30,741:INFO:Calculating mean and std
2025-12-08 15:09:30,744:INFO:Creating metrics dataframe
2025-12-08 15:09:30,749:INFO:Uploading results into container
2025-12-08 15:09:30,749:INFO:Uploading model into container now
2025-12-08 15:09:30,752:INFO:_master_model_container: 14
2025-12-08 15:09:30,752:INFO:_display_container: 2
2025-12-08 15:09:30,753:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-08 15:09:30,753:INFO:create_model() successfully completed......................................
2025-12-08 15:09:30,887:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:30,892:INFO:Creating metrics dataframe
2025-12-08 15:09:30,920:INFO:Initializing AdaBoost Regressor
2025-12-08 15:09:30,920:INFO:Total runtime is 0.5052163084348043 minutes
2025-12-08 15:09:30,928:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:30,930:INFO:Initializing create_model()
2025-12-08 15:09:30,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:30,930:INFO:Checking exceptions
2025-12-08 15:09:30,932:INFO:Importing libraries
2025-12-08 15:09:30,932:INFO:Copying training dataset
2025-12-08 15:09:30,951:INFO:Defining folds
2025-12-08 15:09:30,951:INFO:Declaring metric variables
2025-12-08 15:09:30,964:INFO:Importing untrained model
2025-12-08 15:09:30,974:INFO:AdaBoost Regressor Imported successfully
2025-12-08 15:09:30,992:INFO:Starting cross validation
2025-12-08 15:09:30,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:31,878:INFO:Calculating mean and std
2025-12-08 15:09:31,878:INFO:Creating metrics dataframe
2025-12-08 15:09:31,883:INFO:Uploading results into container
2025-12-08 15:09:31,883:INFO:Uploading model into container now
2025-12-08 15:09:31,883:INFO:_master_model_container: 15
2025-12-08 15:09:31,883:INFO:_display_container: 2
2025-12-08 15:09:31,883:INFO:AdaBoostRegressor(random_state=123)
2025-12-08 15:09:31,883:INFO:create_model() successfully completed......................................
2025-12-08 15:09:32,009:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:32,009:INFO:Creating metrics dataframe
2025-12-08 15:09:32,033:INFO:Initializing Gradient Boosting Regressor
2025-12-08 15:09:32,033:INFO:Total runtime is 0.5237634340922037 minutes
2025-12-08 15:09:32,042:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:32,045:INFO:Initializing create_model()
2025-12-08 15:09:32,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:32,045:INFO:Checking exceptions
2025-12-08 15:09:32,045:INFO:Importing libraries
2025-12-08 15:09:32,045:INFO:Copying training dataset
2025-12-08 15:09:32,066:INFO:Defining folds
2025-12-08 15:09:32,069:INFO:Declaring metric variables
2025-12-08 15:09:32,077:INFO:Importing untrained model
2025-12-08 15:09:32,087:INFO:Gradient Boosting Regressor Imported successfully
2025-12-08 15:09:32,105:INFO:Starting cross validation
2025-12-08 15:09:32,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:33,344:INFO:Calculating mean and std
2025-12-08 15:09:33,345:INFO:Creating metrics dataframe
2025-12-08 15:09:33,351:INFO:Uploading results into container
2025-12-08 15:09:33,351:INFO:Uploading model into container now
2025-12-08 15:09:33,351:INFO:_master_model_container: 16
2025-12-08 15:09:33,354:INFO:_display_container: 2
2025-12-08 15:09:33,354:INFO:GradientBoostingRegressor(random_state=123)
2025-12-08 15:09:33,356:INFO:create_model() successfully completed......................................
2025-12-08 15:09:33,483:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:33,483:INFO:Creating metrics dataframe
2025-12-08 15:09:33,515:INFO:Initializing Light Gradient Boosting Machine
2025-12-08 15:09:33,515:INFO:Total runtime is 0.5484680811564127 minutes
2025-12-08 15:09:33,525:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:33,525:INFO:Initializing create_model()
2025-12-08 15:09:33,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:33,527:INFO:Checking exceptions
2025-12-08 15:09:33,527:INFO:Importing libraries
2025-12-08 15:09:33,527:INFO:Copying training dataset
2025-12-08 15:09:33,543:INFO:Defining folds
2025-12-08 15:09:33,543:INFO:Declaring metric variables
2025-12-08 15:09:33,555:INFO:Importing untrained model
2025-12-08 15:09:33,566:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:09:33,587:INFO:Starting cross validation
2025-12-08 15:09:33,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:35,532:INFO:Calculating mean and std
2025-12-08 15:09:35,534:INFO:Creating metrics dataframe
2025-12-08 15:09:35,540:INFO:Uploading results into container
2025-12-08 15:09:35,542:INFO:Uploading model into container now
2025-12-08 15:09:35,542:INFO:_master_model_container: 17
2025-12-08 15:09:35,544:INFO:_display_container: 2
2025-12-08 15:09:35,544:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 15:09:35,544:INFO:create_model() successfully completed......................................
2025-12-08 15:09:35,682:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:35,685:INFO:Creating metrics dataframe
2025-12-08 15:09:35,712:INFO:Initializing Dummy Regressor
2025-12-08 15:09:35,712:INFO:Total runtime is 0.5850927193959553 minutes
2025-12-08 15:09:35,718:INFO:SubProcess create_model() called ==================================
2025-12-08 15:09:35,718:INFO:Initializing create_model()
2025-12-08 15:09:35,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926C61240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:35,726:INFO:Checking exceptions
2025-12-08 15:09:35,726:INFO:Importing libraries
2025-12-08 15:09:35,726:INFO:Copying training dataset
2025-12-08 15:09:35,745:INFO:Defining folds
2025-12-08 15:09:35,745:INFO:Declaring metric variables
2025-12-08 15:09:35,755:INFO:Importing untrained model
2025-12-08 15:09:35,766:INFO:Dummy Regressor Imported successfully
2025-12-08 15:09:35,792:INFO:Starting cross validation
2025-12-08 15:09:35,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:09:36,029:INFO:Calculating mean and std
2025-12-08 15:09:36,032:INFO:Creating metrics dataframe
2025-12-08 15:09:36,036:INFO:Uploading results into container
2025-12-08 15:09:36,038:INFO:Uploading model into container now
2025-12-08 15:09:36,038:INFO:_master_model_container: 18
2025-12-08 15:09:36,038:INFO:_display_container: 2
2025-12-08 15:09:36,038:INFO:DummyRegressor()
2025-12-08 15:09:36,038:INFO:create_model() successfully completed......................................
2025-12-08 15:09:36,159:INFO:SubProcess create_model() end ==================================
2025-12-08 15:09:36,159:INFO:Creating metrics dataframe
2025-12-08 15:09:36,193:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-08 15:09:36,213:INFO:Initializing create_model()
2025-12-08 15:09:36,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:09:36,215:INFO:Checking exceptions
2025-12-08 15:09:36,218:INFO:Importing libraries
2025-12-08 15:09:36,218:INFO:Copying training dataset
2025-12-08 15:09:36,232:INFO:Defining folds
2025-12-08 15:09:36,232:INFO:Declaring metric variables
2025-12-08 15:09:36,235:INFO:Importing untrained model
2025-12-08 15:09:36,235:INFO:Declaring custom model
2025-12-08 15:09:36,235:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:09:36,235:INFO:Cross validation set to False
2025-12-08 15:09:36,235:INFO:Fitting Model
2025-12-08 15:09:36,282:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 15:09:36,286:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.
2025-12-08 15:09:36,286:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 15:09:36,286:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 15:09:36,286:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 15:09:36,286:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 15:09:36,288:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 15:09:36,638:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 15:09:36,638:INFO:create_model() successfully completed......................................
2025-12-08 15:09:36,848:INFO:_master_model_container: 18
2025-12-08 15:09:36,848:INFO:_display_container: 2
2025-12-08 15:09:36,850:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 15:09:36,850:INFO:compare_models() successfully completed......................................
2025-12-08 15:09:36,853:INFO:Initializing tune_model()
2025-12-08 15:09:36,853:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>)
2025-12-08 15:09:36,853:INFO:Checking exceptions
2025-12-08 15:09:36,893:INFO:Copying training dataset
2025-12-08 15:09:36,905:INFO:Checking base model
2025-12-08 15:09:36,906:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 15:09:36,908:INFO:Declaring metric variables
2025-12-08 15:09:36,923:INFO:Defining Hyperparameters
2025-12-08 15:09:37,048:INFO:Tuning with n_jobs=-1
2025-12-08 15:09:37,049:INFO:Initializing RandomizedSearchCV
2025-12-08 15:10:03,095:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-08 15:10:03,098:INFO:Hyperparameter search completed
2025-12-08 15:10:03,100:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:03,102:INFO:Initializing create_model()
2025-12-08 15:10:03,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91C04A800>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-08 15:10:03,102:INFO:Checking exceptions
2025-12-08 15:10:03,104:INFO:Importing libraries
2025-12-08 15:10:03,104:INFO:Copying training dataset
2025-12-08 15:10:03,127:INFO:Defining folds
2025-12-08 15:10:03,127:INFO:Declaring metric variables
2025-12-08 15:10:03,140:INFO:Importing untrained model
2025-12-08 15:10:03,140:INFO:Declaring custom model
2025-12-08 15:10:03,157:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:10:03,184:INFO:Starting cross validation
2025-12-08 15:10:03,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:04,997:INFO:Calculating mean and std
2025-12-08 15:10:05,001:INFO:Creating metrics dataframe
2025-12-08 15:10:05,017:INFO:Finalizing model
2025-12-08 15:10:05,063:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-08 15:10:05,063:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-08 15:10:05,063:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-08 15:10:05,071:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 15:10:05,071:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-08 15:10:05,071:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-08 15:10:05,073:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-08 15:10:05,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.
2025-12-08 15:10:05,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 15:10:05,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 15:10:05,075:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 15:10:05,075:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 15:10:05,078:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 15:10:05,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 15:10:05,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 15:10:05,375:INFO:Uploading results into container
2025-12-08 15:10:05,377:INFO:Uploading model into container now
2025-12-08 15:10:05,379:INFO:_master_model_container: 19
2025-12-08 15:10:05,379:INFO:_display_container: 3
2025-12-08 15:10:05,383:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005)
2025-12-08 15:10:05,383:INFO:create_model() successfully completed......................................
2025-12-08 15:10:05,519:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:05,519:INFO:choose_better activated
2025-12-08 15:10:05,538:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:05,541:INFO:Initializing create_model()
2025-12-08 15:10:05,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A91C2896C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:05,541:INFO:Checking exceptions
2025-12-08 15:10:05,547:INFO:Importing libraries
2025-12-08 15:10:05,548:INFO:Copying training dataset
2025-12-08 15:10:05,565:INFO:Defining folds
2025-12-08 15:10:05,565:INFO:Declaring metric variables
2025-12-08 15:10:05,567:INFO:Importing untrained model
2025-12-08 15:10:05,567:INFO:Declaring custom model
2025-12-08 15:10:05,567:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:10:05,567:INFO:Starting cross validation
2025-12-08 15:10:05,567:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:07,641:INFO:Calculating mean and std
2025-12-08 15:10:07,643:INFO:Creating metrics dataframe
2025-12-08 15:10:07,648:INFO:Finalizing model
2025-12-08 15:10:07,701:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 15:10:07,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001189 seconds.
2025-12-08 15:10:07,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 15:10:07,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 15:10:07,717:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 15:10:07,717:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 15:10:07,719:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 15:10:07,995:INFO:Uploading results into container
2025-12-08 15:10:07,998:INFO:Uploading model into container now
2025-12-08 15:10:08,000:INFO:_master_model_container: 20
2025-12-08 15:10:08,000:INFO:_display_container: 4
2025-12-08 15:10:08,001:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 15:10:08,001:INFO:create_model() successfully completed......................................
2025-12-08 15:10:08,143:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:08,148:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9584
2025-12-08 15:10:08,151:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005) result for R2 is 0.9462
2025-12-08 15:10:08,153:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-12-08 15:10:08,153:INFO:choose_better completed
2025-12-08 15:10:08,153:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-08 15:10:08,190:INFO:_master_model_container: 20
2025-12-08 15:10:08,190:INFO:_display_container: 3
2025-12-08 15:10:08,194:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 15:10:08,194:INFO:tune_model() successfully completed......................................
2025-12-08 15:10:08,371:INFO:PyCaret ClassificationExperiment
2025-12-08 15:10:08,371:INFO:Logging name: clf-default-name
2025-12-08 15:10:08,371:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-08 15:10:08,371:INFO:version 3.3.2
2025-12-08 15:10:08,371:INFO:Initializing setup()
2025-12-08 15:10:08,371:INFO:self.USI: 9d1c
2025-12-08 15:10:08,371:INFO:self._variable_keys: {'X', 'X_test', 'exp_name_log', 'USI', 'idx', 'fold_generator', 'fold_groups_param', 'fix_imbalance', 'memory', 'gpu_n_jobs_param', '_ml_usecase', 'n_jobs_param', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'y', '_available_plots', 'y_test', 'data', 'gpu_param', 'logging_param', 'X_train', 'is_multiclass', 'target_param', 'seed', 'pipeline', 'exp_id'}
2025-12-08 15:10:08,371:INFO:Checking environment
2025-12-08 15:10:08,371:INFO:python_version: 3.10.19
2025-12-08 15:10:08,371:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-08 15:10:08,371:INFO:machine: AMD64
2025-12-08 15:10:08,371:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-08 15:10:08,371:INFO:Memory: svmem(total=33699516416, available=14554763264, percent=56.8, used=19144753152, free=14554763264)
2025-12-08 15:10:08,371:INFO:Physical Core: 8
2025-12-08 15:10:08,371:INFO:Logical Core: 16
2025-12-08 15:10:08,371:INFO:Checking libraries
2025-12-08 15:10:08,371:INFO:System:
2025-12-08 15:10:08,371:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-08 15:10:08,374:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-08 15:10:08,374:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-08 15:10:08,374:INFO:PyCaret required dependencies:
2025-12-08 15:10:08,374:INFO:                 pip: 25.3
2025-12-08 15:10:08,374:INFO:          setuptools: 80.9.0
2025-12-08 15:10:08,374:INFO:             pycaret: 3.3.2
2025-12-08 15:10:08,374:INFO:             IPython: 8.37.0
2025-12-08 15:10:08,374:INFO:          ipywidgets: 8.1.8
2025-12-08 15:10:08,374:INFO:                tqdm: 4.67.1
2025-12-08 15:10:08,374:INFO:               numpy: 1.26.4
2025-12-08 15:10:08,374:INFO:              pandas: 2.1.4
2025-12-08 15:10:08,374:INFO:              jinja2: 3.1.6
2025-12-08 15:10:08,374:INFO:               scipy: 1.11.4
2025-12-08 15:10:08,374:INFO:              joblib: 1.3.2
2025-12-08 15:10:08,374:INFO:             sklearn: 1.4.2
2025-12-08 15:10:08,374:INFO:                pyod: 2.0.6
2025-12-08 15:10:08,374:INFO:            imblearn: 0.14.0
2025-12-08 15:10:08,374:INFO:   category_encoders: 2.7.0
2025-12-08 15:10:08,374:INFO:            lightgbm: 4.6.0
2025-12-08 15:10:08,374:INFO:               numba: 0.62.1
2025-12-08 15:10:08,374:INFO:            requests: 2.32.5
2025-12-08 15:10:08,374:INFO:          matplotlib: 3.7.5
2025-12-08 15:10:08,374:INFO:          scikitplot: 0.3.7
2025-12-08 15:10:08,374:INFO:         yellowbrick: 1.5
2025-12-08 15:10:08,374:INFO:              plotly: 6.5.0
2025-12-08 15:10:08,374:INFO:    plotly-resampler: Not installed
2025-12-08 15:10:08,374:INFO:             kaleido: 1.2.0
2025-12-08 15:10:08,374:INFO:           schemdraw: 0.15
2025-12-08 15:10:08,374:INFO:         statsmodels: 0.14.5
2025-12-08 15:10:08,374:INFO:              sktime: 0.26.0
2025-12-08 15:10:08,374:INFO:               tbats: 1.1.3
2025-12-08 15:10:08,374:INFO:            pmdarima: 2.0.4
2025-12-08 15:10:08,374:INFO:              psutil: 7.1.3
2025-12-08 15:10:08,374:INFO:          markupsafe: 3.0.3
2025-12-08 15:10:08,374:INFO:             pickle5: Not installed
2025-12-08 15:10:08,374:INFO:         cloudpickle: 3.1.2
2025-12-08 15:10:08,374:INFO:         deprecation: 2.1.0
2025-12-08 15:10:08,374:INFO:              xxhash: 3.6.0
2025-12-08 15:10:08,374:INFO:           wurlitzer: Not installed
2025-12-08 15:10:08,374:INFO:PyCaret optional dependencies:
2025-12-08 15:10:08,374:INFO:                shap: Not installed
2025-12-08 15:10:08,374:INFO:           interpret: Not installed
2025-12-08 15:10:08,374:INFO:                umap: Not installed
2025-12-08 15:10:08,374:INFO:     ydata_profiling: Not installed
2025-12-08 15:10:08,374:INFO:  explainerdashboard: Not installed
2025-12-08 15:10:08,374:INFO:             autoviz: Not installed
2025-12-08 15:10:08,374:INFO:           fairlearn: Not installed
2025-12-08 15:10:08,374:INFO:          deepchecks: Not installed
2025-12-08 15:10:08,374:INFO:             xgboost: Not installed
2025-12-08 15:10:08,374:INFO:            catboost: Not installed
2025-12-08 15:10:08,374:INFO:              kmodes: Not installed
2025-12-08 15:10:08,374:INFO:             mlxtend: Not installed
2025-12-08 15:10:08,374:INFO:       statsforecast: Not installed
2025-12-08 15:10:08,374:INFO:        tune_sklearn: Not installed
2025-12-08 15:10:08,374:INFO:                 ray: Not installed
2025-12-08 15:10:08,374:INFO:            hyperopt: Not installed
2025-12-08 15:10:08,374:INFO:              optuna: Not installed
2025-12-08 15:10:08,374:INFO:               skopt: Not installed
2025-12-08 15:10:08,374:INFO:              mlflow: Not installed
2025-12-08 15:10:08,374:INFO:              gradio: Not installed
2025-12-08 15:10:08,374:INFO:             fastapi: Not installed
2025-12-08 15:10:08,380:INFO:             uvicorn: Not installed
2025-12-08 15:10:08,380:INFO:              m2cgen: Not installed
2025-12-08 15:10:08,380:INFO:           evidently: Not installed
2025-12-08 15:10:08,380:INFO:               fugue: Not installed
2025-12-08 15:10:08,380:INFO:           streamlit: Not installed
2025-12-08 15:10:08,380:INFO:             prophet: Not installed
2025-12-08 15:10:08,380:INFO:None
2025-12-08 15:10:08,380:INFO:Set up data.
2025-12-08 15:10:08,399:INFO:Set up folding strategy.
2025-12-08 15:10:08,399:INFO:Set up train/test split.
2025-12-08 15:10:08,418:INFO:Set up index.
2025-12-08 15:10:08,418:INFO:Assigning column types.
2025-12-08 15:10:08,432:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-08 15:10:08,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:10:08,565:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 15:10:08,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:08,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:08,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:10:08,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 15:10:08,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:08,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:08,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-08 15:10:08,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 15:10:09,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:09,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:09,183:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 15:10:09,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:09,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:09,252:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-08 15:10:09,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:09,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:09,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:09,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:09,637:INFO:Preparing preprocessing pipeline...
2025-12-08 15:10:09,638:INFO:Set up simple imputation.
2025-12-08 15:10:09,638:INFO:Set up imbalanced handling.
2025-12-08 15:10:09,641:INFO:Set up column name cleaning.
2025-12-08 15:10:09,732:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] O sistema no pode encontrar o arquivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-12-08 15:10:09,817:INFO:Finished creating preprocessing pipeline.
2025-12-08 15:10:09,841:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'selling_price',
                                             'km_driven', 'mileage', 'engine',
                                             'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Sec...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-08 15:10:09,843:INFO:Creating final display dataframe.
2025-12-08 15:10:10,064:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 17)
4        Transformed data shape           (11982, 17)
5   Transformed train set shape            (9610, 17)
6    Transformed test set shape            (2372, 17)
7              Numeric features                    16
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                Fix imbalance                  True
13         Fix imbalance method                 SMOTE
14               Fold Generator       StratifiedKFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment                 False
19              Experiment Name      clf-default-name
20                          USI                  9d1c
2025-12-08 15:10:10,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:10,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:10,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:10,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:10:10,453:INFO:setup() successfully completed in 2.09s...............
2025-12-08 15:10:10,453:INFO:Initializing compare_models()
2025-12-08 15:10:10,453:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-08 15:10:10,453:INFO:Checking exceptions
2025-12-08 15:10:10,467:INFO:Preparing display monitor
2025-12-08 15:10:10,548:INFO:Initializing Logistic Regression
2025-12-08 15:10:10,548:INFO:Total runtime is 0.0 minutes
2025-12-08 15:10:10,560:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:10,560:INFO:Initializing create_model()
2025-12-08 15:10:10,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:10,561:INFO:Checking exceptions
2025-12-08 15:10:10,563:INFO:Importing libraries
2025-12-08 15:10:10,563:INFO:Copying training dataset
2025-12-08 15:10:10,585:INFO:Defining folds
2025-12-08 15:10:10,585:INFO:Declaring metric variables
2025-12-08 15:10:10,586:INFO:Importing untrained model
2025-12-08 15:10:10,598:INFO:Logistic Regression Imported successfully
2025-12-08 15:10:10,621:INFO:Starting cross validation
2025-12-08 15:10:10,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:12,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:10:12,473:INFO:Calculating mean and std
2025-12-08 15:10:12,476:INFO:Creating metrics dataframe
2025-12-08 15:10:12,481:INFO:Uploading results into container
2025-12-08 15:10:12,483:INFO:Uploading model into container now
2025-12-08 15:10:12,486:INFO:_master_model_container: 1
2025-12-08 15:10:12,486:INFO:_display_container: 2
2025-12-08 15:10:12,486:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:10:12,486:INFO:create_model() successfully completed......................................
2025-12-08 15:10:12,625:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:12,625:INFO:Creating metrics dataframe
2025-12-08 15:10:12,643:INFO:Initializing K Neighbors Classifier
2025-12-08 15:10:12,643:INFO:Total runtime is 0.0349159836769104 minutes
2025-12-08 15:10:12,650:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:12,656:INFO:Initializing create_model()
2025-12-08 15:10:12,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:12,656:INFO:Checking exceptions
2025-12-08 15:10:12,656:INFO:Importing libraries
2025-12-08 15:10:12,656:INFO:Copying training dataset
2025-12-08 15:10:12,677:INFO:Defining folds
2025-12-08 15:10:12,677:INFO:Declaring metric variables
2025-12-08 15:10:12,690:INFO:Importing untrained model
2025-12-08 15:10:12,699:INFO:K Neighbors Classifier Imported successfully
2025-12-08 15:10:12,719:INFO:Starting cross validation
2025-12-08 15:10:12,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:13,196:INFO:Calculating mean and std
2025-12-08 15:10:13,199:INFO:Creating metrics dataframe
2025-12-08 15:10:13,204:INFO:Uploading results into container
2025-12-08 15:10:13,204:INFO:Uploading model into container now
2025-12-08 15:10:13,204:INFO:_master_model_container: 2
2025-12-08 15:10:13,204:INFO:_display_container: 2
2025-12-08 15:10:13,209:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-08 15:10:13,209:INFO:create_model() successfully completed......................................
2025-12-08 15:10:13,333:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:13,333:INFO:Creating metrics dataframe
2025-12-08 15:10:13,348:INFO:Initializing Naive Bayes
2025-12-08 15:10:13,350:INFO:Total runtime is 0.046695029735565184 minutes
2025-12-08 15:10:13,357:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:13,359:INFO:Initializing create_model()
2025-12-08 15:10:13,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:13,359:INFO:Checking exceptions
2025-12-08 15:10:13,359:INFO:Importing libraries
2025-12-08 15:10:13,359:INFO:Copying training dataset
2025-12-08 15:10:13,376:INFO:Defining folds
2025-12-08 15:10:13,378:INFO:Declaring metric variables
2025-12-08 15:10:13,388:INFO:Importing untrained model
2025-12-08 15:10:13,398:INFO:Naive Bayes Imported successfully
2025-12-08 15:10:13,415:INFO:Starting cross validation
2025-12-08 15:10:13,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:13,661:INFO:Calculating mean and std
2025-12-08 15:10:13,664:INFO:Creating metrics dataframe
2025-12-08 15:10:13,668:INFO:Uploading results into container
2025-12-08 15:10:13,668:INFO:Uploading model into container now
2025-12-08 15:10:13,671:INFO:_master_model_container: 3
2025-12-08 15:10:13,671:INFO:_display_container: 2
2025-12-08 15:10:13,671:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-08 15:10:13,673:INFO:create_model() successfully completed......................................
2025-12-08 15:10:13,791:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:13,791:INFO:Creating metrics dataframe
2025-12-08 15:10:13,811:INFO:Initializing Decision Tree Classifier
2025-12-08 15:10:13,813:INFO:Total runtime is 0.05441042979558309 minutes
2025-12-08 15:10:13,822:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:13,824:INFO:Initializing create_model()
2025-12-08 15:10:13,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:13,824:INFO:Checking exceptions
2025-12-08 15:10:13,824:INFO:Importing libraries
2025-12-08 15:10:13,824:INFO:Copying training dataset
2025-12-08 15:10:13,842:INFO:Defining folds
2025-12-08 15:10:13,842:INFO:Declaring metric variables
2025-12-08 15:10:13,857:INFO:Importing untrained model
2025-12-08 15:10:13,865:INFO:Decision Tree Classifier Imported successfully
2025-12-08 15:10:13,885:INFO:Starting cross validation
2025-12-08 15:10:13,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:14,227:INFO:Calculating mean and std
2025-12-08 15:10:14,232:INFO:Creating metrics dataframe
2025-12-08 15:10:14,238:INFO:Uploading results into container
2025-12-08 15:10:14,238:INFO:Uploading model into container now
2025-12-08 15:10:14,240:INFO:_master_model_container: 4
2025-12-08 15:10:14,240:INFO:_display_container: 2
2025-12-08 15:10:14,240:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-08 15:10:14,240:INFO:create_model() successfully completed......................................
2025-12-08 15:10:14,363:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:14,363:INFO:Creating metrics dataframe
2025-12-08 15:10:14,380:INFO:Initializing SVM - Linear Kernel
2025-12-08 15:10:14,381:INFO:Total runtime is 0.06387952168782551 minutes
2025-12-08 15:10:14,384:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:14,384:INFO:Initializing create_model()
2025-12-08 15:10:14,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:14,384:INFO:Checking exceptions
2025-12-08 15:10:14,384:INFO:Importing libraries
2025-12-08 15:10:14,384:INFO:Copying training dataset
2025-12-08 15:10:14,411:INFO:Defining folds
2025-12-08 15:10:14,411:INFO:Declaring metric variables
2025-12-08 15:10:14,421:INFO:Importing untrained model
2025-12-08 15:10:14,431:INFO:SVM - Linear Kernel Imported successfully
2025-12-08 15:10:14,448:INFO:Starting cross validation
2025-12-08 15:10:14,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:14,895:INFO:Calculating mean and std
2025-12-08 15:10:14,898:INFO:Creating metrics dataframe
2025-12-08 15:10:14,901:INFO:Uploading results into container
2025-12-08 15:10:14,903:INFO:Uploading model into container now
2025-12-08 15:10:14,903:INFO:_master_model_container: 5
2025-12-08 15:10:14,903:INFO:_display_container: 2
2025-12-08 15:10:14,903:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-08 15:10:14,906:INFO:create_model() successfully completed......................................
2025-12-08 15:10:15,026:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:15,026:INFO:Creating metrics dataframe
2025-12-08 15:10:15,048:INFO:Initializing Ridge Classifier
2025-12-08 15:10:15,048:INFO:Total runtime is 0.07500437895456949 minutes
2025-12-08 15:10:15,059:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:15,061:INFO:Initializing create_model()
2025-12-08 15:10:15,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:15,061:INFO:Checking exceptions
2025-12-08 15:10:15,061:INFO:Importing libraries
2025-12-08 15:10:15,061:INFO:Copying training dataset
2025-12-08 15:10:15,083:INFO:Defining folds
2025-12-08 15:10:15,084:INFO:Declaring metric variables
2025-12-08 15:10:15,093:INFO:Importing untrained model
2025-12-08 15:10:15,105:INFO:Ridge Classifier Imported successfully
2025-12-08 15:10:15,125:INFO:Starting cross validation
2025-12-08 15:10:15,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:15,339:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.07985e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,339:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.22879e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,341:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.25459e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,341:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.18612e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,342:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.12855e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,342:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97653e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,344:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.76553e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,344:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97415e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,355:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.27127e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,369:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.84536e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:10:15,432:INFO:Calculating mean and std
2025-12-08 15:10:15,432:INFO:Creating metrics dataframe
2025-12-08 15:10:15,432:INFO:Uploading results into container
2025-12-08 15:10:15,432:INFO:Uploading model into container now
2025-12-08 15:10:15,432:INFO:_master_model_container: 6
2025-12-08 15:10:15,432:INFO:_display_container: 2
2025-12-08 15:10:15,432:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-08 15:10:15,432:INFO:create_model() successfully completed......................................
2025-12-08 15:10:15,560:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:15,560:INFO:Creating metrics dataframe
2025-12-08 15:10:15,575:INFO:Initializing Random Forest Classifier
2025-12-08 15:10:15,575:INFO:Total runtime is 0.08377585013707478 minutes
2025-12-08 15:10:15,588:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:15,588:INFO:Initializing create_model()
2025-12-08 15:10:15,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:15,591:INFO:Checking exceptions
2025-12-08 15:10:15,591:INFO:Importing libraries
2025-12-08 15:10:15,591:INFO:Copying training dataset
2025-12-08 15:10:15,606:INFO:Defining folds
2025-12-08 15:10:15,606:INFO:Declaring metric variables
2025-12-08 15:10:15,615:INFO:Importing untrained model
2025-12-08 15:10:15,625:INFO:Random Forest Classifier Imported successfully
2025-12-08 15:10:15,645:INFO:Starting cross validation
2025-12-08 15:10:15,649:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:17,997:INFO:Calculating mean and std
2025-12-08 15:10:18,000:INFO:Creating metrics dataframe
2025-12-08 15:10:18,006:INFO:Uploading results into container
2025-12-08 15:10:18,006:INFO:Uploading model into container now
2025-12-08 15:10:18,009:INFO:_master_model_container: 7
2025-12-08 15:10:18,009:INFO:_display_container: 2
2025-12-08 15:10:18,009:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-08 15:10:18,009:INFO:create_model() successfully completed......................................
2025-12-08 15:10:18,141:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:18,141:INFO:Creating metrics dataframe
2025-12-08 15:10:18,158:INFO:Initializing Quadratic Discriminant Analysis
2025-12-08 15:10:18,163:INFO:Total runtime is 0.12691253026326496 minutes
2025-12-08 15:10:18,172:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:18,173:INFO:Initializing create_model()
2025-12-08 15:10:18,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:18,174:INFO:Checking exceptions
2025-12-08 15:10:18,174:INFO:Importing libraries
2025-12-08 15:10:18,174:INFO:Copying training dataset
2025-12-08 15:10:18,198:INFO:Defining folds
2025-12-08 15:10:18,198:INFO:Declaring metric variables
2025-12-08 15:10:18,209:INFO:Importing untrained model
2025-12-08 15:10:18,217:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-08 15:10:18,241:INFO:Starting cross validation
2025-12-08 15:10:18,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:18,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,421:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,421:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,425:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,438:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,438:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,440:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,440:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,443:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,445:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,445:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,445:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,448:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,450:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,453:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,453:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,453:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

.5)))

2025-12-08 15:10:18,453:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,453:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,455:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,457:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,457:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,459:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,461:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,463:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,463:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,464:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,470:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,470:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:10:18,472:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,476:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,476:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,476:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,478:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,478:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,480:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,481:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,481:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,481:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,481:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,486:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,486:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,486:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,488:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,490:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,490:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,490:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,490:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,490:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,490:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,492:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,492:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,492:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,494:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,499:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,499:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,499:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,499:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,501:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,501:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,501:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,505:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,507:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:10:18,509:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,509:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:10:18,511:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,515:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,517:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,521:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,525:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:10:18,529:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,532:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,535:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,539:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,539:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:18,577:INFO:Calculating mean and std
2025-12-08 15:10:18,578:INFO:Creating metrics dataframe
2025-12-08 15:10:18,584:INFO:Uploading results into container
2025-12-08 15:10:18,585:INFO:Uploading model into container now
2025-12-08 15:10:18,585:INFO:_master_model_container: 8
2025-12-08 15:10:18,587:INFO:_display_container: 2
2025-12-08 15:10:18,587:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-08 15:10:18,587:INFO:create_model() successfully completed......................................
2025-12-08 15:10:18,714:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:18,716:INFO:Creating metrics dataframe
2025-12-08 15:10:18,737:INFO:Initializing Ada Boost Classifier
2025-12-08 15:10:18,737:INFO:Total runtime is 0.13648876349131264 minutes
2025-12-08 15:10:18,747:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:18,748:INFO:Initializing create_model()
2025-12-08 15:10:18,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:18,748:INFO:Checking exceptions
2025-12-08 15:10:18,748:INFO:Importing libraries
2025-12-08 15:10:18,748:INFO:Copying training dataset
2025-12-08 15:10:18,765:INFO:Defining folds
2025-12-08 15:10:18,765:INFO:Declaring metric variables
2025-12-08 15:10:18,776:INFO:Importing untrained model
2025-12-08 15:10:18,787:INFO:Ada Boost Classifier Imported successfully
2025-12-08 15:10:18,804:INFO:Starting cross validation
2025-12-08 15:10:18,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:19,015:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,015:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,015:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,017:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,017:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,017:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:19,021:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:10:20,163:INFO:Calculating mean and std
2025-12-08 15:10:20,164:INFO:Creating metrics dataframe
2025-12-08 15:10:20,168:INFO:Uploading results into container
2025-12-08 15:10:20,171:INFO:Uploading model into container now
2025-12-08 15:10:20,171:INFO:_master_model_container: 9
2025-12-08 15:10:20,171:INFO:_display_container: 2
2025-12-08 15:10:20,173:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-08 15:10:20,173:INFO:create_model() successfully completed......................................
2025-12-08 15:10:20,302:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:20,305:INFO:Creating metrics dataframe
2025-12-08 15:10:20,325:INFO:Initializing Gradient Boosting Classifier
2025-12-08 15:10:20,325:INFO:Total runtime is 0.16294782161712645 minutes
2025-12-08 15:10:20,337:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:20,338:INFO:Initializing create_model()
2025-12-08 15:10:20,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:20,340:INFO:Checking exceptions
2025-12-08 15:10:20,340:INFO:Importing libraries
2025-12-08 15:10:20,340:INFO:Copying training dataset
2025-12-08 15:10:20,353:INFO:Defining folds
2025-12-08 15:10:20,353:INFO:Declaring metric variables
2025-12-08 15:10:20,369:INFO:Importing untrained model
2025-12-08 15:10:20,377:INFO:Gradient Boosting Classifier Imported successfully
2025-12-08 15:10:20,398:INFO:Starting cross validation
2025-12-08 15:10:20,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:23,775:INFO:Calculating mean and std
2025-12-08 15:10:23,778:INFO:Creating metrics dataframe
2025-12-08 15:10:23,784:INFO:Uploading results into container
2025-12-08 15:10:23,786:INFO:Uploading model into container now
2025-12-08 15:10:23,787:INFO:_master_model_container: 10
2025-12-08 15:10:23,789:INFO:_display_container: 2
2025-12-08 15:10:23,789:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-08 15:10:23,789:INFO:create_model() successfully completed......................................
2025-12-08 15:10:23,915:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:23,915:INFO:Creating metrics dataframe
2025-12-08 15:10:23,936:INFO:Initializing Linear Discriminant Analysis
2025-12-08 15:10:23,936:INFO:Total runtime is 0.22313509782155355 minutes
2025-12-08 15:10:23,945:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:23,947:INFO:Initializing create_model()
2025-12-08 15:10:23,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:23,947:INFO:Checking exceptions
2025-12-08 15:10:23,947:INFO:Importing libraries
2025-12-08 15:10:23,950:INFO:Copying training dataset
2025-12-08 15:10:23,981:INFO:Defining folds
2025-12-08 15:10:23,981:INFO:Declaring metric variables
2025-12-08 15:10:23,994:INFO:Importing untrained model
2025-12-08 15:10:24,008:INFO:Linear Discriminant Analysis Imported successfully
2025-12-08 15:10:24,032:INFO:Starting cross validation
2025-12-08 15:10:24,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:24,296:INFO:Calculating mean and std
2025-12-08 15:10:24,298:INFO:Creating metrics dataframe
2025-12-08 15:10:24,303:INFO:Uploading results into container
2025-12-08 15:10:24,303:INFO:Uploading model into container now
2025-12-08 15:10:24,304:INFO:_master_model_container: 11
2025-12-08 15:10:24,304:INFO:_display_container: 2
2025-12-08 15:10:24,304:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-08 15:10:24,304:INFO:create_model() successfully completed......................................
2025-12-08 15:10:24,428:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:24,431:INFO:Creating metrics dataframe
2025-12-08 15:10:24,450:INFO:Initializing Extra Trees Classifier
2025-12-08 15:10:24,453:INFO:Total runtime is 0.2317559520403544 minutes
2025-12-08 15:10:24,460:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:24,460:INFO:Initializing create_model()
2025-12-08 15:10:24,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:24,460:INFO:Checking exceptions
2025-12-08 15:10:24,463:INFO:Importing libraries
2025-12-08 15:10:24,463:INFO:Copying training dataset
2025-12-08 15:10:24,479:INFO:Defining folds
2025-12-08 15:10:24,481:INFO:Declaring metric variables
2025-12-08 15:10:24,489:INFO:Importing untrained model
2025-12-08 15:10:24,498:INFO:Extra Trees Classifier Imported successfully
2025-12-08 15:10:24,516:INFO:Starting cross validation
2025-12-08 15:10:24,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:26,330:INFO:Calculating mean and std
2025-12-08 15:10:26,333:INFO:Creating metrics dataframe
2025-12-08 15:10:26,339:INFO:Uploading results into container
2025-12-08 15:10:26,339:INFO:Uploading model into container now
2025-12-08 15:10:26,341:INFO:_master_model_container: 12
2025-12-08 15:10:26,341:INFO:_display_container: 2
2025-12-08 15:10:26,343:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-08 15:10:26,343:INFO:create_model() successfully completed......................................
2025-12-08 15:10:26,475:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:26,475:INFO:Creating metrics dataframe
2025-12-08 15:10:26,499:INFO:Initializing Light Gradient Boosting Machine
2025-12-08 15:10:26,499:INFO:Total runtime is 0.2658452192942301 minutes
2025-12-08 15:10:26,505:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:26,505:INFO:Initializing create_model()
2025-12-08 15:10:26,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:26,505:INFO:Checking exceptions
2025-12-08 15:10:26,505:INFO:Importing libraries
2025-12-08 15:10:26,505:INFO:Copying training dataset
2025-12-08 15:10:26,534:INFO:Defining folds
2025-12-08 15:10:26,534:INFO:Declaring metric variables
2025-12-08 15:10:26,543:INFO:Importing untrained model
2025-12-08 15:10:26,555:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:10:26,575:INFO:Starting cross validation
2025-12-08 15:10:26,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:30,604:INFO:Calculating mean and std
2025-12-08 15:10:30,608:INFO:Creating metrics dataframe
2025-12-08 15:10:30,620:INFO:Uploading results into container
2025-12-08 15:10:30,622:INFO:Uploading model into container now
2025-12-08 15:10:30,624:INFO:_master_model_container: 13
2025-12-08 15:10:30,624:INFO:_display_container: 2
2025-12-08 15:10:30,626:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 15:10:30,626:INFO:create_model() successfully completed......................................
2025-12-08 15:10:30,780:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:30,782:INFO:Creating metrics dataframe
2025-12-08 15:10:30,805:INFO:Initializing Dummy Classifier
2025-12-08 15:10:30,805:INFO:Total runtime is 0.3376214385032653 minutes
2025-12-08 15:10:30,817:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:30,817:INFO:Initializing create_model()
2025-12-08 15:10:30,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A92439F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:30,819:INFO:Checking exceptions
2025-12-08 15:10:30,819:INFO:Importing libraries
2025-12-08 15:10:30,819:INFO:Copying training dataset
2025-12-08 15:10:30,839:INFO:Defining folds
2025-12-08 15:10:30,839:INFO:Declaring metric variables
2025-12-08 15:10:30,850:INFO:Importing untrained model
2025-12-08 15:10:30,858:INFO:Dummy Classifier Imported successfully
2025-12-08 15:10:30,876:INFO:Starting cross validation
2025-12-08 15:10:30,879:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:31,055:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,066:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,072:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,075:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,082:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,082:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,082:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,089:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,101:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,103:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:10:31,129:INFO:Calculating mean and std
2025-12-08 15:10:31,132:INFO:Creating metrics dataframe
2025-12-08 15:10:31,138:INFO:Uploading results into container
2025-12-08 15:10:31,138:INFO:Uploading model into container now
2025-12-08 15:10:31,141:INFO:_master_model_container: 14
2025-12-08 15:10:31,141:INFO:_display_container: 2
2025-12-08 15:10:31,142:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-08 15:10:31,142:INFO:create_model() successfully completed......................................
2025-12-08 15:10:31,288:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:31,288:INFO:Creating metrics dataframe
2025-12-08 15:10:31,320:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-08 15:10:31,341:INFO:Initializing create_model()
2025-12-08 15:10:31,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:31,341:INFO:Checking exceptions
2025-12-08 15:10:31,348:INFO:Importing libraries
2025-12-08 15:10:31,348:INFO:Copying training dataset
2025-12-08 15:10:31,364:INFO:Defining folds
2025-12-08 15:10:31,364:INFO:Declaring metric variables
2025-12-08 15:10:31,364:INFO:Importing untrained model
2025-12-08 15:10:31,367:INFO:Declaring custom model
2025-12-08 15:10:31,368:INFO:Logistic Regression Imported successfully
2025-12-08 15:10:31,371:INFO:Cross validation set to False
2025-12-08 15:10:31,371:INFO:Fitting Model
2025-12-08 15:10:33,362:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:10:33,362:INFO:create_model() successfully completed......................................
2025-12-08 15:10:33,583:INFO:_master_model_container: 14
2025-12-08 15:10:33,583:INFO:_display_container: 2
2025-12-08 15:10:33,583:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:10:33,583:INFO:compare_models() successfully completed......................................
2025-12-08 15:10:33,589:INFO:Initializing tune_model()
2025-12-08 15:10:33,589:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>)
2025-12-08 15:10:33,589:INFO:Checking exceptions
2025-12-08 15:10:33,642:INFO:Copying training dataset
2025-12-08 15:10:33,660:INFO:Checking base model
2025-12-08 15:10:33,661:INFO:Base model : Logistic Regression
2025-12-08 15:10:33,671:INFO:Declaring metric variables
2025-12-08 15:10:33,685:INFO:Defining Hyperparameters
2025-12-08 15:10:33,832:INFO:Tuning with n_jobs=-1
2025-12-08 15:10:33,832:INFO:Initializing RandomizedSearchCV
2025-12-08 15:10:38,901:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:10:40,442:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:10:45,954:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:10:47,215:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:10:47,248:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-08 15:10:47,253:INFO:Hyperparameter search completed
2025-12-08 15:10:47,253:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:47,255:INFO:Initializing create_model()
2025-12-08 15:10:47,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A926421F60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-08 15:10:47,257:INFO:Checking exceptions
2025-12-08 15:10:47,257:INFO:Importing libraries
2025-12-08 15:10:47,257:INFO:Copying training dataset
2025-12-08 15:10:47,280:INFO:Defining folds
2025-12-08 15:10:47,280:INFO:Declaring metric variables
2025-12-08 15:10:47,288:INFO:Importing untrained model
2025-12-08 15:10:47,290:INFO:Declaring custom model
2025-12-08 15:10:47,301:INFO:Logistic Regression Imported successfully
2025-12-08 15:10:47,316:INFO:Starting cross validation
2025-12-08 15:10:47,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:49,236:INFO:Calculating mean and std
2025-12-08 15:10:49,237:INFO:Creating metrics dataframe
2025-12-08 15:10:49,252:INFO:Finalizing model
2025-12-08 15:10:51,639:INFO:Uploading results into container
2025-12-08 15:10:51,639:INFO:Uploading model into container now
2025-12-08 15:10:51,643:INFO:_master_model_container: 15
2025-12-08 15:10:51,643:INFO:_display_container: 3
2025-12-08 15:10:51,644:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:10:51,644:INFO:create_model() successfully completed......................................
2025-12-08 15:10:51,840:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:51,840:INFO:choose_better activated
2025-12-08 15:10:51,852:INFO:SubProcess create_model() called ==================================
2025-12-08 15:10:51,855:INFO:Initializing create_model()
2025-12-08 15:10:51,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A926B901C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:10:51,855:INFO:Checking exceptions
2025-12-08 15:10:51,859:INFO:Importing libraries
2025-12-08 15:10:51,859:INFO:Copying training dataset
2025-12-08 15:10:51,880:INFO:Defining folds
2025-12-08 15:10:51,883:INFO:Declaring metric variables
2025-12-08 15:10:51,883:INFO:Importing untrained model
2025-12-08 15:10:51,883:INFO:Declaring custom model
2025-12-08 15:10:51,885:INFO:Logistic Regression Imported successfully
2025-12-08 15:10:51,885:INFO:Starting cross validation
2025-12-08 15:10:51,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:10:53,780:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:10:53,861:INFO:Calculating mean and std
2025-12-08 15:10:53,863:INFO:Creating metrics dataframe
2025-12-08 15:10:53,869:INFO:Finalizing model
2025-12-08 15:10:55,654:INFO:Uploading results into container
2025-12-08 15:10:55,657:INFO:Uploading model into container now
2025-12-08 15:10:55,657:INFO:_master_model_container: 16
2025-12-08 15:10:55,657:INFO:_display_container: 4
2025-12-08 15:10:55,659:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:10:55,659:INFO:create_model() successfully completed......................................
2025-12-08 15:10:55,782:INFO:SubProcess create_model() end ==================================
2025-12-08 15:10:55,782:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-08 15:10:55,782:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-08 15:10:55,782:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-08 15:10:55,782:INFO:choose_better completed
2025-12-08 15:10:55,782:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-08 15:10:55,818:INFO:_master_model_container: 16
2025-12-08 15:10:55,818:INFO:_display_container: 3
2025-12-08 15:10:55,820:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:10:55,820:INFO:tune_model() successfully completed......................................
2025-12-08 15:26:24,818:INFO:PyCaret RegressionExperiment
2025-12-08 15:26:24,818:INFO:Logging name: reg-default-name
2025-12-08 15:26:24,818:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-08 15:26:24,818:INFO:version 3.3.2
2025-12-08 15:26:24,818:INFO:Initializing setup()
2025-12-08 15:26:24,818:INFO:self.USI: 7b97
2025-12-08 15:26:24,818:INFO:self._variable_keys: {'X', 'X_test', 'exp_name_log', 'USI', 'idx', 'fold_generator', 'fold_groups_param', 'memory', 'gpu_n_jobs_param', '_ml_usecase', 'n_jobs_param', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'y', '_available_plots', 'y_test', 'transform_target_param', 'data', 'gpu_param', 'logging_param', 'X_train', 'target_param', 'seed', 'pipeline', 'exp_id'}
2025-12-08 15:26:24,819:INFO:Checking environment
2025-12-08 15:26:24,819:INFO:python_version: 3.10.19
2025-12-08 15:26:24,819:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-08 15:26:24,819:INFO:machine: AMD64
2025-12-08 15:26:24,819:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-08 15:26:24,819:INFO:Memory: svmem(total=33699516416, available=16743989248, percent=50.3, used=16955527168, free=16743989248)
2025-12-08 15:26:24,821:INFO:Physical Core: 8
2025-12-08 15:26:24,821:INFO:Logical Core: 16
2025-12-08 15:26:24,821:INFO:Checking libraries
2025-12-08 15:26:24,821:INFO:System:
2025-12-08 15:26:24,821:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-08 15:26:24,821:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-08 15:26:24,821:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-08 15:26:24,821:INFO:PyCaret required dependencies:
2025-12-08 15:26:24,821:INFO:                 pip: 25.3
2025-12-08 15:26:24,821:INFO:          setuptools: 80.9.0
2025-12-08 15:26:24,821:INFO:             pycaret: 3.3.2
2025-12-08 15:26:24,821:INFO:             IPython: 8.37.0
2025-12-08 15:26:24,821:INFO:          ipywidgets: 8.1.8
2025-12-08 15:26:24,821:INFO:                tqdm: 4.67.1
2025-12-08 15:26:24,823:INFO:               numpy: 1.26.4
2025-12-08 15:26:24,823:INFO:              pandas: 2.1.4
2025-12-08 15:26:24,823:INFO:              jinja2: 3.1.6
2025-12-08 15:26:24,823:INFO:               scipy: 1.11.4
2025-12-08 15:26:24,823:INFO:              joblib: 1.3.2
2025-12-08 15:26:24,823:INFO:             sklearn: 1.4.2
2025-12-08 15:26:24,823:INFO:                pyod: 2.0.6
2025-12-08 15:26:24,823:INFO:            imblearn: 0.14.0
2025-12-08 15:26:24,823:INFO:   category_encoders: 2.7.0
2025-12-08 15:26:24,823:INFO:            lightgbm: 4.6.0
2025-12-08 15:26:24,823:INFO:               numba: 0.62.1
2025-12-08 15:26:24,824:INFO:            requests: 2.32.5
2025-12-08 15:26:24,824:INFO:          matplotlib: 3.7.5
2025-12-08 15:26:24,824:INFO:          scikitplot: 0.3.7
2025-12-08 15:26:24,825:INFO:         yellowbrick: 1.5
2025-12-08 15:26:24,825:INFO:              plotly: 6.5.0
2025-12-08 15:26:24,825:INFO:    plotly-resampler: Not installed
2025-12-08 15:26:24,825:INFO:             kaleido: 1.2.0
2025-12-08 15:26:24,826:INFO:           schemdraw: 0.15
2025-12-08 15:26:24,826:INFO:         statsmodels: 0.14.5
2025-12-08 15:26:24,826:INFO:              sktime: 0.26.0
2025-12-08 15:26:24,826:INFO:               tbats: 1.1.3
2025-12-08 15:26:24,826:INFO:            pmdarima: 2.0.4
2025-12-08 15:26:24,826:INFO:              psutil: 7.1.3
2025-12-08 15:26:24,826:INFO:          markupsafe: 3.0.3
2025-12-08 15:26:24,826:INFO:             pickle5: Not installed
2025-12-08 15:26:24,826:INFO:         cloudpickle: 3.1.2
2025-12-08 15:26:24,827:INFO:         deprecation: 2.1.0
2025-12-08 15:26:24,827:INFO:              xxhash: 3.6.0
2025-12-08 15:26:24,827:INFO:           wurlitzer: Not installed
2025-12-08 15:26:24,827:INFO:PyCaret optional dependencies:
2025-12-08 15:26:24,827:INFO:                shap: Not installed
2025-12-08 15:26:24,827:INFO:           interpret: Not installed
2025-12-08 15:26:24,827:INFO:                umap: Not installed
2025-12-08 15:26:24,827:INFO:     ydata_profiling: Not installed
2025-12-08 15:26:24,827:INFO:  explainerdashboard: Not installed
2025-12-08 15:26:24,827:INFO:             autoviz: Not installed
2025-12-08 15:26:24,827:INFO:           fairlearn: Not installed
2025-12-08 15:26:24,828:INFO:          deepchecks: Not installed
2025-12-08 15:26:24,828:INFO:             xgboost: Not installed
2025-12-08 15:26:24,828:INFO:            catboost: Not installed
2025-12-08 15:26:24,828:INFO:              kmodes: Not installed
2025-12-08 15:26:24,828:INFO:             mlxtend: Not installed
2025-12-08 15:26:24,828:INFO:       statsforecast: Not installed
2025-12-08 15:26:24,828:INFO:        tune_sklearn: Not installed
2025-12-08 15:26:24,828:INFO:                 ray: Not installed
2025-12-08 15:26:24,828:INFO:            hyperopt: Not installed
2025-12-08 15:26:24,828:INFO:              optuna: Not installed
2025-12-08 15:26:24,828:INFO:               skopt: Not installed
2025-12-08 15:26:24,830:INFO:              mlflow: Not installed
2025-12-08 15:26:24,830:INFO:              gradio: Not installed
2025-12-08 15:26:24,830:INFO:             fastapi: Not installed
2025-12-08 15:26:24,830:INFO:             uvicorn: Not installed
2025-12-08 15:26:24,830:INFO:              m2cgen: Not installed
2025-12-08 15:26:24,830:INFO:           evidently: Not installed
2025-12-08 15:26:24,830:INFO:               fugue: Not installed
2025-12-08 15:26:24,830:INFO:           streamlit: Not installed
2025-12-08 15:26:24,830:INFO:             prophet: Not installed
2025-12-08 15:26:24,830:INFO:None
2025-12-08 15:26:24,830:INFO:Set up data.
2025-12-08 15:26:24,848:INFO:Set up folding strategy.
2025-12-08 15:26:24,848:INFO:Set up train/test split.
2025-12-08 15:26:24,867:INFO:Set up index.
2025-12-08 15:26:24,868:INFO:Assigning column types.
2025-12-08 15:26:24,886:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-08 15:26:24,886:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-08 15:26:24,897:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 15:26:24,909:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:25,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:25,222:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,237:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,250:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,429:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,547:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:25,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:25,548:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-08 15:26:25,562:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,575:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:25,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:25,880:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 15:26:25,893:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:26,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:26,181:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-08 15:26:26,208:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:26,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:26,554:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:26:26,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:26,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:26,846:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-08 15:26:27,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:27,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:26:27,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:27,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:27,329:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:27,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:26:27,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:27,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:27,447:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-08 15:26:27,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:27,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:27,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:27,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 15:26:28,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:28,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:28,063:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-08 15:26:28,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:28,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:28,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:28,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:28,711:INFO:Preparing preprocessing pipeline...
2025-12-08 15:26:28,713:INFO:Set up simple imputation.
2025-12-08 15:26:28,713:INFO:Set up feature normalization.
2025-12-08 15:26:28,715:INFO:Set up column name cleaning.
2025-12-08 15:26:28,828:INFO:Finished creating preprocessing pipeline.
2025-12-08 15:26:28,840:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'transmission_encoded',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'ow...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-08 15:26:28,840:INFO:Creating final display dataframe.
2025-12-08 15:26:29,165:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 17)
4        Transformed data shape        (7906, 17)
5   Transformed train set shape        (5534, 17)
6    Transformed test set shape        (2372, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              7b97
2025-12-08 15:26:29,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:29,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:29,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:29,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:26:29,794:INFO:setup() successfully completed in 4.98s...............
2025-12-08 15:26:29,798:INFO:Initializing compare_models()
2025-12-08 15:26:29,798:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-08 15:26:29,798:INFO:Checking exceptions
2025-12-08 15:26:29,804:INFO:Preparing display monitor
2025-12-08 15:26:29,874:INFO:Initializing Linear Regression
2025-12-08 15:26:29,875:INFO:Total runtime is 9.1552734375e-06 minutes
2025-12-08 15:26:29,887:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:29,888:INFO:Initializing create_model()
2025-12-08 15:26:29,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:29,889:INFO:Checking exceptions
2025-12-08 15:26:29,889:INFO:Importing libraries
2025-12-08 15:26:29,889:INFO:Copying training dataset
2025-12-08 15:26:29,917:INFO:Defining folds
2025-12-08 15:26:29,917:INFO:Declaring metric variables
2025-12-08 15:26:29,928:INFO:Importing untrained model
2025-12-08 15:26:29,944:INFO:Linear Regression Imported successfully
2025-12-08 15:26:29,969:INFO:Starting cross validation
2025-12-08 15:26:29,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:39,906:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,911:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,912:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,916:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,919:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,921:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,927:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,928:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,930:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:39,931:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:40,555:INFO:Calculating mean and std
2025-12-08 15:26:40,561:INFO:Creating metrics dataframe
2025-12-08 15:26:40,570:INFO:Uploading results into container
2025-12-08 15:26:40,575:INFO:Uploading model into container now
2025-12-08 15:26:40,576:INFO:_master_model_container: 1
2025-12-08 15:26:40,576:INFO:_display_container: 2
2025-12-08 15:26:40,577:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-12-08 15:26:40,577:INFO:create_model() successfully completed......................................
2025-12-08 15:26:40,780:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:40,780:INFO:Creating metrics dataframe
2025-12-08 15:26:40,797:INFO:Initializing Lasso Regression
2025-12-08 15:26:40,797:INFO:Total runtime is 0.1820489009221395 minutes
2025-12-08 15:26:40,805:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:40,805:INFO:Initializing create_model()
2025-12-08 15:26:40,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:40,807:INFO:Checking exceptions
2025-12-08 15:26:40,807:INFO:Importing libraries
2025-12-08 15:26:40,808:INFO:Copying training dataset
2025-12-08 15:26:40,829:INFO:Defining folds
2025-12-08 15:26:40,830:INFO:Declaring metric variables
2025-12-08 15:26:40,840:INFO:Importing untrained model
2025-12-08 15:26:40,851:INFO:Lasso Regression Imported successfully
2025-12-08 15:26:40,868:INFO:Starting cross validation
2025-12-08 15:26:40,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:47,615:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:47,643:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:47,674:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:47,686:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:47,693:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:47,704:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 15:26:48,241:INFO:Calculating mean and std
2025-12-08 15:26:48,245:INFO:Creating metrics dataframe
2025-12-08 15:26:48,253:INFO:Uploading results into container
2025-12-08 15:26:48,255:INFO:Uploading model into container now
2025-12-08 15:26:48,257:INFO:_master_model_container: 2
2025-12-08 15:26:48,258:INFO:_display_container: 2
2025-12-08 15:26:48,260:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-12-08 15:26:48,260:INFO:create_model() successfully completed......................................
2025-12-08 15:26:48,406:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:48,406:INFO:Creating metrics dataframe
2025-12-08 15:26:48,427:INFO:Initializing Ridge Regression
2025-12-08 15:26:48,427:INFO:Total runtime is 0.30920819838841757 minutes
2025-12-08 15:26:48,434:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:48,437:INFO:Initializing create_model()
2025-12-08 15:26:48,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:48,437:INFO:Checking exceptions
2025-12-08 15:26:48,437:INFO:Importing libraries
2025-12-08 15:26:48,437:INFO:Copying training dataset
2025-12-08 15:26:48,463:INFO:Defining folds
2025-12-08 15:26:48,463:INFO:Declaring metric variables
2025-12-08 15:26:48,474:INFO:Importing untrained model
2025-12-08 15:26:48,484:INFO:Ridge Regression Imported successfully
2025-12-08 15:26:48,502:INFO:Starting cross validation
2025-12-08 15:26:48,505:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:48,713:INFO:Calculating mean and std
2025-12-08 15:26:48,715:INFO:Creating metrics dataframe
2025-12-08 15:26:48,720:INFO:Uploading results into container
2025-12-08 15:26:48,721:INFO:Uploading model into container now
2025-12-08 15:26:48,722:INFO:_master_model_container: 3
2025-12-08 15:26:48,724:INFO:_display_container: 2
2025-12-08 15:26:48,725:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-12-08 15:26:48,725:INFO:create_model() successfully completed......................................
2025-12-08 15:26:48,855:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:48,855:INFO:Creating metrics dataframe
2025-12-08 15:26:48,872:INFO:Initializing Elastic Net
2025-12-08 15:26:48,872:INFO:Total runtime is 0.3166377743085225 minutes
2025-12-08 15:26:48,882:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:48,883:INFO:Initializing create_model()
2025-12-08 15:26:48,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:48,884:INFO:Checking exceptions
2025-12-08 15:26:48,884:INFO:Importing libraries
2025-12-08 15:26:48,884:INFO:Copying training dataset
2025-12-08 15:26:48,902:INFO:Defining folds
2025-12-08 15:26:48,903:INFO:Declaring metric variables
2025-12-08 15:26:48,914:INFO:Importing untrained model
2025-12-08 15:26:48,926:INFO:Elastic Net Imported successfully
2025-12-08 15:26:48,949:INFO:Starting cross validation
2025-12-08 15:26:48,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:49,200:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+12, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-08 15:26:49,240:INFO:Calculating mean and std
2025-12-08 15:26:49,243:INFO:Creating metrics dataframe
2025-12-08 15:26:49,247:INFO:Uploading results into container
2025-12-08 15:26:49,247:INFO:Uploading model into container now
2025-12-08 15:26:49,249:INFO:_master_model_container: 4
2025-12-08 15:26:49,249:INFO:_display_container: 2
2025-12-08 15:26:49,251:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-12-08 15:26:49,251:INFO:create_model() successfully completed......................................
2025-12-08 15:26:49,385:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:49,385:INFO:Creating metrics dataframe
2025-12-08 15:26:49,403:INFO:Initializing Least Angle Regression
2025-12-08 15:26:49,404:INFO:Total runtime is 0.32550516128540036 minutes
2025-12-08 15:26:49,415:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:49,416:INFO:Initializing create_model()
2025-12-08 15:26:49,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:49,416:INFO:Checking exceptions
2025-12-08 15:26:49,416:INFO:Importing libraries
2025-12-08 15:26:49,417:INFO:Copying training dataset
2025-12-08 15:26:49,451:INFO:Defining folds
2025-12-08 15:26:49,451:INFO:Declaring metric variables
2025-12-08 15:26:49,465:INFO:Importing untrained model
2025-12-08 15:26:49,479:INFO:Least Angle Regression Imported successfully
2025-12-08 15:26:49,497:INFO:Starting cross validation
2025-12-08 15:26:49,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:49,744:INFO:Calculating mean and std
2025-12-08 15:26:49,747:INFO:Creating metrics dataframe
2025-12-08 15:26:49,752:INFO:Uploading results into container
2025-12-08 15:26:49,752:INFO:Uploading model into container now
2025-12-08 15:26:49,754:INFO:_master_model_container: 5
2025-12-08 15:26:49,755:INFO:_display_container: 2
2025-12-08 15:26:49,755:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-12-08 15:26:49,755:INFO:create_model() successfully completed......................................
2025-12-08 15:26:49,885:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:49,887:INFO:Creating metrics dataframe
2025-12-08 15:26:49,906:INFO:Initializing Lasso Least Angle Regression
2025-12-08 15:26:49,907:INFO:Total runtime is 0.333876895904541 minutes
2025-12-08 15:26:49,914:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:49,917:INFO:Initializing create_model()
2025-12-08 15:26:49,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:49,917:INFO:Checking exceptions
2025-12-08 15:26:49,917:INFO:Importing libraries
2025-12-08 15:26:49,917:INFO:Copying training dataset
2025-12-08 15:26:49,936:INFO:Defining folds
2025-12-08 15:26:49,937:INFO:Declaring metric variables
2025-12-08 15:26:49,949:INFO:Importing untrained model
2025-12-08 15:26:49,963:INFO:Lasso Least Angle Regression Imported successfully
2025-12-08 15:26:49,987:INFO:Starting cross validation
2025-12-08 15:26:49,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:50,254:INFO:Calculating mean and std
2025-12-08 15:26:50,256:INFO:Creating metrics dataframe
2025-12-08 15:26:50,259:INFO:Uploading results into container
2025-12-08 15:26:50,261:INFO:Uploading model into container now
2025-12-08 15:26:50,262:INFO:_master_model_container: 6
2025-12-08 15:26:50,262:INFO:_display_container: 2
2025-12-08 15:26:50,265:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-12-08 15:26:50,266:INFO:create_model() successfully completed......................................
2025-12-08 15:26:50,394:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:50,394:INFO:Creating metrics dataframe
2025-12-08 15:26:50,413:INFO:Initializing Orthogonal Matching Pursuit
2025-12-08 15:26:50,413:INFO:Total runtime is 0.34231866598129274 minutes
2025-12-08 15:26:50,421:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:50,423:INFO:Initializing create_model()
2025-12-08 15:26:50,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:50,424:INFO:Checking exceptions
2025-12-08 15:26:50,424:INFO:Importing libraries
2025-12-08 15:26:50,424:INFO:Copying training dataset
2025-12-08 15:26:50,446:INFO:Defining folds
2025-12-08 15:26:50,446:INFO:Declaring metric variables
2025-12-08 15:26:50,460:INFO:Importing untrained model
2025-12-08 15:26:50,474:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-08 15:26:50,496:INFO:Starting cross validation
2025-12-08 15:26:50,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:50,730:INFO:Calculating mean and std
2025-12-08 15:26:50,733:INFO:Creating metrics dataframe
2025-12-08 15:26:50,739:INFO:Uploading results into container
2025-12-08 15:26:50,740:INFO:Uploading model into container now
2025-12-08 15:26:50,742:INFO:_master_model_container: 7
2025-12-08 15:26:50,742:INFO:_display_container: 2
2025-12-08 15:26:50,742:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-12-08 15:26:50,742:INFO:create_model() successfully completed......................................
2025-12-08 15:26:50,871:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:50,872:INFO:Creating metrics dataframe
2025-12-08 15:26:50,892:INFO:Initializing Bayesian Ridge
2025-12-08 15:26:50,893:INFO:Total runtime is 0.3503122806549072 minutes
2025-12-08 15:26:50,902:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:50,903:INFO:Initializing create_model()
2025-12-08 15:26:50,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:50,904:INFO:Checking exceptions
2025-12-08 15:26:50,904:INFO:Importing libraries
2025-12-08 15:26:50,904:INFO:Copying training dataset
2025-12-08 15:26:50,930:INFO:Defining folds
2025-12-08 15:26:50,930:INFO:Declaring metric variables
2025-12-08 15:26:50,941:INFO:Importing untrained model
2025-12-08 15:26:50,952:INFO:Bayesian Ridge Imported successfully
2025-12-08 15:26:50,976:INFO:Starting cross validation
2025-12-08 15:26:50,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:51,207:INFO:Calculating mean and std
2025-12-08 15:26:51,210:INFO:Creating metrics dataframe
2025-12-08 15:26:51,213:INFO:Uploading results into container
2025-12-08 15:26:51,215:INFO:Uploading model into container now
2025-12-08 15:26:51,216:INFO:_master_model_container: 8
2025-12-08 15:26:51,217:INFO:_display_container: 2
2025-12-08 15:26:51,218:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-12-08 15:26:51,218:INFO:create_model() successfully completed......................................
2025-12-08 15:26:51,349:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:51,351:INFO:Creating metrics dataframe
2025-12-08 15:26:51,370:INFO:Initializing Passive Aggressive Regressor
2025-12-08 15:26:51,370:INFO:Total runtime is 0.3582636594772339 minutes
2025-12-08 15:26:51,380:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:51,381:INFO:Initializing create_model()
2025-12-08 15:26:51,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:51,381:INFO:Checking exceptions
2025-12-08 15:26:51,381:INFO:Importing libraries
2025-12-08 15:26:51,382:INFO:Copying training dataset
2025-12-08 15:26:51,400:INFO:Defining folds
2025-12-08 15:26:51,402:INFO:Declaring metric variables
2025-12-08 15:26:51,411:INFO:Importing untrained model
2025-12-08 15:26:51,421:INFO:Passive Aggressive Regressor Imported successfully
2025-12-08 15:26:51,441:INFO:Starting cross validation
2025-12-08 15:26:51,444:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:52,667:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,709:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,720:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,726:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,757:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,764:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,779:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,801:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,811:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 15:26:52,838:INFO:Calculating mean and std
2025-12-08 15:26:52,841:INFO:Creating metrics dataframe
2025-12-08 15:26:52,845:INFO:Uploading results into container
2025-12-08 15:26:52,847:INFO:Uploading model into container now
2025-12-08 15:26:52,848:INFO:_master_model_container: 9
2025-12-08 15:26:52,848:INFO:_display_container: 2
2025-12-08 15:26:52,850:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-08 15:26:52,850:INFO:create_model() successfully completed......................................
2025-12-08 15:26:52,981:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:52,981:INFO:Creating metrics dataframe
2025-12-08 15:26:53,002:INFO:Initializing Huber Regressor
2025-12-08 15:26:53,004:INFO:Total runtime is 0.38549755811691283 minutes
2025-12-08 15:26:53,013:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:53,013:INFO:Initializing create_model()
2025-12-08 15:26:53,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:53,015:INFO:Checking exceptions
2025-12-08 15:26:53,015:INFO:Importing libraries
2025-12-08 15:26:53,015:INFO:Copying training dataset
2025-12-08 15:26:53,034:INFO:Defining folds
2025-12-08 15:26:53,034:INFO:Declaring metric variables
2025-12-08 15:26:53,045:INFO:Importing untrained model
2025-12-08 15:26:53,054:INFO:Huber Regressor Imported successfully
2025-12-08 15:26:53,073:INFO:Starting cross validation
2025-12-08 15:26:53,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:53,491:INFO:Calculating mean and std
2025-12-08 15:26:53,494:INFO:Creating metrics dataframe
2025-12-08 15:26:53,498:INFO:Uploading results into container
2025-12-08 15:26:53,499:INFO:Uploading model into container now
2025-12-08 15:26:53,499:INFO:_master_model_container: 10
2025-12-08 15:26:53,500:INFO:_display_container: 2
2025-12-08 15:26:53,502:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-12-08 15:26:53,503:INFO:create_model() successfully completed......................................
2025-12-08 15:26:53,638:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:53,638:INFO:Creating metrics dataframe
2025-12-08 15:26:53,660:INFO:Initializing K Neighbors Regressor
2025-12-08 15:26:53,660:INFO:Total runtime is 0.39642972946166993 minutes
2025-12-08 15:26:53,670:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:53,671:INFO:Initializing create_model()
2025-12-08 15:26:53,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:53,672:INFO:Checking exceptions
2025-12-08 15:26:53,672:INFO:Importing libraries
2025-12-08 15:26:53,672:INFO:Copying training dataset
2025-12-08 15:26:53,691:INFO:Defining folds
2025-12-08 15:26:53,693:INFO:Declaring metric variables
2025-12-08 15:26:53,702:INFO:Importing untrained model
2025-12-08 15:26:53,714:INFO:K Neighbors Regressor Imported successfully
2025-12-08 15:26:53,736:INFO:Starting cross validation
2025-12-08 15:26:53,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:54,028:INFO:Calculating mean and std
2025-12-08 15:26:54,030:INFO:Creating metrics dataframe
2025-12-08 15:26:54,035:INFO:Uploading results into container
2025-12-08 15:26:54,036:INFO:Uploading model into container now
2025-12-08 15:26:54,036:INFO:_master_model_container: 11
2025-12-08 15:26:54,038:INFO:_display_container: 2
2025-12-08 15:26:54,038:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-12-08 15:26:54,040:INFO:create_model() successfully completed......................................
2025-12-08 15:26:54,174:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:54,174:INFO:Creating metrics dataframe
2025-12-08 15:26:54,197:INFO:Initializing Decision Tree Regressor
2025-12-08 15:26:54,198:INFO:Total runtime is 0.40539294481277466 minutes
2025-12-08 15:26:54,207:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:54,208:INFO:Initializing create_model()
2025-12-08 15:26:54,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:54,208:INFO:Checking exceptions
2025-12-08 15:26:54,210:INFO:Importing libraries
2025-12-08 15:26:54,210:INFO:Copying training dataset
2025-12-08 15:26:54,228:INFO:Defining folds
2025-12-08 15:26:54,229:INFO:Declaring metric variables
2025-12-08 15:26:54,247:INFO:Importing untrained model
2025-12-08 15:26:54,260:INFO:Decision Tree Regressor Imported successfully
2025-12-08 15:26:54,280:INFO:Starting cross validation
2025-12-08 15:26:54,281:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:54,546:INFO:Calculating mean and std
2025-12-08 15:26:54,548:INFO:Creating metrics dataframe
2025-12-08 15:26:54,551:INFO:Uploading results into container
2025-12-08 15:26:54,554:INFO:Uploading model into container now
2025-12-08 15:26:54,555:INFO:_master_model_container: 12
2025-12-08 15:26:54,555:INFO:_display_container: 2
2025-12-08 15:26:54,557:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-12-08 15:26:54,557:INFO:create_model() successfully completed......................................
2025-12-08 15:26:54,689:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:54,690:INFO:Creating metrics dataframe
2025-12-08 15:26:54,717:INFO:Initializing Random Forest Regressor
2025-12-08 15:26:54,717:INFO:Total runtime is 0.4140543778737386 minutes
2025-12-08 15:26:54,729:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:54,729:INFO:Initializing create_model()
2025-12-08 15:26:54,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:54,731:INFO:Checking exceptions
2025-12-08 15:26:54,731:INFO:Importing libraries
2025-12-08 15:26:54,731:INFO:Copying training dataset
2025-12-08 15:26:54,751:INFO:Defining folds
2025-12-08 15:26:54,751:INFO:Declaring metric variables
2025-12-08 15:26:54,764:INFO:Importing untrained model
2025-12-08 15:26:54,774:INFO:Random Forest Regressor Imported successfully
2025-12-08 15:26:54,800:INFO:Starting cross validation
2025-12-08 15:26:54,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:26:58,175:INFO:Calculating mean and std
2025-12-08 15:26:58,179:INFO:Creating metrics dataframe
2025-12-08 15:26:58,185:INFO:Uploading results into container
2025-12-08 15:26:58,188:INFO:Uploading model into container now
2025-12-08 15:26:58,189:INFO:_master_model_container: 13
2025-12-08 15:26:58,189:INFO:_display_container: 2
2025-12-08 15:26:58,191:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-12-08 15:26:58,191:INFO:create_model() successfully completed......................................
2025-12-08 15:26:58,327:INFO:SubProcess create_model() end ==================================
2025-12-08 15:26:58,329:INFO:Creating metrics dataframe
2025-12-08 15:26:58,355:INFO:Initializing Extra Trees Regressor
2025-12-08 15:26:58,357:INFO:Total runtime is 0.4747038761774699 minutes
2025-12-08 15:26:58,367:INFO:SubProcess create_model() called ==================================
2025-12-08 15:26:58,369:INFO:Initializing create_model()
2025-12-08 15:26:58,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:26:58,369:INFO:Checking exceptions
2025-12-08 15:26:58,369:INFO:Importing libraries
2025-12-08 15:26:58,369:INFO:Copying training dataset
2025-12-08 15:26:58,389:INFO:Defining folds
2025-12-08 15:26:58,390:INFO:Declaring metric variables
2025-12-08 15:26:58,400:INFO:Importing untrained model
2025-12-08 15:26:58,416:INFO:Extra Trees Regressor Imported successfully
2025-12-08 15:26:58,442:INFO:Starting cross validation
2025-12-08 15:26:58,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:27:01,455:INFO:Calculating mean and std
2025-12-08 15:27:01,459:INFO:Creating metrics dataframe
2025-12-08 15:27:01,466:INFO:Uploading results into container
2025-12-08 15:27:01,467:INFO:Uploading model into container now
2025-12-08 15:27:01,469:INFO:_master_model_container: 14
2025-12-08 15:27:01,469:INFO:_display_container: 2
2025-12-08 15:27:01,472:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-08 15:27:01,473:INFO:create_model() successfully completed......................................
2025-12-08 15:27:01,634:INFO:SubProcess create_model() end ==================================
2025-12-08 15:27:01,637:INFO:Creating metrics dataframe
2025-12-08 15:27:01,673:INFO:Initializing AdaBoost Regressor
2025-12-08 15:27:01,673:INFO:Total runtime is 0.5299861391385396 minutes
2025-12-08 15:27:01,685:INFO:SubProcess create_model() called ==================================
2025-12-08 15:27:01,686:INFO:Initializing create_model()
2025-12-08 15:27:01,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:27:01,687:INFO:Checking exceptions
2025-12-08 15:27:01,687:INFO:Importing libraries
2025-12-08 15:27:01,687:INFO:Copying training dataset
2025-12-08 15:27:01,715:INFO:Defining folds
2025-12-08 15:27:01,716:INFO:Declaring metric variables
2025-12-08 15:27:01,729:INFO:Importing untrained model
2025-12-08 15:27:01,745:INFO:AdaBoost Regressor Imported successfully
2025-12-08 15:27:01,771:INFO:Starting cross validation
2025-12-08 15:27:01,774:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:27:02,799:INFO:Calculating mean and std
2025-12-08 15:27:02,802:INFO:Creating metrics dataframe
2025-12-08 15:27:02,808:INFO:Uploading results into container
2025-12-08 15:27:02,811:INFO:Uploading model into container now
2025-12-08 15:27:02,812:INFO:_master_model_container: 15
2025-12-08 15:27:02,812:INFO:_display_container: 2
2025-12-08 15:27:02,812:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-12-08 15:27:02,814:INFO:create_model() successfully completed......................................
2025-12-08 15:27:02,973:INFO:SubProcess create_model() end ==================================
2025-12-08 15:27:02,973:INFO:Creating metrics dataframe
2025-12-08 15:27:03,006:INFO:Initializing Gradient Boosting Regressor
2025-12-08 15:27:03,006:INFO:Total runtime is 0.5521988352139791 minutes
2025-12-08 15:27:03,019:INFO:SubProcess create_model() called ==================================
2025-12-08 15:27:03,021:INFO:Initializing create_model()
2025-12-08 15:27:03,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:27:03,022:INFO:Checking exceptions
2025-12-08 15:27:03,023:INFO:Importing libraries
2025-12-08 15:27:03,024:INFO:Copying training dataset
2025-12-08 15:27:03,047:INFO:Defining folds
2025-12-08 15:27:03,048:INFO:Declaring metric variables
2025-12-08 15:27:03,064:INFO:Importing untrained model
2025-12-08 15:27:03,077:INFO:Gradient Boosting Regressor Imported successfully
2025-12-08 15:27:03,100:INFO:Starting cross validation
2025-12-08 15:27:03,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:27:04,475:INFO:Calculating mean and std
2025-12-08 15:27:04,478:INFO:Creating metrics dataframe
2025-12-08 15:27:04,484:INFO:Uploading results into container
2025-12-08 15:27:04,486:INFO:Uploading model into container now
2025-12-08 15:27:04,488:INFO:_master_model_container: 16
2025-12-08 15:27:04,488:INFO:_display_container: 2
2025-12-08 15:27:04,490:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-08 15:27:04,491:INFO:create_model() successfully completed......................................
2025-12-08 15:27:04,625:INFO:SubProcess create_model() end ==================================
2025-12-08 15:27:04,625:INFO:Creating metrics dataframe
2025-12-08 15:27:04,655:INFO:Initializing Light Gradient Boosting Machine
2025-12-08 15:27:04,656:INFO:Total runtime is 0.5796907226244609 minutes
2025-12-08 15:27:04,667:INFO:SubProcess create_model() called ==================================
2025-12-08 15:27:04,668:INFO:Initializing create_model()
2025-12-08 15:27:04,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:27:04,668:INFO:Checking exceptions
2025-12-08 15:27:04,668:INFO:Importing libraries
2025-12-08 15:27:04,668:INFO:Copying training dataset
2025-12-08 15:27:04,694:INFO:Defining folds
2025-12-08 15:27:04,696:INFO:Declaring metric variables
2025-12-08 15:27:04,711:INFO:Importing untrained model
2025-12-08 15:27:04,725:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:27:04,750:INFO:Starting cross validation
2025-12-08 15:27:04,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:27:06,788:INFO:Calculating mean and std
2025-12-08 15:27:06,792:INFO:Creating metrics dataframe
2025-12-08 15:27:06,796:INFO:Uploading results into container
2025-12-08 15:27:06,798:INFO:Uploading model into container now
2025-12-08 15:27:06,800:INFO:_master_model_container: 17
2025-12-08 15:27:06,800:INFO:_display_container: 2
2025-12-08 15:27:06,804:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-08 15:27:06,804:INFO:create_model() successfully completed......................................
2025-12-08 15:27:06,955:INFO:SubProcess create_model() end ==================================
2025-12-08 15:27:06,956:INFO:Creating metrics dataframe
2025-12-08 15:27:06,986:INFO:Initializing Dummy Regressor
2025-12-08 15:27:06,986:INFO:Total runtime is 0.6185350338617961 minutes
2025-12-08 15:27:06,999:INFO:SubProcess create_model() called ==================================
2025-12-08 15:27:07,000:INFO:Initializing create_model()
2025-12-08 15:27:07,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A95C43CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:27:07,001:INFO:Checking exceptions
2025-12-08 15:27:07,001:INFO:Importing libraries
2025-12-08 15:27:07,001:INFO:Copying training dataset
2025-12-08 15:27:07,026:INFO:Defining folds
2025-12-08 15:27:07,026:INFO:Declaring metric variables
2025-12-08 15:27:07,040:INFO:Importing untrained model
2025-12-08 15:27:07,054:INFO:Dummy Regressor Imported successfully
2025-12-08 15:27:07,078:INFO:Starting cross validation
2025-12-08 15:27:07,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:27:07,356:INFO:Calculating mean and std
2025-12-08 15:27:07,361:INFO:Creating metrics dataframe
2025-12-08 15:27:07,366:INFO:Uploading results into container
2025-12-08 15:27:07,369:INFO:Uploading model into container now
2025-12-08 15:27:07,369:INFO:_master_model_container: 18
2025-12-08 15:27:07,370:INFO:_display_container: 2
2025-12-08 15:27:07,370:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-12-08 15:27:07,372:INFO:create_model() successfully completed......................................
2025-12-08 15:27:07,513:INFO:SubProcess create_model() end ==================================
2025-12-08 15:27:07,513:INFO:Creating metrics dataframe
2025-12-08 15:27:07,549:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-08 15:27:07,580:INFO:Initializing create_model()
2025-12-08 15:27:07,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:27:07,580:INFO:Checking exceptions
2025-12-08 15:27:07,584:INFO:Importing libraries
2025-12-08 15:27:07,585:INFO:Copying training dataset
2025-12-08 15:27:07,608:INFO:Defining folds
2025-12-08 15:27:07,608:INFO:Declaring metric variables
2025-12-08 15:27:07,609:INFO:Importing untrained model
2025-12-08 15:27:07,609:INFO:Declaring custom model
2025-12-08 15:27:07,612:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:27:07,614:INFO:Cross validation set to False
2025-12-08 15:27:07,614:INFO:Fitting Model
2025-12-08 15:27:07,671:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 15:27:07,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001012 seconds.
2025-12-08 15:27:07,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 15:27:07,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 15:27:07,676:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 15:27:07,676:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 15:27:07,676:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 15:27:07,937:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-08 15:27:07,937:INFO:create_model() successfully completed......................................
2025-12-08 15:27:08,191:INFO:_master_model_container: 18
2025-12-08 15:27:08,192:INFO:_display_container: 2
2025-12-08 15:27:08,194:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-08 15:27:08,195:INFO:compare_models() successfully completed......................................
2025-12-08 15:27:08,201:INFO:Initializing tune_model()
2025-12-08 15:27:08,201:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>)
2025-12-08 15:27:08,203:INFO:Checking exceptions
2025-12-08 15:27:08,262:INFO:Copying training dataset
2025-12-08 15:27:08,282:INFO:Checking base model
2025-12-08 15:27:08,284:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 15:27:08,298:INFO:Declaring metric variables
2025-12-08 15:27:08,311:INFO:Defining Hyperparameters
2025-12-08 15:27:08,496:INFO:Tuning with n_jobs=-1
2025-12-08 15:27:08,497:INFO:Initializing RandomizedSearchCV
2025-12-08 15:27:48,354:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-08 15:27:48,357:INFO:Hyperparameter search completed
2025-12-08 15:27:48,357:INFO:SubProcess create_model() called ==================================
2025-12-08 15:27:48,362:INFO:Initializing create_model()
2025-12-08 15:27:48,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91FC09150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-08 15:27:48,363:INFO:Checking exceptions
2025-12-08 15:27:48,363:INFO:Importing libraries
2025-12-08 15:27:48,363:INFO:Copying training dataset
2025-12-08 15:27:48,397:INFO:Defining folds
2025-12-08 15:27:48,397:INFO:Declaring metric variables
2025-12-08 15:27:48,411:INFO:Importing untrained model
2025-12-08 15:27:48,411:INFO:Declaring custom model
2025-12-08 15:27:48,430:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:27:48,468:INFO:Starting cross validation
2025-12-08 15:27:48,473:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:27:50,679:INFO:Calculating mean and std
2025-12-08 15:27:50,683:INFO:Creating metrics dataframe
2025-12-08 15:27:50,713:INFO:Finalizing model
2025-12-08 15:27:50,777:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-08 15:27:50,777:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-08 15:27:50,777:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-08 15:27:50,788:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 15:27:50,790:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-08 15:27:50,791:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-08 15:27:50,791:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-08 15:27:50,793:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001404 seconds.
2025-12-08 15:27:50,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-08 15:27:50,794:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 15:27:50,794:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 15:27:50,795:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 15:27:50,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 15:27:51,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 15:27:51,179:INFO:Uploading results into container
2025-12-08 15:27:51,182:INFO:Uploading model into container now
2025-12-08 15:27:51,183:INFO:_master_model_container: 19
2025-12-08 15:27:51,184:INFO:_display_container: 3
2025-12-08 15:27:51,188:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
              importance_type='split', learning_rate=0.4, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
              random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-12-08 15:27:51,188:INFO:create_model() successfully completed......................................
2025-12-08 15:27:51,375:INFO:SubProcess create_model() end ==================================
2025-12-08 15:27:51,375:INFO:choose_better activated
2025-12-08 15:27:51,389:INFO:SubProcess create_model() called ==================================
2025-12-08 15:27:51,392:INFO:Initializing create_model()
2025-12-08 15:27:51,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A926C61630>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:27:51,393:INFO:Checking exceptions
2025-12-08 15:27:51,398:INFO:Importing libraries
2025-12-08 15:27:51,398:INFO:Copying training dataset
2025-12-08 15:27:51,424:INFO:Defining folds
2025-12-08 15:27:51,424:INFO:Declaring metric variables
2025-12-08 15:27:51,425:INFO:Importing untrained model
2025-12-08 15:27:51,426:INFO:Declaring custom model
2025-12-08 15:27:51,429:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:27:51,431:INFO:Starting cross validation
2025-12-08 15:27:51,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:27:53,671:INFO:Calculating mean and std
2025-12-08 15:27:53,673:INFO:Creating metrics dataframe
2025-12-08 15:27:53,679:INFO:Finalizing model
2025-12-08 15:27:53,741:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 15:27:53,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.
2025-12-08 15:27:53,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 15:27:53,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 15:27:53,746:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 15:27:53,746:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 15:27:53,747:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 15:27:54,094:INFO:Uploading results into container
2025-12-08 15:27:54,096:INFO:Uploading model into container now
2025-12-08 15:27:54,097:INFO:_master_model_container: 20
2025-12-08 15:27:54,097:INFO:_display_container: 4
2025-12-08 15:27:54,099:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-08 15:27:54,099:INFO:create_model() successfully completed......................................
2025-12-08 15:27:54,269:INFO:SubProcess create_model() end ==================================
2025-12-08 15:27:54,271:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.9584
2025-12-08 15:27:54,274:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
              importance_type='split', learning_rate=0.4, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
              random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.9462
2025-12-08 15:27:54,276:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-08 15:27:54,278:INFO:choose_better completed
2025-12-08 15:27:54,278:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-08 15:27:54,317:INFO:_master_model_container: 20
2025-12-08 15:27:54,318:INFO:_display_container: 3
2025-12-08 15:27:54,320:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-08 15:27:54,321:INFO:tune_model() successfully completed......................................
2025-12-08 15:27:54,539:INFO:PyCaret ClassificationExperiment
2025-12-08 15:27:54,539:INFO:Logging name: clf-default-name
2025-12-08 15:27:54,539:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-08 15:27:54,539:INFO:version 3.3.2
2025-12-08 15:27:54,539:INFO:Initializing setup()
2025-12-08 15:27:54,539:INFO:self.USI: 1153
2025-12-08 15:27:54,539:INFO:self._variable_keys: {'X', 'X_test', 'exp_name_log', 'USI', 'idx', 'fold_generator', 'fold_groups_param', 'fix_imbalance', 'memory', 'gpu_n_jobs_param', '_ml_usecase', 'n_jobs_param', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'y', '_available_plots', 'y_test', 'data', 'gpu_param', 'logging_param', 'X_train', 'is_multiclass', 'target_param', 'seed', 'pipeline', 'exp_id'}
2025-12-08 15:27:54,541:INFO:Checking environment
2025-12-08 15:27:54,541:INFO:python_version: 3.10.19
2025-12-08 15:27:54,541:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-08 15:27:54,541:INFO:machine: AMD64
2025-12-08 15:27:54,541:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-08 15:27:54,541:INFO:Memory: svmem(total=33699516416, available=13849939968, percent=58.9, used=19849576448, free=13849939968)
2025-12-08 15:27:54,541:INFO:Physical Core: 8
2025-12-08 15:27:54,541:INFO:Logical Core: 16
2025-12-08 15:27:54,541:INFO:Checking libraries
2025-12-08 15:27:54,541:INFO:System:
2025-12-08 15:27:54,541:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-08 15:27:54,543:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-08 15:27:54,543:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-08 15:27:54,543:INFO:PyCaret required dependencies:
2025-12-08 15:27:54,543:INFO:                 pip: 25.3
2025-12-08 15:27:54,543:INFO:          setuptools: 80.9.0
2025-12-08 15:27:54,543:INFO:             pycaret: 3.3.2
2025-12-08 15:27:54,543:INFO:             IPython: 8.37.0
2025-12-08 15:27:54,543:INFO:          ipywidgets: 8.1.8
2025-12-08 15:27:54,543:INFO:                tqdm: 4.67.1
2025-12-08 15:27:54,543:INFO:               numpy: 1.26.4
2025-12-08 15:27:54,543:INFO:              pandas: 2.1.4
2025-12-08 15:27:54,543:INFO:              jinja2: 3.1.6
2025-12-08 15:27:54,543:INFO:               scipy: 1.11.4
2025-12-08 15:27:54,543:INFO:              joblib: 1.3.2
2025-12-08 15:27:54,543:INFO:             sklearn: 1.4.2
2025-12-08 15:27:54,543:INFO:                pyod: 2.0.6
2025-12-08 15:27:54,544:INFO:            imblearn: 0.14.0
2025-12-08 15:27:54,544:INFO:   category_encoders: 2.7.0
2025-12-08 15:27:54,544:INFO:            lightgbm: 4.6.0
2025-12-08 15:27:54,544:INFO:               numba: 0.62.1
2025-12-08 15:27:54,544:INFO:            requests: 2.32.5
2025-12-08 15:27:54,544:INFO:          matplotlib: 3.7.5
2025-12-08 15:27:54,544:INFO:          scikitplot: 0.3.7
2025-12-08 15:27:54,544:INFO:         yellowbrick: 1.5
2025-12-08 15:27:54,544:INFO:              plotly: 6.5.0
2025-12-08 15:27:54,544:INFO:    plotly-resampler: Not installed
2025-12-08 15:27:54,544:INFO:             kaleido: 1.2.0
2025-12-08 15:27:54,544:INFO:           schemdraw: 0.15
2025-12-08 15:27:54,544:INFO:         statsmodels: 0.14.5
2025-12-08 15:27:54,544:INFO:              sktime: 0.26.0
2025-12-08 15:27:54,544:INFO:               tbats: 1.1.3
2025-12-08 15:27:54,544:INFO:            pmdarima: 2.0.4
2025-12-08 15:27:54,544:INFO:              psutil: 7.1.3
2025-12-08 15:27:54,544:INFO:          markupsafe: 3.0.3
2025-12-08 15:27:54,546:INFO:             pickle5: Not installed
2025-12-08 15:27:54,546:INFO:         cloudpickle: 3.1.2
2025-12-08 15:27:54,546:INFO:         deprecation: 2.1.0
2025-12-08 15:27:54,546:INFO:              xxhash: 3.6.0
2025-12-08 15:27:54,546:INFO:           wurlitzer: Not installed
2025-12-08 15:27:54,546:INFO:PyCaret optional dependencies:
2025-12-08 15:27:54,546:INFO:                shap: Not installed
2025-12-08 15:27:54,546:INFO:           interpret: Not installed
2025-12-08 15:27:54,546:INFO:                umap: Not installed
2025-12-08 15:27:54,546:INFO:     ydata_profiling: Not installed
2025-12-08 15:27:54,546:INFO:  explainerdashboard: Not installed
2025-12-08 15:27:54,546:INFO:             autoviz: Not installed
2025-12-08 15:27:54,546:INFO:           fairlearn: Not installed
2025-12-08 15:27:54,546:INFO:          deepchecks: Not installed
2025-12-08 15:27:54,546:INFO:             xgboost: Not installed
2025-12-08 15:27:54,546:INFO:            catboost: Not installed
2025-12-08 15:27:54,548:INFO:              kmodes: Not installed
2025-12-08 15:27:54,548:INFO:             mlxtend: Not installed
2025-12-08 15:27:54,548:INFO:       statsforecast: Not installed
2025-12-08 15:27:54,548:INFO:        tune_sklearn: Not installed
2025-12-08 15:27:54,548:INFO:                 ray: Not installed
2025-12-08 15:27:54,548:INFO:            hyperopt: Not installed
2025-12-08 15:27:54,548:INFO:              optuna: Not installed
2025-12-08 15:27:54,548:INFO:               skopt: Not installed
2025-12-08 15:27:54,548:INFO:              mlflow: Not installed
2025-12-08 15:27:54,548:INFO:              gradio: Not installed
2025-12-08 15:27:54,548:INFO:             fastapi: Not installed
2025-12-08 15:27:54,548:INFO:             uvicorn: Not installed
2025-12-08 15:27:54,549:INFO:              m2cgen: Not installed
2025-12-08 15:27:54,549:INFO:           evidently: Not installed
2025-12-08 15:27:54,549:INFO:               fugue: Not installed
2025-12-08 15:27:54,549:INFO:           streamlit: Not installed
2025-12-08 15:27:54,549:INFO:             prophet: Not installed
2025-12-08 15:27:54,550:INFO:None
2025-12-08 15:27:54,550:INFO:Set up data.
2025-12-08 15:27:54,579:INFO:Set up folding strategy.
2025-12-08 15:27:54,579:INFO:Set up train/test split.
2025-12-08 15:27:54,612:INFO:Set up index.
2025-12-08 15:27:54,613:INFO:Assigning column types.
2025-12-08 15:27:54,638:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-08 15:27:54,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:27:54,785:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 15:27:54,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:54,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:55,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 15:27:55,027:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 15:27:55,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:55,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:55,120:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-08 15:27:55,257:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 15:27:55,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:55,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:55,492:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 15:27:55,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:55,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:55,581:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-08 15:27:55,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:55,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:56,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:56,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:56,041:INFO:Preparing preprocessing pipeline...
2025-12-08 15:27:56,047:INFO:Set up simple imputation.
2025-12-08 15:27:56,047:INFO:Set up imbalanced handling.
2025-12-08 15:27:56,052:INFO:Set up column name cleaning.
2025-12-08 15:27:56,349:INFO:Finished creating preprocessing pipeline.
2025-12-08 15:27:56,368:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'selling_price',
                                             'km_driven', 'mileage', 'engine',
                                             'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Sec...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-08 15:27:56,369:INFO:Creating final display dataframe.
2025-12-08 15:27:56,627:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 17)
4        Transformed data shape           (11982, 17)
5   Transformed train set shape            (9610, 17)
6    Transformed test set shape            (2372, 17)
7              Numeric features                    16
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                Fix imbalance                  True
13         Fix imbalance method                 SMOTE
14               Fold Generator       StratifiedKFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment                 False
19              Experiment Name      clf-default-name
20                          USI                  1153
2025-12-08 15:27:56,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:56,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:57,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:57,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 15:27:57,086:INFO:setup() successfully completed in 2.55s...............
2025-12-08 15:27:57,092:INFO:Initializing compare_models()
2025-12-08 15:27:57,092:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-08 15:27:57,093:INFO:Checking exceptions
2025-12-08 15:27:57,110:INFO:Preparing display monitor
2025-12-08 15:27:57,197:INFO:Initializing Logistic Regression
2025-12-08 15:27:57,199:INFO:Total runtime is 2.7088324228922524e-05 minutes
2025-12-08 15:27:57,215:INFO:SubProcess create_model() called ==================================
2025-12-08 15:27:57,216:INFO:Initializing create_model()
2025-12-08 15:27:57,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:27:57,216:INFO:Checking exceptions
2025-12-08 15:27:57,216:INFO:Importing libraries
2025-12-08 15:27:57,218:INFO:Copying training dataset
2025-12-08 15:27:57,250:INFO:Defining folds
2025-12-08 15:27:57,250:INFO:Declaring metric variables
2025-12-08 15:27:57,264:INFO:Importing untrained model
2025-12-08 15:27:57,277:INFO:Logistic Regression Imported successfully
2025-12-08 15:27:57,310:INFO:Starting cross validation
2025-12-08 15:27:57,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:27:59,563:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:27:59,634:INFO:Calculating mean and std
2025-12-08 15:27:59,639:INFO:Creating metrics dataframe
2025-12-08 15:27:59,645:INFO:Uploading results into container
2025-12-08 15:27:59,647:INFO:Uploading model into container now
2025-12-08 15:27:59,648:INFO:_master_model_container: 1
2025-12-08 15:27:59,648:INFO:_display_container: 2
2025-12-08 15:27:59,650:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:27:59,650:INFO:create_model() successfully completed......................................
2025-12-08 15:27:59,819:INFO:SubProcess create_model() end ==================================
2025-12-08 15:27:59,820:INFO:Creating metrics dataframe
2025-12-08 15:27:59,842:INFO:Initializing K Neighbors Classifier
2025-12-08 15:27:59,842:INFO:Total runtime is 0.04408291180928548 minutes
2025-12-08 15:27:59,854:INFO:SubProcess create_model() called ==================================
2025-12-08 15:27:59,856:INFO:Initializing create_model()
2025-12-08 15:27:59,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:27:59,857:INFO:Checking exceptions
2025-12-08 15:27:59,857:INFO:Importing libraries
2025-12-08 15:27:59,857:INFO:Copying training dataset
2025-12-08 15:27:59,892:INFO:Defining folds
2025-12-08 15:27:59,892:INFO:Declaring metric variables
2025-12-08 15:27:59,907:INFO:Importing untrained model
2025-12-08 15:27:59,919:INFO:K Neighbors Classifier Imported successfully
2025-12-08 15:27:59,951:INFO:Starting cross validation
2025-12-08 15:27:59,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:00,539:INFO:Calculating mean and std
2025-12-08 15:28:00,543:INFO:Creating metrics dataframe
2025-12-08 15:28:00,551:INFO:Uploading results into container
2025-12-08 15:28:00,552:INFO:Uploading model into container now
2025-12-08 15:28:00,554:INFO:_master_model_container: 2
2025-12-08 15:28:00,555:INFO:_display_container: 2
2025-12-08 15:28:00,556:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-08 15:28:00,557:INFO:create_model() successfully completed......................................
2025-12-08 15:28:00,715:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:00,715:INFO:Creating metrics dataframe
2025-12-08 15:28:00,741:INFO:Initializing Naive Bayes
2025-12-08 15:28:00,741:INFO:Total runtime is 0.05907004276911418 minutes
2025-12-08 15:28:00,750:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:00,752:INFO:Initializing create_model()
2025-12-08 15:28:00,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:00,752:INFO:Checking exceptions
2025-12-08 15:28:00,752:INFO:Importing libraries
2025-12-08 15:28:00,753:INFO:Copying training dataset
2025-12-08 15:28:00,783:INFO:Defining folds
2025-12-08 15:28:00,783:INFO:Declaring metric variables
2025-12-08 15:28:00,798:INFO:Importing untrained model
2025-12-08 15:28:00,811:INFO:Naive Bayes Imported successfully
2025-12-08 15:28:00,842:INFO:Starting cross validation
2025-12-08 15:28:00,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:01,151:INFO:Calculating mean and std
2025-12-08 15:28:01,153:INFO:Creating metrics dataframe
2025-12-08 15:28:01,159:INFO:Uploading results into container
2025-12-08 15:28:01,161:INFO:Uploading model into container now
2025-12-08 15:28:01,162:INFO:_master_model_container: 3
2025-12-08 15:28:01,162:INFO:_display_container: 2
2025-12-08 15:28:01,163:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-08 15:28:01,164:INFO:create_model() successfully completed......................................
2025-12-08 15:28:01,311:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:01,311:INFO:Creating metrics dataframe
2025-12-08 15:28:01,335:INFO:Initializing Decision Tree Classifier
2025-12-08 15:28:01,335:INFO:Total runtime is 0.06896653970082602 minutes
2025-12-08 15:28:01,346:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:01,348:INFO:Initializing create_model()
2025-12-08 15:28:01,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:01,348:INFO:Checking exceptions
2025-12-08 15:28:01,349:INFO:Importing libraries
2025-12-08 15:28:01,350:INFO:Copying training dataset
2025-12-08 15:28:01,378:INFO:Defining folds
2025-12-08 15:28:01,378:INFO:Declaring metric variables
2025-12-08 15:28:01,391:INFO:Importing untrained model
2025-12-08 15:28:01,402:INFO:Decision Tree Classifier Imported successfully
2025-12-08 15:28:01,428:INFO:Starting cross validation
2025-12-08 15:28:01,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:01,800:INFO:Calculating mean and std
2025-12-08 15:28:01,802:INFO:Creating metrics dataframe
2025-12-08 15:28:01,807:INFO:Uploading results into container
2025-12-08 15:28:01,809:INFO:Uploading model into container now
2025-12-08 15:28:01,811:INFO:_master_model_container: 4
2025-12-08 15:28:01,811:INFO:_display_container: 2
2025-12-08 15:28:01,812:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-08 15:28:01,813:INFO:create_model() successfully completed......................................
2025-12-08 15:28:01,966:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:01,966:INFO:Creating metrics dataframe
2025-12-08 15:28:01,991:INFO:Initializing SVM - Linear Kernel
2025-12-08 15:28:01,993:INFO:Total runtime is 0.07992984453837078 minutes
2025-12-08 15:28:02,003:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:02,003:INFO:Initializing create_model()
2025-12-08 15:28:02,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:02,003:INFO:Checking exceptions
2025-12-08 15:28:02,003:INFO:Importing libraries
2025-12-08 15:28:02,005:INFO:Copying training dataset
2025-12-08 15:28:02,032:INFO:Defining folds
2025-12-08 15:28:02,033:INFO:Declaring metric variables
2025-12-08 15:28:02,047:INFO:Importing untrained model
2025-12-08 15:28:02,060:INFO:SVM - Linear Kernel Imported successfully
2025-12-08 15:28:02,087:INFO:Starting cross validation
2025-12-08 15:28:02,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:02,685:INFO:Calculating mean and std
2025-12-08 15:28:02,688:INFO:Creating metrics dataframe
2025-12-08 15:28:02,695:INFO:Uploading results into container
2025-12-08 15:28:02,697:INFO:Uploading model into container now
2025-12-08 15:28:02,698:INFO:_master_model_container: 5
2025-12-08 15:28:02,699:INFO:_display_container: 2
2025-12-08 15:28:02,701:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-08 15:28:02,701:INFO:create_model() successfully completed......................................
2025-12-08 15:28:02,864:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:02,865:INFO:Creating metrics dataframe
2025-12-08 15:28:02,893:INFO:Initializing Ridge Classifier
2025-12-08 15:28:02,893:INFO:Total runtime is 0.09494129419326783 minutes
2025-12-08 15:28:02,908:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:02,908:INFO:Initializing create_model()
2025-12-08 15:28:02,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:02,910:INFO:Checking exceptions
2025-12-08 15:28:02,910:INFO:Importing libraries
2025-12-08 15:28:02,911:INFO:Copying training dataset
2025-12-08 15:28:02,937:INFO:Defining folds
2025-12-08 15:28:02,938:INFO:Declaring metric variables
2025-12-08 15:28:02,949:INFO:Importing untrained model
2025-12-08 15:28:02,963:INFO:Ridge Classifier Imported successfully
2025-12-08 15:28:02,988:INFO:Starting cross validation
2025-12-08 15:28:02,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:03,155:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.07985e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,160:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97415e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,169:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.22879e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,185:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.76553e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,187:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.12855e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,192:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97653e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,193:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.25459e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,203:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.18612e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,211:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.84536e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.27127e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 15:28:03,303:INFO:Calculating mean and std
2025-12-08 15:28:03,306:INFO:Creating metrics dataframe
2025-12-08 15:28:03,313:INFO:Uploading results into container
2025-12-08 15:28:03,314:INFO:Uploading model into container now
2025-12-08 15:28:03,316:INFO:_master_model_container: 6
2025-12-08 15:28:03,316:INFO:_display_container: 2
2025-12-08 15:28:03,317:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-08 15:28:03,318:INFO:create_model() successfully completed......................................
2025-12-08 15:28:03,490:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:03,491:INFO:Creating metrics dataframe
2025-12-08 15:28:03,518:INFO:Initializing Random Forest Classifier
2025-12-08 15:28:03,518:INFO:Total runtime is 0.10534254709879558 minutes
2025-12-08 15:28:03,529:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:03,530:INFO:Initializing create_model()
2025-12-08 15:28:03,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:03,532:INFO:Checking exceptions
2025-12-08 15:28:03,532:INFO:Importing libraries
2025-12-08 15:28:03,532:INFO:Copying training dataset
2025-12-08 15:28:03,562:INFO:Defining folds
2025-12-08 15:28:03,563:INFO:Declaring metric variables
2025-12-08 15:28:03,578:INFO:Importing untrained model
2025-12-08 15:28:03,590:INFO:Random Forest Classifier Imported successfully
2025-12-08 15:28:03,615:INFO:Starting cross validation
2025-12-08 15:28:03,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:05,989:INFO:Calculating mean and std
2025-12-08 15:28:05,994:INFO:Creating metrics dataframe
2025-12-08 15:28:06,000:INFO:Uploading results into container
2025-12-08 15:28:06,002:INFO:Uploading model into container now
2025-12-08 15:28:06,003:INFO:_master_model_container: 7
2025-12-08 15:28:06,004:INFO:_display_container: 2
2025-12-08 15:28:06,005:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-08 15:28:06,006:INFO:create_model() successfully completed......................................
2025-12-08 15:28:06,149:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:06,149:INFO:Creating metrics dataframe
2025-12-08 15:28:06,176:INFO:Initializing Quadratic Discriminant Analysis
2025-12-08 15:28:06,176:INFO:Total runtime is 0.14965450763702393 minutes
2025-12-08 15:28:06,188:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:06,190:INFO:Initializing create_model()
2025-12-08 15:28:06,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:06,190:INFO:Checking exceptions
2025-12-08 15:28:06,190:INFO:Importing libraries
2025-12-08 15:28:06,190:INFO:Copying training dataset
2025-12-08 15:28:06,217:INFO:Defining folds
2025-12-08 15:28:06,217:INFO:Declaring metric variables
2025-12-08 15:28:06,232:INFO:Importing untrained model
2025-12-08 15:28:06,248:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-08 15:28:06,273:INFO:Starting cross validation
2025-12-08 15:28:06,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:06,433:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,434:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,443:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,445:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,457:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,457:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,457:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,457:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,465:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,465:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,466:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,466:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,466:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,466:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,466:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,466:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,469:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,469:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,470:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,471:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,474:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,474:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,475:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,476:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,477:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,477:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,478:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,479:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,481:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,481:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,483:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,486:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 15:28:06,488:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,489:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,489:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,489:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,489:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,489:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,489:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,491:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,491:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,491:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,493:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,493:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,494:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,494:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,498:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,498:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,498:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,498:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,499:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,499:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,499:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,500:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,501:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,501:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,501:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,502:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,504:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,507:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,510:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,510:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,510:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,510:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,511:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,512:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,515:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,515:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,515:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,517:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,518:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,519:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,519:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 15:28:06,519:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 15:28:06,527:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,529:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,532:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,535:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 15:28:06,535:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,537:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,546:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,555:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:06,589:INFO:Calculating mean and std
2025-12-08 15:28:06,593:INFO:Creating metrics dataframe
2025-12-08 15:28:06,599:INFO:Uploading results into container
2025-12-08 15:28:06,601:INFO:Uploading model into container now
2025-12-08 15:28:06,602:INFO:_master_model_container: 8
2025-12-08 15:28:06,602:INFO:_display_container: 2
2025-12-08 15:28:06,603:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-08 15:28:06,604:INFO:create_model() successfully completed......................................
2025-12-08 15:28:06,737:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:06,737:INFO:Creating metrics dataframe
2025-12-08 15:28:06,764:INFO:Initializing Ada Boost Classifier
2025-12-08 15:28:06,764:INFO:Total runtime is 0.15944551229476928 minutes
2025-12-08 15:28:06,775:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:06,777:INFO:Initializing create_model()
2025-12-08 15:28:06,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:06,777:INFO:Checking exceptions
2025-12-08 15:28:06,777:INFO:Importing libraries
2025-12-08 15:28:06,779:INFO:Copying training dataset
2025-12-08 15:28:06,803:INFO:Defining folds
2025-12-08 15:28:06,803:INFO:Declaring metric variables
2025-12-08 15:28:06,819:INFO:Importing untrained model
2025-12-08 15:28:06,834:INFO:Ada Boost Classifier Imported successfully
2025-12-08 15:28:06,853:INFO:Starting cross validation
2025-12-08 15:28:06,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:07,011:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,021:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,036:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,048:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,049:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,049:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,056:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,057:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:07,070:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 15:28:08,205:INFO:Calculating mean and std
2025-12-08 15:28:08,208:INFO:Creating metrics dataframe
2025-12-08 15:28:08,215:INFO:Uploading results into container
2025-12-08 15:28:08,216:INFO:Uploading model into container now
2025-12-08 15:28:08,218:INFO:_master_model_container: 9
2025-12-08 15:28:08,218:INFO:_display_container: 2
2025-12-08 15:28:08,220:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-08 15:28:08,221:INFO:create_model() successfully completed......................................
2025-12-08 15:28:08,358:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:08,359:INFO:Creating metrics dataframe
2025-12-08 15:28:08,390:INFO:Initializing Gradient Boosting Classifier
2025-12-08 15:28:08,390:INFO:Total runtime is 0.18654493490854898 minutes
2025-12-08 15:28:08,402:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:08,404:INFO:Initializing create_model()
2025-12-08 15:28:08,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:08,405:INFO:Checking exceptions
2025-12-08 15:28:08,406:INFO:Importing libraries
2025-12-08 15:28:08,406:INFO:Copying training dataset
2025-12-08 15:28:08,432:INFO:Defining folds
2025-12-08 15:28:08,432:INFO:Declaring metric variables
2025-12-08 15:28:08,443:INFO:Importing untrained model
2025-12-08 15:28:08,455:INFO:Gradient Boosting Classifier Imported successfully
2025-12-08 15:28:08,478:INFO:Starting cross validation
2025-12-08 15:28:08,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:11,970:INFO:Calculating mean and std
2025-12-08 15:28:11,975:INFO:Creating metrics dataframe
2025-12-08 15:28:11,981:INFO:Uploading results into container
2025-12-08 15:28:11,981:INFO:Uploading model into container now
2025-12-08 15:28:11,983:INFO:_master_model_container: 10
2025-12-08 15:28:11,983:INFO:_display_container: 2
2025-12-08 15:28:11,986:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-08 15:28:11,986:INFO:create_model() successfully completed......................................
2025-12-08 15:28:12,127:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:12,127:INFO:Creating metrics dataframe
2025-12-08 15:28:12,156:INFO:Initializing Linear Discriminant Analysis
2025-12-08 15:28:12,156:INFO:Total runtime is 0.2493159015973409 minutes
2025-12-08 15:28:12,165:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:12,167:INFO:Initializing create_model()
2025-12-08 15:28:12,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:12,167:INFO:Checking exceptions
2025-12-08 15:28:12,167:INFO:Importing libraries
2025-12-08 15:28:12,167:INFO:Copying training dataset
2025-12-08 15:28:12,191:INFO:Defining folds
2025-12-08 15:28:12,191:INFO:Declaring metric variables
2025-12-08 15:28:12,202:INFO:Importing untrained model
2025-12-08 15:28:12,213:INFO:Linear Discriminant Analysis Imported successfully
2025-12-08 15:28:12,240:INFO:Starting cross validation
2025-12-08 15:28:12,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:12,553:INFO:Calculating mean and std
2025-12-08 15:28:12,556:INFO:Creating metrics dataframe
2025-12-08 15:28:12,562:INFO:Uploading results into container
2025-12-08 15:28:12,564:INFO:Uploading model into container now
2025-12-08 15:28:12,564:INFO:_master_model_container: 11
2025-12-08 15:28:12,565:INFO:_display_container: 2
2025-12-08 15:28:12,567:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-08 15:28:12,567:INFO:create_model() successfully completed......................................
2025-12-08 15:28:12,719:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:12,719:INFO:Creating metrics dataframe
2025-12-08 15:28:12,750:INFO:Initializing Extra Trees Classifier
2025-12-08 15:28:12,750:INFO:Total runtime is 0.25921106735865274 minutes
2025-12-08 15:28:12,762:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:12,762:INFO:Initializing create_model()
2025-12-08 15:28:12,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:12,764:INFO:Checking exceptions
2025-12-08 15:28:12,764:INFO:Importing libraries
2025-12-08 15:28:12,764:INFO:Copying training dataset
2025-12-08 15:28:12,792:INFO:Defining folds
2025-12-08 15:28:12,792:INFO:Declaring metric variables
2025-12-08 15:28:12,805:INFO:Importing untrained model
2025-12-08 15:28:12,818:INFO:Extra Trees Classifier Imported successfully
2025-12-08 15:28:12,841:INFO:Starting cross validation
2025-12-08 15:28:12,844:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:14,787:INFO:Calculating mean and std
2025-12-08 15:28:14,792:INFO:Creating metrics dataframe
2025-12-08 15:28:14,800:INFO:Uploading results into container
2025-12-08 15:28:14,803:INFO:Uploading model into container now
2025-12-08 15:28:14,803:INFO:_master_model_container: 12
2025-12-08 15:28:14,803:INFO:_display_container: 2
2025-12-08 15:28:14,806:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-08 15:28:14,806:INFO:create_model() successfully completed......................................
2025-12-08 15:28:14,975:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:14,975:INFO:Creating metrics dataframe
2025-12-08 15:28:15,014:INFO:Initializing Light Gradient Boosting Machine
2025-12-08 15:28:15,014:INFO:Total runtime is 0.2969495375951131 minutes
2025-12-08 15:28:15,028:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:15,029:INFO:Initializing create_model()
2025-12-08 15:28:15,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:15,031:INFO:Checking exceptions
2025-12-08 15:28:15,031:INFO:Importing libraries
2025-12-08 15:28:15,032:INFO:Copying training dataset
2025-12-08 15:28:15,060:INFO:Defining folds
2025-12-08 15:28:15,060:INFO:Declaring metric variables
2025-12-08 15:28:15,073:INFO:Importing untrained model
2025-12-08 15:28:15,090:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 15:28:15,116:INFO:Starting cross validation
2025-12-08 15:28:15,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:17,917:INFO:Calculating mean and std
2025-12-08 15:28:17,921:INFO:Creating metrics dataframe
2025-12-08 15:28:17,926:INFO:Uploading results into container
2025-12-08 15:28:17,928:INFO:Uploading model into container now
2025-12-08 15:28:17,932:INFO:_master_model_container: 13
2025-12-08 15:28:17,934:INFO:_display_container: 2
2025-12-08 15:28:17,937:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 15:28:17,937:INFO:create_model() successfully completed......................................
2025-12-08 15:28:18,091:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:18,091:INFO:Creating metrics dataframe
2025-12-08 15:28:18,126:INFO:Initializing Dummy Classifier
2025-12-08 15:28:18,128:INFO:Total runtime is 0.34884440898895264 minutes
2025-12-08 15:28:18,138:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:18,140:INFO:Initializing create_model()
2025-12-08 15:28:18,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91E34CA00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:18,140:INFO:Checking exceptions
2025-12-08 15:28:18,140:INFO:Importing libraries
2025-12-08 15:28:18,141:INFO:Copying training dataset
2025-12-08 15:28:18,165:INFO:Defining folds
2025-12-08 15:28:18,165:INFO:Declaring metric variables
2025-12-08 15:28:18,178:INFO:Importing untrained model
2025-12-08 15:28:18,191:INFO:Dummy Classifier Imported successfully
2025-12-08 15:28:18,214:INFO:Starting cross validation
2025-12-08 15:28:18,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:18,415:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,431:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,434:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,439:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,445:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,446:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,457:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,469:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,469:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 15:28:18,496:INFO:Calculating mean and std
2025-12-08 15:28:18,499:INFO:Creating metrics dataframe
2025-12-08 15:28:18,505:INFO:Uploading results into container
2025-12-08 15:28:18,507:INFO:Uploading model into container now
2025-12-08 15:28:18,509:INFO:_master_model_container: 14
2025-12-08 15:28:18,509:INFO:_display_container: 2
2025-12-08 15:28:18,509:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-08 15:28:18,510:INFO:create_model() successfully completed......................................
2025-12-08 15:28:18,654:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:18,655:INFO:Creating metrics dataframe
2025-12-08 15:28:18,692:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-08 15:28:18,721:INFO:Initializing create_model()
2025-12-08 15:28:18,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:18,722:INFO:Checking exceptions
2025-12-08 15:28:18,727:INFO:Importing libraries
2025-12-08 15:28:18,728:INFO:Copying training dataset
2025-12-08 15:28:18,751:INFO:Defining folds
2025-12-08 15:28:18,751:INFO:Declaring metric variables
2025-12-08 15:28:18,752:INFO:Importing untrained model
2025-12-08 15:28:18,752:INFO:Declaring custom model
2025-12-08 15:28:18,755:INFO:Logistic Regression Imported successfully
2025-12-08 15:28:18,758:INFO:Cross validation set to False
2025-12-08 15:28:18,758:INFO:Fitting Model
2025-12-08 15:28:20,907:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:28:20,908:INFO:create_model() successfully completed......................................
2025-12-08 15:28:21,151:INFO:_master_model_container: 14
2025-12-08 15:28:21,151:INFO:_display_container: 2
2025-12-08 15:28:21,152:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:28:21,153:INFO:compare_models() successfully completed......................................
2025-12-08 15:28:21,158:INFO:Initializing tune_model()
2025-12-08 15:28:21,158:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>)
2025-12-08 15:28:21,158:INFO:Checking exceptions
2025-12-08 15:28:21,230:INFO:Copying training dataset
2025-12-08 15:28:21,249:INFO:Checking base model
2025-12-08 15:28:21,249:INFO:Base model : Logistic Regression
2025-12-08 15:28:21,263:INFO:Declaring metric variables
2025-12-08 15:28:21,279:INFO:Defining Hyperparameters
2025-12-08 15:28:21,458:INFO:Tuning with n_jobs=-1
2025-12-08 15:28:21,458:INFO:Initializing RandomizedSearchCV
2025-12-08 15:28:26,706:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:28:26,728:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:28:33,574:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:28:34,631:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:28:34,668:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-08 15:28:34,671:INFO:Hyperparameter search completed
2025-12-08 15:28:34,672:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:34,674:INFO:Initializing create_model()
2025-12-08 15:28:34,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A91F7EF5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-08 15:28:34,676:INFO:Checking exceptions
2025-12-08 15:28:34,676:INFO:Importing libraries
2025-12-08 15:28:34,676:INFO:Copying training dataset
2025-12-08 15:28:34,700:INFO:Defining folds
2025-12-08 15:28:34,700:INFO:Declaring metric variables
2025-12-08 15:28:34,712:INFO:Importing untrained model
2025-12-08 15:28:34,713:INFO:Declaring custom model
2025-12-08 15:28:34,725:INFO:Logistic Regression Imported successfully
2025-12-08 15:28:34,750:INFO:Starting cross validation
2025-12-08 15:28:34,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:36,878:INFO:Calculating mean and std
2025-12-08 15:28:36,881:INFO:Creating metrics dataframe
2025-12-08 15:28:36,898:INFO:Finalizing model
2025-12-08 15:28:39,499:INFO:Uploading results into container
2025-12-08 15:28:39,502:INFO:Uploading model into container now
2025-12-08 15:28:39,504:INFO:_master_model_container: 15
2025-12-08 15:28:39,506:INFO:_display_container: 3
2025-12-08 15:28:39,508:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:28:39,508:INFO:create_model() successfully completed......................................
2025-12-08 15:28:39,646:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:39,646:INFO:choose_better activated
2025-12-08 15:28:39,656:INFO:SubProcess create_model() called ==================================
2025-12-08 15:28:39,658:INFO:Initializing create_model()
2025-12-08 15:28:39,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A91C1BD510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 15:28:39,660:INFO:Checking exceptions
2025-12-08 15:28:39,663:INFO:Importing libraries
2025-12-08 15:28:39,663:INFO:Copying training dataset
2025-12-08 15:28:39,687:INFO:Defining folds
2025-12-08 15:28:39,687:INFO:Declaring metric variables
2025-12-08 15:28:39,688:INFO:Importing untrained model
2025-12-08 15:28:39,688:INFO:Declaring custom model
2025-12-08 15:28:39,690:INFO:Logistic Regression Imported successfully
2025-12-08 15:28:39,691:INFO:Starting cross validation
2025-12-08 15:28:39,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 15:28:41,614:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 15:28:41,683:INFO:Calculating mean and std
2025-12-08 15:28:41,684:INFO:Creating metrics dataframe
2025-12-08 15:28:41,689:INFO:Finalizing model
2025-12-08 15:28:43,763:INFO:Uploading results into container
2025-12-08 15:28:43,765:INFO:Uploading model into container now
2025-12-08 15:28:43,765:INFO:_master_model_container: 16
2025-12-08 15:28:43,765:INFO:_display_container: 4
2025-12-08 15:28:43,766:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:28:43,766:INFO:create_model() successfully completed......................................
2025-12-08 15:28:43,904:INFO:SubProcess create_model() end ==================================
2025-12-08 15:28:43,905:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-08 15:28:43,908:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-08 15:28:43,908:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-08 15:28:43,908:INFO:choose_better completed
2025-12-08 15:28:43,908:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-08 15:28:43,937:INFO:_master_model_container: 16
2025-12-08 15:28:43,938:INFO:_display_container: 3
2025-12-08 15:28:43,939:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 15:28:43,941:INFO:tune_model() successfully completed......................................
2025-12-08 19:57:03,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-08 19:57:03,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-08 19:57:03,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-08 19:57:03,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-08 19:57:04,364:INFO:PyCaret RegressionExperiment
2025-12-08 19:57:04,365:INFO:Logging name: reg-default-name
2025-12-08 19:57:04,365:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-08 19:57:04,365:INFO:version 3.3.2
2025-12-08 19:57:04,365:INFO:Initializing setup()
2025-12-08 19:57:04,365:INFO:self.USI: ac4a
2025-12-08 19:57:04,365:INFO:self._variable_keys: {'pipeline', 'y', 'seed', 'y_train', 'target_param', 'X_test', 'fold_groups_param', 'log_plots_param', 'data', 'memory', 'fold_generator', 'exp_name_log', 'gpu_n_jobs_param', 'transform_target_param', 'fold_shuffle_param', 'exp_id', '_available_plots', 'X_train', 'n_jobs_param', 'y_test', 'gpu_param', 'idx', 'html_param', '_ml_usecase', 'USI', 'X', 'logging_param'}
2025-12-08 19:57:04,365:INFO:Checking environment
2025-12-08 19:57:04,365:INFO:python_version: 3.10.19
2025-12-08 19:57:04,366:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-08 19:57:04,366:INFO:machine: AMD64
2025-12-08 19:57:04,366:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-08 19:57:04,367:INFO:Memory: svmem(total=33699516416, available=16450506752, percent=51.2, used=17249009664, free=16450506752)
2025-12-08 19:57:04,367:INFO:Physical Core: 8
2025-12-08 19:57:04,367:INFO:Logical Core: 16
2025-12-08 19:57:04,367:INFO:Checking libraries
2025-12-08 19:57:04,367:INFO:System:
2025-12-08 19:57:04,368:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-08 19:57:04,368:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-08 19:57:04,368:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-08 19:57:04,368:INFO:PyCaret required dependencies:
2025-12-08 19:57:04,370:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:04,457:INFO:                 pip: 25.3
2025-12-08 19:57:04,458:INFO:          setuptools: 80.9.0
2025-12-08 19:57:04,458:INFO:             pycaret: 3.3.2
2025-12-08 19:57:04,458:INFO:             IPython: 8.37.0
2025-12-08 19:57:04,458:INFO:          ipywidgets: 8.1.8
2025-12-08 19:57:04,458:INFO:                tqdm: 4.67.1
2025-12-08 19:57:04,458:INFO:               numpy: 1.26.4
2025-12-08 19:57:04,458:INFO:              pandas: 2.1.4
2025-12-08 19:57:04,458:INFO:              jinja2: 3.1.6
2025-12-08 19:57:04,459:INFO:               scipy: 1.11.4
2025-12-08 19:57:04,459:INFO:              joblib: 1.3.2
2025-12-08 19:57:04,459:INFO:             sklearn: 1.4.2
2025-12-08 19:57:04,459:INFO:                pyod: 2.0.6
2025-12-08 19:57:04,459:INFO:            imblearn: 0.14.0
2025-12-08 19:57:04,459:INFO:   category_encoders: 2.7.0
2025-12-08 19:57:04,459:INFO:            lightgbm: 4.6.0
2025-12-08 19:57:04,459:INFO:               numba: 0.62.1
2025-12-08 19:57:04,459:INFO:            requests: 2.32.5
2025-12-08 19:57:04,459:INFO:          matplotlib: 3.7.5
2025-12-08 19:57:04,459:INFO:          scikitplot: 0.3.7
2025-12-08 19:57:04,459:INFO:         yellowbrick: 1.5
2025-12-08 19:57:04,459:INFO:              plotly: 6.5.0
2025-12-08 19:57:04,460:INFO:    plotly-resampler: Not installed
2025-12-08 19:57:04,460:INFO:             kaleido: 1.2.0
2025-12-08 19:57:04,460:INFO:           schemdraw: 0.15
2025-12-08 19:57:04,461:INFO:         statsmodels: 0.14.5
2025-12-08 19:57:04,461:INFO:              sktime: 0.26.0
2025-12-08 19:57:04,461:INFO:               tbats: 1.1.3
2025-12-08 19:57:04,461:INFO:            pmdarima: 2.0.4
2025-12-08 19:57:04,461:INFO:              psutil: 7.1.3
2025-12-08 19:57:04,461:INFO:          markupsafe: 3.0.3
2025-12-08 19:57:04,461:INFO:             pickle5: Not installed
2025-12-08 19:57:04,461:INFO:         cloudpickle: 3.1.2
2025-12-08 19:57:04,461:INFO:         deprecation: 2.1.0
2025-12-08 19:57:04,461:INFO:              xxhash: 3.6.0
2025-12-08 19:57:04,462:INFO:           wurlitzer: Not installed
2025-12-08 19:57:04,462:INFO:PyCaret optional dependencies:
2025-12-08 19:57:04,488:INFO:                shap: Not installed
2025-12-08 19:57:04,488:INFO:           interpret: Not installed
2025-12-08 19:57:04,488:INFO:                umap: Not installed
2025-12-08 19:57:04,488:INFO:     ydata_profiling: Not installed
2025-12-08 19:57:04,488:INFO:  explainerdashboard: Not installed
2025-12-08 19:57:04,488:INFO:             autoviz: Not installed
2025-12-08 19:57:04,488:INFO:           fairlearn: Not installed
2025-12-08 19:57:04,488:INFO:          deepchecks: Not installed
2025-12-08 19:57:04,488:INFO:             xgboost: Not installed
2025-12-08 19:57:04,488:INFO:            catboost: Not installed
2025-12-08 19:57:04,488:INFO:              kmodes: Not installed
2025-12-08 19:57:04,488:INFO:             mlxtend: Not installed
2025-12-08 19:57:04,489:INFO:       statsforecast: Not installed
2025-12-08 19:57:04,489:INFO:        tune_sklearn: Not installed
2025-12-08 19:57:04,489:INFO:                 ray: Not installed
2025-12-08 19:57:04,489:INFO:            hyperopt: Not installed
2025-12-08 19:57:04,489:INFO:              optuna: Not installed
2025-12-08 19:57:04,490:INFO:               skopt: Not installed
2025-12-08 19:57:04,490:INFO:              mlflow: Not installed
2025-12-08 19:57:04,490:INFO:              gradio: Not installed
2025-12-08 19:57:04,490:INFO:             fastapi: Not installed
2025-12-08 19:57:04,490:INFO:             uvicorn: Not installed
2025-12-08 19:57:04,490:INFO:              m2cgen: Not installed
2025-12-08 19:57:04,490:INFO:           evidently: Not installed
2025-12-08 19:57:04,490:INFO:               fugue: Not installed
2025-12-08 19:57:04,490:INFO:           streamlit: Not installed
2025-12-08 19:57:04,490:INFO:             prophet: Not installed
2025-12-08 19:57:04,490:INFO:None
2025-12-08 19:57:04,490:INFO:Set up data.
2025-12-08 19:57:04,510:INFO:Set up folding strategy.
2025-12-08 19:57:04,512:INFO:Set up train/test split.
2025-12-08 19:57:04,524:INFO:Set up index.
2025-12-08 19:57:04,526:INFO:Assigning column types.
2025-12-08 19:57:04,542:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-08 19:57:04,542:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-08 19:57:04,555:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 19:57:04,567:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 19:57:04,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:04,860:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:57:04,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:04,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:04,863:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-08 19:57:04,874:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 19:57:04,886:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:05,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:05,155:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-08 19:57:05,167:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,180:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:05,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:05,481:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,494:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,661:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:05,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:05,772:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-08 19:57:05,798:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 19:57:05,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:06,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:06,088:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:06,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:06,358:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-08 19:57:06,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:06,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:06,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:57:06,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:06,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:06,944:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-08 19:57:07,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:07,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:07,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:07,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-08 19:57:07,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:07,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:07,551:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-08 19:57:07,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:07,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:08,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:08,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:08,180:INFO:Preparing preprocessing pipeline...
2025-12-08 19:57:08,180:INFO:Set up simple imputation.
2025-12-08 19:57:08,180:INFO:Set up feature normalization.
2025-12-08 19:57:08,182:INFO:Set up column name cleaning.
2025-12-08 19:57:08,337:INFO:Finished creating preprocessing pipeline.
2025-12-08 19:57:08,356:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'transmission_encoded',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner_Test Drive Car',
                                             'owner_Third Owner'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-12-08 19:57:08,357:INFO:Creating final display dataframe.
2025-12-08 19:57:08,703:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 17)
4        Transformed data shape        (7906, 17)
5   Transformed train set shape        (5534, 17)
6    Transformed test set shape        (2372, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              ac4a
2025-12-08 19:57:08,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:08,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:09,281:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:09,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:57:09,283:INFO:setup() successfully completed in 4.93s...............
2025-12-08 19:57:09,283:INFO:Initializing compare_models()
2025-12-08 19:57:09,283:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-08 19:57:09,283:INFO:Checking exceptions
2025-12-08 19:57:09,289:INFO:Preparing display monitor
2025-12-08 19:57:09,357:INFO:Initializing Linear Regression
2025-12-08 19:57:09,357:INFO:Total runtime is 0.0 minutes
2025-12-08 19:57:09,370:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:09,372:INFO:Initializing create_model()
2025-12-08 19:57:09,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:09,372:INFO:Checking exceptions
2025-12-08 19:57:09,372:INFO:Importing libraries
2025-12-08 19:57:09,372:INFO:Copying training dataset
2025-12-08 19:57:09,393:INFO:Defining folds
2025-12-08 19:57:09,393:INFO:Declaring metric variables
2025-12-08 19:57:09,404:INFO:Importing untrained model
2025-12-08 19:57:09,414:INFO:Linear Regression Imported successfully
2025-12-08 19:57:09,432:INFO:Starting cross validation
2025-12-08 19:57:09,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:19,626:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,639:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,644:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,645:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,647:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,652:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,655:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,662:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,678:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:19,703:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:20,302:INFO:Calculating mean and std
2025-12-08 19:57:20,305:INFO:Creating metrics dataframe
2025-12-08 19:57:20,313:INFO:Uploading results into container
2025-12-08 19:57:20,315:INFO:Uploading model into container now
2025-12-08 19:57:20,317:INFO:_master_model_container: 1
2025-12-08 19:57:20,318:INFO:_display_container: 2
2025-12-08 19:57:20,318:INFO:LinearRegression(n_jobs=-1)
2025-12-08 19:57:20,319:INFO:create_model() successfully completed......................................
2025-12-08 19:57:20,562:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:20,563:INFO:Creating metrics dataframe
2025-12-08 19:57:20,581:INFO:Initializing Lasso Regression
2025-12-08 19:57:20,581:INFO:Total runtime is 0.18705352147420248 minutes
2025-12-08 19:57:20,591:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:20,592:INFO:Initializing create_model()
2025-12-08 19:57:20,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:20,594:INFO:Checking exceptions
2025-12-08 19:57:20,594:INFO:Importing libraries
2025-12-08 19:57:20,594:INFO:Copying training dataset
2025-12-08 19:57:20,616:INFO:Defining folds
2025-12-08 19:57:20,617:INFO:Declaring metric variables
2025-12-08 19:57:20,626:INFO:Importing untrained model
2025-12-08 19:57:20,635:INFO:Lasso Regression Imported successfully
2025-12-08 19:57:20,653:INFO:Starting cross validation
2025-12-08 19:57:20,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:27,144:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:27,147:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:27,178:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:27,199:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:27,209:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:27,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 19:57:27,739:INFO:Calculating mean and std
2025-12-08 19:57:27,742:INFO:Creating metrics dataframe
2025-12-08 19:57:27,749:INFO:Uploading results into container
2025-12-08 19:57:27,750:INFO:Uploading model into container now
2025-12-08 19:57:27,752:INFO:_master_model_container: 2
2025-12-08 19:57:27,752:INFO:_display_container: 2
2025-12-08 19:57:27,754:INFO:Lasso(random_state=123)
2025-12-08 19:57:27,754:INFO:create_model() successfully completed......................................
2025-12-08 19:57:27,899:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:27,900:INFO:Creating metrics dataframe
2025-12-08 19:57:27,916:INFO:Initializing Ridge Regression
2025-12-08 19:57:27,917:INFO:Total runtime is 0.309313710530599 minutes
2025-12-08 19:57:27,928:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:27,959:INFO:Initializing create_model()
2025-12-08 19:57:27,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:27,960:INFO:Checking exceptions
2025-12-08 19:57:27,960:INFO:Importing libraries
2025-12-08 19:57:27,960:INFO:Copying training dataset
2025-12-08 19:57:27,978:INFO:Defining folds
2025-12-08 19:57:27,978:INFO:Declaring metric variables
2025-12-08 19:57:27,988:INFO:Importing untrained model
2025-12-08 19:57:27,999:INFO:Ridge Regression Imported successfully
2025-12-08 19:57:28,017:INFO:Starting cross validation
2025-12-08 19:57:28,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:28,240:INFO:Calculating mean and std
2025-12-08 19:57:28,242:INFO:Creating metrics dataframe
2025-12-08 19:57:28,246:INFO:Uploading results into container
2025-12-08 19:57:28,248:INFO:Uploading model into container now
2025-12-08 19:57:28,250:INFO:_master_model_container: 3
2025-12-08 19:57:28,250:INFO:_display_container: 2
2025-12-08 19:57:28,251:INFO:Ridge(random_state=123)
2025-12-08 19:57:28,251:INFO:create_model() successfully completed......................................
2025-12-08 19:57:28,377:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:28,377:INFO:Creating metrics dataframe
2025-12-08 19:57:28,395:INFO:Initializing Elastic Net
2025-12-08 19:57:28,395:INFO:Total runtime is 0.3172905445098877 minutes
2025-12-08 19:57:28,406:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:28,406:INFO:Initializing create_model()
2025-12-08 19:57:28,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:28,406:INFO:Checking exceptions
2025-12-08 19:57:28,407:INFO:Importing libraries
2025-12-08 19:57:28,407:INFO:Copying training dataset
2025-12-08 19:57:28,431:INFO:Defining folds
2025-12-08 19:57:28,432:INFO:Declaring metric variables
2025-12-08 19:57:28,441:INFO:Importing untrained model
2025-12-08 19:57:28,451:INFO:Elastic Net Imported successfully
2025-12-08 19:57:28,467:INFO:Starting cross validation
2025-12-08 19:57:28,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:28,770:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+12, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-08 19:57:28,810:INFO:Calculating mean and std
2025-12-08 19:57:28,812:INFO:Creating metrics dataframe
2025-12-08 19:57:28,815:INFO:Uploading results into container
2025-12-08 19:57:28,817:INFO:Uploading model into container now
2025-12-08 19:57:28,818:INFO:_master_model_container: 4
2025-12-08 19:57:28,818:INFO:_display_container: 2
2025-12-08 19:57:28,820:INFO:ElasticNet(random_state=123)
2025-12-08 19:57:28,820:INFO:create_model() successfully completed......................................
2025-12-08 19:57:28,944:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:28,944:INFO:Creating metrics dataframe
2025-12-08 19:57:28,960:INFO:Initializing Least Angle Regression
2025-12-08 19:57:28,962:INFO:Total runtime is 0.32674619754155476 minutes
2025-12-08 19:57:28,970:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:28,971:INFO:Initializing create_model()
2025-12-08 19:57:28,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:28,971:INFO:Checking exceptions
2025-12-08 19:57:28,972:INFO:Importing libraries
2025-12-08 19:57:28,972:INFO:Copying training dataset
2025-12-08 19:57:28,991:INFO:Defining folds
2025-12-08 19:57:28,991:INFO:Declaring metric variables
2025-12-08 19:57:29,001:INFO:Importing untrained model
2025-12-08 19:57:29,010:INFO:Least Angle Regression Imported successfully
2025-12-08 19:57:29,028:INFO:Starting cross validation
2025-12-08 19:57:29,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:29,271:INFO:Calculating mean and std
2025-12-08 19:57:29,273:INFO:Creating metrics dataframe
2025-12-08 19:57:29,277:INFO:Uploading results into container
2025-12-08 19:57:29,279:INFO:Uploading model into container now
2025-12-08 19:57:29,280:INFO:_master_model_container: 5
2025-12-08 19:57:29,281:INFO:_display_container: 2
2025-12-08 19:57:29,282:INFO:Lars(random_state=123)
2025-12-08 19:57:29,282:INFO:create_model() successfully completed......................................
2025-12-08 19:57:29,407:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:29,407:INFO:Creating metrics dataframe
2025-12-08 19:57:29,423:INFO:Initializing Lasso Least Angle Regression
2025-12-08 19:57:29,425:INFO:Total runtime is 0.3344566345214844 minutes
2025-12-08 19:57:29,434:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:29,435:INFO:Initializing create_model()
2025-12-08 19:57:29,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:29,436:INFO:Checking exceptions
2025-12-08 19:57:29,436:INFO:Importing libraries
2025-12-08 19:57:29,436:INFO:Copying training dataset
2025-12-08 19:57:29,454:INFO:Defining folds
2025-12-08 19:57:29,455:INFO:Declaring metric variables
2025-12-08 19:57:29,464:INFO:Importing untrained model
2025-12-08 19:57:29,473:INFO:Lasso Least Angle Regression Imported successfully
2025-12-08 19:57:29,490:INFO:Starting cross validation
2025-12-08 19:57:29,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:29,703:INFO:Calculating mean and std
2025-12-08 19:57:29,705:INFO:Creating metrics dataframe
2025-12-08 19:57:29,710:INFO:Uploading results into container
2025-12-08 19:57:29,712:INFO:Uploading model into container now
2025-12-08 19:57:29,712:INFO:_master_model_container: 6
2025-12-08 19:57:29,713:INFO:_display_container: 2
2025-12-08 19:57:29,714:INFO:LassoLars(random_state=123)
2025-12-08 19:57:29,715:INFO:create_model() successfully completed......................................
2025-12-08 19:57:29,840:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:29,840:INFO:Creating metrics dataframe
2025-12-08 19:57:29,857:INFO:Initializing Orthogonal Matching Pursuit
2025-12-08 19:57:29,858:INFO:Total runtime is 0.3416820446650187 minutes
2025-12-08 19:57:29,867:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:29,868:INFO:Initializing create_model()
2025-12-08 19:57:29,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:29,868:INFO:Checking exceptions
2025-12-08 19:57:29,869:INFO:Importing libraries
2025-12-08 19:57:29,870:INFO:Copying training dataset
2025-12-08 19:57:29,885:INFO:Defining folds
2025-12-08 19:57:29,887:INFO:Declaring metric variables
2025-12-08 19:57:29,896:INFO:Importing untrained model
2025-12-08 19:57:29,905:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-08 19:57:29,923:INFO:Starting cross validation
2025-12-08 19:57:29,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:30,152:INFO:Calculating mean and std
2025-12-08 19:57:30,155:INFO:Creating metrics dataframe
2025-12-08 19:57:30,158:INFO:Uploading results into container
2025-12-08 19:57:30,159:INFO:Uploading model into container now
2025-12-08 19:57:30,161:INFO:_master_model_container: 7
2025-12-08 19:57:30,161:INFO:_display_container: 2
2025-12-08 19:57:30,162:INFO:OrthogonalMatchingPursuit()
2025-12-08 19:57:30,163:INFO:create_model() successfully completed......................................
2025-12-08 19:57:30,289:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:30,290:INFO:Creating metrics dataframe
2025-12-08 19:57:30,310:INFO:Initializing Bayesian Ridge
2025-12-08 19:57:30,310:INFO:Total runtime is 0.34921772877375284 minutes
2025-12-08 19:57:30,319:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:30,320:INFO:Initializing create_model()
2025-12-08 19:57:30,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:30,320:INFO:Checking exceptions
2025-12-08 19:57:30,321:INFO:Importing libraries
2025-12-08 19:57:30,321:INFO:Copying training dataset
2025-12-08 19:57:30,339:INFO:Defining folds
2025-12-08 19:57:30,339:INFO:Declaring metric variables
2025-12-08 19:57:30,349:INFO:Importing untrained model
2025-12-08 19:57:30,360:INFO:Bayesian Ridge Imported successfully
2025-12-08 19:57:30,379:INFO:Starting cross validation
2025-12-08 19:57:30,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:30,638:INFO:Calculating mean and std
2025-12-08 19:57:30,640:INFO:Creating metrics dataframe
2025-12-08 19:57:30,645:INFO:Uploading results into container
2025-12-08 19:57:30,647:INFO:Uploading model into container now
2025-12-08 19:57:30,648:INFO:_master_model_container: 8
2025-12-08 19:57:30,648:INFO:_display_container: 2
2025-12-08 19:57:30,650:INFO:BayesianRidge()
2025-12-08 19:57:30,650:INFO:create_model() successfully completed......................................
2025-12-08 19:57:30,789:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:30,790:INFO:Creating metrics dataframe
2025-12-08 19:57:30,808:INFO:Initializing Passive Aggressive Regressor
2025-12-08 19:57:30,809:INFO:Total runtime is 0.3575237512588501 minutes
2025-12-08 19:57:30,817:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:30,819:INFO:Initializing create_model()
2025-12-08 19:57:30,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:30,819:INFO:Checking exceptions
2025-12-08 19:57:30,819:INFO:Importing libraries
2025-12-08 19:57:30,819:INFO:Copying training dataset
2025-12-08 19:57:30,838:INFO:Defining folds
2025-12-08 19:57:30,838:INFO:Declaring metric variables
2025-12-08 19:57:30,848:INFO:Importing untrained model
2025-12-08 19:57:30,856:INFO:Passive Aggressive Regressor Imported successfully
2025-12-08 19:57:30,873:INFO:Starting cross validation
2025-12-08 19:57:30,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:32,042:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,047:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,069:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,074:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,088:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,113:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,135:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,153:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,153:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-08 19:57:32,190:INFO:Calculating mean and std
2025-12-08 19:57:32,194:INFO:Creating metrics dataframe
2025-12-08 19:57:32,197:INFO:Uploading results into container
2025-12-08 19:57:32,197:INFO:Uploading model into container now
2025-12-08 19:57:32,199:INFO:_master_model_container: 9
2025-12-08 19:57:32,199:INFO:_display_container: 2
2025-12-08 19:57:32,201:INFO:PassiveAggressiveRegressor(random_state=123)
2025-12-08 19:57:32,201:INFO:create_model() successfully completed......................................
2025-12-08 19:57:32,331:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:32,331:INFO:Creating metrics dataframe
2025-12-08 19:57:32,360:INFO:Initializing Huber Regressor
2025-12-08 19:57:32,360:INFO:Total runtime is 0.38337327241897584 minutes
2025-12-08 19:57:32,369:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:32,371:INFO:Initializing create_model()
2025-12-08 19:57:32,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:32,372:INFO:Checking exceptions
2025-12-08 19:57:32,372:INFO:Importing libraries
2025-12-08 19:57:32,372:INFO:Copying training dataset
2025-12-08 19:57:32,390:INFO:Defining folds
2025-12-08 19:57:32,392:INFO:Declaring metric variables
2025-12-08 19:57:32,406:INFO:Importing untrained model
2025-12-08 19:57:32,418:INFO:Huber Regressor Imported successfully
2025-12-08 19:57:32,436:INFO:Starting cross validation
2025-12-08 19:57:32,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:32,807:INFO:Calculating mean and std
2025-12-08 19:57:32,810:INFO:Creating metrics dataframe
2025-12-08 19:57:32,815:INFO:Uploading results into container
2025-12-08 19:57:32,817:INFO:Uploading model into container now
2025-12-08 19:57:32,818:INFO:_master_model_container: 10
2025-12-08 19:57:32,818:INFO:_display_container: 2
2025-12-08 19:57:32,818:INFO:HuberRegressor()
2025-12-08 19:57:32,818:INFO:create_model() successfully completed......................................
2025-12-08 19:57:32,946:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:32,946:INFO:Creating metrics dataframe
2025-12-08 19:57:32,966:INFO:Initializing K Neighbors Regressor
2025-12-08 19:57:32,968:INFO:Total runtime is 0.3935038129488627 minutes
2025-12-08 19:57:32,976:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:32,978:INFO:Initializing create_model()
2025-12-08 19:57:32,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:32,978:INFO:Checking exceptions
2025-12-08 19:57:32,978:INFO:Importing libraries
2025-12-08 19:57:32,978:INFO:Copying training dataset
2025-12-08 19:57:32,996:INFO:Defining folds
2025-12-08 19:57:32,996:INFO:Declaring metric variables
2025-12-08 19:57:33,008:INFO:Importing untrained model
2025-12-08 19:57:33,018:INFO:K Neighbors Regressor Imported successfully
2025-12-08 19:57:33,038:INFO:Starting cross validation
2025-12-08 19:57:33,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:33,325:INFO:Calculating mean and std
2025-12-08 19:57:33,328:INFO:Creating metrics dataframe
2025-12-08 19:57:33,333:INFO:Uploading results into container
2025-12-08 19:57:33,334:INFO:Uploading model into container now
2025-12-08 19:57:33,336:INFO:_master_model_container: 11
2025-12-08 19:57:33,336:INFO:_display_container: 2
2025-12-08 19:57:33,336:INFO:KNeighborsRegressor(n_jobs=-1)
2025-12-08 19:57:33,338:INFO:create_model() successfully completed......................................
2025-12-08 19:57:33,465:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:33,465:INFO:Creating metrics dataframe
2025-12-08 19:57:33,485:INFO:Initializing Decision Tree Regressor
2025-12-08 19:57:33,488:INFO:Total runtime is 0.40216019153594973 minutes
2025-12-08 19:57:33,494:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:33,496:INFO:Initializing create_model()
2025-12-08 19:57:33,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:33,497:INFO:Checking exceptions
2025-12-08 19:57:33,497:INFO:Importing libraries
2025-12-08 19:57:33,497:INFO:Copying training dataset
2025-12-08 19:57:33,513:INFO:Defining folds
2025-12-08 19:57:33,513:INFO:Declaring metric variables
2025-12-08 19:57:33,522:INFO:Importing untrained model
2025-12-08 19:57:33,532:INFO:Decision Tree Regressor Imported successfully
2025-12-08 19:57:33,551:INFO:Starting cross validation
2025-12-08 19:57:33,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:33,841:INFO:Calculating mean and std
2025-12-08 19:57:33,844:INFO:Creating metrics dataframe
2025-12-08 19:57:33,848:INFO:Uploading results into container
2025-12-08 19:57:33,850:INFO:Uploading model into container now
2025-12-08 19:57:33,850:INFO:_master_model_container: 12
2025-12-08 19:57:33,850:INFO:_display_container: 2
2025-12-08 19:57:33,852:INFO:DecisionTreeRegressor(random_state=123)
2025-12-08 19:57:33,852:INFO:create_model() successfully completed......................................
2025-12-08 19:57:33,977:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:33,977:INFO:Creating metrics dataframe
2025-12-08 19:57:33,999:INFO:Initializing Random Forest Regressor
2025-12-08 19:57:33,999:INFO:Total runtime is 0.4106952667236328 minutes
2025-12-08 19:57:34,008:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:34,009:INFO:Initializing create_model()
2025-12-08 19:57:34,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:34,009:INFO:Checking exceptions
2025-12-08 19:57:34,009:INFO:Importing libraries
2025-12-08 19:57:34,011:INFO:Copying training dataset
2025-12-08 19:57:34,028:INFO:Defining folds
2025-12-08 19:57:34,029:INFO:Declaring metric variables
2025-12-08 19:57:34,037:INFO:Importing untrained model
2025-12-08 19:57:34,047:INFO:Random Forest Regressor Imported successfully
2025-12-08 19:57:34,067:INFO:Starting cross validation
2025-12-08 19:57:34,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:37,222:INFO:Calculating mean and std
2025-12-08 19:57:37,226:INFO:Creating metrics dataframe
2025-12-08 19:57:37,230:INFO:Uploading results into container
2025-12-08 19:57:37,231:INFO:Uploading model into container now
2025-12-08 19:57:37,232:INFO:_master_model_container: 13
2025-12-08 19:57:37,233:INFO:_display_container: 2
2025-12-08 19:57:37,234:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-12-08 19:57:37,234:INFO:create_model() successfully completed......................................
2025-12-08 19:57:37,389:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:37,389:INFO:Creating metrics dataframe
2025-12-08 19:57:37,419:INFO:Initializing Extra Trees Regressor
2025-12-08 19:57:37,419:INFO:Total runtime is 0.46768916845321656 minutes
2025-12-08 19:57:37,428:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:37,428:INFO:Initializing create_model()
2025-12-08 19:57:37,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:37,429:INFO:Checking exceptions
2025-12-08 19:57:37,429:INFO:Importing libraries
2025-12-08 19:57:37,430:INFO:Copying training dataset
2025-12-08 19:57:37,446:INFO:Defining folds
2025-12-08 19:57:37,448:INFO:Declaring metric variables
2025-12-08 19:57:37,458:INFO:Importing untrained model
2025-12-08 19:57:37,467:INFO:Extra Trees Regressor Imported successfully
2025-12-08 19:57:37,486:INFO:Starting cross validation
2025-12-08 19:57:37,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:39,874:INFO:Calculating mean and std
2025-12-08 19:57:39,878:INFO:Creating metrics dataframe
2025-12-08 19:57:39,883:INFO:Uploading results into container
2025-12-08 19:57:39,885:INFO:Uploading model into container now
2025-12-08 19:57:39,885:INFO:_master_model_container: 14
2025-12-08 19:57:39,885:INFO:_display_container: 2
2025-12-08 19:57:39,885:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-08 19:57:39,886:INFO:create_model() successfully completed......................................
2025-12-08 19:57:40,008:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:40,009:INFO:Creating metrics dataframe
2025-12-08 19:57:40,034:INFO:Initializing AdaBoost Regressor
2025-12-08 19:57:40,035:INFO:Total runtime is 0.5112898627916972 minutes
2025-12-08 19:57:40,045:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:40,046:INFO:Initializing create_model()
2025-12-08 19:57:40,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:40,046:INFO:Checking exceptions
2025-12-08 19:57:40,047:INFO:Importing libraries
2025-12-08 19:57:40,047:INFO:Copying training dataset
2025-12-08 19:57:40,068:INFO:Defining folds
2025-12-08 19:57:40,069:INFO:Declaring metric variables
2025-12-08 19:57:40,081:INFO:Importing untrained model
2025-12-08 19:57:40,091:INFO:AdaBoost Regressor Imported successfully
2025-12-08 19:57:40,112:INFO:Starting cross validation
2025-12-08 19:57:40,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:40,967:INFO:Calculating mean and std
2025-12-08 19:57:40,969:INFO:Creating metrics dataframe
2025-12-08 19:57:40,973:INFO:Uploading results into container
2025-12-08 19:57:40,975:INFO:Uploading model into container now
2025-12-08 19:57:40,977:INFO:_master_model_container: 15
2025-12-08 19:57:40,977:INFO:_display_container: 2
2025-12-08 19:57:40,978:INFO:AdaBoostRegressor(random_state=123)
2025-12-08 19:57:40,978:INFO:create_model() successfully completed......................................
2025-12-08 19:57:41,109:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:41,109:INFO:Creating metrics dataframe
2025-12-08 19:57:41,134:INFO:Initializing Gradient Boosting Regressor
2025-12-08 19:57:41,134:INFO:Total runtime is 0.529618239402771 minutes
2025-12-08 19:57:41,146:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:41,147:INFO:Initializing create_model()
2025-12-08 19:57:41,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:41,147:INFO:Checking exceptions
2025-12-08 19:57:41,147:INFO:Importing libraries
2025-12-08 19:57:41,147:INFO:Copying training dataset
2025-12-08 19:57:41,169:INFO:Defining folds
2025-12-08 19:57:41,170:INFO:Declaring metric variables
2025-12-08 19:57:41,180:INFO:Importing untrained model
2025-12-08 19:57:41,195:INFO:Gradient Boosting Regressor Imported successfully
2025-12-08 19:57:41,216:INFO:Starting cross validation
2025-12-08 19:57:41,221:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:42,469:INFO:Calculating mean and std
2025-12-08 19:57:42,472:INFO:Creating metrics dataframe
2025-12-08 19:57:42,476:INFO:Uploading results into container
2025-12-08 19:57:42,477:INFO:Uploading model into container now
2025-12-08 19:57:42,479:INFO:_master_model_container: 16
2025-12-08 19:57:42,479:INFO:_display_container: 2
2025-12-08 19:57:42,481:INFO:GradientBoostingRegressor(random_state=123)
2025-12-08 19:57:42,481:INFO:create_model() successfully completed......................................
2025-12-08 19:57:42,611:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:42,611:INFO:Creating metrics dataframe
2025-12-08 19:57:42,633:INFO:Initializing Light Gradient Boosting Machine
2025-12-08 19:57:42,634:INFO:Total runtime is 0.5546154499053955 minutes
2025-12-08 19:57:42,642:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:42,642:INFO:Initializing create_model()
2025-12-08 19:57:42,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:42,644:INFO:Checking exceptions
2025-12-08 19:57:42,644:INFO:Importing libraries
2025-12-08 19:57:42,644:INFO:Copying training dataset
2025-12-08 19:57:42,660:INFO:Defining folds
2025-12-08 19:57:42,661:INFO:Declaring metric variables
2025-12-08 19:57:42,672:INFO:Importing untrained model
2025-12-08 19:57:42,682:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 19:57:42,698:INFO:Starting cross validation
2025-12-08 19:57:42,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:44,635:INFO:Calculating mean and std
2025-12-08 19:57:44,638:INFO:Creating metrics dataframe
2025-12-08 19:57:44,644:INFO:Uploading results into container
2025-12-08 19:57:44,646:INFO:Uploading model into container now
2025-12-08 19:57:44,647:INFO:_master_model_container: 17
2025-12-08 19:57:44,647:INFO:_display_container: 2
2025-12-08 19:57:44,649:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 19:57:44,649:INFO:create_model() successfully completed......................................
2025-12-08 19:57:44,796:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:44,797:INFO:Creating metrics dataframe
2025-12-08 19:57:44,824:INFO:Initializing Dummy Regressor
2025-12-08 19:57:44,824:INFO:Total runtime is 0.5911139329274495 minutes
2025-12-08 19:57:44,835:INFO:SubProcess create_model() called ==================================
2025-12-08 19:57:44,835:INFO:Initializing create_model()
2025-12-08 19:57:44,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026559FC7130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:44,837:INFO:Checking exceptions
2025-12-08 19:57:44,838:INFO:Importing libraries
2025-12-08 19:57:44,838:INFO:Copying training dataset
2025-12-08 19:57:44,856:INFO:Defining folds
2025-12-08 19:57:44,858:INFO:Declaring metric variables
2025-12-08 19:57:44,868:INFO:Importing untrained model
2025-12-08 19:57:44,879:INFO:Dummy Regressor Imported successfully
2025-12-08 19:57:44,921:INFO:Starting cross validation
2025-12-08 19:57:44,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:57:45,168:INFO:Calculating mean and std
2025-12-08 19:57:45,169:INFO:Creating metrics dataframe
2025-12-08 19:57:45,174:INFO:Uploading results into container
2025-12-08 19:57:45,174:INFO:Uploading model into container now
2025-12-08 19:57:45,177:INFO:_master_model_container: 18
2025-12-08 19:57:45,177:INFO:_display_container: 2
2025-12-08 19:57:45,178:INFO:DummyRegressor()
2025-12-08 19:57:45,179:INFO:create_model() successfully completed......................................
2025-12-08 19:57:45,308:INFO:SubProcess create_model() end ==================================
2025-12-08 19:57:45,308:INFO:Creating metrics dataframe
2025-12-08 19:57:45,340:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-08 19:57:45,364:INFO:Initializing create_model()
2025-12-08 19:57:45,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:57:45,365:INFO:Checking exceptions
2025-12-08 19:57:45,368:INFO:Importing libraries
2025-12-08 19:57:45,368:INFO:Copying training dataset
2025-12-08 19:57:45,386:INFO:Defining folds
2025-12-08 19:57:45,386:INFO:Declaring metric variables
2025-12-08 19:57:45,386:INFO:Importing untrained model
2025-12-08 19:57:45,386:INFO:Declaring custom model
2025-12-08 19:57:45,389:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 19:57:45,391:INFO:Cross validation set to False
2025-12-08 19:57:45,391:INFO:Fitting Model
2025-12-08 19:57:45,443:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 19:57:45,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001127 seconds.
2025-12-08 19:57:45,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 19:57:45,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 19:57:45,447:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 19:57:45,447:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 19:57:45,449:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 19:57:45,712:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 19:57:45,712:INFO:create_model() successfully completed......................................
2025-12-08 19:57:45,927:INFO:_master_model_container: 18
2025-12-08 19:57:45,929:INFO:_display_container: 2
2025-12-08 19:57:45,930:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 19:57:45,930:INFO:compare_models() successfully completed......................................
2025-12-08 19:57:45,931:INFO:Initializing tune_model()
2025-12-08 19:57:45,933:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>)
2025-12-08 19:57:45,934:INFO:Checking exceptions
2025-12-08 19:57:45,973:INFO:Copying training dataset
2025-12-08 19:57:45,989:INFO:Checking base model
2025-12-08 19:57:45,990:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 19:57:45,999:INFO:Declaring metric variables
2025-12-08 19:57:46,008:INFO:Defining Hyperparameters
2025-12-08 19:57:46,146:INFO:Tuning with n_jobs=-1
2025-12-08 19:57:46,148:INFO:Initializing RandomizedSearchCV
2025-12-08 19:58:12,360:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-08 19:58:12,362:INFO:Hyperparameter search completed
2025-12-08 19:58:12,364:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:12,365:INFO:Initializing create_model()
2025-12-08 19:58:12,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265588D9C00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-08 19:58:12,365:INFO:Checking exceptions
2025-12-08 19:58:12,367:INFO:Importing libraries
2025-12-08 19:58:12,368:INFO:Copying training dataset
2025-12-08 19:58:12,392:INFO:Defining folds
2025-12-08 19:58:12,392:INFO:Declaring metric variables
2025-12-08 19:58:12,405:INFO:Importing untrained model
2025-12-08 19:58:12,407:INFO:Declaring custom model
2025-12-08 19:58:12,426:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 19:58:12,448:INFO:Starting cross validation
2025-12-08 19:58:12,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:14,220:INFO:Calculating mean and std
2025-12-08 19:58:14,223:INFO:Creating metrics dataframe
2025-12-08 19:58:14,239:INFO:Finalizing model
2025-12-08 19:58:14,285:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-08 19:58:14,285:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-08 19:58:14,285:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-08 19:58:14,295:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 19:58:14,295:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-08 19:58:14,295:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-08 19:58:14,296:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-08 19:58:14,298:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.
2025-12-08 19:58:14,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 19:58:14,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 19:58:14,299:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 19:58:14,300:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 19:58:14,300:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 19:58:14,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 19:58:14,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 19:58:14,548:INFO:Uploading results into container
2025-12-08 19:58:14,550:INFO:Uploading model into container now
2025-12-08 19:58:14,551:INFO:_master_model_container: 19
2025-12-08 19:58:14,552:INFO:_display_container: 3
2025-12-08 19:58:14,555:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005)
2025-12-08 19:58:14,556:INFO:create_model() successfully completed......................................
2025-12-08 19:58:14,707:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:14,707:INFO:choose_better activated
2025-12-08 19:58:14,716:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:14,717:INFO:Initializing create_model()
2025-12-08 19:58:14,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000265542EEA70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:14,719:INFO:Checking exceptions
2025-12-08 19:58:14,725:INFO:Importing libraries
2025-12-08 19:58:14,725:INFO:Copying training dataset
2025-12-08 19:58:14,744:INFO:Defining folds
2025-12-08 19:58:14,744:INFO:Declaring metric variables
2025-12-08 19:58:14,745:INFO:Importing untrained model
2025-12-08 19:58:14,745:INFO:Declaring custom model
2025-12-08 19:58:14,748:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 19:58:14,748:INFO:Starting cross validation
2025-12-08 19:58:14,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:16,721:INFO:Calculating mean and std
2025-12-08 19:58:16,722:INFO:Creating metrics dataframe
2025-12-08 19:58:16,727:INFO:Finalizing model
2025-12-08 19:58:16,778:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 19:58:16,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001195 seconds.
2025-12-08 19:58:16,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-08 19:58:16,781:INFO:[LightGBM] [Info] Total Bins 874
2025-12-08 19:58:16,781:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-08 19:58:16,781:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-08 19:58:17,033:INFO:Uploading results into container
2025-12-08 19:58:17,035:INFO:Uploading model into container now
2025-12-08 19:58:17,036:INFO:_master_model_container: 20
2025-12-08 19:58:17,036:INFO:_display_container: 4
2025-12-08 19:58:17,037:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 19:58:17,037:INFO:create_model() successfully completed......................................
2025-12-08 19:58:17,185:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:17,193:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9584
2025-12-08 19:58:17,195:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005) result for R2 is 0.9462
2025-12-08 19:58:17,196:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-12-08 19:58:17,196:INFO:choose_better completed
2025-12-08 19:58:17,196:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-08 19:58:17,220:INFO:_master_model_container: 20
2025-12-08 19:58:17,222:INFO:_display_container: 3
2025-12-08 19:58:17,223:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-08 19:58:17,223:INFO:tune_model() successfully completed......................................
2025-12-08 19:58:17,386:INFO:PyCaret ClassificationExperiment
2025-12-08 19:58:17,386:INFO:Logging name: clf-default-name
2025-12-08 19:58:17,386:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-08 19:58:17,386:INFO:version 3.3.2
2025-12-08 19:58:17,386:INFO:Initializing setup()
2025-12-08 19:58:17,386:INFO:self.USI: 751d
2025-12-08 19:58:17,386:INFO:self._variable_keys: {'pipeline', 'y', 'seed', 'y_train', 'target_param', 'X_test', 'fold_groups_param', 'fix_imbalance', 'log_plots_param', 'data', 'memory', 'fold_generator', 'exp_name_log', 'gpu_n_jobs_param', 'is_multiclass', 'fold_shuffle_param', 'exp_id', '_available_plots', 'X_train', 'n_jobs_param', 'y_test', 'gpu_param', 'idx', 'html_param', '_ml_usecase', 'USI', 'X', 'logging_param'}
2025-12-08 19:58:17,386:INFO:Checking environment
2025-12-08 19:58:17,387:INFO:python_version: 3.10.19
2025-12-08 19:58:17,387:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-08 19:58:17,387:INFO:machine: AMD64
2025-12-08 19:58:17,387:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-08 19:58:17,388:INFO:Memory: svmem(total=33699516416, available=14493802496, percent=57.0, used=19205713920, free=14493802496)
2025-12-08 19:58:17,388:INFO:Physical Core: 8
2025-12-08 19:58:17,388:INFO:Logical Core: 16
2025-12-08 19:58:17,388:INFO:Checking libraries
2025-12-08 19:58:17,388:INFO:System:
2025-12-08 19:58:17,388:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-08 19:58:17,388:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-08 19:58:17,388:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-08 19:58:17,388:INFO:PyCaret required dependencies:
2025-12-08 19:58:17,389:INFO:                 pip: 25.3
2025-12-08 19:58:17,389:INFO:          setuptools: 80.9.0
2025-12-08 19:58:17,389:INFO:             pycaret: 3.3.2
2025-12-08 19:58:17,389:INFO:             IPython: 8.37.0
2025-12-08 19:58:17,389:INFO:          ipywidgets: 8.1.8
2025-12-08 19:58:17,389:INFO:                tqdm: 4.67.1
2025-12-08 19:58:17,389:INFO:               numpy: 1.26.4
2025-12-08 19:58:17,389:INFO:              pandas: 2.1.4
2025-12-08 19:58:17,389:INFO:              jinja2: 3.1.6
2025-12-08 19:58:17,389:INFO:               scipy: 1.11.4
2025-12-08 19:58:17,390:INFO:              joblib: 1.3.2
2025-12-08 19:58:17,390:INFO:             sklearn: 1.4.2
2025-12-08 19:58:17,390:INFO:                pyod: 2.0.6
2025-12-08 19:58:17,390:INFO:            imblearn: 0.14.0
2025-12-08 19:58:17,390:INFO:   category_encoders: 2.7.0
2025-12-08 19:58:17,390:INFO:            lightgbm: 4.6.0
2025-12-08 19:58:17,390:INFO:               numba: 0.62.1
2025-12-08 19:58:17,390:INFO:            requests: 2.32.5
2025-12-08 19:58:17,390:INFO:          matplotlib: 3.7.5
2025-12-08 19:58:17,390:INFO:          scikitplot: 0.3.7
2025-12-08 19:58:17,390:INFO:         yellowbrick: 1.5
2025-12-08 19:58:17,390:INFO:              plotly: 6.5.0
2025-12-08 19:58:17,390:INFO:    plotly-resampler: Not installed
2025-12-08 19:58:17,391:INFO:             kaleido: 1.2.0
2025-12-08 19:58:17,391:INFO:           schemdraw: 0.15
2025-12-08 19:58:17,391:INFO:         statsmodels: 0.14.5
2025-12-08 19:58:17,392:INFO:              sktime: 0.26.0
2025-12-08 19:58:17,392:INFO:               tbats: 1.1.3
2025-12-08 19:58:17,392:INFO:            pmdarima: 2.0.4
2025-12-08 19:58:17,392:INFO:              psutil: 7.1.3
2025-12-08 19:58:17,392:INFO:          markupsafe: 3.0.3
2025-12-08 19:58:17,392:INFO:             pickle5: Not installed
2025-12-08 19:58:17,393:INFO:         cloudpickle: 3.1.2
2025-12-08 19:58:17,393:INFO:         deprecation: 2.1.0
2025-12-08 19:58:17,393:INFO:              xxhash: 3.6.0
2025-12-08 19:58:17,393:INFO:           wurlitzer: Not installed
2025-12-08 19:58:17,393:INFO:PyCaret optional dependencies:
2025-12-08 19:58:17,393:INFO:                shap: Not installed
2025-12-08 19:58:17,393:INFO:           interpret: Not installed
2025-12-08 19:58:17,393:INFO:                umap: Not installed
2025-12-08 19:58:17,393:INFO:     ydata_profiling: Not installed
2025-12-08 19:58:17,393:INFO:  explainerdashboard: Not installed
2025-12-08 19:58:17,393:INFO:             autoviz: Not installed
2025-12-08 19:58:17,393:INFO:           fairlearn: Not installed
2025-12-08 19:58:17,395:INFO:          deepchecks: Not installed
2025-12-08 19:58:17,395:INFO:             xgboost: Not installed
2025-12-08 19:58:17,395:INFO:            catboost: Not installed
2025-12-08 19:58:17,395:INFO:              kmodes: Not installed
2025-12-08 19:58:17,395:INFO:             mlxtend: Not installed
2025-12-08 19:58:17,395:INFO:       statsforecast: Not installed
2025-12-08 19:58:17,395:INFO:        tune_sklearn: Not installed
2025-12-08 19:58:17,395:INFO:                 ray: Not installed
2025-12-08 19:58:17,395:INFO:            hyperopt: Not installed
2025-12-08 19:58:17,395:INFO:              optuna: Not installed
2025-12-08 19:58:17,395:INFO:               skopt: Not installed
2025-12-08 19:58:17,395:INFO:              mlflow: Not installed
2025-12-08 19:58:17,396:INFO:              gradio: Not installed
2025-12-08 19:58:17,396:INFO:             fastapi: Not installed
2025-12-08 19:58:17,396:INFO:             uvicorn: Not installed
2025-12-08 19:58:17,396:INFO:              m2cgen: Not installed
2025-12-08 19:58:17,396:INFO:           evidently: Not installed
2025-12-08 19:58:17,396:INFO:               fugue: Not installed
2025-12-08 19:58:17,396:INFO:           streamlit: Not installed
2025-12-08 19:58:17,396:INFO:             prophet: Not installed
2025-12-08 19:58:17,396:INFO:None
2025-12-08 19:58:17,396:INFO:Set up data.
2025-12-08 19:58:17,417:INFO:Set up folding strategy.
2025-12-08 19:58:17,417:INFO:Set up train/test split.
2025-12-08 19:58:17,434:INFO:Set up index.
2025-12-08 19:58:17,435:INFO:Assigning column types.
2025-12-08 19:58:17,451:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-08 19:58:17,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:58:17,564:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 19:58:17,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:17,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:17,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-08 19:58:17,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 19:58:17,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:17,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:17,863:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-08 19:58:17,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 19:58:18,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:18,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:18,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-08 19:58:18,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:18,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:18,232:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-08 19:58:18,421:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:18,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:18,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:18,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:18,612:INFO:Preparing preprocessing pipeline...
2025-12-08 19:58:18,615:INFO:Set up simple imputation.
2025-12-08 19:58:18,615:INFO:Set up imbalanced handling.
2025-12-08 19:58:18,618:INFO:Set up column name cleaning.
2025-12-08 19:58:18,741:INFO:Finished creating preprocessing pipeline.
2025-12-08 19:58:18,759:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'selling_price',
                                             'km_driven', 'mileage', 'engine',
                                             'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Sec...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-08 19:58:18,759:INFO:Creating final display dataframe.
2025-12-08 19:58:19,055:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 17)
4        Transformed data shape           (11982, 17)
5   Transformed train set shape            (9610, 17)
6    Transformed test set shape            (2372, 17)
7              Numeric features                    16
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                Fix imbalance                  True
13         Fix imbalance method                 SMOTE
14               Fold Generator       StratifiedKFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment                 False
19              Experiment Name      clf-default-name
20                          USI                  751d
2025-12-08 19:58:19,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:19,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:19,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:19,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-08 19:58:19,453:INFO:setup() successfully completed in 2.07s...............
2025-12-08 19:58:19,453:INFO:Initializing compare_models()
2025-12-08 19:58:19,453:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-08 19:58:19,453:INFO:Checking exceptions
2025-12-08 19:58:19,466:INFO:Preparing display monitor
2025-12-08 19:58:19,531:INFO:Initializing Logistic Regression
2025-12-08 19:58:19,532:INFO:Total runtime is 2.367893854777018e-05 minutes
2025-12-08 19:58:19,542:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:19,543:INFO:Initializing create_model()
2025-12-08 19:58:19,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:19,543:INFO:Checking exceptions
2025-12-08 19:58:19,543:INFO:Importing libraries
2025-12-08 19:58:19,543:INFO:Copying training dataset
2025-12-08 19:58:19,560:INFO:Defining folds
2025-12-08 19:58:19,560:INFO:Declaring metric variables
2025-12-08 19:58:19,568:INFO:Importing untrained model
2025-12-08 19:58:19,577:INFO:Logistic Regression Imported successfully
2025-12-08 19:58:19,594:INFO:Starting cross validation
2025-12-08 19:58:19,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:21,307:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 19:58:21,376:INFO:Calculating mean and std
2025-12-08 19:58:21,380:INFO:Creating metrics dataframe
2025-12-08 19:58:21,386:INFO:Uploading results into container
2025-12-08 19:58:21,388:INFO:Uploading model into container now
2025-12-08 19:58:21,390:INFO:_master_model_container: 1
2025-12-08 19:58:21,390:INFO:_display_container: 2
2025-12-08 19:58:21,394:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 19:58:21,394:INFO:create_model() successfully completed......................................
2025-12-08 19:58:21,532:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:21,532:INFO:Creating metrics dataframe
2025-12-08 19:58:21,547:INFO:Initializing K Neighbors Classifier
2025-12-08 19:58:21,547:INFO:Total runtime is 0.03360369205474854 minutes
2025-12-08 19:58:21,556:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:21,557:INFO:Initializing create_model()
2025-12-08 19:58:21,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:21,558:INFO:Checking exceptions
2025-12-08 19:58:21,558:INFO:Importing libraries
2025-12-08 19:58:21,559:INFO:Copying training dataset
2025-12-08 19:58:21,578:INFO:Defining folds
2025-12-08 19:58:21,579:INFO:Declaring metric variables
2025-12-08 19:58:21,587:INFO:Importing untrained model
2025-12-08 19:58:21,598:INFO:K Neighbors Classifier Imported successfully
2025-12-08 19:58:21,617:INFO:Starting cross validation
2025-12-08 19:58:21,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:22,070:INFO:Calculating mean and std
2025-12-08 19:58:22,073:INFO:Creating metrics dataframe
2025-12-08 19:58:22,077:INFO:Uploading results into container
2025-12-08 19:58:22,079:INFO:Uploading model into container now
2025-12-08 19:58:22,079:INFO:_master_model_container: 2
2025-12-08 19:58:22,079:INFO:_display_container: 2
2025-12-08 19:58:22,081:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-08 19:58:22,081:INFO:create_model() successfully completed......................................
2025-12-08 19:58:22,215:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:22,216:INFO:Creating metrics dataframe
2025-12-08 19:58:22,234:INFO:Initializing Naive Bayes
2025-12-08 19:58:22,234:INFO:Total runtime is 0.04506080945332845 minutes
2025-12-08 19:58:22,244:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:22,245:INFO:Initializing create_model()
2025-12-08 19:58:22,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:22,245:INFO:Checking exceptions
2025-12-08 19:58:22,246:INFO:Importing libraries
2025-12-08 19:58:22,246:INFO:Copying training dataset
2025-12-08 19:58:22,265:INFO:Defining folds
2025-12-08 19:58:22,265:INFO:Declaring metric variables
2025-12-08 19:58:22,277:INFO:Importing untrained model
2025-12-08 19:58:22,286:INFO:Naive Bayes Imported successfully
2025-12-08 19:58:22,306:INFO:Starting cross validation
2025-12-08 19:58:22,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:22,602:INFO:Calculating mean and std
2025-12-08 19:58:22,604:INFO:Creating metrics dataframe
2025-12-08 19:58:22,609:INFO:Uploading results into container
2025-12-08 19:58:22,610:INFO:Uploading model into container now
2025-12-08 19:58:22,611:INFO:_master_model_container: 3
2025-12-08 19:58:22,612:INFO:_display_container: 2
2025-12-08 19:58:22,613:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-08 19:58:22,613:INFO:create_model() successfully completed......................................
2025-12-08 19:58:22,740:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:22,742:INFO:Creating metrics dataframe
2025-12-08 19:58:22,757:INFO:Initializing Decision Tree Classifier
2025-12-08 19:58:22,758:INFO:Total runtime is 0.053783126672108966 minutes
2025-12-08 19:58:22,765:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:22,765:INFO:Initializing create_model()
2025-12-08 19:58:22,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:22,767:INFO:Checking exceptions
2025-12-08 19:58:22,768:INFO:Importing libraries
2025-12-08 19:58:22,768:INFO:Copying training dataset
2025-12-08 19:58:22,787:INFO:Defining folds
2025-12-08 19:58:22,789:INFO:Declaring metric variables
2025-12-08 19:58:22,800:INFO:Importing untrained model
2025-12-08 19:58:22,811:INFO:Decision Tree Classifier Imported successfully
2025-12-08 19:58:22,828:INFO:Starting cross validation
2025-12-08 19:58:22,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:23,174:INFO:Calculating mean and std
2025-12-08 19:58:23,177:INFO:Creating metrics dataframe
2025-12-08 19:58:23,180:INFO:Uploading results into container
2025-12-08 19:58:23,181:INFO:Uploading model into container now
2025-12-08 19:58:23,183:INFO:_master_model_container: 4
2025-12-08 19:58:23,184:INFO:_display_container: 2
2025-12-08 19:58:23,184:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-08 19:58:23,186:INFO:create_model() successfully completed......................................
2025-12-08 19:58:23,311:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:23,312:INFO:Creating metrics dataframe
2025-12-08 19:58:23,328:INFO:Initializing SVM - Linear Kernel
2025-12-08 19:58:23,328:INFO:Total runtime is 0.06329134305318196 minutes
2025-12-08 19:58:23,336:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:23,336:INFO:Initializing create_model()
2025-12-08 19:58:23,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:23,336:INFO:Checking exceptions
2025-12-08 19:58:23,337:INFO:Importing libraries
2025-12-08 19:58:23,337:INFO:Copying training dataset
2025-12-08 19:58:23,353:INFO:Defining folds
2025-12-08 19:58:23,354:INFO:Declaring metric variables
2025-12-08 19:58:23,364:INFO:Importing untrained model
2025-12-08 19:58:23,372:INFO:SVM - Linear Kernel Imported successfully
2025-12-08 19:58:23,391:INFO:Starting cross validation
2025-12-08 19:58:23,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:23,841:INFO:Calculating mean and std
2025-12-08 19:58:23,844:INFO:Creating metrics dataframe
2025-12-08 19:58:23,849:INFO:Uploading results into container
2025-12-08 19:58:23,849:INFO:Uploading model into container now
2025-12-08 19:58:23,851:INFO:_master_model_container: 5
2025-12-08 19:58:23,851:INFO:_display_container: 2
2025-12-08 19:58:23,852:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-08 19:58:23,852:INFO:create_model() successfully completed......................................
2025-12-08 19:58:23,989:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:24,004:INFO:Creating metrics dataframe
2025-12-08 19:58:24,028:INFO:Initializing Ridge Classifier
2025-12-08 19:58:24,028:INFO:Total runtime is 0.07496058543523151 minutes
2025-12-08 19:58:24,036:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:24,038:INFO:Initializing create_model()
2025-12-08 19:58:24,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:24,038:INFO:Checking exceptions
2025-12-08 19:58:24,038:INFO:Importing libraries
2025-12-08 19:58:24,038:INFO:Copying training dataset
2025-12-08 19:58:24,061:INFO:Defining folds
2025-12-08 19:58:24,061:INFO:Declaring metric variables
2025-12-08 19:58:24,070:INFO:Importing untrained model
2025-12-08 19:58:24,085:INFO:Ridge Classifier Imported successfully
2025-12-08 19:58:24,108:INFO:Starting cross validation
2025-12-08 19:58:24,113:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:24,328:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.07985e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,330:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.12855e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,330:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97415e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,331:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.22879e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,331:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.27127e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,331:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.76553e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,333:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97653e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,335:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.25459e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,335:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.18612e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,335:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.84536e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-08 19:58:24,410:INFO:Calculating mean and std
2025-12-08 19:58:24,413:INFO:Creating metrics dataframe
2025-12-08 19:58:24,417:INFO:Uploading results into container
2025-12-08 19:58:24,419:INFO:Uploading model into container now
2025-12-08 19:58:24,419:INFO:_master_model_container: 6
2025-12-08 19:58:24,420:INFO:_display_container: 2
2025-12-08 19:58:24,421:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-08 19:58:24,422:INFO:create_model() successfully completed......................................
2025-12-08 19:58:24,556:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:24,558:INFO:Creating metrics dataframe
2025-12-08 19:58:24,576:INFO:Initializing Random Forest Classifier
2025-12-08 19:58:24,577:INFO:Total runtime is 0.08411199649175007 minutes
2025-12-08 19:58:24,585:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:24,587:INFO:Initializing create_model()
2025-12-08 19:58:24,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:24,587:INFO:Checking exceptions
2025-12-08 19:58:24,587:INFO:Importing libraries
2025-12-08 19:58:24,587:INFO:Copying training dataset
2025-12-08 19:58:24,604:INFO:Defining folds
2025-12-08 19:58:24,604:INFO:Declaring metric variables
2025-12-08 19:58:24,614:INFO:Importing untrained model
2025-12-08 19:58:24,623:INFO:Random Forest Classifier Imported successfully
2025-12-08 19:58:24,639:INFO:Starting cross validation
2025-12-08 19:58:24,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:26,800:INFO:Calculating mean and std
2025-12-08 19:58:26,801:INFO:Creating metrics dataframe
2025-12-08 19:58:26,806:INFO:Uploading results into container
2025-12-08 19:58:26,808:INFO:Uploading model into container now
2025-12-08 19:58:26,810:INFO:_master_model_container: 7
2025-12-08 19:58:26,810:INFO:_display_container: 2
2025-12-08 19:58:26,812:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-08 19:58:26,812:INFO:create_model() successfully completed......................................
2025-12-08 19:58:26,941:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:26,943:INFO:Creating metrics dataframe
2025-12-08 19:58:26,961:INFO:Initializing Quadratic Discriminant Analysis
2025-12-08 19:58:26,962:INFO:Total runtime is 0.12385841210683185 minutes
2025-12-08 19:58:26,971:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:26,972:INFO:Initializing create_model()
2025-12-08 19:58:26,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:26,972:INFO:Checking exceptions
2025-12-08 19:58:26,973:INFO:Importing libraries
2025-12-08 19:58:26,973:INFO:Copying training dataset
2025-12-08 19:58:26,994:INFO:Defining folds
2025-12-08 19:58:26,995:INFO:Declaring metric variables
2025-12-08 19:58:27,003:INFO:Importing untrained model
2025-12-08 19:58:27,014:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-08 19:58:27,034:INFO:Starting cross validation
2025-12-08 19:58:27,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:27,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,220:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,220:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,221:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,222:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,223:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,224:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,224:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,227:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,233:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-08 19:58:27,244:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,247:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,247:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,248:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,248:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,249:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,250:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,250:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,250:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,251:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,251:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,251:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,251:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,253:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,254:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,254:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,254:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,255:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,255:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,255:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,255:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,256:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,256:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,256:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,256:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,256:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,256:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,257:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,259:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,259:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,259:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,259:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,260:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,260:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,267:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,268:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-08 19:58:27,268:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-08 19:58:27,269:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,269:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,271:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,271:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,272:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,272:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,272:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,274:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,285:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-08 19:58:27,289:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,289:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,291:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,292:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,293:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,293:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,293:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,294:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,303:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:27,341:INFO:Calculating mean and std
2025-12-08 19:58:27,344:INFO:Creating metrics dataframe
2025-12-08 19:58:27,349:INFO:Uploading results into container
2025-12-08 19:58:27,350:INFO:Uploading model into container now
2025-12-08 19:58:27,352:INFO:_master_model_container: 8
2025-12-08 19:58:27,352:INFO:_display_container: 2
2025-12-08 19:58:27,353:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-08 19:58:27,354:INFO:create_model() successfully completed......................................
2025-12-08 19:58:27,485:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:27,485:INFO:Creating metrics dataframe
2025-12-08 19:58:27,503:INFO:Initializing Ada Boost Classifier
2025-12-08 19:58:27,504:INFO:Total runtime is 0.13289443254470823 minutes
2025-12-08 19:58:27,514:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:27,515:INFO:Initializing create_model()
2025-12-08 19:58:27,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:27,515:INFO:Checking exceptions
2025-12-08 19:58:27,516:INFO:Importing libraries
2025-12-08 19:58:27,516:INFO:Copying training dataset
2025-12-08 19:58:27,532:INFO:Defining folds
2025-12-08 19:58:27,534:INFO:Declaring metric variables
2025-12-08 19:58:27,542:INFO:Importing untrained model
2025-12-08 19:58:27,551:INFO:Ada Boost Classifier Imported successfully
2025-12-08 19:58:27,568:INFO:Starting cross validation
2025-12-08 19:58:27,571:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:27,742:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,742:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,743:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,745:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,745:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,747:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,747:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,748:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,749:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:27,749:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-08 19:58:28,872:INFO:Calculating mean and std
2025-12-08 19:58:28,875:INFO:Creating metrics dataframe
2025-12-08 19:58:28,880:INFO:Uploading results into container
2025-12-08 19:58:28,881:INFO:Uploading model into container now
2025-12-08 19:58:28,881:INFO:_master_model_container: 9
2025-12-08 19:58:28,883:INFO:_display_container: 2
2025-12-08 19:58:28,883:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-08 19:58:28,883:INFO:create_model() successfully completed......................................
2025-12-08 19:58:29,009:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:29,010:INFO:Creating metrics dataframe
2025-12-08 19:58:29,032:INFO:Initializing Gradient Boosting Classifier
2025-12-08 19:58:29,032:INFO:Total runtime is 0.1583587010701497 minutes
2025-12-08 19:58:29,041:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:29,043:INFO:Initializing create_model()
2025-12-08 19:58:29,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:29,043:INFO:Checking exceptions
2025-12-08 19:58:29,043:INFO:Importing libraries
2025-12-08 19:58:29,043:INFO:Copying training dataset
2025-12-08 19:58:29,060:INFO:Defining folds
2025-12-08 19:58:29,061:INFO:Declaring metric variables
2025-12-08 19:58:29,070:INFO:Importing untrained model
2025-12-08 19:58:29,080:INFO:Gradient Boosting Classifier Imported successfully
2025-12-08 19:58:29,097:INFO:Starting cross validation
2025-12-08 19:58:29,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:32,508:INFO:Calculating mean and std
2025-12-08 19:58:32,512:INFO:Creating metrics dataframe
2025-12-08 19:58:32,517:INFO:Uploading results into container
2025-12-08 19:58:32,518:INFO:Uploading model into container now
2025-12-08 19:58:32,520:INFO:_master_model_container: 10
2025-12-08 19:58:32,520:INFO:_display_container: 2
2025-12-08 19:58:32,521:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-08 19:58:32,521:INFO:create_model() successfully completed......................................
2025-12-08 19:58:32,651:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:32,652:INFO:Creating metrics dataframe
2025-12-08 19:58:32,677:INFO:Initializing Linear Discriminant Analysis
2025-12-08 19:58:32,677:INFO:Total runtime is 0.21909885803858437 minutes
2025-12-08 19:58:32,684:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:32,686:INFO:Initializing create_model()
2025-12-08 19:58:32,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:32,686:INFO:Checking exceptions
2025-12-08 19:58:32,686:INFO:Importing libraries
2025-12-08 19:58:32,686:INFO:Copying training dataset
2025-12-08 19:58:32,705:INFO:Defining folds
2025-12-08 19:58:32,707:INFO:Declaring metric variables
2025-12-08 19:58:32,715:INFO:Importing untrained model
2025-12-08 19:58:32,725:INFO:Linear Discriminant Analysis Imported successfully
2025-12-08 19:58:32,742:INFO:Starting cross validation
2025-12-08 19:58:32,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:33,090:INFO:Calculating mean and std
2025-12-08 19:58:33,093:INFO:Creating metrics dataframe
2025-12-08 19:58:33,098:INFO:Uploading results into container
2025-12-08 19:58:33,099:INFO:Uploading model into container now
2025-12-08 19:58:33,099:INFO:_master_model_container: 11
2025-12-08 19:58:33,101:INFO:_display_container: 2
2025-12-08 19:58:33,101:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-08 19:58:33,101:INFO:create_model() successfully completed......................................
2025-12-08 19:58:33,240:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:33,240:INFO:Creating metrics dataframe
2025-12-08 19:58:33,265:INFO:Initializing Extra Trees Classifier
2025-12-08 19:58:33,265:INFO:Total runtime is 0.2289133032162984 minutes
2025-12-08 19:58:33,276:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:33,277:INFO:Initializing create_model()
2025-12-08 19:58:33,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:33,278:INFO:Checking exceptions
2025-12-08 19:58:33,278:INFO:Importing libraries
2025-12-08 19:58:33,278:INFO:Copying training dataset
2025-12-08 19:58:33,299:INFO:Defining folds
2025-12-08 19:58:33,300:INFO:Declaring metric variables
2025-12-08 19:58:33,310:INFO:Importing untrained model
2025-12-08 19:58:33,320:INFO:Extra Trees Classifier Imported successfully
2025-12-08 19:58:33,340:INFO:Starting cross validation
2025-12-08 19:58:33,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:35,201:INFO:Calculating mean and std
2025-12-08 19:58:35,204:INFO:Creating metrics dataframe
2025-12-08 19:58:35,212:INFO:Uploading results into container
2025-12-08 19:58:35,213:INFO:Uploading model into container now
2025-12-08 19:58:35,215:INFO:_master_model_container: 12
2025-12-08 19:58:35,216:INFO:_display_container: 2
2025-12-08 19:58:35,217:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-08 19:58:35,217:INFO:create_model() successfully completed......................................
2025-12-08 19:58:35,364:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:35,364:INFO:Creating metrics dataframe
2025-12-08 19:58:35,389:INFO:Initializing Light Gradient Boosting Machine
2025-12-08 19:58:35,389:INFO:Total runtime is 0.26430468559265136 minutes
2025-12-08 19:58:35,403:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:35,404:INFO:Initializing create_model()
2025-12-08 19:58:35,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:35,405:INFO:Checking exceptions
2025-12-08 19:58:35,405:INFO:Importing libraries
2025-12-08 19:58:35,405:INFO:Copying training dataset
2025-12-08 19:58:35,424:INFO:Defining folds
2025-12-08 19:58:35,426:INFO:Declaring metric variables
2025-12-08 19:58:35,434:INFO:Importing untrained model
2025-12-08 19:58:35,446:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 19:58:35,464:INFO:Starting cross validation
2025-12-08 19:58:35,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:38,049:INFO:Calculating mean and std
2025-12-08 19:58:38,051:INFO:Creating metrics dataframe
2025-12-08 19:58:38,059:INFO:Uploading results into container
2025-12-08 19:58:38,060:INFO:Uploading model into container now
2025-12-08 19:58:38,062:INFO:_master_model_container: 13
2025-12-08 19:58:38,062:INFO:_display_container: 2
2025-12-08 19:58:38,063:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 19:58:38,065:INFO:create_model() successfully completed......................................
2025-12-08 19:58:38,215:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:38,216:INFO:Creating metrics dataframe
2025-12-08 19:58:38,241:INFO:Initializing Dummy Classifier
2025-12-08 19:58:38,241:INFO:Total runtime is 0.3118410468101501 minutes
2025-12-08 19:58:38,250:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:38,252:INFO:Initializing create_model()
2025-12-08 19:58:38,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:38,252:INFO:Checking exceptions
2025-12-08 19:58:38,252:INFO:Importing libraries
2025-12-08 19:58:38,253:INFO:Copying training dataset
2025-12-08 19:58:38,270:INFO:Defining folds
2025-12-08 19:58:38,272:INFO:Declaring metric variables
2025-12-08 19:58:38,284:INFO:Importing untrained model
2025-12-08 19:58:38,293:INFO:Dummy Classifier Imported successfully
2025-12-08 19:58:38,311:INFO:Starting cross validation
2025-12-08 19:58:38,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:38,494:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,496:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,496:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,500:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,504:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,512:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,513:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,525:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,531:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,538:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-08 19:58:38,559:INFO:Calculating mean and std
2025-12-08 19:58:38,562:INFO:Creating metrics dataframe
2025-12-08 19:58:38,565:INFO:Uploading results into container
2025-12-08 19:58:38,567:INFO:Uploading model into container now
2025-12-08 19:58:38,568:INFO:_master_model_container: 14
2025-12-08 19:58:38,568:INFO:_display_container: 2
2025-12-08 19:58:38,568:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-08 19:58:38,570:INFO:create_model() successfully completed......................................
2025-12-08 19:58:38,702:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:38,702:INFO:Creating metrics dataframe
2025-12-08 19:58:38,730:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-08 19:58:38,751:INFO:Initializing create_model()
2025-12-08 19:58:38,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:38,752:INFO:Checking exceptions
2025-12-08 19:58:38,755:INFO:Importing libraries
2025-12-08 19:58:38,755:INFO:Copying training dataset
2025-12-08 19:58:38,773:INFO:Defining folds
2025-12-08 19:58:38,774:INFO:Declaring metric variables
2025-12-08 19:58:38,774:INFO:Importing untrained model
2025-12-08 19:58:38,775:INFO:Declaring custom model
2025-12-08 19:58:38,776:INFO:Logistic Regression Imported successfully
2025-12-08 19:58:38,778:INFO:Cross validation set to False
2025-12-08 19:58:38,778:INFO:Fitting Model
2025-12-08 19:58:38,851:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] O sistema no pode encontrar o arquivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-12-08 19:58:38,853:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\joblib\externals\loky\backend\context.py", line 257, in _count_physical_cores
2025-12-08 19:58:38,853:WARNING:    cpu_info = subprocess.run(
2025-12-08 19:58:38,854:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 503, in run
2025-12-08 19:58:38,854:WARNING:    with Popen(*popenargs, **kwargs) as process:
2025-12-08 19:58:38,854:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 971, in __init__
2025-12-08 19:58:38,854:WARNING:    self._execute_child(args, executable, preexec_fn, close_fds,
2025-12-08 19:58:38,854:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 1456, in _execute_child
2025-12-08 19:58:38,854:WARNING:    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
2025-12-08 19:58:40,706:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 19:58:40,706:INFO:create_model() successfully completed......................................
2025-12-08 19:58:40,911:INFO:_master_model_container: 14
2025-12-08 19:58:40,911:INFO:_display_container: 2
2025-12-08 19:58:40,913:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 19:58:40,913:INFO:compare_models() successfully completed......................................
2025-12-08 19:58:40,916:INFO:Initializing tune_model()
2025-12-08 19:58:40,917:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>)
2025-12-08 19:58:40,917:INFO:Checking exceptions
2025-12-08 19:58:40,962:INFO:Copying training dataset
2025-12-08 19:58:40,978:INFO:Checking base model
2025-12-08 19:58:40,978:INFO:Base model : Logistic Regression
2025-12-08 19:58:40,987:INFO:Declaring metric variables
2025-12-08 19:58:40,998:INFO:Defining Hyperparameters
2025-12-08 19:58:41,137:INFO:Tuning with n_jobs=-1
2025-12-08 19:58:41,137:INFO:Initializing RandomizedSearchCV
2025-12-08 19:58:46,146:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 19:58:46,272:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 19:58:52,997:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 19:58:53,715:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 19:58:53,733:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-08 19:58:53,734:INFO:Hyperparameter search completed
2025-12-08 19:58:53,734:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:53,736:INFO:Initializing create_model()
2025-12-08 19:58:53,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026553EF3EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-08 19:58:53,736:INFO:Checking exceptions
2025-12-08 19:58:53,738:INFO:Importing libraries
2025-12-08 19:58:53,738:INFO:Copying training dataset
2025-12-08 19:58:53,757:INFO:Defining folds
2025-12-08 19:58:53,757:INFO:Declaring metric variables
2025-12-08 19:58:53,765:INFO:Importing untrained model
2025-12-08 19:58:53,766:INFO:Declaring custom model
2025-12-08 19:58:53,776:INFO:Logistic Regression Imported successfully
2025-12-08 19:58:53,794:INFO:Starting cross validation
2025-12-08 19:58:53,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:55,497:INFO:Calculating mean and std
2025-12-08 19:58:55,499:INFO:Creating metrics dataframe
2025-12-08 19:58:55,513:INFO:Finalizing model
2025-12-08 19:58:57,803:INFO:Uploading results into container
2025-12-08 19:58:57,804:INFO:Uploading model into container now
2025-12-08 19:58:57,805:INFO:_master_model_container: 15
2025-12-08 19:58:57,806:INFO:_display_container: 3
2025-12-08 19:58:57,808:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 19:58:57,808:INFO:create_model() successfully completed......................................
2025-12-08 19:58:57,942:INFO:SubProcess create_model() end ==================================
2025-12-08 19:58:57,942:INFO:choose_better activated
2025-12-08 19:58:57,950:INFO:SubProcess create_model() called ==================================
2025-12-08 19:58:57,952:INFO:Initializing create_model()
2025-12-08 19:58:57,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265588D9900>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 19:58:57,953:INFO:Checking exceptions
2025-12-08 19:58:57,956:INFO:Importing libraries
2025-12-08 19:58:57,956:INFO:Copying training dataset
2025-12-08 19:58:57,972:INFO:Defining folds
2025-12-08 19:58:57,972:INFO:Declaring metric variables
2025-12-08 19:58:57,974:INFO:Importing untrained model
2025-12-08 19:58:57,974:INFO:Declaring custom model
2025-12-08 19:58:57,976:INFO:Logistic Regression Imported successfully
2025-12-08 19:58:57,977:INFO:Starting cross validation
2025-12-08 19:58:57,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 19:58:59,608:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-08 19:58:59,654:INFO:Calculating mean and std
2025-12-08 19:58:59,655:INFO:Creating metrics dataframe
2025-12-08 19:58:59,660:INFO:Finalizing model
2025-12-08 19:59:01,468:INFO:Uploading results into container
2025-12-08 19:59:01,470:INFO:Uploading model into container now
2025-12-08 19:59:01,471:INFO:_master_model_container: 16
2025-12-08 19:59:01,471:INFO:_display_container: 4
2025-12-08 19:59:01,471:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 19:59:01,471:INFO:create_model() successfully completed......................................
2025-12-08 19:59:01,602:INFO:SubProcess create_model() end ==================================
2025-12-08 19:59:01,604:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-08 19:59:01,606:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-08 19:59:01,607:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-08 19:59:01,608:INFO:choose_better completed
2025-12-08 19:59:01,608:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-08 19:59:01,633:INFO:_master_model_container: 16
2025-12-08 19:59:01,634:INFO:_display_container: 3
2025-12-08 19:59:01,635:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-08 19:59:01,636:INFO:tune_model() successfully completed......................................
2025-12-09 12:07:24,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-09 12:07:24,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-09 12:07:24,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-09 12:07:24,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-09 12:07:25,597:INFO:PyCaret RegressionExperiment
2025-12-09 12:07:25,597:INFO:Logging name: reg-default-name
2025-12-09 12:07:25,598:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-09 12:07:25,598:INFO:version 3.3.2
2025-12-09 12:07:25,598:INFO:Initializing setup()
2025-12-09 12:07:25,598:INFO:self.USI: da47
2025-12-09 12:07:25,598:INFO:self._variable_keys: {'_available_plots', 'fold_shuffle_param', 'data', 'gpu_n_jobs_param', '_ml_usecase', 'y_train', 'gpu_param', 'n_jobs_param', 'X_train', 'idx', 'target_param', 'log_plots_param', 'html_param', 'pipeline', 'X', 'USI', 'transform_target_param', 'seed', 'fold_groups_param', 'exp_id', 'X_test', 'logging_param', 'exp_name_log', 'y_test', 'y', 'fold_generator', 'memory'}
2025-12-09 12:07:25,598:INFO:Checking environment
2025-12-09 12:07:25,599:INFO:python_version: 3.10.19
2025-12-09 12:07:25,599:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-09 12:07:25,600:INFO:machine: AMD64
2025-12-09 12:07:25,600:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-09 12:07:25,600:INFO:Memory: svmem(total=33699516416, available=17160441856, percent=49.1, used=16539074560, free=17160441856)
2025-12-09 12:07:25,601:INFO:Physical Core: 8
2025-12-09 12:07:25,601:INFO:Logical Core: 16
2025-12-09 12:07:25,601:INFO:Checking libraries
2025-12-09 12:07:25,601:INFO:System:
2025-12-09 12:07:25,601:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-09 12:07:25,602:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-09 12:07:25,602:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-09 12:07:25,602:INFO:PyCaret required dependencies:
2025-12-09 12:07:25,604:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:25,681:INFO:                 pip: 25.3
2025-12-09 12:07:25,681:INFO:          setuptools: 80.9.0
2025-12-09 12:07:25,681:INFO:             pycaret: 3.3.2
2025-12-09 12:07:25,681:INFO:             IPython: 8.37.0
2025-12-09 12:07:25,681:INFO:          ipywidgets: 8.1.8
2025-12-09 12:07:25,681:INFO:                tqdm: 4.67.1
2025-12-09 12:07:25,681:INFO:               numpy: 1.26.4
2025-12-09 12:07:25,681:INFO:              pandas: 2.1.4
2025-12-09 12:07:25,681:INFO:              jinja2: 3.1.6
2025-12-09 12:07:25,681:INFO:               scipy: 1.11.4
2025-12-09 12:07:25,681:INFO:              joblib: 1.3.2
2025-12-09 12:07:25,681:INFO:             sklearn: 1.4.2
2025-12-09 12:07:25,681:INFO:                pyod: 2.0.6
2025-12-09 12:07:25,681:INFO:            imblearn: 0.14.0
2025-12-09 12:07:25,683:INFO:   category_encoders: 2.7.0
2025-12-09 12:07:25,683:INFO:            lightgbm: 4.6.0
2025-12-09 12:07:25,683:INFO:               numba: 0.62.1
2025-12-09 12:07:25,683:INFO:            requests: 2.32.5
2025-12-09 12:07:25,683:INFO:          matplotlib: 3.7.5
2025-12-09 12:07:25,683:INFO:          scikitplot: 0.3.7
2025-12-09 12:07:25,683:INFO:         yellowbrick: 1.5
2025-12-09 12:07:25,683:INFO:              plotly: 6.5.0
2025-12-09 12:07:25,683:INFO:    plotly-resampler: Not installed
2025-12-09 12:07:25,683:INFO:             kaleido: 1.2.0
2025-12-09 12:07:25,683:INFO:           schemdraw: 0.15
2025-12-09 12:07:25,683:INFO:         statsmodels: 0.14.5
2025-12-09 12:07:25,683:INFO:              sktime: 0.26.0
2025-12-09 12:07:25,683:INFO:               tbats: 1.1.3
2025-12-09 12:07:25,683:INFO:            pmdarima: 2.0.4
2025-12-09 12:07:25,683:INFO:              psutil: 7.1.3
2025-12-09 12:07:25,683:INFO:          markupsafe: 3.0.3
2025-12-09 12:07:25,683:INFO:             pickle5: Not installed
2025-12-09 12:07:25,684:INFO:         cloudpickle: 3.1.2
2025-12-09 12:07:25,684:INFO:         deprecation: 2.1.0
2025-12-09 12:07:25,684:INFO:              xxhash: 3.6.0
2025-12-09 12:07:25,684:INFO:           wurlitzer: Not installed
2025-12-09 12:07:25,684:INFO:PyCaret optional dependencies:
2025-12-09 12:07:25,707:INFO:                shap: Not installed
2025-12-09 12:07:25,707:INFO:           interpret: Not installed
2025-12-09 12:07:25,707:INFO:                umap: Not installed
2025-12-09 12:07:25,707:INFO:     ydata_profiling: Not installed
2025-12-09 12:07:25,707:INFO:  explainerdashboard: Not installed
2025-12-09 12:07:25,708:INFO:             autoviz: Not installed
2025-12-09 12:07:25,708:INFO:           fairlearn: Not installed
2025-12-09 12:07:25,708:INFO:          deepchecks: Not installed
2025-12-09 12:07:25,708:INFO:             xgboost: Not installed
2025-12-09 12:07:25,708:INFO:            catboost: Not installed
2025-12-09 12:07:25,708:INFO:              kmodes: Not installed
2025-12-09 12:07:25,708:INFO:             mlxtend: Not installed
2025-12-09 12:07:25,708:INFO:       statsforecast: Not installed
2025-12-09 12:07:25,708:INFO:        tune_sklearn: Not installed
2025-12-09 12:07:25,708:INFO:                 ray: Not installed
2025-12-09 12:07:25,708:INFO:            hyperopt: Not installed
2025-12-09 12:07:25,708:INFO:              optuna: Not installed
2025-12-09 12:07:25,708:INFO:               skopt: Not installed
2025-12-09 12:07:25,709:INFO:              mlflow: Not installed
2025-12-09 12:07:25,709:INFO:              gradio: Not installed
2025-12-09 12:07:25,709:INFO:             fastapi: Not installed
2025-12-09 12:07:25,709:INFO:             uvicorn: Not installed
2025-12-09 12:07:25,709:INFO:              m2cgen: Not installed
2025-12-09 12:07:25,710:INFO:           evidently: Not installed
2025-12-09 12:07:25,710:INFO:               fugue: Not installed
2025-12-09 12:07:25,710:INFO:           streamlit: Not installed
2025-12-09 12:07:25,710:INFO:             prophet: Not installed
2025-12-09 12:07:25,710:INFO:None
2025-12-09 12:07:25,710:INFO:Set up data.
2025-12-09 12:07:25,729:INFO:Set up folding strategy.
2025-12-09 12:07:25,729:INFO:Set up train/test split.
2025-12-09 12:07:25,741:INFO:Set up index.
2025-12-09 12:07:25,741:INFO:Assigning column types.
2025-12-09 12:07:25,755:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-09 12:07:25,755:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-09 12:07:25,768:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-09 12:07:25,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-09 12:07:25,964:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,073:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:26,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:26,075:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,087:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,099:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,362:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:26,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:26,365:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-09 12:07:26,376:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,387:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,543:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,658:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:26,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:26,671:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,686:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:07:26,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:26,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:26,954:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-09 12:07:26,977:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-09 12:07:27,166:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:27,278:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:07:27,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:27,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:27,303:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-09 12:07:27,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:27,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:07:27,557:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:27,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:27,561:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-09 12:07:27,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:27,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:07:27,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:27,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:28,028:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:28,139:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:07:28,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:28,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:28,142:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-09 12:07:28,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:28,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:28,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:28,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-09 12:07:28,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:28,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:28,726:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-09 12:07:29,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:29,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:29,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:29,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:29,316:INFO:Preparing preprocessing pipeline...
2025-12-09 12:07:29,316:INFO:Set up simple imputation.
2025-12-09 12:07:29,316:INFO:Set up feature normalization.
2025-12-09 12:07:29,320:INFO:Set up column name cleaning.
2025-12-09 12:07:29,495:INFO:Finished creating preprocessing pipeline.
2025-12-09 12:07:29,512:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'transmission_encoded',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner_Test Drive Car',
                                             'owner_Third Owner'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-12-09 12:07:29,512:INFO:Creating final display dataframe.
2025-12-09 12:07:29,840:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 17)
4        Transformed data shape        (7906, 17)
5   Transformed train set shape        (5534, 17)
6    Transformed test set shape        (2372, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              da47
2025-12-09 12:07:30,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:30,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:30,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:30,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:07:30,433:INFO:setup() successfully completed in 4.85s...............
2025-12-09 12:07:30,433:INFO:Initializing compare_models()
2025-12-09 12:07:30,433:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-09 12:07:30,433:INFO:Checking exceptions
2025-12-09 12:07:30,439:INFO:Preparing display monitor
2025-12-09 12:07:30,514:INFO:Initializing Linear Regression
2025-12-09 12:07:30,514:INFO:Total runtime is 2.7219454447428387e-05 minutes
2025-12-09 12:07:30,526:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:30,526:INFO:Initializing create_model()
2025-12-09 12:07:30,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:30,528:INFO:Checking exceptions
2025-12-09 12:07:30,529:INFO:Importing libraries
2025-12-09 12:07:30,530:INFO:Copying training dataset
2025-12-09 12:07:30,552:INFO:Defining folds
2025-12-09 12:07:30,552:INFO:Declaring metric variables
2025-12-09 12:07:30,565:INFO:Importing untrained model
2025-12-09 12:07:30,577:INFO:Linear Regression Imported successfully
2025-12-09 12:07:30,601:INFO:Starting cross validation
2025-12-09 12:07:30,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:39,760:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,763:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,778:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,798:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,815:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,820:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,825:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,838:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,879:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:39,903:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:40,474:INFO:Calculating mean and std
2025-12-09 12:07:40,478:INFO:Creating metrics dataframe
2025-12-09 12:07:40,485:INFO:Uploading results into container
2025-12-09 12:07:40,488:INFO:Uploading model into container now
2025-12-09 12:07:40,489:INFO:_master_model_container: 1
2025-12-09 12:07:40,490:INFO:_display_container: 2
2025-12-09 12:07:40,491:INFO:LinearRegression(n_jobs=-1)
2025-12-09 12:07:40,491:INFO:create_model() successfully completed......................................
2025-12-09 12:07:40,648:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:40,649:INFO:Creating metrics dataframe
2025-12-09 12:07:40,662:INFO:Initializing Lasso Regression
2025-12-09 12:07:40,664:INFO:Total runtime is 0.16920228401819865 minutes
2025-12-09 12:07:40,674:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:40,675:INFO:Initializing create_model()
2025-12-09 12:07:40,675:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:40,675:INFO:Checking exceptions
2025-12-09 12:07:40,675:INFO:Importing libraries
2025-12-09 12:07:40,675:INFO:Copying training dataset
2025-12-09 12:07:40,693:INFO:Defining folds
2025-12-09 12:07:40,693:INFO:Declaring metric variables
2025-12-09 12:07:40,703:INFO:Importing untrained model
2025-12-09 12:07:40,711:INFO:Lasso Regression Imported successfully
2025-12-09 12:07:40,728:INFO:Starting cross validation
2025-12-09 12:07:40,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:47,247:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:47,251:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:47,258:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:47,265:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:47,272:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:47,330:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 12:07:47,882:INFO:Calculating mean and std
2025-12-09 12:07:47,885:INFO:Creating metrics dataframe
2025-12-09 12:07:47,893:INFO:Uploading results into container
2025-12-09 12:07:47,894:INFO:Uploading model into container now
2025-12-09 12:07:47,897:INFO:_master_model_container: 2
2025-12-09 12:07:47,897:INFO:_display_container: 2
2025-12-09 12:07:47,900:INFO:Lasso(random_state=123)
2025-12-09 12:07:47,900:INFO:create_model() successfully completed......................................
2025-12-09 12:07:48,028:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:48,028:INFO:Creating metrics dataframe
2025-12-09 12:07:48,049:INFO:Initializing Ridge Regression
2025-12-09 12:07:48,049:INFO:Total runtime is 0.2922828872998555 minutes
2025-12-09 12:07:48,058:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:48,060:INFO:Initializing create_model()
2025-12-09 12:07:48,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:48,060:INFO:Checking exceptions
2025-12-09 12:07:48,061:INFO:Importing libraries
2025-12-09 12:07:48,061:INFO:Copying training dataset
2025-12-09 12:07:48,082:INFO:Defining folds
2025-12-09 12:07:48,084:INFO:Declaring metric variables
2025-12-09 12:07:48,097:INFO:Importing untrained model
2025-12-09 12:07:48,109:INFO:Ridge Regression Imported successfully
2025-12-09 12:07:48,127:INFO:Starting cross validation
2025-12-09 12:07:48,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:48,371:INFO:Calculating mean and std
2025-12-09 12:07:48,374:INFO:Creating metrics dataframe
2025-12-09 12:07:48,378:INFO:Uploading results into container
2025-12-09 12:07:48,379:INFO:Uploading model into container now
2025-12-09 12:07:48,381:INFO:_master_model_container: 3
2025-12-09 12:07:48,381:INFO:_display_container: 2
2025-12-09 12:07:48,381:INFO:Ridge(random_state=123)
2025-12-09 12:07:48,382:INFO:create_model() successfully completed......................................
2025-12-09 12:07:48,503:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:48,503:INFO:Creating metrics dataframe
2025-12-09 12:07:48,523:INFO:Initializing Elastic Net
2025-12-09 12:07:48,523:INFO:Total runtime is 0.30018823544184364 minutes
2025-12-09 12:07:48,533:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:48,535:INFO:Initializing create_model()
2025-12-09 12:07:48,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:48,535:INFO:Checking exceptions
2025-12-09 12:07:48,535:INFO:Importing libraries
2025-12-09 12:07:48,535:INFO:Copying training dataset
2025-12-09 12:07:48,554:INFO:Defining folds
2025-12-09 12:07:48,554:INFO:Declaring metric variables
2025-12-09 12:07:48,563:INFO:Importing untrained model
2025-12-09 12:07:48,575:INFO:Elastic Net Imported successfully
2025-12-09 12:07:48,592:INFO:Starting cross validation
2025-12-09 12:07:48,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:48,900:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+12, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-09 12:07:48,937:INFO:Calculating mean and std
2025-12-09 12:07:48,939:INFO:Creating metrics dataframe
2025-12-09 12:07:48,944:INFO:Uploading results into container
2025-12-09 12:07:48,946:INFO:Uploading model into container now
2025-12-09 12:07:48,946:INFO:_master_model_container: 4
2025-12-09 12:07:48,946:INFO:_display_container: 2
2025-12-09 12:07:48,948:INFO:ElasticNet(random_state=123)
2025-12-09 12:07:48,948:INFO:create_model() successfully completed......................................
2025-12-09 12:07:49,069:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:49,069:INFO:Creating metrics dataframe
2025-12-09 12:07:49,085:INFO:Initializing Least Angle Regression
2025-12-09 12:07:49,085:INFO:Total runtime is 0.309549347559611 minutes
2025-12-09 12:07:49,095:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:49,097:INFO:Initializing create_model()
2025-12-09 12:07:49,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:49,098:INFO:Checking exceptions
2025-12-09 12:07:49,098:INFO:Importing libraries
2025-12-09 12:07:49,098:INFO:Copying training dataset
2025-12-09 12:07:49,116:INFO:Defining folds
2025-12-09 12:07:49,116:INFO:Declaring metric variables
2025-12-09 12:07:49,128:INFO:Importing untrained model
2025-12-09 12:07:49,141:INFO:Least Angle Regression Imported successfully
2025-12-09 12:07:49,161:INFO:Starting cross validation
2025-12-09 12:07:49,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:49,420:INFO:Calculating mean and std
2025-12-09 12:07:49,423:INFO:Creating metrics dataframe
2025-12-09 12:07:49,427:INFO:Uploading results into container
2025-12-09 12:07:49,428:INFO:Uploading model into container now
2025-12-09 12:07:49,429:INFO:_master_model_container: 5
2025-12-09 12:07:49,429:INFO:_display_container: 2
2025-12-09 12:07:49,430:INFO:Lars(random_state=123)
2025-12-09 12:07:49,430:INFO:create_model() successfully completed......................................
2025-12-09 12:07:49,550:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:49,550:INFO:Creating metrics dataframe
2025-12-09 12:07:49,567:INFO:Initializing Lasso Least Angle Regression
2025-12-09 12:07:49,569:INFO:Total runtime is 0.3176136295000712 minutes
2025-12-09 12:07:49,578:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:49,579:INFO:Initializing create_model()
2025-12-09 12:07:49,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:49,579:INFO:Checking exceptions
2025-12-09 12:07:49,579:INFO:Importing libraries
2025-12-09 12:07:49,580:INFO:Copying training dataset
2025-12-09 12:07:49,596:INFO:Defining folds
2025-12-09 12:07:49,598:INFO:Declaring metric variables
2025-12-09 12:07:49,609:INFO:Importing untrained model
2025-12-09 12:07:49,617:INFO:Lasso Least Angle Regression Imported successfully
2025-12-09 12:07:49,634:INFO:Starting cross validation
2025-12-09 12:07:49,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:49,866:INFO:Calculating mean and std
2025-12-09 12:07:49,868:INFO:Creating metrics dataframe
2025-12-09 12:07:49,874:INFO:Uploading results into container
2025-12-09 12:07:49,876:INFO:Uploading model into container now
2025-12-09 12:07:49,876:INFO:_master_model_container: 6
2025-12-09 12:07:49,877:INFO:_display_container: 2
2025-12-09 12:07:49,877:INFO:LassoLars(random_state=123)
2025-12-09 12:07:49,878:INFO:create_model() successfully completed......................................
2025-12-09 12:07:49,998:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:49,998:INFO:Creating metrics dataframe
2025-12-09 12:07:50,017:INFO:Initializing Orthogonal Matching Pursuit
2025-12-09 12:07:50,017:INFO:Total runtime is 0.3250873446464539 minutes
2025-12-09 12:07:50,026:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:50,026:INFO:Initializing create_model()
2025-12-09 12:07:50,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:50,027:INFO:Checking exceptions
2025-12-09 12:07:50,028:INFO:Importing libraries
2025-12-09 12:07:50,028:INFO:Copying training dataset
2025-12-09 12:07:50,044:INFO:Defining folds
2025-12-09 12:07:50,065:INFO:Declaring metric variables
2025-12-09 12:07:50,078:INFO:Importing untrained model
2025-12-09 12:07:50,090:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-09 12:07:50,110:INFO:Starting cross validation
2025-12-09 12:07:50,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:50,319:INFO:Calculating mean and std
2025-12-09 12:07:50,322:INFO:Creating metrics dataframe
2025-12-09 12:07:50,327:INFO:Uploading results into container
2025-12-09 12:07:50,328:INFO:Uploading model into container now
2025-12-09 12:07:50,328:INFO:_master_model_container: 7
2025-12-09 12:07:50,330:INFO:_display_container: 2
2025-12-09 12:07:50,330:INFO:OrthogonalMatchingPursuit()
2025-12-09 12:07:50,330:INFO:create_model() successfully completed......................................
2025-12-09 12:07:50,453:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:50,453:INFO:Creating metrics dataframe
2025-12-09 12:07:50,473:INFO:Initializing Bayesian Ridge
2025-12-09 12:07:50,473:INFO:Total runtime is 0.3326795975367228 minutes
2025-12-09 12:07:50,483:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:50,484:INFO:Initializing create_model()
2025-12-09 12:07:50,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:50,484:INFO:Checking exceptions
2025-12-09 12:07:50,484:INFO:Importing libraries
2025-12-09 12:07:50,484:INFO:Copying training dataset
2025-12-09 12:07:50,502:INFO:Defining folds
2025-12-09 12:07:50,503:INFO:Declaring metric variables
2025-12-09 12:07:50,513:INFO:Importing untrained model
2025-12-09 12:07:50,525:INFO:Bayesian Ridge Imported successfully
2025-12-09 12:07:50,543:INFO:Starting cross validation
2025-12-09 12:07:50,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:50,818:INFO:Calculating mean and std
2025-12-09 12:07:50,820:INFO:Creating metrics dataframe
2025-12-09 12:07:50,825:INFO:Uploading results into container
2025-12-09 12:07:50,825:INFO:Uploading model into container now
2025-12-09 12:07:50,827:INFO:_master_model_container: 8
2025-12-09 12:07:50,828:INFO:_display_container: 2
2025-12-09 12:07:50,829:INFO:BayesianRidge()
2025-12-09 12:07:50,829:INFO:create_model() successfully completed......................................
2025-12-09 12:07:50,949:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:50,950:INFO:Creating metrics dataframe
2025-12-09 12:07:50,967:INFO:Initializing Passive Aggressive Regressor
2025-12-09 12:07:50,969:INFO:Total runtime is 0.3409406622250875 minutes
2025-12-09 12:07:50,976:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:50,977:INFO:Initializing create_model()
2025-12-09 12:07:50,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:50,978:INFO:Checking exceptions
2025-12-09 12:07:50,978:INFO:Importing libraries
2025-12-09 12:07:50,978:INFO:Copying training dataset
2025-12-09 12:07:50,994:INFO:Defining folds
2025-12-09 12:07:50,994:INFO:Declaring metric variables
2025-12-09 12:07:51,004:INFO:Importing untrained model
2025-12-09 12:07:51,014:INFO:Passive Aggressive Regressor Imported successfully
2025-12-09 12:07:51,034:INFO:Starting cross validation
2025-12-09 12:07:51,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:52,164:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,186:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,195:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,197:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,211:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,224:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,231:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,266:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-09 12:07:52,288:INFO:Calculating mean and std
2025-12-09 12:07:52,290:INFO:Creating metrics dataframe
2025-12-09 12:07:52,293:INFO:Uploading results into container
2025-12-09 12:07:52,294:INFO:Uploading model into container now
2025-12-09 12:07:52,296:INFO:_master_model_container: 9
2025-12-09 12:07:52,296:INFO:_display_container: 2
2025-12-09 12:07:52,296:INFO:PassiveAggressiveRegressor(random_state=123)
2025-12-09 12:07:52,298:INFO:create_model() successfully completed......................................
2025-12-09 12:07:52,419:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:52,420:INFO:Creating metrics dataframe
2025-12-09 12:07:52,455:INFO:Initializing Huber Regressor
2025-12-09 12:07:52,455:INFO:Total runtime is 0.36571015516916916 minutes
2025-12-09 12:07:52,469:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:52,469:INFO:Initializing create_model()
2025-12-09 12:07:52,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:52,471:INFO:Checking exceptions
2025-12-09 12:07:52,471:INFO:Importing libraries
2025-12-09 12:07:52,472:INFO:Copying training dataset
2025-12-09 12:07:52,494:INFO:Defining folds
2025-12-09 12:07:52,495:INFO:Declaring metric variables
2025-12-09 12:07:52,503:INFO:Importing untrained model
2025-12-09 12:07:52,513:INFO:Huber Regressor Imported successfully
2025-12-09 12:07:52,533:INFO:Starting cross validation
2025-12-09 12:07:52,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:52,884:INFO:Calculating mean and std
2025-12-09 12:07:52,886:INFO:Creating metrics dataframe
2025-12-09 12:07:52,891:INFO:Uploading results into container
2025-12-09 12:07:52,892:INFO:Uploading model into container now
2025-12-09 12:07:52,894:INFO:_master_model_container: 10
2025-12-09 12:07:52,895:INFO:_display_container: 2
2025-12-09 12:07:52,895:INFO:HuberRegressor()
2025-12-09 12:07:52,896:INFO:create_model() successfully completed......................................
2025-12-09 12:07:53,015:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:53,015:INFO:Creating metrics dataframe
2025-12-09 12:07:53,035:INFO:Initializing K Neighbors Regressor
2025-12-09 12:07:53,035:INFO:Total runtime is 0.37538467645645146 minutes
2025-12-09 12:07:53,043:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:53,044:INFO:Initializing create_model()
2025-12-09 12:07:53,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:53,045:INFO:Checking exceptions
2025-12-09 12:07:53,045:INFO:Importing libraries
2025-12-09 12:07:53,045:INFO:Copying training dataset
2025-12-09 12:07:53,065:INFO:Defining folds
2025-12-09 12:07:53,065:INFO:Declaring metric variables
2025-12-09 12:07:53,076:INFO:Importing untrained model
2025-12-09 12:07:53,090:INFO:K Neighbors Regressor Imported successfully
2025-12-09 12:07:53,111:INFO:Starting cross validation
2025-12-09 12:07:53,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:53,386:INFO:Calculating mean and std
2025-12-09 12:07:53,388:INFO:Creating metrics dataframe
2025-12-09 12:07:53,392:INFO:Uploading results into container
2025-12-09 12:07:53,394:INFO:Uploading model into container now
2025-12-09 12:07:53,395:INFO:_master_model_container: 11
2025-12-09 12:07:53,396:INFO:_display_container: 2
2025-12-09 12:07:53,398:INFO:KNeighborsRegressor(n_jobs=-1)
2025-12-09 12:07:53,398:INFO:create_model() successfully completed......................................
2025-12-09 12:07:53,517:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:53,517:INFO:Creating metrics dataframe
2025-12-09 12:07:53,537:INFO:Initializing Decision Tree Regressor
2025-12-09 12:07:53,538:INFO:Total runtime is 0.38377014001210535 minutes
2025-12-09 12:07:53,547:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:53,548:INFO:Initializing create_model()
2025-12-09 12:07:53,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:53,548:INFO:Checking exceptions
2025-12-09 12:07:53,548:INFO:Importing libraries
2025-12-09 12:07:53,548:INFO:Copying training dataset
2025-12-09 12:07:53,567:INFO:Defining folds
2025-12-09 12:07:53,568:INFO:Declaring metric variables
2025-12-09 12:07:53,577:INFO:Importing untrained model
2025-12-09 12:07:53,585:INFO:Decision Tree Regressor Imported successfully
2025-12-09 12:07:53,602:INFO:Starting cross validation
2025-12-09 12:07:53,606:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:53,887:INFO:Calculating mean and std
2025-12-09 12:07:53,889:INFO:Creating metrics dataframe
2025-12-09 12:07:53,893:INFO:Uploading results into container
2025-12-09 12:07:53,894:INFO:Uploading model into container now
2025-12-09 12:07:53,894:INFO:_master_model_container: 12
2025-12-09 12:07:53,896:INFO:_display_container: 2
2025-12-09 12:07:53,896:INFO:DecisionTreeRegressor(random_state=123)
2025-12-09 12:07:53,898:INFO:create_model() successfully completed......................................
2025-12-09 12:07:54,017:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:54,017:INFO:Creating metrics dataframe
2025-12-09 12:07:54,037:INFO:Initializing Random Forest Regressor
2025-12-09 12:07:54,039:INFO:Total runtime is 0.3921117186546326 minutes
2025-12-09 12:07:54,047:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:54,048:INFO:Initializing create_model()
2025-12-09 12:07:54,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:54,049:INFO:Checking exceptions
2025-12-09 12:07:54,049:INFO:Importing libraries
2025-12-09 12:07:54,049:INFO:Copying training dataset
2025-12-09 12:07:54,162:INFO:Defining folds
2025-12-09 12:07:54,167:INFO:Declaring metric variables
2025-12-09 12:07:54,192:INFO:Importing untrained model
2025-12-09 12:07:54,215:INFO:Random Forest Regressor Imported successfully
2025-12-09 12:07:54,237:INFO:Starting cross validation
2025-12-09 12:07:54,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:07:57,398:INFO:Calculating mean and std
2025-12-09 12:07:57,401:INFO:Creating metrics dataframe
2025-12-09 12:07:57,406:INFO:Uploading results into container
2025-12-09 12:07:57,408:INFO:Uploading model into container now
2025-12-09 12:07:57,409:INFO:_master_model_container: 13
2025-12-09 12:07:57,410:INFO:_display_container: 2
2025-12-09 12:07:57,411:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-12-09 12:07:57,412:INFO:create_model() successfully completed......................................
2025-12-09 12:07:57,549:INFO:SubProcess create_model() end ==================================
2025-12-09 12:07:57,549:INFO:Creating metrics dataframe
2025-12-09 12:07:57,572:INFO:Initializing Extra Trees Regressor
2025-12-09 12:07:57,574:INFO:Total runtime is 0.45103187163670866 minutes
2025-12-09 12:07:57,583:INFO:SubProcess create_model() called ==================================
2025-12-09 12:07:57,584:INFO:Initializing create_model()
2025-12-09 12:07:57,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:07:57,584:INFO:Checking exceptions
2025-12-09 12:07:57,584:INFO:Importing libraries
2025-12-09 12:07:57,584:INFO:Copying training dataset
2025-12-09 12:07:57,602:INFO:Defining folds
2025-12-09 12:07:57,602:INFO:Declaring metric variables
2025-12-09 12:07:57,612:INFO:Importing untrained model
2025-12-09 12:07:57,624:INFO:Extra Trees Regressor Imported successfully
2025-12-09 12:07:57,648:INFO:Starting cross validation
2025-12-09 12:07:57,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:00,039:INFO:Calculating mean and std
2025-12-09 12:08:00,042:INFO:Creating metrics dataframe
2025-12-09 12:08:00,047:INFO:Uploading results into container
2025-12-09 12:08:00,048:INFO:Uploading model into container now
2025-12-09 12:08:00,049:INFO:_master_model_container: 14
2025-12-09 12:08:00,050:INFO:_display_container: 2
2025-12-09 12:08:00,050:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-09 12:08:00,051:INFO:create_model() successfully completed......................................
2025-12-09 12:08:00,188:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:00,190:INFO:Creating metrics dataframe
2025-12-09 12:08:00,216:INFO:Initializing AdaBoost Regressor
2025-12-09 12:08:00,216:INFO:Total runtime is 0.4950565854708354 minutes
2025-12-09 12:08:00,224:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:00,224:INFO:Initializing create_model()
2025-12-09 12:08:00,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:00,226:INFO:Checking exceptions
2025-12-09 12:08:00,226:INFO:Importing libraries
2025-12-09 12:08:00,226:INFO:Copying training dataset
2025-12-09 12:08:00,244:INFO:Defining folds
2025-12-09 12:08:00,244:INFO:Declaring metric variables
2025-12-09 12:08:00,254:INFO:Importing untrained model
2025-12-09 12:08:00,263:INFO:AdaBoost Regressor Imported successfully
2025-12-09 12:08:00,284:INFO:Starting cross validation
2025-12-09 12:08:00,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:01,156:INFO:Calculating mean and std
2025-12-09 12:08:01,191:INFO:Creating metrics dataframe
2025-12-09 12:08:01,196:INFO:Uploading results into container
2025-12-09 12:08:01,197:INFO:Uploading model into container now
2025-12-09 12:08:01,199:INFO:_master_model_container: 15
2025-12-09 12:08:01,199:INFO:_display_container: 2
2025-12-09 12:08:01,200:INFO:AdaBoostRegressor(random_state=123)
2025-12-09 12:08:01,200:INFO:create_model() successfully completed......................................
2025-12-09 12:08:01,321:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:01,321:INFO:Creating metrics dataframe
2025-12-09 12:08:01,344:INFO:Initializing Gradient Boosting Regressor
2025-12-09 12:08:01,346:INFO:Total runtime is 0.513889483610789 minutes
2025-12-09 12:08:01,354:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:01,355:INFO:Initializing create_model()
2025-12-09 12:08:01,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:01,357:INFO:Checking exceptions
2025-12-09 12:08:01,357:INFO:Importing libraries
2025-12-09 12:08:01,357:INFO:Copying training dataset
2025-12-09 12:08:01,388:INFO:Defining folds
2025-12-09 12:08:01,390:INFO:Declaring metric variables
2025-12-09 12:08:01,425:INFO:Importing untrained model
2025-12-09 12:08:01,439:INFO:Gradient Boosting Regressor Imported successfully
2025-12-09 12:08:01,461:INFO:Starting cross validation
2025-12-09 12:08:01,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:02,688:INFO:Calculating mean and std
2025-12-09 12:08:02,691:INFO:Creating metrics dataframe
2025-12-09 12:08:02,695:INFO:Uploading results into container
2025-12-09 12:08:02,696:INFO:Uploading model into container now
2025-12-09 12:08:02,698:INFO:_master_model_container: 16
2025-12-09 12:08:02,698:INFO:_display_container: 2
2025-12-09 12:08:02,699:INFO:GradientBoostingRegressor(random_state=123)
2025-12-09 12:08:02,699:INFO:create_model() successfully completed......................................
2025-12-09 12:08:02,820:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:02,822:INFO:Creating metrics dataframe
2025-12-09 12:08:02,848:INFO:Initializing Light Gradient Boosting Machine
2025-12-09 12:08:02,848:INFO:Total runtime is 0.5389357169469198 minutes
2025-12-09 12:08:02,857:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:02,857:INFO:Initializing create_model()
2025-12-09 12:08:02,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:02,859:INFO:Checking exceptions
2025-12-09 12:08:02,859:INFO:Importing libraries
2025-12-09 12:08:02,859:INFO:Copying training dataset
2025-12-09 12:08:02,880:INFO:Defining folds
2025-12-09 12:08:02,880:INFO:Declaring metric variables
2025-12-09 12:08:02,891:INFO:Importing untrained model
2025-12-09 12:08:02,900:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-09 12:08:02,923:INFO:Starting cross validation
2025-12-09 12:08:02,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:04,820:INFO:Calculating mean and std
2025-12-09 12:08:04,824:INFO:Creating metrics dataframe
2025-12-09 12:08:04,830:INFO:Uploading results into container
2025-12-09 12:08:04,831:INFO:Uploading model into container now
2025-12-09 12:08:04,833:INFO:_master_model_container: 17
2025-12-09 12:08:04,833:INFO:_display_container: 2
2025-12-09 12:08:04,835:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-09 12:08:04,835:INFO:create_model() successfully completed......................................
2025-12-09 12:08:04,972:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:04,972:INFO:Creating metrics dataframe
2025-12-09 12:08:04,997:INFO:Initializing Dummy Regressor
2025-12-09 12:08:04,997:INFO:Total runtime is 0.574754011631012 minutes
2025-12-09 12:08:05,008:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:05,008:INFO:Initializing create_model()
2025-12-09 12:08:05,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019922EFDB40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:05,008:INFO:Checking exceptions
2025-12-09 12:08:05,008:INFO:Importing libraries
2025-12-09 12:08:05,008:INFO:Copying training dataset
2025-12-09 12:08:05,025:INFO:Defining folds
2025-12-09 12:08:05,025:INFO:Declaring metric variables
2025-12-09 12:08:05,036:INFO:Importing untrained model
2025-12-09 12:08:05,046:INFO:Dummy Regressor Imported successfully
2025-12-09 12:08:05,064:INFO:Starting cross validation
2025-12-09 12:08:05,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:05,277:INFO:Calculating mean and std
2025-12-09 12:08:05,279:INFO:Creating metrics dataframe
2025-12-09 12:08:05,284:INFO:Uploading results into container
2025-12-09 12:08:05,285:INFO:Uploading model into container now
2025-12-09 12:08:05,286:INFO:_master_model_container: 18
2025-12-09 12:08:05,287:INFO:_display_container: 2
2025-12-09 12:08:05,287:INFO:DummyRegressor()
2025-12-09 12:08:05,287:INFO:create_model() successfully completed......................................
2025-12-09 12:08:05,410:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:05,410:INFO:Creating metrics dataframe
2025-12-09 12:08:05,440:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-09 12:08:05,460:INFO:Initializing create_model()
2025-12-09 12:08:05,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:05,461:INFO:Checking exceptions
2025-12-09 12:08:05,465:INFO:Importing libraries
2025-12-09 12:08:05,465:INFO:Copying training dataset
2025-12-09 12:08:05,481:INFO:Defining folds
2025-12-09 12:08:05,481:INFO:Declaring metric variables
2025-12-09 12:08:05,481:INFO:Importing untrained model
2025-12-09 12:08:05,481:INFO:Declaring custom model
2025-12-09 12:08:05,484:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-09 12:08:05,486:INFO:Cross validation set to False
2025-12-09 12:08:05,486:INFO:Fitting Model
2025-12-09 12:08:05,536:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-09 12:08:05,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001827 seconds.
2025-12-09 12:08:05,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-09 12:08:05,543:INFO:[LightGBM] [Info] Total Bins 874
2025-12-09 12:08:05,543:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-09 12:08:05,544:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-09 12:08:05,811:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-09 12:08:05,811:INFO:create_model() successfully completed......................................
2025-12-09 12:08:06,018:INFO:_master_model_container: 18
2025-12-09 12:08:06,020:INFO:_display_container: 2
2025-12-09 12:08:06,023:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-09 12:08:06,023:INFO:compare_models() successfully completed......................................
2025-12-09 12:08:06,028:INFO:Initializing tune_model()
2025-12-09 12:08:06,028:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>)
2025-12-09 12:08:06,028:INFO:Checking exceptions
2025-12-09 12:08:06,070:INFO:Copying training dataset
2025-12-09 12:08:06,085:INFO:Checking base model
2025-12-09 12:08:06,085:INFO:Base model : Light Gradient Boosting Machine
2025-12-09 12:08:06,096:INFO:Declaring metric variables
2025-12-09 12:08:06,105:INFO:Defining Hyperparameters
2025-12-09 12:08:06,260:INFO:Tuning with n_jobs=-1
2025-12-09 12:08:06,260:INFO:Initializing RandomizedSearchCV
2025-12-09 12:08:31,236:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-09 12:08:31,240:INFO:Hyperparameter search completed
2025-12-09 12:08:31,241:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:31,242:INFO:Initializing create_model()
2025-12-09 12:08:31,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001991A74A470>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-09 12:08:31,243:INFO:Checking exceptions
2025-12-09 12:08:31,243:INFO:Importing libraries
2025-12-09 12:08:31,243:INFO:Copying training dataset
2025-12-09 12:08:31,266:INFO:Defining folds
2025-12-09 12:08:31,266:INFO:Declaring metric variables
2025-12-09 12:08:31,276:INFO:Importing untrained model
2025-12-09 12:08:31,276:INFO:Declaring custom model
2025-12-09 12:08:31,290:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-09 12:08:31,311:INFO:Starting cross validation
2025-12-09 12:08:31,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:33,069:INFO:Calculating mean and std
2025-12-09 12:08:33,072:INFO:Creating metrics dataframe
2025-12-09 12:08:33,088:INFO:Finalizing model
2025-12-09 12:08:33,133:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-09 12:08:33,133:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-09 12:08:33,134:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-09 12:08:33,142:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-09 12:08:33,142:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-09 12:08:33,142:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-09 12:08:33,142:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-09 12:08:33,145:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.
2025-12-09 12:08:33,145:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-09 12:08:33,145:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-09 12:08:33,146:INFO:[LightGBM] [Info] Total Bins 874
2025-12-09 12:08:33,146:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-09 12:08:33,148:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-09 12:08:33,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-09 12:08:33,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-09 12:08:33,327:INFO:Uploading results into container
2025-12-09 12:08:33,328:INFO:Uploading model into container now
2025-12-09 12:08:33,330:INFO:_master_model_container: 19
2025-12-09 12:08:33,330:INFO:_display_container: 3
2025-12-09 12:08:33,333:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005)
2025-12-09 12:08:33,334:INFO:create_model() successfully completed......................................
2025-12-09 12:08:33,471:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:33,472:INFO:choose_better activated
2025-12-09 12:08:33,480:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:33,482:INFO:Initializing create_model()
2025-12-09 12:08:33,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001991BD37820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:33,482:INFO:Checking exceptions
2025-12-09 12:08:33,487:INFO:Importing libraries
2025-12-09 12:08:33,487:INFO:Copying training dataset
2025-12-09 12:08:33,503:INFO:Defining folds
2025-12-09 12:08:33,503:INFO:Declaring metric variables
2025-12-09 12:08:33,503:INFO:Importing untrained model
2025-12-09 12:08:33,505:INFO:Declaring custom model
2025-12-09 12:08:33,509:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-09 12:08:33,511:INFO:Starting cross validation
2025-12-09 12:08:33,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:35,517:INFO:Calculating mean and std
2025-12-09 12:08:35,518:INFO:Creating metrics dataframe
2025-12-09 12:08:35,521:INFO:Finalizing model
2025-12-09 12:08:35,570:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-09 12:08:35,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001003 seconds.
2025-12-09 12:08:35,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-09 12:08:35,573:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-09 12:08:35,574:INFO:[LightGBM] [Info] Total Bins 874
2025-12-09 12:08:35,574:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-09 12:08:35,574:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-09 12:08:35,766:INFO:Uploading results into container
2025-12-09 12:08:35,768:INFO:Uploading model into container now
2025-12-09 12:08:35,769:INFO:_master_model_container: 20
2025-12-09 12:08:35,769:INFO:_display_container: 4
2025-12-09 12:08:35,770:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-09 12:08:35,770:INFO:create_model() successfully completed......................................
2025-12-09 12:08:35,907:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:35,907:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9584
2025-12-09 12:08:35,910:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005) result for R2 is 0.9462
2025-12-09 12:08:35,912:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-12-09 12:08:35,912:INFO:choose_better completed
2025-12-09 12:08:35,912:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-09 12:08:35,937:INFO:_master_model_container: 20
2025-12-09 12:08:35,938:INFO:_display_container: 3
2025-12-09 12:08:35,939:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-09 12:08:35,940:INFO:tune_model() successfully completed......................................
2025-12-09 12:08:36,098:INFO:PyCaret ClassificationExperiment
2025-12-09 12:08:36,098:INFO:Logging name: clf-default-name
2025-12-09 12:08:36,098:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-09 12:08:36,098:INFO:version 3.3.2
2025-12-09 12:08:36,098:INFO:Initializing setup()
2025-12-09 12:08:36,098:INFO:self.USI: 7ee5
2025-12-09 12:08:36,098:INFO:self._variable_keys: {'_available_plots', 'fold_shuffle_param', 'data', 'gpu_n_jobs_param', '_ml_usecase', 'y_train', 'gpu_param', 'n_jobs_param', 'X_train', 'idx', 'target_param', 'log_plots_param', 'is_multiclass', 'html_param', 'pipeline', 'X', 'USI', 'seed', 'fold_groups_param', 'exp_id', 'X_test', 'logging_param', 'exp_name_log', 'y_test', 'y', 'fold_generator', 'fix_imbalance', 'memory'}
2025-12-09 12:08:36,098:INFO:Checking environment
2025-12-09 12:08:36,098:INFO:python_version: 3.10.19
2025-12-09 12:08:36,098:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-09 12:08:36,098:INFO:machine: AMD64
2025-12-09 12:08:36,099:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-09 12:08:36,100:INFO:Memory: svmem(total=33699516416, available=14962143232, percent=55.6, used=18737373184, free=14962143232)
2025-12-09 12:08:36,100:INFO:Physical Core: 8
2025-12-09 12:08:36,100:INFO:Logical Core: 16
2025-12-09 12:08:36,100:INFO:Checking libraries
2025-12-09 12:08:36,100:INFO:System:
2025-12-09 12:08:36,100:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-09 12:08:36,100:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-09 12:08:36,100:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-09 12:08:36,100:INFO:PyCaret required dependencies:
2025-12-09 12:08:36,101:INFO:                 pip: 25.3
2025-12-09 12:08:36,101:INFO:          setuptools: 80.9.0
2025-12-09 12:08:36,101:INFO:             pycaret: 3.3.2
2025-12-09 12:08:36,101:INFO:             IPython: 8.37.0
2025-12-09 12:08:36,101:INFO:          ipywidgets: 8.1.8
2025-12-09 12:08:36,101:INFO:                tqdm: 4.67.1
2025-12-09 12:08:36,101:INFO:               numpy: 1.26.4
2025-12-09 12:08:36,101:INFO:              pandas: 2.1.4
2025-12-09 12:08:36,101:INFO:              jinja2: 3.1.6
2025-12-09 12:08:36,101:INFO:               scipy: 1.11.4
2025-12-09 12:08:36,101:INFO:              joblib: 1.3.2
2025-12-09 12:08:36,101:INFO:             sklearn: 1.4.2
2025-12-09 12:08:36,101:INFO:                pyod: 2.0.6
2025-12-09 12:08:36,101:INFO:            imblearn: 0.14.0
2025-12-09 12:08:36,101:INFO:   category_encoders: 2.7.0
2025-12-09 12:08:36,101:INFO:            lightgbm: 4.6.0
2025-12-09 12:08:36,103:INFO:               numba: 0.62.1
2025-12-09 12:08:36,103:INFO:            requests: 2.32.5
2025-12-09 12:08:36,103:INFO:          matplotlib: 3.7.5
2025-12-09 12:08:36,103:INFO:          scikitplot: 0.3.7
2025-12-09 12:08:36,103:INFO:         yellowbrick: 1.5
2025-12-09 12:08:36,103:INFO:              plotly: 6.5.0
2025-12-09 12:08:36,103:INFO:    plotly-resampler: Not installed
2025-12-09 12:08:36,103:INFO:             kaleido: 1.2.0
2025-12-09 12:08:36,103:INFO:           schemdraw: 0.15
2025-12-09 12:08:36,103:INFO:         statsmodels: 0.14.5
2025-12-09 12:08:36,103:INFO:              sktime: 0.26.0
2025-12-09 12:08:36,103:INFO:               tbats: 1.1.3
2025-12-09 12:08:36,103:INFO:            pmdarima: 2.0.4
2025-12-09 12:08:36,103:INFO:              psutil: 7.1.3
2025-12-09 12:08:36,103:INFO:          markupsafe: 3.0.3
2025-12-09 12:08:36,103:INFO:             pickle5: Not installed
2025-12-09 12:08:36,103:INFO:         cloudpickle: 3.1.2
2025-12-09 12:08:36,104:INFO:         deprecation: 2.1.0
2025-12-09 12:08:36,104:INFO:              xxhash: 3.6.0
2025-12-09 12:08:36,104:INFO:           wurlitzer: Not installed
2025-12-09 12:08:36,104:INFO:PyCaret optional dependencies:
2025-12-09 12:08:36,104:INFO:                shap: Not installed
2025-12-09 12:08:36,104:INFO:           interpret: Not installed
2025-12-09 12:08:36,104:INFO:                umap: Not installed
2025-12-09 12:08:36,104:INFO:     ydata_profiling: Not installed
2025-12-09 12:08:36,104:INFO:  explainerdashboard: Not installed
2025-12-09 12:08:36,105:INFO:             autoviz: Not installed
2025-12-09 12:08:36,105:INFO:           fairlearn: Not installed
2025-12-09 12:08:36,105:INFO:          deepchecks: Not installed
2025-12-09 12:08:36,105:INFO:             xgboost: Not installed
2025-12-09 12:08:36,105:INFO:            catboost: Not installed
2025-12-09 12:08:36,106:INFO:              kmodes: Not installed
2025-12-09 12:08:36,106:INFO:             mlxtend: Not installed
2025-12-09 12:08:36,106:INFO:       statsforecast: Not installed
2025-12-09 12:08:36,106:INFO:        tune_sklearn: Not installed
2025-12-09 12:08:36,106:INFO:                 ray: Not installed
2025-12-09 12:08:36,106:INFO:            hyperopt: Not installed
2025-12-09 12:08:36,106:INFO:              optuna: Not installed
2025-12-09 12:08:36,106:INFO:               skopt: Not installed
2025-12-09 12:08:36,106:INFO:              mlflow: Not installed
2025-12-09 12:08:36,106:INFO:              gradio: Not installed
2025-12-09 12:08:36,106:INFO:             fastapi: Not installed
2025-12-09 12:08:36,107:INFO:             uvicorn: Not installed
2025-12-09 12:08:36,107:INFO:              m2cgen: Not installed
2025-12-09 12:08:36,107:INFO:           evidently: Not installed
2025-12-09 12:08:36,107:INFO:               fugue: Not installed
2025-12-09 12:08:36,107:INFO:           streamlit: Not installed
2025-12-09 12:08:36,108:INFO:             prophet: Not installed
2025-12-09 12:08:36,108:INFO:None
2025-12-09 12:08:36,108:INFO:Set up data.
2025-12-09 12:08:36,133:INFO:Set up folding strategy.
2025-12-09 12:08:36,133:INFO:Set up train/test split.
2025-12-09 12:08:36,151:INFO:Set up index.
2025-12-09 12:08:36,152:INFO:Assigning column types.
2025-12-09 12:08:36,169:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-09 12:08:36,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:08:36,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-09 12:08:36,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:36,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:36,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-09 12:08:36,509:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-09 12:08:36,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:36,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:36,583:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-09 12:08:36,702:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-09 12:08:36,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:36,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:36,897:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-09 12:08:36,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:36,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:36,973:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-09 12:08:37,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:37,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:37,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:37,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:37,368:INFO:Preparing preprocessing pipeline...
2025-12-09 12:08:37,371:INFO:Set up simple imputation.
2025-12-09 12:08:37,371:INFO:Set up imbalanced handling.
2025-12-09 12:08:37,375:INFO:Set up column name cleaning.
2025-12-09 12:08:37,531:INFO:Finished creating preprocessing pipeline.
2025-12-09 12:08:37,550:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'selling_price',
                                             'km_driven', 'mileage', 'engine',
                                             'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Sec...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-09 12:08:37,550:INFO:Creating final display dataframe.
2025-12-09 12:08:37,841:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 17)
4        Transformed data shape           (11982, 17)
5   Transformed train set shape            (9610, 17)
6    Transformed test set shape            (2372, 17)
7              Numeric features                    16
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                Fix imbalance                  True
13         Fix imbalance method                 SMOTE
14               Fold Generator       StratifiedKFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment                 False
19              Experiment Name      clf-default-name
20                          USI                  7ee5
2025-12-09 12:08:38,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:38,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:38,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:38,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-09 12:08:38,219:INFO:setup() successfully completed in 2.13s...............
2025-12-09 12:08:38,219:INFO:Initializing compare_models()
2025-12-09 12:08:38,221:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-09 12:08:38,221:INFO:Checking exceptions
2025-12-09 12:08:38,234:INFO:Preparing display monitor
2025-12-09 12:08:38,307:INFO:Initializing Logistic Regression
2025-12-09 12:08:38,307:INFO:Total runtime is 0.0 minutes
2025-12-09 12:08:38,319:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:38,320:INFO:Initializing create_model()
2025-12-09 12:08:38,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:38,320:INFO:Checking exceptions
2025-12-09 12:08:38,322:INFO:Importing libraries
2025-12-09 12:08:38,322:INFO:Copying training dataset
2025-12-09 12:08:38,347:INFO:Defining folds
2025-12-09 12:08:38,347:INFO:Declaring metric variables
2025-12-09 12:08:38,357:INFO:Importing untrained model
2025-12-09 12:08:38,371:INFO:Logistic Regression Imported successfully
2025-12-09 12:08:38,394:INFO:Starting cross validation
2025-12-09 12:08:38,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:40,151:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-09 12:08:40,206:INFO:Calculating mean and std
2025-12-09 12:08:40,207:INFO:Creating metrics dataframe
2025-12-09 12:08:40,212:INFO:Uploading results into container
2025-12-09 12:08:40,214:INFO:Uploading model into container now
2025-12-09 12:08:40,216:INFO:_master_model_container: 1
2025-12-09 12:08:40,216:INFO:_display_container: 2
2025-12-09 12:08:40,218:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 12:08:40,218:INFO:create_model() successfully completed......................................
2025-12-09 12:08:40,358:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:40,358:INFO:Creating metrics dataframe
2025-12-09 12:08:40,373:INFO:Initializing K Neighbors Classifier
2025-12-09 12:08:40,374:INFO:Total runtime is 0.034440847237904866 minutes
2025-12-09 12:08:40,383:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:40,384:INFO:Initializing create_model()
2025-12-09 12:08:40,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:40,384:INFO:Checking exceptions
2025-12-09 12:08:40,384:INFO:Importing libraries
2025-12-09 12:08:40,385:INFO:Copying training dataset
2025-12-09 12:08:40,410:INFO:Defining folds
2025-12-09 12:08:40,410:INFO:Declaring metric variables
2025-12-09 12:08:40,419:INFO:Importing untrained model
2025-12-09 12:08:40,430:INFO:K Neighbors Classifier Imported successfully
2025-12-09 12:08:40,451:INFO:Starting cross validation
2025-12-09 12:08:40,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:40,937:INFO:Calculating mean and std
2025-12-09 12:08:40,940:INFO:Creating metrics dataframe
2025-12-09 12:08:40,944:INFO:Uploading results into container
2025-12-09 12:08:40,946:INFO:Uploading model into container now
2025-12-09 12:08:40,947:INFO:_master_model_container: 2
2025-12-09 12:08:40,947:INFO:_display_container: 2
2025-12-09 12:08:40,947:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-09 12:08:40,948:INFO:create_model() successfully completed......................................
2025-12-09 12:08:41,073:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:41,074:INFO:Creating metrics dataframe
2025-12-09 12:08:41,091:INFO:Initializing Naive Bayes
2025-12-09 12:08:41,092:INFO:Total runtime is 0.04640112717946371 minutes
2025-12-09 12:08:41,100:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:41,102:INFO:Initializing create_model()
2025-12-09 12:08:41,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:41,103:INFO:Checking exceptions
2025-12-09 12:08:41,103:INFO:Importing libraries
2025-12-09 12:08:41,103:INFO:Copying training dataset
2025-12-09 12:08:41,126:INFO:Defining folds
2025-12-09 12:08:41,126:INFO:Declaring metric variables
2025-12-09 12:08:41,134:INFO:Importing untrained model
2025-12-09 12:08:41,146:INFO:Naive Bayes Imported successfully
2025-12-09 12:08:41,165:INFO:Starting cross validation
2025-12-09 12:08:41,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:41,454:INFO:Calculating mean and std
2025-12-09 12:08:41,457:INFO:Creating metrics dataframe
2025-12-09 12:08:41,461:INFO:Uploading results into container
2025-12-09 12:08:41,463:INFO:Uploading model into container now
2025-12-09 12:08:41,464:INFO:_master_model_container: 3
2025-12-09 12:08:41,464:INFO:_display_container: 2
2025-12-09 12:08:41,464:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-09 12:08:41,464:INFO:create_model() successfully completed......................................
2025-12-09 12:08:41,587:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:41,588:INFO:Creating metrics dataframe
2025-12-09 12:08:41,606:INFO:Initializing Decision Tree Classifier
2025-12-09 12:08:41,606:INFO:Total runtime is 0.05498292446136475 minutes
2025-12-09 12:08:41,614:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:41,615:INFO:Initializing create_model()
2025-12-09 12:08:41,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:41,615:INFO:Checking exceptions
2025-12-09 12:08:41,615:INFO:Importing libraries
2025-12-09 12:08:41,615:INFO:Copying training dataset
2025-12-09 12:08:41,635:INFO:Defining folds
2025-12-09 12:08:41,636:INFO:Declaring metric variables
2025-12-09 12:08:41,644:INFO:Importing untrained model
2025-12-09 12:08:41,653:INFO:Decision Tree Classifier Imported successfully
2025-12-09 12:08:41,668:INFO:Starting cross validation
2025-12-09 12:08:41,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:42,050:INFO:Calculating mean and std
2025-12-09 12:08:42,053:INFO:Creating metrics dataframe
2025-12-09 12:08:42,057:INFO:Uploading results into container
2025-12-09 12:08:42,059:INFO:Uploading model into container now
2025-12-09 12:08:42,059:INFO:_master_model_container: 4
2025-12-09 12:08:42,059:INFO:_display_container: 2
2025-12-09 12:08:42,060:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-09 12:08:42,062:INFO:create_model() successfully completed......................................
2025-12-09 12:08:42,183:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:42,183:INFO:Creating metrics dataframe
2025-12-09 12:08:42,201:INFO:Initializing SVM - Linear Kernel
2025-12-09 12:08:42,201:INFO:Total runtime is 0.06489091714223226 minutes
2025-12-09 12:08:42,211:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:42,211:INFO:Initializing create_model()
2025-12-09 12:08:42,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:42,212:INFO:Checking exceptions
2025-12-09 12:08:42,212:INFO:Importing libraries
2025-12-09 12:08:42,212:INFO:Copying training dataset
2025-12-09 12:08:42,232:INFO:Defining folds
2025-12-09 12:08:42,232:INFO:Declaring metric variables
2025-12-09 12:08:42,244:INFO:Importing untrained model
2025-12-09 12:08:42,257:INFO:SVM - Linear Kernel Imported successfully
2025-12-09 12:08:42,279:INFO:Starting cross validation
2025-12-09 12:08:42,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:42,754:INFO:Calculating mean and std
2025-12-09 12:08:42,757:INFO:Creating metrics dataframe
2025-12-09 12:08:42,761:INFO:Uploading results into container
2025-12-09 12:08:42,763:INFO:Uploading model into container now
2025-12-09 12:08:42,764:INFO:_master_model_container: 5
2025-12-09 12:08:42,764:INFO:_display_container: 2
2025-12-09 12:08:42,765:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-09 12:08:42,765:INFO:create_model() successfully completed......................................
2025-12-09 12:08:42,890:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:42,890:INFO:Creating metrics dataframe
2025-12-09 12:08:42,910:INFO:Initializing Ridge Classifier
2025-12-09 12:08:42,910:INFO:Total runtime is 0.0767039696375529 minutes
2025-12-09 12:08:42,918:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:42,919:INFO:Initializing create_model()
2025-12-09 12:08:42,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:42,920:INFO:Checking exceptions
2025-12-09 12:08:42,920:INFO:Importing libraries
2025-12-09 12:08:42,921:INFO:Copying training dataset
2025-12-09 12:08:42,943:INFO:Defining folds
2025-12-09 12:08:42,944:INFO:Declaring metric variables
2025-12-09 12:08:42,955:INFO:Importing untrained model
2025-12-09 12:08:42,965:INFO:Ridge Classifier Imported successfully
2025-12-09 12:08:42,983:INFO:Starting cross validation
2025-12-09 12:08:42,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:43,169:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97415e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,171:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.22879e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,171:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.12855e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,172:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.76553e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,175:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.07985e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,176:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97653e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,179:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.25459e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,194:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.84536e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,194:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.18612e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,211:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.27127e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-09 12:08:43,284:INFO:Calculating mean and std
2025-12-09 12:08:43,287:INFO:Creating metrics dataframe
2025-12-09 12:08:43,291:INFO:Uploading results into container
2025-12-09 12:08:43,293:INFO:Uploading model into container now
2025-12-09 12:08:43,294:INFO:_master_model_container: 6
2025-12-09 12:08:43,294:INFO:_display_container: 2
2025-12-09 12:08:43,294:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-09 12:08:43,294:INFO:create_model() successfully completed......................................
2025-12-09 12:08:43,419:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:43,436:INFO:Creating metrics dataframe
2025-12-09 12:08:43,459:INFO:Initializing Random Forest Classifier
2025-12-09 12:08:43,461:INFO:Total runtime is 0.08587816556294758 minutes
2025-12-09 12:08:43,470:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:43,472:INFO:Initializing create_model()
2025-12-09 12:08:43,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:43,472:INFO:Checking exceptions
2025-12-09 12:08:43,473:INFO:Importing libraries
2025-12-09 12:08:43,473:INFO:Copying training dataset
2025-12-09 12:08:43,490:INFO:Defining folds
2025-12-09 12:08:43,491:INFO:Declaring metric variables
2025-12-09 12:08:43,499:INFO:Importing untrained model
2025-12-09 12:08:43,509:INFO:Random Forest Classifier Imported successfully
2025-12-09 12:08:43,525:INFO:Starting cross validation
2025-12-09 12:08:43,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:45,668:INFO:Calculating mean and std
2025-12-09 12:08:45,670:INFO:Creating metrics dataframe
2025-12-09 12:08:45,676:INFO:Uploading results into container
2025-12-09 12:08:45,677:INFO:Uploading model into container now
2025-12-09 12:08:45,678:INFO:_master_model_container: 7
2025-12-09 12:08:45,678:INFO:_display_container: 2
2025-12-09 12:08:45,680:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-09 12:08:45,680:INFO:create_model() successfully completed......................................
2025-12-09 12:08:45,807:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:45,807:INFO:Creating metrics dataframe
2025-12-09 12:08:45,828:INFO:Initializing Quadratic Discriminant Analysis
2025-12-09 12:08:45,829:INFO:Total runtime is 0.12535454432169596 minutes
2025-12-09 12:08:45,837:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:45,838:INFO:Initializing create_model()
2025-12-09 12:08:45,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:45,839:INFO:Checking exceptions
2025-12-09 12:08:45,839:INFO:Importing libraries
2025-12-09 12:08:45,840:INFO:Copying training dataset
2025-12-09 12:08:45,858:INFO:Defining folds
2025-12-09 12:08:45,859:INFO:Declaring metric variables
2025-12-09 12:08:45,867:INFO:Importing untrained model
2025-12-09 12:08:45,878:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-09 12:08:45,896:INFO:Starting cross validation
2025-12-09 12:08:45,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:46,120:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,122:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,149:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,149:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,149:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,149:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,153:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,153:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,153:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,157:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,157:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,158:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,160:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,161:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,161:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,162:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,168:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,170:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,171:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,185:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-09 12:08:46,191:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,192:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,192:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,193:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,193:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,193:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,194:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,198:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,198:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,199:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,200:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,200:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,200:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,201:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,201:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,201:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,201:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,201:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,201:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,203:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,206:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-09 12:08:46,208:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,208:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,208:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,211:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,211:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,211:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,212:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,217:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,222:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,222:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,224:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-09 12:08:46,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-09 12:08:46,227:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-09 12:08:46,227:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,229:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,229:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,229:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,229:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,229:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,230:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,230:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,230:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-09 12:08:46,234:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,234:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,234:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-09 12:08:46,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-09 12:08:46,245:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,245:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-09 12:08:46,245:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,248:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,248:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,250:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-09 12:08:46,251:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-09 12:08:46,266:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,266:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,267:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:46,286:INFO:Calculating mean and std
2025-12-09 12:08:46,289:INFO:Creating metrics dataframe
2025-12-09 12:08:46,292:INFO:Uploading results into container
2025-12-09 12:08:46,294:INFO:Uploading model into container now
2025-12-09 12:08:46,295:INFO:_master_model_container: 8
2025-12-09 12:08:46,295:INFO:_display_container: 2
2025-12-09 12:08:46,295:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-09 12:08:46,296:INFO:create_model() successfully completed......................................
2025-12-09 12:08:46,420:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:46,421:INFO:Creating metrics dataframe
2025-12-09 12:08:46,440:INFO:Initializing Ada Boost Classifier
2025-12-09 12:08:46,442:INFO:Total runtime is 0.13556880156199136 minutes
2025-12-09 12:08:46,450:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:46,451:INFO:Initializing create_model()
2025-12-09 12:08:46,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:46,451:INFO:Checking exceptions
2025-12-09 12:08:46,452:INFO:Importing libraries
2025-12-09 12:08:46,452:INFO:Copying training dataset
2025-12-09 12:08:46,468:INFO:Defining folds
2025-12-09 12:08:46,468:INFO:Declaring metric variables
2025-12-09 12:08:46,479:INFO:Importing untrained model
2025-12-09 12:08:46,489:INFO:Ada Boost Classifier Imported successfully
2025-12-09 12:08:46,507:INFO:Starting cross validation
2025-12-09 12:08:46,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:46,665:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,666:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,668:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,668:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,669:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,669:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,671:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:46,686:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-09 12:08:47,819:INFO:Calculating mean and std
2025-12-09 12:08:47,821:INFO:Creating metrics dataframe
2025-12-09 12:08:47,826:INFO:Uploading results into container
2025-12-09 12:08:47,828:INFO:Uploading model into container now
2025-12-09 12:08:47,829:INFO:_master_model_container: 9
2025-12-09 12:08:47,829:INFO:_display_container: 2
2025-12-09 12:08:47,830:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-09 12:08:47,831:INFO:create_model() successfully completed......................................
2025-12-09 12:08:47,957:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:47,957:INFO:Creating metrics dataframe
2025-12-09 12:08:47,978:INFO:Initializing Gradient Boosting Classifier
2025-12-09 12:08:47,978:INFO:Total runtime is 0.16117242177327473 minutes
2025-12-09 12:08:47,986:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:47,987:INFO:Initializing create_model()
2025-12-09 12:08:47,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:47,987:INFO:Checking exceptions
2025-12-09 12:08:47,987:INFO:Importing libraries
2025-12-09 12:08:47,989:INFO:Copying training dataset
2025-12-09 12:08:48,006:INFO:Defining folds
2025-12-09 12:08:48,007:INFO:Declaring metric variables
2025-12-09 12:08:48,017:INFO:Importing untrained model
2025-12-09 12:08:48,026:INFO:Gradient Boosting Classifier Imported successfully
2025-12-09 12:08:48,049:INFO:Starting cross validation
2025-12-09 12:08:48,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:51,328:INFO:Calculating mean and std
2025-12-09 12:08:51,331:INFO:Creating metrics dataframe
2025-12-09 12:08:51,335:INFO:Uploading results into container
2025-12-09 12:08:51,337:INFO:Uploading model into container now
2025-12-09 12:08:51,337:INFO:_master_model_container: 10
2025-12-09 12:08:51,338:INFO:_display_container: 2
2025-12-09 12:08:51,339:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-09 12:08:51,339:INFO:create_model() successfully completed......................................
2025-12-09 12:08:51,463:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:51,463:INFO:Creating metrics dataframe
2025-12-09 12:08:51,484:INFO:Initializing Linear Discriminant Analysis
2025-12-09 12:08:51,484:INFO:Total runtime is 0.219607671101888 minutes
2025-12-09 12:08:51,493:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:51,493:INFO:Initializing create_model()
2025-12-09 12:08:51,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:51,494:INFO:Checking exceptions
2025-12-09 12:08:51,494:INFO:Importing libraries
2025-12-09 12:08:51,494:INFO:Copying training dataset
2025-12-09 12:08:51,512:INFO:Defining folds
2025-12-09 12:08:51,513:INFO:Declaring metric variables
2025-12-09 12:08:51,521:INFO:Importing untrained model
2025-12-09 12:08:51,531:INFO:Linear Discriminant Analysis Imported successfully
2025-12-09 12:08:51,547:INFO:Starting cross validation
2025-12-09 12:08:51,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:51,801:INFO:Calculating mean and std
2025-12-09 12:08:51,803:INFO:Creating metrics dataframe
2025-12-09 12:08:51,807:INFO:Uploading results into container
2025-12-09 12:08:51,808:INFO:Uploading model into container now
2025-12-09 12:08:51,809:INFO:_master_model_container: 11
2025-12-09 12:08:51,809:INFO:_display_container: 2
2025-12-09 12:08:51,811:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-09 12:08:51,811:INFO:create_model() successfully completed......................................
2025-12-09 12:08:51,934:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:51,934:INFO:Creating metrics dataframe
2025-12-09 12:08:51,959:INFO:Initializing Extra Trees Classifier
2025-12-09 12:08:51,959:INFO:Total runtime is 0.22752027511596679 minutes
2025-12-09 12:08:51,967:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:51,967:INFO:Initializing create_model()
2025-12-09 12:08:51,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:51,968:INFO:Checking exceptions
2025-12-09 12:08:51,969:INFO:Importing libraries
2025-12-09 12:08:51,969:INFO:Copying training dataset
2025-12-09 12:08:51,986:INFO:Defining folds
2025-12-09 12:08:51,986:INFO:Declaring metric variables
2025-12-09 12:08:51,996:INFO:Importing untrained model
2025-12-09 12:08:52,007:INFO:Extra Trees Classifier Imported successfully
2025-12-09 12:08:52,028:INFO:Starting cross validation
2025-12-09 12:08:52,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:53,717:INFO:Calculating mean and std
2025-12-09 12:08:53,719:INFO:Creating metrics dataframe
2025-12-09 12:08:53,723:INFO:Uploading results into container
2025-12-09 12:08:53,725:INFO:Uploading model into container now
2025-12-09 12:08:53,726:INFO:_master_model_container: 12
2025-12-09 12:08:53,726:INFO:_display_container: 2
2025-12-09 12:08:53,728:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-09 12:08:53,728:INFO:create_model() successfully completed......................................
2025-12-09 12:08:53,850:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:53,851:INFO:Creating metrics dataframe
2025-12-09 12:08:53,872:INFO:Initializing Light Gradient Boosting Machine
2025-12-09 12:08:53,874:INFO:Total runtime is 0.25941669940948486 minutes
2025-12-09 12:08:53,881:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:53,882:INFO:Initializing create_model()
2025-12-09 12:08:53,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:53,882:INFO:Checking exceptions
2025-12-09 12:08:53,882:INFO:Importing libraries
2025-12-09 12:08:53,882:INFO:Copying training dataset
2025-12-09 12:08:53,900:INFO:Defining folds
2025-12-09 12:08:53,900:INFO:Declaring metric variables
2025-12-09 12:08:53,911:INFO:Importing untrained model
2025-12-09 12:08:53,920:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-09 12:08:53,937:INFO:Starting cross validation
2025-12-09 12:08:53,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:56,219:INFO:Calculating mean and std
2025-12-09 12:08:56,223:INFO:Creating metrics dataframe
2025-12-09 12:08:56,229:INFO:Uploading results into container
2025-12-09 12:08:56,231:INFO:Uploading model into container now
2025-12-09 12:08:56,232:INFO:_master_model_container: 13
2025-12-09 12:08:56,233:INFO:_display_container: 2
2025-12-09 12:08:56,235:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-09 12:08:56,235:INFO:create_model() successfully completed......................................
2025-12-09 12:08:56,369:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:56,369:INFO:Creating metrics dataframe
2025-12-09 12:08:56,396:INFO:Initializing Dummy Classifier
2025-12-09 12:08:56,396:INFO:Total runtime is 0.30146961609522505 minutes
2025-12-09 12:08:56,404:INFO:SubProcess create_model() called ==================================
2025-12-09 12:08:56,406:INFO:Initializing create_model()
2025-12-09 12:08:56,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199204FCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:56,406:INFO:Checking exceptions
2025-12-09 12:08:56,406:INFO:Importing libraries
2025-12-09 12:08:56,407:INFO:Copying training dataset
2025-12-09 12:08:56,428:INFO:Defining folds
2025-12-09 12:08:56,428:INFO:Declaring metric variables
2025-12-09 12:08:56,438:INFO:Importing untrained model
2025-12-09 12:08:56,447:INFO:Dummy Classifier Imported successfully
2025-12-09 12:08:56,469:INFO:Starting cross validation
2025-12-09 12:08:56,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:08:56,659:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,664:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,671:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,675:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,685:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,690:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,693:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,695:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,704:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,715:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-09 12:08:56,736:INFO:Calculating mean and std
2025-12-09 12:08:56,738:INFO:Creating metrics dataframe
2025-12-09 12:08:56,745:INFO:Uploading results into container
2025-12-09 12:08:56,746:INFO:Uploading model into container now
2025-12-09 12:08:56,746:INFO:_master_model_container: 14
2025-12-09 12:08:56,747:INFO:_display_container: 2
2025-12-09 12:08:56,748:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-09 12:08:56,748:INFO:create_model() successfully completed......................................
2025-12-09 12:08:56,871:INFO:SubProcess create_model() end ==================================
2025-12-09 12:08:56,871:INFO:Creating metrics dataframe
2025-12-09 12:08:56,897:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-09 12:08:56,918:INFO:Initializing create_model()
2025-12-09 12:08:56,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:08:56,919:INFO:Checking exceptions
2025-12-09 12:08:56,923:INFO:Importing libraries
2025-12-09 12:08:56,923:INFO:Copying training dataset
2025-12-09 12:08:56,941:INFO:Defining folds
2025-12-09 12:08:56,942:INFO:Declaring metric variables
2025-12-09 12:08:56,942:INFO:Importing untrained model
2025-12-09 12:08:56,942:INFO:Declaring custom model
2025-12-09 12:08:56,943:INFO:Logistic Regression Imported successfully
2025-12-09 12:08:56,946:INFO:Cross validation set to False
2025-12-09 12:08:56,946:INFO:Fitting Model
2025-12-09 12:08:57,035:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] O sistema no pode encontrar o arquivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-12-09 12:08:57,040:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\joblib\externals\loky\backend\context.py", line 257, in _count_physical_cores
2025-12-09 12:08:57,040:WARNING:    cpu_info = subprocess.run(
2025-12-09 12:08:57,040:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 503, in run
2025-12-09 12:08:57,040:WARNING:    with Popen(*popenargs, **kwargs) as process:
2025-12-09 12:08:57,040:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 971, in __init__
2025-12-09 12:08:57,040:WARNING:    self._execute_child(args, executable, preexec_fn, close_fds,
2025-12-09 12:08:57,040:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 1456, in _execute_child
2025-12-09 12:08:57,040:WARNING:    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
2025-12-09 12:08:58,581:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 12:08:58,581:INFO:create_model() successfully completed......................................
2025-12-09 12:08:58,779:INFO:_master_model_container: 14
2025-12-09 12:08:58,779:INFO:_display_container: 2
2025-12-09 12:08:58,780:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 12:08:58,781:INFO:compare_models() successfully completed......................................
2025-12-09 12:08:58,784:INFO:Initializing tune_model()
2025-12-09 12:08:58,784:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>)
2025-12-09 12:08:58,784:INFO:Checking exceptions
2025-12-09 12:08:58,835:INFO:Copying training dataset
2025-12-09 12:08:58,852:INFO:Checking base model
2025-12-09 12:08:58,853:INFO:Base model : Logistic Regression
2025-12-09 12:08:58,866:INFO:Declaring metric variables
2025-12-09 12:08:58,877:INFO:Defining Hyperparameters
2025-12-09 12:08:59,032:INFO:Tuning with n_jobs=-1
2025-12-09 12:08:59,032:INFO:Initializing RandomizedSearchCV
2025-12-09 12:09:03,879:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-09 12:09:04,016:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-09 12:09:10,623:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-09 12:09:11,475:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-09 12:09:11,501:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-09 12:09:11,502:INFO:Hyperparameter search completed
2025-12-09 12:09:11,503:INFO:SubProcess create_model() called ==================================
2025-12-09 12:09:11,504:INFO:Initializing create_model()
2025-12-09 12:09:11,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001991C079CF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-09 12:09:11,505:INFO:Checking exceptions
2025-12-09 12:09:11,505:INFO:Importing libraries
2025-12-09 12:09:11,507:INFO:Copying training dataset
2025-12-09 12:09:11,524:INFO:Defining folds
2025-12-09 12:09:11,525:INFO:Declaring metric variables
2025-12-09 12:09:11,532:INFO:Importing untrained model
2025-12-09 12:09:11,534:INFO:Declaring custom model
2025-12-09 12:09:11,543:INFO:Logistic Regression Imported successfully
2025-12-09 12:09:11,563:INFO:Starting cross validation
2025-12-09 12:09:11,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:09:13,350:INFO:Calculating mean and std
2025-12-09 12:09:13,352:INFO:Creating metrics dataframe
2025-12-09 12:09:13,367:INFO:Finalizing model
2025-12-09 12:09:15,377:INFO:Uploading results into container
2025-12-09 12:09:15,378:INFO:Uploading model into container now
2025-12-09 12:09:15,380:INFO:_master_model_container: 15
2025-12-09 12:09:15,381:INFO:_display_container: 3
2025-12-09 12:09:15,382:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 12:09:15,382:INFO:create_model() successfully completed......................................
2025-12-09 12:09:15,527:INFO:SubProcess create_model() end ==================================
2025-12-09 12:09:15,527:INFO:choose_better activated
2025-12-09 12:09:15,536:INFO:SubProcess create_model() called ==================================
2025-12-09 12:09:15,540:INFO:Initializing create_model()
2025-12-09 12:09:15,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019918586E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 12:09:15,540:INFO:Checking exceptions
2025-12-09 12:09:15,543:INFO:Importing libraries
2025-12-09 12:09:15,543:INFO:Copying training dataset
2025-12-09 12:09:15,561:INFO:Defining folds
2025-12-09 12:09:15,561:INFO:Declaring metric variables
2025-12-09 12:09:15,561:INFO:Importing untrained model
2025-12-09 12:09:15,562:INFO:Declaring custom model
2025-12-09 12:09:15,563:INFO:Logistic Regression Imported successfully
2025-12-09 12:09:15,563:INFO:Starting cross validation
2025-12-09 12:09:15,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 12:09:17,212:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-09 12:09:17,272:INFO:Calculating mean and std
2025-12-09 12:09:17,273:INFO:Creating metrics dataframe
2025-12-09 12:09:17,276:INFO:Finalizing model
2025-12-09 12:09:18,831:INFO:Uploading results into container
2025-12-09 12:09:18,832:INFO:Uploading model into container now
2025-12-09 12:09:18,833:INFO:_master_model_container: 16
2025-12-09 12:09:18,833:INFO:_display_container: 4
2025-12-09 12:09:18,833:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 12:09:18,834:INFO:create_model() successfully completed......................................
2025-12-09 12:09:18,959:INFO:SubProcess create_model() end ==================================
2025-12-09 12:09:18,961:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-09 12:09:18,961:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-09 12:09:18,962:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-09 12:09:18,962:INFO:choose_better completed
2025-12-09 12:09:18,962:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-09 12:09:18,992:INFO:_master_model_container: 16
2025-12-09 12:09:18,992:INFO:_display_container: 3
2025-12-09 12:09:18,993:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 12:09:18,994:INFO:tune_model() successfully completed......................................
2025-12-10 17:59:47,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-10 17:59:47,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-10 17:59:47,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-10 17:59:47,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-10 17:59:47,987:INFO:PyCaret RegressionExperiment
2025-12-10 17:59:47,987:INFO:Logging name: reg-default-name
2025-12-10 17:59:47,987:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-10 17:59:47,987:INFO:version 3.3.2
2025-12-10 17:59:47,987:INFO:Initializing setup()
2025-12-10 17:59:47,987:INFO:self.USI: 5e89
2025-12-10 17:59:47,987:INFO:self._variable_keys: {'X', 'USI', 'log_plots_param', 'exp_id', 'html_param', 'y_test', 'y_train', '_ml_usecase', 'X_train', 'n_jobs_param', 'pipeline', 'memory', '_available_plots', 'gpu_param', 'X_test', 'idx', 'seed', 'logging_param', 'exp_name_log', 'data', 'y', 'transform_target_param', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-12-10 17:59:47,989:INFO:Checking environment
2025-12-10 17:59:47,989:INFO:python_version: 3.10.19
2025-12-10 17:59:47,989:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-10 17:59:47,989:INFO:machine: AMD64
2025-12-10 17:59:47,989:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-10 17:59:47,989:INFO:Memory: svmem(total=33699516416, available=18385928192, percent=45.4, used=15313588224, free=18385928192)
2025-12-10 17:59:47,989:INFO:Physical Core: 8
2025-12-10 17:59:47,989:INFO:Logical Core: 16
2025-12-10 17:59:47,989:INFO:Checking libraries
2025-12-10 17:59:47,989:INFO:System:
2025-12-10 17:59:47,989:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-10 17:59:47,989:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-10 17:59:47,989:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-10 17:59:47,989:INFO:PyCaret required dependencies:
2025-12-10 17:59:47,991:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:48,044:INFO:                 pip: 25.3
2025-12-10 17:59:48,044:INFO:          setuptools: 80.9.0
2025-12-10 17:59:48,044:INFO:             pycaret: 3.3.2
2025-12-10 17:59:48,044:INFO:             IPython: 8.37.0
2025-12-10 17:59:48,044:INFO:          ipywidgets: 8.1.8
2025-12-10 17:59:48,044:INFO:                tqdm: 4.67.1
2025-12-10 17:59:48,044:INFO:               numpy: 1.26.4
2025-12-10 17:59:48,044:INFO:              pandas: 2.1.4
2025-12-10 17:59:48,044:INFO:              jinja2: 3.1.6
2025-12-10 17:59:48,044:INFO:               scipy: 1.11.4
2025-12-10 17:59:48,044:INFO:              joblib: 1.3.2
2025-12-10 17:59:48,044:INFO:             sklearn: 1.4.2
2025-12-10 17:59:48,044:INFO:                pyod: 2.0.6
2025-12-10 17:59:48,046:INFO:            imblearn: 0.14.0
2025-12-10 17:59:48,046:INFO:   category_encoders: 2.7.0
2025-12-10 17:59:48,046:INFO:            lightgbm: 4.6.0
2025-12-10 17:59:48,046:INFO:               numba: 0.62.1
2025-12-10 17:59:48,046:INFO:            requests: 2.32.5
2025-12-10 17:59:48,046:INFO:          matplotlib: 3.7.5
2025-12-10 17:59:48,046:INFO:          scikitplot: 0.3.7
2025-12-10 17:59:48,046:INFO:         yellowbrick: 1.5
2025-12-10 17:59:48,046:INFO:              plotly: 6.5.0
2025-12-10 17:59:48,046:INFO:    plotly-resampler: Not installed
2025-12-10 17:59:48,046:INFO:             kaleido: 1.2.0
2025-12-10 17:59:48,046:INFO:           schemdraw: 0.15
2025-12-10 17:59:48,046:INFO:         statsmodels: 0.14.5
2025-12-10 17:59:48,046:INFO:              sktime: 0.26.0
2025-12-10 17:59:48,046:INFO:               tbats: 1.1.3
2025-12-10 17:59:48,046:INFO:            pmdarima: 2.0.4
2025-12-10 17:59:48,046:INFO:              psutil: 7.1.3
2025-12-10 17:59:48,046:INFO:          markupsafe: 3.0.3
2025-12-10 17:59:48,046:INFO:             pickle5: Not installed
2025-12-10 17:59:48,046:INFO:         cloudpickle: 3.1.2
2025-12-10 17:59:48,046:INFO:         deprecation: 2.1.0
2025-12-10 17:59:48,046:INFO:              xxhash: 3.6.0
2025-12-10 17:59:48,046:INFO:           wurlitzer: Not installed
2025-12-10 17:59:48,046:INFO:PyCaret optional dependencies:
2025-12-10 17:59:48,058:INFO:                shap: Not installed
2025-12-10 17:59:48,058:INFO:           interpret: Not installed
2025-12-10 17:59:48,058:INFO:                umap: Not installed
2025-12-10 17:59:48,058:INFO:     ydata_profiling: Not installed
2025-12-10 17:59:48,058:INFO:  explainerdashboard: Not installed
2025-12-10 17:59:48,058:INFO:             autoviz: Not installed
2025-12-10 17:59:48,058:INFO:           fairlearn: Not installed
2025-12-10 17:59:48,058:INFO:          deepchecks: Not installed
2025-12-10 17:59:48,058:INFO:             xgboost: Not installed
2025-12-10 17:59:48,058:INFO:            catboost: Not installed
2025-12-10 17:59:48,058:INFO:              kmodes: Not installed
2025-12-10 17:59:48,058:INFO:             mlxtend: Not installed
2025-12-10 17:59:48,058:INFO:       statsforecast: Not installed
2025-12-10 17:59:48,058:INFO:        tune_sklearn: Not installed
2025-12-10 17:59:48,058:INFO:                 ray: Not installed
2025-12-10 17:59:48,058:INFO:            hyperopt: Not installed
2025-12-10 17:59:48,058:INFO:              optuna: Not installed
2025-12-10 17:59:48,058:INFO:               skopt: Not installed
2025-12-10 17:59:48,058:INFO:              mlflow: Not installed
2025-12-10 17:59:48,058:INFO:              gradio: Not installed
2025-12-10 17:59:48,058:INFO:             fastapi: Not installed
2025-12-10 17:59:48,058:INFO:             uvicorn: Not installed
2025-12-10 17:59:48,058:INFO:              m2cgen: Not installed
2025-12-10 17:59:48,058:INFO:           evidently: Not installed
2025-12-10 17:59:48,058:INFO:               fugue: Not installed
2025-12-10 17:59:48,058:INFO:           streamlit: Not installed
2025-12-10 17:59:48,058:INFO:             prophet: Not installed
2025-12-10 17:59:48,059:INFO:None
2025-12-10 17:59:48,059:INFO:Set up data.
2025-12-10 17:59:48,070:INFO:Set up folding strategy.
2025-12-10 17:59:48,070:INFO:Set up train/test split.
2025-12-10 17:59:48,078:INFO:Set up index.
2025-12-10 17:59:48,078:INFO:Assigning column types.
2025-12-10 17:59:48,086:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-10 17:59:48,086:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,090:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,096:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,166:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,220:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,226:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,231:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,296:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,348:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-10 17:59:48,353:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,359:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,476:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,482:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,487:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,602:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,602:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-10 17:59:48,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,678:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,753:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,821:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,871:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-10 17:59:48,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 17:59:48,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:48,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:49,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 17:59:49,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,127:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-10 17:59:49,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:49,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,329:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 17:59:49,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,379:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-10 17:59:49,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:49,637:INFO:Preparing preprocessing pipeline...
2025-12-10 17:59:49,637:INFO:Set up simple imputation.
2025-12-10 17:59:49,637:INFO:Set up feature normalization.
2025-12-10 17:59:49,638:INFO:Set up column name cleaning.
2025-12-10 17:59:49,747:INFO:Finished creating preprocessing pipeline.
2025-12-10 17:59:49,755:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'transmission_encoded',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner_Test Drive Car',
                                             'owner_Third Owner'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-12-10 17:59:49,755:INFO:Creating final display dataframe.
2025-12-10 17:59:49,912:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 17)
4        Transformed data shape        (7906, 17)
5   Transformed train set shape        (5534, 17)
6    Transformed test set shape        (2372, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              5e89
2025-12-10 17:59:50,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:50,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:50,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:50,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 17:59:50,165:INFO:setup() successfully completed in 2.18s...............
2025-12-10 17:59:50,166:INFO:Initializing compare_models()
2025-12-10 17:59:50,166:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-10 17:59:50,166:INFO:Checking exceptions
2025-12-10 17:59:50,170:INFO:Preparing display monitor
2025-12-10 17:59:50,206:INFO:Initializing Linear Regression
2025-12-10 17:59:50,206:INFO:Total runtime is 1.5683968861897786e-05 minutes
2025-12-10 17:59:50,216:INFO:SubProcess create_model() called ==================================
2025-12-10 17:59:50,216:INFO:Initializing create_model()
2025-12-10 17:59:50,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 17:59:50,217:INFO:Checking exceptions
2025-12-10 17:59:50,217:INFO:Importing libraries
2025-12-10 17:59:50,217:INFO:Copying training dataset
2025-12-10 17:59:50,232:INFO:Defining folds
2025-12-10 17:59:50,232:INFO:Declaring metric variables
2025-12-10 17:59:50,239:INFO:Importing untrained model
2025-12-10 17:59:50,246:INFO:Linear Regression Imported successfully
2025-12-10 17:59:50,258:INFO:Starting cross validation
2025-12-10 17:59:50,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 17:59:56,659:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,660:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,660:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,669:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,674:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,680:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,681:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,684:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,685:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:56,689:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 17:59:57,092:INFO:Calculating mean and std
2025-12-10 17:59:57,095:INFO:Creating metrics dataframe
2025-12-10 17:59:57,099:INFO:Uploading results into container
2025-12-10 17:59:57,102:INFO:Uploading model into container now
2025-12-10 17:59:57,103:INFO:_master_model_container: 1
2025-12-10 17:59:57,104:INFO:_display_container: 2
2025-12-10 17:59:57,104:INFO:LinearRegression(n_jobs=-1)
2025-12-10 17:59:57,104:INFO:create_model() successfully completed......................................
2025-12-10 17:59:57,439:INFO:SubProcess create_model() end ==================================
2025-12-10 17:59:57,439:INFO:Creating metrics dataframe
2025-12-10 17:59:57,450:INFO:Initializing Lasso Regression
2025-12-10 17:59:57,450:INFO:Total runtime is 0.12074362436930339 minutes
2025-12-10 17:59:57,458:INFO:SubProcess create_model() called ==================================
2025-12-10 17:59:57,458:INFO:Initializing create_model()
2025-12-10 17:59:57,458:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 17:59:57,458:INFO:Checking exceptions
2025-12-10 17:59:57,458:INFO:Importing libraries
2025-12-10 17:59:57,458:INFO:Copying training dataset
2025-12-10 17:59:57,470:INFO:Defining folds
2025-12-10 17:59:57,470:INFO:Declaring metric variables
2025-12-10 17:59:57,477:INFO:Importing untrained model
2025-12-10 17:59:57,482:INFO:Lasso Regression Imported successfully
2025-12-10 17:59:57,492:INFO:Starting cross validation
2025-12-10 17:59:57,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:01,432:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:00:01,436:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:00:01,463:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:00:01,467:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:00:01,470:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:00:01,470:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:00:01,791:INFO:Calculating mean and std
2025-12-10 18:00:01,792:INFO:Creating metrics dataframe
2025-12-10 18:00:01,796:INFO:Uploading results into container
2025-12-10 18:00:01,797:INFO:Uploading model into container now
2025-12-10 18:00:01,797:INFO:_master_model_container: 2
2025-12-10 18:00:01,799:INFO:_display_container: 2
2025-12-10 18:00:01,799:INFO:Lasso(random_state=123)
2025-12-10 18:00:01,799:INFO:create_model() successfully completed......................................
2025-12-10 18:00:01,952:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:01,952:INFO:Creating metrics dataframe
2025-12-10 18:00:01,962:INFO:Initializing Ridge Regression
2025-12-10 18:00:01,962:INFO:Total runtime is 0.19594176212946574 minutes
2025-12-10 18:00:01,967:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:01,968:INFO:Initializing create_model()
2025-12-10 18:00:01,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:01,968:INFO:Checking exceptions
2025-12-10 18:00:01,968:INFO:Importing libraries
2025-12-10 18:00:01,968:INFO:Copying training dataset
2025-12-10 18:00:01,978:INFO:Defining folds
2025-12-10 18:00:01,978:INFO:Declaring metric variables
2025-12-10 18:00:01,985:INFO:Importing untrained model
2025-12-10 18:00:01,992:INFO:Ridge Regression Imported successfully
2025-12-10 18:00:02,000:INFO:Starting cross validation
2025-12-10 18:00:02,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:02,121:INFO:Calculating mean and std
2025-12-10 18:00:02,123:INFO:Creating metrics dataframe
2025-12-10 18:00:02,126:INFO:Uploading results into container
2025-12-10 18:00:02,126:INFO:Uploading model into container now
2025-12-10 18:00:02,128:INFO:_master_model_container: 3
2025-12-10 18:00:02,128:INFO:_display_container: 2
2025-12-10 18:00:02,128:INFO:Ridge(random_state=123)
2025-12-10 18:00:02,128:INFO:create_model() successfully completed......................................
2025-12-10 18:00:02,245:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:02,245:INFO:Creating metrics dataframe
2025-12-10 18:00:02,254:INFO:Initializing Elastic Net
2025-12-10 18:00:02,255:INFO:Total runtime is 0.20082243283589682 minutes
2025-12-10 18:00:02,261:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:02,261:INFO:Initializing create_model()
2025-12-10 18:00:02,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:02,261:INFO:Checking exceptions
2025-12-10 18:00:02,261:INFO:Importing libraries
2025-12-10 18:00:02,261:INFO:Copying training dataset
2025-12-10 18:00:02,272:INFO:Defining folds
2025-12-10 18:00:02,272:INFO:Declaring metric variables
2025-12-10 18:00:02,279:INFO:Importing untrained model
2025-12-10 18:00:02,284:INFO:Elastic Net Imported successfully
2025-12-10 18:00:02,292:INFO:Starting cross validation
2025-12-10 18:00:02,294:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:02,413:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+12, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-10 18:00:02,436:INFO:Calculating mean and std
2025-12-10 18:00:02,437:INFO:Creating metrics dataframe
2025-12-10 18:00:02,439:INFO:Uploading results into container
2025-12-10 18:00:02,441:INFO:Uploading model into container now
2025-12-10 18:00:02,443:INFO:_master_model_container: 4
2025-12-10 18:00:02,443:INFO:_display_container: 2
2025-12-10 18:00:02,443:INFO:ElasticNet(random_state=123)
2025-12-10 18:00:02,444:INFO:create_model() successfully completed......................................
2025-12-10 18:00:02,564:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:02,565:INFO:Creating metrics dataframe
2025-12-10 18:00:02,573:INFO:Initializing Least Angle Regression
2025-12-10 18:00:02,574:INFO:Total runtime is 0.20613789955774944 minutes
2025-12-10 18:00:02,578:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:02,580:INFO:Initializing create_model()
2025-12-10 18:00:02,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:02,581:INFO:Checking exceptions
2025-12-10 18:00:02,581:INFO:Importing libraries
2025-12-10 18:00:02,581:INFO:Copying training dataset
2025-12-10 18:00:02,589:INFO:Defining folds
2025-12-10 18:00:02,590:INFO:Declaring metric variables
2025-12-10 18:00:02,596:INFO:Importing untrained model
2025-12-10 18:00:02,601:INFO:Least Angle Regression Imported successfully
2025-12-10 18:00:02,611:INFO:Starting cross validation
2025-12-10 18:00:02,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:02,755:INFO:Calculating mean and std
2025-12-10 18:00:02,758:INFO:Creating metrics dataframe
2025-12-10 18:00:02,761:INFO:Uploading results into container
2025-12-10 18:00:02,761:INFO:Uploading model into container now
2025-12-10 18:00:02,762:INFO:_master_model_container: 5
2025-12-10 18:00:02,762:INFO:_display_container: 2
2025-12-10 18:00:02,762:INFO:Lars(random_state=123)
2025-12-10 18:00:02,764:INFO:create_model() successfully completed......................................
2025-12-10 18:00:02,885:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:02,886:INFO:Creating metrics dataframe
2025-12-10 18:00:02,896:INFO:Initializing Lasso Least Angle Regression
2025-12-10 18:00:02,896:INFO:Total runtime is 0.21151286760965984 minutes
2025-12-10 18:00:02,901:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:02,901:INFO:Initializing create_model()
2025-12-10 18:00:02,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:02,903:INFO:Checking exceptions
2025-12-10 18:00:02,903:INFO:Importing libraries
2025-12-10 18:00:02,903:INFO:Copying training dataset
2025-12-10 18:00:02,913:INFO:Defining folds
2025-12-10 18:00:02,913:INFO:Declaring metric variables
2025-12-10 18:00:02,919:INFO:Importing untrained model
2025-12-10 18:00:02,925:INFO:Lasso Least Angle Regression Imported successfully
2025-12-10 18:00:02,934:INFO:Starting cross validation
2025-12-10 18:00:02,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:03,071:INFO:Calculating mean and std
2025-12-10 18:00:03,073:INFO:Creating metrics dataframe
2025-12-10 18:00:03,076:INFO:Uploading results into container
2025-12-10 18:00:03,077:INFO:Uploading model into container now
2025-12-10 18:00:03,077:INFO:_master_model_container: 6
2025-12-10 18:00:03,077:INFO:_display_container: 2
2025-12-10 18:00:03,078:INFO:LassoLars(random_state=123)
2025-12-10 18:00:03,078:INFO:create_model() successfully completed......................................
2025-12-10 18:00:03,200:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:03,200:INFO:Creating metrics dataframe
2025-12-10 18:00:03,208:INFO:Initializing Orthogonal Matching Pursuit
2025-12-10 18:00:03,208:INFO:Total runtime is 0.2167112469673157 minutes
2025-12-10 18:00:03,214:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:03,214:INFO:Initializing create_model()
2025-12-10 18:00:03,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:03,216:INFO:Checking exceptions
2025-12-10 18:00:03,216:INFO:Importing libraries
2025-12-10 18:00:03,216:INFO:Copying training dataset
2025-12-10 18:00:03,225:INFO:Defining folds
2025-12-10 18:00:03,225:INFO:Declaring metric variables
2025-12-10 18:00:03,230:INFO:Importing untrained model
2025-12-10 18:00:03,236:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-10 18:00:03,247:INFO:Starting cross validation
2025-12-10 18:00:03,248:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:03,372:INFO:Calculating mean and std
2025-12-10 18:00:03,374:INFO:Creating metrics dataframe
2025-12-10 18:00:03,376:INFO:Uploading results into container
2025-12-10 18:00:03,376:INFO:Uploading model into container now
2025-12-10 18:00:03,377:INFO:_master_model_container: 7
2025-12-10 18:00:03,378:INFO:_display_container: 2
2025-12-10 18:00:03,378:INFO:OrthogonalMatchingPursuit()
2025-12-10 18:00:03,378:INFO:create_model() successfully completed......................................
2025-12-10 18:00:03,521:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:03,521:INFO:Creating metrics dataframe
2025-12-10 18:00:03,531:INFO:Initializing Bayesian Ridge
2025-12-10 18:00:03,531:INFO:Total runtime is 0.22209359804789228 minutes
2025-12-10 18:00:03,536:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:03,537:INFO:Initializing create_model()
2025-12-10 18:00:03,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:03,538:INFO:Checking exceptions
2025-12-10 18:00:03,538:INFO:Importing libraries
2025-12-10 18:00:03,538:INFO:Copying training dataset
2025-12-10 18:00:03,547:INFO:Defining folds
2025-12-10 18:00:03,547:INFO:Declaring metric variables
2025-12-10 18:00:03,554:INFO:Importing untrained model
2025-12-10 18:00:03,560:INFO:Bayesian Ridge Imported successfully
2025-12-10 18:00:03,570:INFO:Starting cross validation
2025-12-10 18:00:03,571:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:03,688:INFO:Calculating mean and std
2025-12-10 18:00:03,690:INFO:Creating metrics dataframe
2025-12-10 18:00:03,692:INFO:Uploading results into container
2025-12-10 18:00:03,692:INFO:Uploading model into container now
2025-12-10 18:00:03,694:INFO:_master_model_container: 8
2025-12-10 18:00:03,694:INFO:_display_container: 2
2025-12-10 18:00:03,694:INFO:BayesianRidge()
2025-12-10 18:00:03,695:INFO:create_model() successfully completed......................................
2025-12-10 18:00:03,815:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:03,815:INFO:Creating metrics dataframe
2025-12-10 18:00:03,824:INFO:Initializing Passive Aggressive Regressor
2025-12-10 18:00:03,824:INFO:Total runtime is 0.22697307268778485 minutes
2025-12-10 18:00:03,828:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:03,830:INFO:Initializing create_model()
2025-12-10 18:00:03,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:03,830:INFO:Checking exceptions
2025-12-10 18:00:03,830:INFO:Importing libraries
2025-12-10 18:00:03,830:INFO:Copying training dataset
2025-12-10 18:00:03,840:INFO:Defining folds
2025-12-10 18:00:03,840:INFO:Declaring metric variables
2025-12-10 18:00:03,846:INFO:Importing untrained model
2025-12-10 18:00:03,851:INFO:Passive Aggressive Regressor Imported successfully
2025-12-10 18:00:03,860:INFO:Starting cross validation
2025-12-10 18:00:03,863:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:04,511:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,512:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,512:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,512:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,512:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,514:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,514:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,514:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,514:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:00:04,539:INFO:Calculating mean and std
2025-12-10 18:00:04,540:INFO:Creating metrics dataframe
2025-12-10 18:00:04,543:INFO:Uploading results into container
2025-12-10 18:00:04,543:INFO:Uploading model into container now
2025-12-10 18:00:04,544:INFO:_master_model_container: 9
2025-12-10 18:00:04,544:INFO:_display_container: 2
2025-12-10 18:00:04,544:INFO:PassiveAggressiveRegressor(random_state=123)
2025-12-10 18:00:04,544:INFO:create_model() successfully completed......................................
2025-12-10 18:00:04,663:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:04,663:INFO:Creating metrics dataframe
2025-12-10 18:00:04,675:INFO:Initializing Huber Regressor
2025-12-10 18:00:04,675:INFO:Total runtime is 0.24115842978159588 minutes
2025-12-10 18:00:04,680:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:04,680:INFO:Initializing create_model()
2025-12-10 18:00:04,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:04,680:INFO:Checking exceptions
2025-12-10 18:00:04,680:INFO:Importing libraries
2025-12-10 18:00:04,680:INFO:Copying training dataset
2025-12-10 18:00:04,691:INFO:Defining folds
2025-12-10 18:00:04,691:INFO:Declaring metric variables
2025-12-10 18:00:04,696:INFO:Importing untrained model
2025-12-10 18:00:04,701:INFO:Huber Regressor Imported successfully
2025-12-10 18:00:04,711:INFO:Starting cross validation
2025-12-10 18:00:04,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:04,920:INFO:Calculating mean and std
2025-12-10 18:00:04,922:INFO:Creating metrics dataframe
2025-12-10 18:00:04,926:INFO:Uploading results into container
2025-12-10 18:00:04,927:INFO:Uploading model into container now
2025-12-10 18:00:04,927:INFO:_master_model_container: 10
2025-12-10 18:00:04,927:INFO:_display_container: 2
2025-12-10 18:00:04,927:INFO:HuberRegressor()
2025-12-10 18:00:04,928:INFO:create_model() successfully completed......................................
2025-12-10 18:00:05,046:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:05,046:INFO:Creating metrics dataframe
2025-12-10 18:00:05,057:INFO:Initializing K Neighbors Regressor
2025-12-10 18:00:05,057:INFO:Total runtime is 0.2475255886713664 minutes
2025-12-10 18:00:05,062:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:05,063:INFO:Initializing create_model()
2025-12-10 18:00:05,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:05,063:INFO:Checking exceptions
2025-12-10 18:00:05,063:INFO:Importing libraries
2025-12-10 18:00:05,063:INFO:Copying training dataset
2025-12-10 18:00:05,072:INFO:Defining folds
2025-12-10 18:00:05,105:INFO:Declaring metric variables
2025-12-10 18:00:05,110:INFO:Importing untrained model
2025-12-10 18:00:05,114:INFO:K Neighbors Regressor Imported successfully
2025-12-10 18:00:05,126:INFO:Starting cross validation
2025-12-10 18:00:05,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:05,269:INFO:Calculating mean and std
2025-12-10 18:00:05,270:INFO:Creating metrics dataframe
2025-12-10 18:00:05,273:INFO:Uploading results into container
2025-12-10 18:00:05,274:INFO:Uploading model into container now
2025-12-10 18:00:05,274:INFO:_master_model_container: 11
2025-12-10 18:00:05,276:INFO:_display_container: 2
2025-12-10 18:00:05,276:INFO:KNeighborsRegressor(n_jobs=-1)
2025-12-10 18:00:05,276:INFO:create_model() successfully completed......................................
2025-12-10 18:00:05,397:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:05,398:INFO:Creating metrics dataframe
2025-12-10 18:00:05,409:INFO:Initializing Decision Tree Regressor
2025-12-10 18:00:05,409:INFO:Total runtime is 0.2533978899319967 minutes
2025-12-10 18:00:05,415:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:05,415:INFO:Initializing create_model()
2025-12-10 18:00:05,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:05,415:INFO:Checking exceptions
2025-12-10 18:00:05,415:INFO:Importing libraries
2025-12-10 18:00:05,415:INFO:Copying training dataset
2025-12-10 18:00:05,426:INFO:Defining folds
2025-12-10 18:00:05,427:INFO:Declaring metric variables
2025-12-10 18:00:05,435:INFO:Importing untrained model
2025-12-10 18:00:05,443:INFO:Decision Tree Regressor Imported successfully
2025-12-10 18:00:05,454:INFO:Starting cross validation
2025-12-10 18:00:05,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:05,640:INFO:Calculating mean and std
2025-12-10 18:00:05,641:INFO:Creating metrics dataframe
2025-12-10 18:00:05,645:INFO:Uploading results into container
2025-12-10 18:00:05,646:INFO:Uploading model into container now
2025-12-10 18:00:05,646:INFO:_master_model_container: 12
2025-12-10 18:00:05,646:INFO:_display_container: 2
2025-12-10 18:00:05,647:INFO:DecisionTreeRegressor(random_state=123)
2025-12-10 18:00:05,647:INFO:create_model() successfully completed......................................
2025-12-10 18:00:05,768:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:05,770:INFO:Creating metrics dataframe
2025-12-10 18:00:05,783:INFO:Initializing Random Forest Regressor
2025-12-10 18:00:05,783:INFO:Total runtime is 0.25962874492009486 minutes
2025-12-10 18:00:05,788:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:05,788:INFO:Initializing create_model()
2025-12-10 18:00:05,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:05,789:INFO:Checking exceptions
2025-12-10 18:00:05,789:INFO:Importing libraries
2025-12-10 18:00:05,789:INFO:Copying training dataset
2025-12-10 18:00:05,798:INFO:Defining folds
2025-12-10 18:00:05,799:INFO:Declaring metric variables
2025-12-10 18:00:05,803:INFO:Importing untrained model
2025-12-10 18:00:05,810:INFO:Random Forest Regressor Imported successfully
2025-12-10 18:00:05,818:INFO:Starting cross validation
2025-12-10 18:00:05,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:07,832:INFO:Calculating mean and std
2025-12-10 18:00:07,834:INFO:Creating metrics dataframe
2025-12-10 18:00:07,836:INFO:Uploading results into container
2025-12-10 18:00:07,837:INFO:Uploading model into container now
2025-12-10 18:00:07,839:INFO:_master_model_container: 13
2025-12-10 18:00:07,839:INFO:_display_container: 2
2025-12-10 18:00:07,839:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-12-10 18:00:07,841:INFO:create_model() successfully completed......................................
2025-12-10 18:00:07,963:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:07,990:INFO:Creating metrics dataframe
2025-12-10 18:00:08,002:INFO:Initializing Extra Trees Regressor
2025-12-10 18:00:08,002:INFO:Total runtime is 0.29660793145497644 minutes
2025-12-10 18:00:08,008:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:08,008:INFO:Initializing create_model()
2025-12-10 18:00:08,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:08,008:INFO:Checking exceptions
2025-12-10 18:00:08,009:INFO:Importing libraries
2025-12-10 18:00:08,009:INFO:Copying training dataset
2025-12-10 18:00:08,017:INFO:Defining folds
2025-12-10 18:00:08,018:INFO:Declaring metric variables
2025-12-10 18:00:08,022:INFO:Importing untrained model
2025-12-10 18:00:08,029:INFO:Extra Trees Regressor Imported successfully
2025-12-10 18:00:08,039:INFO:Starting cross validation
2025-12-10 18:00:08,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:09,619:INFO:Calculating mean and std
2025-12-10 18:00:09,620:INFO:Creating metrics dataframe
2025-12-10 18:00:09,625:INFO:Uploading results into container
2025-12-10 18:00:09,626:INFO:Uploading model into container now
2025-12-10 18:00:09,628:INFO:_master_model_container: 14
2025-12-10 18:00:09,628:INFO:_display_container: 2
2025-12-10 18:00:09,628:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-10 18:00:09,628:INFO:create_model() successfully completed......................................
2025-12-10 18:00:09,750:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:09,750:INFO:Creating metrics dataframe
2025-12-10 18:00:09,763:INFO:Initializing AdaBoost Regressor
2025-12-10 18:00:09,763:INFO:Total runtime is 0.32595867315928145 minutes
2025-12-10 18:00:09,768:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:09,770:INFO:Initializing create_model()
2025-12-10 18:00:09,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:09,770:INFO:Checking exceptions
2025-12-10 18:00:09,770:INFO:Importing libraries
2025-12-10 18:00:09,770:INFO:Copying training dataset
2025-12-10 18:00:09,783:INFO:Defining folds
2025-12-10 18:00:09,783:INFO:Declaring metric variables
2025-12-10 18:00:09,789:INFO:Importing untrained model
2025-12-10 18:00:09,797:INFO:AdaBoost Regressor Imported successfully
2025-12-10 18:00:09,810:INFO:Starting cross validation
2025-12-10 18:00:09,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:10,323:INFO:Calculating mean and std
2025-12-10 18:00:10,325:INFO:Creating metrics dataframe
2025-12-10 18:00:10,327:INFO:Uploading results into container
2025-12-10 18:00:10,329:INFO:Uploading model into container now
2025-12-10 18:00:10,329:INFO:_master_model_container: 15
2025-12-10 18:00:10,329:INFO:_display_container: 2
2025-12-10 18:00:10,330:INFO:AdaBoostRegressor(random_state=123)
2025-12-10 18:00:10,330:INFO:create_model() successfully completed......................................
2025-12-10 18:00:10,452:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:10,452:INFO:Creating metrics dataframe
2025-12-10 18:00:10,466:INFO:Initializing Gradient Boosting Regressor
2025-12-10 18:00:10,467:INFO:Total runtime is 0.33769360780715946 minutes
2025-12-10 18:00:10,475:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:10,475:INFO:Initializing create_model()
2025-12-10 18:00:10,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:10,475:INFO:Checking exceptions
2025-12-10 18:00:10,475:INFO:Importing libraries
2025-12-10 18:00:10,475:INFO:Copying training dataset
2025-12-10 18:00:10,485:INFO:Defining folds
2025-12-10 18:00:10,486:INFO:Declaring metric variables
2025-12-10 18:00:10,494:INFO:Importing untrained model
2025-12-10 18:00:10,502:INFO:Gradient Boosting Regressor Imported successfully
2025-12-10 18:00:10,512:INFO:Starting cross validation
2025-12-10 18:00:10,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:11,247:INFO:Calculating mean and std
2025-12-10 18:00:11,248:INFO:Creating metrics dataframe
2025-12-10 18:00:11,249:INFO:Uploading results into container
2025-12-10 18:00:11,251:INFO:Uploading model into container now
2025-12-10 18:00:11,251:INFO:_master_model_container: 16
2025-12-10 18:00:11,251:INFO:_display_container: 2
2025-12-10 18:00:11,253:INFO:GradientBoostingRegressor(random_state=123)
2025-12-10 18:00:11,253:INFO:create_model() successfully completed......................................
2025-12-10 18:00:11,371:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:11,372:INFO:Creating metrics dataframe
2025-12-10 18:00:11,383:INFO:Initializing Light Gradient Boosting Machine
2025-12-10 18:00:11,385:INFO:Total runtime is 0.3529840429623922 minutes
2025-12-10 18:00:11,390:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:11,390:INFO:Initializing create_model()
2025-12-10 18:00:11,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:11,391:INFO:Checking exceptions
2025-12-10 18:00:11,391:INFO:Importing libraries
2025-12-10 18:00:11,391:INFO:Copying training dataset
2025-12-10 18:00:11,399:INFO:Defining folds
2025-12-10 18:00:11,399:INFO:Declaring metric variables
2025-12-10 18:00:11,405:INFO:Importing untrained model
2025-12-10 18:00:11,411:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:00:11,421:INFO:Starting cross validation
2025-12-10 18:00:11,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:12,624:INFO:Calculating mean and std
2025-12-10 18:00:12,626:INFO:Creating metrics dataframe
2025-12-10 18:00:12,630:INFO:Uploading results into container
2025-12-10 18:00:12,632:INFO:Uploading model into container now
2025-12-10 18:00:12,632:INFO:_master_model_container: 17
2025-12-10 18:00:12,632:INFO:_display_container: 2
2025-12-10 18:00:12,633:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-10 18:00:12,633:INFO:create_model() successfully completed......................................
2025-12-10 18:00:12,780:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:12,780:INFO:Creating metrics dataframe
2025-12-10 18:00:12,792:INFO:Initializing Dummy Regressor
2025-12-10 18:00:12,792:INFO:Total runtime is 0.3764477690060934 minutes
2025-12-10 18:00:12,797:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:12,797:INFO:Initializing create_model()
2025-12-10 18:00:12,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D08F7250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:12,798:INFO:Checking exceptions
2025-12-10 18:00:12,798:INFO:Importing libraries
2025-12-10 18:00:12,798:INFO:Copying training dataset
2025-12-10 18:00:12,807:INFO:Defining folds
2025-12-10 18:00:12,808:INFO:Declaring metric variables
2025-12-10 18:00:12,813:INFO:Importing untrained model
2025-12-10 18:00:12,817:INFO:Dummy Regressor Imported successfully
2025-12-10 18:00:12,828:INFO:Starting cross validation
2025-12-10 18:00:12,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:12,930:INFO:Calculating mean and std
2025-12-10 18:00:12,932:INFO:Creating metrics dataframe
2025-12-10 18:00:12,933:INFO:Uploading results into container
2025-12-10 18:00:12,935:INFO:Uploading model into container now
2025-12-10 18:00:12,935:INFO:_master_model_container: 18
2025-12-10 18:00:12,936:INFO:_display_container: 2
2025-12-10 18:00:12,936:INFO:DummyRegressor()
2025-12-10 18:00:12,936:INFO:create_model() successfully completed......................................
2025-12-10 18:00:13,076:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:13,076:INFO:Creating metrics dataframe
2025-12-10 18:00:13,093:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-10 18:00:13,104:INFO:Initializing create_model()
2025-12-10 18:00:13,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:13,106:INFO:Checking exceptions
2025-12-10 18:00:13,109:INFO:Importing libraries
2025-12-10 18:00:13,109:INFO:Copying training dataset
2025-12-10 18:00:13,117:INFO:Defining folds
2025-12-10 18:00:13,117:INFO:Declaring metric variables
2025-12-10 18:00:13,117:INFO:Importing untrained model
2025-12-10 18:00:13,117:INFO:Declaring custom model
2025-12-10 18:00:13,119:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:00:13,119:INFO:Cross validation set to False
2025-12-10 18:00:13,119:INFO:Fitting Model
2025-12-10 18:00:13,145:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 18:00:13,146:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.
2025-12-10 18:00:13,146:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-10 18:00:13,146:INFO:[LightGBM] [Info] Total Bins 874
2025-12-10 18:00:13,146:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-10 18:00:13,147:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-10 18:00:13,248:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-10 18:00:13,250:INFO:create_model() successfully completed......................................
2025-12-10 18:00:13,449:INFO:_master_model_container: 18
2025-12-10 18:00:13,449:INFO:_display_container: 2
2025-12-10 18:00:13,450:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-10 18:00:13,450:INFO:compare_models() successfully completed......................................
2025-12-10 18:00:13,452:INFO:Initializing tune_model()
2025-12-10 18:00:13,452:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>)
2025-12-10 18:00:13,452:INFO:Checking exceptions
2025-12-10 18:00:13,473:INFO:Copying training dataset
2025-12-10 18:00:13,484:INFO:Checking base model
2025-12-10 18:00:13,484:INFO:Base model : Light Gradient Boosting Machine
2025-12-10 18:00:13,492:INFO:Declaring metric variables
2025-12-10 18:00:13,496:INFO:Defining Hyperparameters
2025-12-10 18:00:13,618:INFO:Tuning with n_jobs=-1
2025-12-10 18:00:13,618:INFO:Initializing RandomizedSearchCV
2025-12-10 18:00:30,296:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-10 18:00:30,297:INFO:Hyperparameter search completed
2025-12-10 18:00:30,297:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:30,298:INFO:Initializing create_model()
2025-12-10 18:00:30,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F682E7A320>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-10 18:00:30,300:INFO:Checking exceptions
2025-12-10 18:00:30,300:INFO:Importing libraries
2025-12-10 18:00:30,300:INFO:Copying training dataset
2025-12-10 18:00:30,315:INFO:Defining folds
2025-12-10 18:00:30,315:INFO:Declaring metric variables
2025-12-10 18:00:30,322:INFO:Importing untrained model
2025-12-10 18:00:30,322:INFO:Declaring custom model
2025-12-10 18:00:30,331:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:00:30,350:INFO:Starting cross validation
2025-12-10 18:00:30,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:31,726:INFO:Calculating mean and std
2025-12-10 18:00:31,728:INFO:Creating metrics dataframe
2025-12-10 18:00:31,737:INFO:Finalizing model
2025-12-10 18:00:31,766:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-10 18:00:31,766:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-10 18:00:31,766:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-10 18:00:31,772:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 18:00:31,773:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-10 18:00:31,774:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-10 18:00:31,774:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-10 18:00:31,774:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000576 seconds.
2025-12-10 18:00:31,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 18:00:31,776:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 18:00:31,776:INFO:[LightGBM] [Info] Total Bins 874
2025-12-10 18:00:31,776:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-10 18:00:31,776:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-10 18:00:31,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 18:00:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 18:00:31,958:INFO:Uploading results into container
2025-12-10 18:00:31,960:INFO:Uploading model into container now
2025-12-10 18:00:31,961:INFO:_master_model_container: 19
2025-12-10 18:00:31,961:INFO:_display_container: 3
2025-12-10 18:00:31,962:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005)
2025-12-10 18:00:31,962:INFO:create_model() successfully completed......................................
2025-12-10 18:00:32,111:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:32,111:INFO:choose_better activated
2025-12-10 18:00:32,117:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:32,117:INFO:Initializing create_model()
2025-12-10 18:00:32,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA233AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:32,117:INFO:Checking exceptions
2025-12-10 18:00:32,120:INFO:Importing libraries
2025-12-10 18:00:32,120:INFO:Copying training dataset
2025-12-10 18:00:32,129:INFO:Defining folds
2025-12-10 18:00:32,129:INFO:Declaring metric variables
2025-12-10 18:00:32,129:INFO:Importing untrained model
2025-12-10 18:00:32,129:INFO:Declaring custom model
2025-12-10 18:00:32,131:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:00:32,131:INFO:Starting cross validation
2025-12-10 18:00:32,131:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:33,435:INFO:Calculating mean and std
2025-12-10 18:00:33,435:INFO:Creating metrics dataframe
2025-12-10 18:00:33,437:INFO:Finalizing model
2025-12-10 18:00:33,471:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 18:00:33,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000801 seconds.
2025-12-10 18:00:33,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 18:00:33,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 18:00:33,474:INFO:[LightGBM] [Info] Total Bins 874
2025-12-10 18:00:33,475:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-10 18:00:33,475:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-10 18:00:33,661:INFO:Uploading results into container
2025-12-10 18:00:33,661:INFO:Uploading model into container now
2025-12-10 18:00:33,662:INFO:_master_model_container: 20
2025-12-10 18:00:33,662:INFO:_display_container: 4
2025-12-10 18:00:33,662:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-10 18:00:33,662:INFO:create_model() successfully completed......................................
2025-12-10 18:00:33,819:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:33,819:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9584
2025-12-10 18:00:33,820:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, feature_fraction=0.5,
              learning_rate=0.4, min_child_samples=6, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, random_state=123,
              reg_alpha=0.005, reg_lambda=0.0005) result for R2 is 0.9462
2025-12-10 18:00:33,820:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-12-10 18:00:33,822:INFO:choose_better completed
2025-12-10 18:00:33,823:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-10 18:00:33,835:INFO:_master_model_container: 20
2025-12-10 18:00:33,836:INFO:_display_container: 3
2025-12-10 18:00:33,836:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-10 18:00:33,836:INFO:tune_model() successfully completed......................................
2025-12-10 18:00:33,985:INFO:PyCaret ClassificationExperiment
2025-12-10 18:00:33,985:INFO:Logging name: clf-default-name
2025-12-10 18:00:33,985:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-10 18:00:33,985:INFO:version 3.3.2
2025-12-10 18:00:33,985:INFO:Initializing setup()
2025-12-10 18:00:33,985:INFO:self.USI: 103d
2025-12-10 18:00:33,985:INFO:self._variable_keys: {'X', 'USI', 'log_plots_param', 'exp_id', 'html_param', 'y_test', 'y_train', 'fix_imbalance', '_ml_usecase', 'X_train', 'n_jobs_param', 'pipeline', 'memory', '_available_plots', 'is_multiclass', 'gpu_param', 'X_test', 'idx', 'seed', 'logging_param', 'exp_name_log', 'data', 'y', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-12-10 18:00:33,985:INFO:Checking environment
2025-12-10 18:00:33,985:INFO:python_version: 3.10.19
2025-12-10 18:00:33,985:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-10 18:00:33,985:INFO:machine: AMD64
2025-12-10 18:00:33,985:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-10 18:00:33,987:INFO:Memory: svmem(total=33699516416, available=16086843392, percent=52.3, used=17612673024, free=16086843392)
2025-12-10 18:00:33,987:INFO:Physical Core: 8
2025-12-10 18:00:33,987:INFO:Logical Core: 16
2025-12-10 18:00:33,987:INFO:Checking libraries
2025-12-10 18:00:33,987:INFO:System:
2025-12-10 18:00:33,987:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-10 18:00:33,987:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-10 18:00:33,987:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-10 18:00:33,987:INFO:PyCaret required dependencies:
2025-12-10 18:00:33,987:INFO:                 pip: 25.3
2025-12-10 18:00:33,987:INFO:          setuptools: 80.9.0
2025-12-10 18:00:33,987:INFO:             pycaret: 3.3.2
2025-12-10 18:00:33,987:INFO:             IPython: 8.37.0
2025-12-10 18:00:33,987:INFO:          ipywidgets: 8.1.8
2025-12-10 18:00:33,987:INFO:                tqdm: 4.67.1
2025-12-10 18:00:33,987:INFO:               numpy: 1.26.4
2025-12-10 18:00:33,987:INFO:              pandas: 2.1.4
2025-12-10 18:00:33,987:INFO:              jinja2: 3.1.6
2025-12-10 18:00:33,987:INFO:               scipy: 1.11.4
2025-12-10 18:00:33,987:INFO:              joblib: 1.3.2
2025-12-10 18:00:33,987:INFO:             sklearn: 1.4.2
2025-12-10 18:00:33,987:INFO:                pyod: 2.0.6
2025-12-10 18:00:33,987:INFO:            imblearn: 0.14.0
2025-12-10 18:00:33,987:INFO:   category_encoders: 2.7.0
2025-12-10 18:00:33,987:INFO:            lightgbm: 4.6.0
2025-12-10 18:00:33,987:INFO:               numba: 0.62.1
2025-12-10 18:00:33,987:INFO:            requests: 2.32.5
2025-12-10 18:00:33,987:INFO:          matplotlib: 3.7.5
2025-12-10 18:00:33,987:INFO:          scikitplot: 0.3.7
2025-12-10 18:00:33,987:INFO:         yellowbrick: 1.5
2025-12-10 18:00:33,987:INFO:              plotly: 6.5.0
2025-12-10 18:00:33,987:INFO:    plotly-resampler: Not installed
2025-12-10 18:00:33,987:INFO:             kaleido: 1.2.0
2025-12-10 18:00:33,989:INFO:           schemdraw: 0.15
2025-12-10 18:00:33,989:INFO:         statsmodels: 0.14.5
2025-12-10 18:00:33,989:INFO:              sktime: 0.26.0
2025-12-10 18:00:33,989:INFO:               tbats: 1.1.3
2025-12-10 18:00:33,989:INFO:            pmdarima: 2.0.4
2025-12-10 18:00:33,989:INFO:              psutil: 7.1.3
2025-12-10 18:00:33,989:INFO:          markupsafe: 3.0.3
2025-12-10 18:00:33,989:INFO:             pickle5: Not installed
2025-12-10 18:00:33,989:INFO:         cloudpickle: 3.1.2
2025-12-10 18:00:33,989:INFO:         deprecation: 2.1.0
2025-12-10 18:00:33,989:INFO:              xxhash: 3.6.0
2025-12-10 18:00:33,989:INFO:           wurlitzer: Not installed
2025-12-10 18:00:33,989:INFO:PyCaret optional dependencies:
2025-12-10 18:00:33,989:INFO:                shap: Not installed
2025-12-10 18:00:33,989:INFO:           interpret: Not installed
2025-12-10 18:00:33,989:INFO:                umap: Not installed
2025-12-10 18:00:33,989:INFO:     ydata_profiling: Not installed
2025-12-10 18:00:33,989:INFO:  explainerdashboard: Not installed
2025-12-10 18:00:33,989:INFO:             autoviz: Not installed
2025-12-10 18:00:33,989:INFO:           fairlearn: Not installed
2025-12-10 18:00:33,989:INFO:          deepchecks: Not installed
2025-12-10 18:00:33,989:INFO:             xgboost: Not installed
2025-12-10 18:00:33,989:INFO:            catboost: Not installed
2025-12-10 18:00:33,989:INFO:              kmodes: Not installed
2025-12-10 18:00:33,989:INFO:             mlxtend: Not installed
2025-12-10 18:00:33,989:INFO:       statsforecast: Not installed
2025-12-10 18:00:33,989:INFO:        tune_sklearn: Not installed
2025-12-10 18:00:33,989:INFO:                 ray: Not installed
2025-12-10 18:00:33,989:INFO:            hyperopt: Not installed
2025-12-10 18:00:33,989:INFO:              optuna: Not installed
2025-12-10 18:00:33,989:INFO:               skopt: Not installed
2025-12-10 18:00:33,989:INFO:              mlflow: Not installed
2025-12-10 18:00:33,989:INFO:              gradio: Not installed
2025-12-10 18:00:33,989:INFO:             fastapi: Not installed
2025-12-10 18:00:33,989:INFO:             uvicorn: Not installed
2025-12-10 18:00:33,989:INFO:              m2cgen: Not installed
2025-12-10 18:00:33,990:INFO:           evidently: Not installed
2025-12-10 18:00:33,990:INFO:               fugue: Not installed
2025-12-10 18:00:33,990:INFO:           streamlit: Not installed
2025-12-10 18:00:33,990:INFO:             prophet: Not installed
2025-12-10 18:00:33,990:INFO:None
2025-12-10 18:00:33,990:INFO:Set up data.
2025-12-10 18:00:33,999:INFO:Set up folding strategy.
2025-12-10 18:00:33,999:INFO:Set up train/test split.
2025-12-10 18:00:34,008:INFO:Set up index.
2025-12-10 18:00:34,008:INFO:Assigning column types.
2025-12-10 18:00:34,015:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-10 18:00:34,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:00:34,067:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:00:34,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:00:34,159:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:00:34,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,191:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-10 18:00:34,242:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:00:34,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,325:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:00:34,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,355:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-10 18:00:34,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,519:INFO:Preparing preprocessing pipeline...
2025-12-10 18:00:34,520:INFO:Set up simple imputation.
2025-12-10 18:00:34,521:INFO:Set up imbalanced handling.
2025-12-10 18:00:34,522:INFO:Set up column name cleaning.
2025-12-10 18:00:34,616:INFO:Finished creating preprocessing pipeline.
2025-12-10 18:00:34,624:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'selling_price',
                                             'km_driven', 'mileage', 'engine',
                                             'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Sec...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-10 18:00:34,624:INFO:Creating final display dataframe.
2025-12-10 18:00:34,765:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 17)
4        Transformed data shape           (11982, 17)
5   Transformed train set shape            (9610, 17)
6    Transformed test set shape            (2372, 17)
7              Numeric features                    16
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                Fix imbalance                  True
13         Fix imbalance method                 SMOTE
14               Fold Generator       StratifiedKFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment                 False
19              Experiment Name      clf-default-name
20                          USI                  103d
2025-12-10 18:00:34,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:00:34,929:INFO:setup() successfully completed in 0.95s...............
2025-12-10 18:00:34,930:INFO:Initializing compare_models()
2025-12-10 18:00:34,930:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-10 18:00:34,930:INFO:Checking exceptions
2025-12-10 18:00:34,969:INFO:Preparing display monitor
2025-12-10 18:00:35,000:INFO:Initializing Logistic Regression
2025-12-10 18:00:35,001:INFO:Total runtime is 1.9490718841552734e-05 minutes
2025-12-10 18:00:35,007:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:35,008:INFO:Initializing create_model()
2025-12-10 18:00:35,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:35,008:INFO:Checking exceptions
2025-12-10 18:00:35,008:INFO:Importing libraries
2025-12-10 18:00:35,008:INFO:Copying training dataset
2025-12-10 18:00:35,016:INFO:Defining folds
2025-12-10 18:00:35,016:INFO:Declaring metric variables
2025-12-10 18:00:35,021:INFO:Importing untrained model
2025-12-10 18:00:35,027:INFO:Logistic Regression Imported successfully
2025-12-10 18:00:35,035:INFO:Starting cross validation
2025-12-10 18:00:35,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:36,271:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:00:36,299:INFO:Calculating mean and std
2025-12-10 18:00:36,300:INFO:Creating metrics dataframe
2025-12-10 18:00:36,303:INFO:Uploading results into container
2025-12-10 18:00:36,304:INFO:Uploading model into container now
2025-12-10 18:00:36,305:INFO:_master_model_container: 1
2025-12-10 18:00:36,306:INFO:_display_container: 2
2025-12-10 18:00:36,307:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:00:36,307:INFO:create_model() successfully completed......................................
2025-12-10 18:00:36,467:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:36,467:INFO:Creating metrics dataframe
2025-12-10 18:00:36,475:INFO:Initializing K Neighbors Classifier
2025-12-10 18:00:36,475:INFO:Total runtime is 0.024589780966440836 minutes
2025-12-10 18:00:36,480:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:36,480:INFO:Initializing create_model()
2025-12-10 18:00:36,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:36,480:INFO:Checking exceptions
2025-12-10 18:00:36,480:INFO:Importing libraries
2025-12-10 18:00:36,480:INFO:Copying training dataset
2025-12-10 18:00:36,491:INFO:Defining folds
2025-12-10 18:00:36,491:INFO:Declaring metric variables
2025-12-10 18:00:36,495:INFO:Importing untrained model
2025-12-10 18:00:36,501:INFO:K Neighbors Classifier Imported successfully
2025-12-10 18:00:36,510:INFO:Starting cross validation
2025-12-10 18:00:36,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:36,789:INFO:Calculating mean and std
2025-12-10 18:00:36,790:INFO:Creating metrics dataframe
2025-12-10 18:00:36,793:INFO:Uploading results into container
2025-12-10 18:00:36,794:INFO:Uploading model into container now
2025-12-10 18:00:36,794:INFO:_master_model_container: 2
2025-12-10 18:00:36,794:INFO:_display_container: 2
2025-12-10 18:00:36,796:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-10 18:00:36,796:INFO:create_model() successfully completed......................................
2025-12-10 18:00:36,936:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:36,936:INFO:Creating metrics dataframe
2025-12-10 18:00:36,944:INFO:Initializing Naive Bayes
2025-12-10 18:00:36,945:INFO:Total runtime is 0.03242473602294922 minutes
2025-12-10 18:00:36,949:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:36,949:INFO:Initializing create_model()
2025-12-10 18:00:36,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:36,949:INFO:Checking exceptions
2025-12-10 18:00:36,950:INFO:Importing libraries
2025-12-10 18:00:36,950:INFO:Copying training dataset
2025-12-10 18:00:36,959:INFO:Defining folds
2025-12-10 18:00:36,961:INFO:Declaring metric variables
2025-12-10 18:00:36,966:INFO:Importing untrained model
2025-12-10 18:00:36,971:INFO:Naive Bayes Imported successfully
2025-12-10 18:00:36,981:INFO:Starting cross validation
2025-12-10 18:00:36,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:37,135:INFO:Calculating mean and std
2025-12-10 18:00:37,136:INFO:Creating metrics dataframe
2025-12-10 18:00:37,139:INFO:Uploading results into container
2025-12-10 18:00:37,140:INFO:Uploading model into container now
2025-12-10 18:00:37,141:INFO:_master_model_container: 3
2025-12-10 18:00:37,141:INFO:_display_container: 2
2025-12-10 18:00:37,142:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-10 18:00:37,142:INFO:create_model() successfully completed......................................
2025-12-10 18:00:37,273:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:37,273:INFO:Creating metrics dataframe
2025-12-10 18:00:37,282:INFO:Initializing Decision Tree Classifier
2025-12-10 18:00:37,282:INFO:Total runtime is 0.03804616530736288 minutes
2025-12-10 18:00:37,287:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:37,288:INFO:Initializing create_model()
2025-12-10 18:00:37,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:37,288:INFO:Checking exceptions
2025-12-10 18:00:37,288:INFO:Importing libraries
2025-12-10 18:00:37,288:INFO:Copying training dataset
2025-12-10 18:00:37,298:INFO:Defining folds
2025-12-10 18:00:37,299:INFO:Declaring metric variables
2025-12-10 18:00:37,305:INFO:Importing untrained model
2025-12-10 18:00:37,310:INFO:Decision Tree Classifier Imported successfully
2025-12-10 18:00:37,319:INFO:Starting cross validation
2025-12-10 18:00:37,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:37,523:INFO:Calculating mean and std
2025-12-10 18:00:37,524:INFO:Creating metrics dataframe
2025-12-10 18:00:37,527:INFO:Uploading results into container
2025-12-10 18:00:37,528:INFO:Uploading model into container now
2025-12-10 18:00:37,528:INFO:_master_model_container: 4
2025-12-10 18:00:37,528:INFO:_display_container: 2
2025-12-10 18:00:37,528:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-10 18:00:37,530:INFO:create_model() successfully completed......................................
2025-12-10 18:00:37,657:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:37,658:INFO:Creating metrics dataframe
2025-12-10 18:00:37,668:INFO:Initializing SVM - Linear Kernel
2025-12-10 18:00:37,668:INFO:Total runtime is 0.044465418656667074 minutes
2025-12-10 18:00:37,672:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:37,673:INFO:Initializing create_model()
2025-12-10 18:00:37,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:37,673:INFO:Checking exceptions
2025-12-10 18:00:37,673:INFO:Importing libraries
2025-12-10 18:00:37,673:INFO:Copying training dataset
2025-12-10 18:00:37,683:INFO:Defining folds
2025-12-10 18:00:37,683:INFO:Declaring metric variables
2025-12-10 18:00:37,689:INFO:Importing untrained model
2025-12-10 18:00:37,696:INFO:SVM - Linear Kernel Imported successfully
2025-12-10 18:00:37,706:INFO:Starting cross validation
2025-12-10 18:00:37,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:37,969:INFO:Calculating mean and std
2025-12-10 18:00:37,972:INFO:Creating metrics dataframe
2025-12-10 18:00:37,975:INFO:Uploading results into container
2025-12-10 18:00:37,975:INFO:Uploading model into container now
2025-12-10 18:00:37,976:INFO:_master_model_container: 5
2025-12-10 18:00:37,976:INFO:_display_container: 2
2025-12-10 18:00:37,976:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-10 18:00:37,978:INFO:create_model() successfully completed......................................
2025-12-10 18:00:38,098:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:38,098:INFO:Creating metrics dataframe
2025-12-10 18:00:38,107:INFO:Initializing Ridge Classifier
2025-12-10 18:00:38,108:INFO:Total runtime is 0.05181052287419637 minutes
2025-12-10 18:00:38,113:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:38,113:INFO:Initializing create_model()
2025-12-10 18:00:38,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:38,113:INFO:Checking exceptions
2025-12-10 18:00:38,113:INFO:Importing libraries
2025-12-10 18:00:38,113:INFO:Copying training dataset
2025-12-10 18:00:38,125:INFO:Defining folds
2025-12-10 18:00:38,125:INFO:Declaring metric variables
2025-12-10 18:00:38,130:INFO:Importing untrained model
2025-12-10 18:00:38,134:INFO:Ridge Classifier Imported successfully
2025-12-10 18:00:38,143:INFO:Starting cross validation
2025-12-10 18:00:38,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:38,271:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.07985e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,272:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97415e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,273:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.76553e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,273:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.18612e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,274:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.84536e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,275:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.12855e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,276:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97653e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,276:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.27127e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,277:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.25459e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,277:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.22879e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:00:38,321:INFO:Calculating mean and std
2025-12-10 18:00:38,323:INFO:Creating metrics dataframe
2025-12-10 18:00:38,326:INFO:Uploading results into container
2025-12-10 18:00:38,327:INFO:Uploading model into container now
2025-12-10 18:00:38,327:INFO:_master_model_container: 6
2025-12-10 18:00:38,327:INFO:_display_container: 2
2025-12-10 18:00:38,329:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-10 18:00:38,329:INFO:create_model() successfully completed......................................
2025-12-10 18:00:38,461:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:38,461:INFO:Creating metrics dataframe
2025-12-10 18:00:38,471:INFO:Initializing Random Forest Classifier
2025-12-10 18:00:38,472:INFO:Total runtime is 0.05786932706832886 minutes
2025-12-10 18:00:38,478:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:38,478:INFO:Initializing create_model()
2025-12-10 18:00:38,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:38,478:INFO:Checking exceptions
2025-12-10 18:00:38,478:INFO:Importing libraries
2025-12-10 18:00:38,478:INFO:Copying training dataset
2025-12-10 18:00:38,488:INFO:Defining folds
2025-12-10 18:00:38,489:INFO:Declaring metric variables
2025-12-10 18:00:38,495:INFO:Importing untrained model
2025-12-10 18:00:38,499:INFO:Random Forest Classifier Imported successfully
2025-12-10 18:00:38,510:INFO:Starting cross validation
2025-12-10 18:00:38,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:39,984:INFO:Calculating mean and std
2025-12-10 18:00:39,985:INFO:Creating metrics dataframe
2025-12-10 18:00:39,990:INFO:Uploading results into container
2025-12-10 18:00:39,991:INFO:Uploading model into container now
2025-12-10 18:00:39,991:INFO:_master_model_container: 7
2025-12-10 18:00:39,991:INFO:_display_container: 2
2025-12-10 18:00:39,993:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-10 18:00:39,993:INFO:create_model() successfully completed......................................
2025-12-10 18:00:40,124:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:40,125:INFO:Creating metrics dataframe
2025-12-10 18:00:40,137:INFO:Initializing Quadratic Discriminant Analysis
2025-12-10 18:00:40,137:INFO:Total runtime is 0.08562271197636923 minutes
2025-12-10 18:00:40,143:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:40,143:INFO:Initializing create_model()
2025-12-10 18:00:40,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:40,144:INFO:Checking exceptions
2025-12-10 18:00:40,144:INFO:Importing libraries
2025-12-10 18:00:40,144:INFO:Copying training dataset
2025-12-10 18:00:40,152:INFO:Defining folds
2025-12-10 18:00:40,152:INFO:Declaring metric variables
2025-12-10 18:00:40,159:INFO:Importing untrained model
2025-12-10 18:00:40,164:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-10 18:00:40,175:INFO:Starting cross validation
2025-12-10 18:00:40,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:40,300:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,301:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,301:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,302:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,302:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,303:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,304:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,305:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,306:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,307:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:00:40,316:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,316:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,316:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,317:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,317:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,317:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

 self.scalings_])

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,319:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,321:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,321:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,321:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,322:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,323:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,324:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))


2025-12-10 18:00:40,325:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,325:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,325:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,325:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

 self.scalings_])

2025-12-10 18:00:40,325:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

 self.scalings_])

2025-12-10 18:00:40,325:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,326:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,327:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,327:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,328:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,328:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,328:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:00:40,330:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:00:40,336:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:00:40,337:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:00:40,337:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:00:40,338:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:00:40,339:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:00:40,341:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:00:40,342:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:00:40,343:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:00:40,350:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,352:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,352:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,352:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,352:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,352:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,352:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,352:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,357:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:40,376:INFO:Calculating mean and std
2025-12-10 18:00:40,378:INFO:Creating metrics dataframe
2025-12-10 18:00:40,381:INFO:Uploading results into container
2025-12-10 18:00:40,381:INFO:Uploading model into container now
2025-12-10 18:00:40,382:INFO:_master_model_container: 8
2025-12-10 18:00:40,382:INFO:_display_container: 2
2025-12-10 18:00:40,383:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-10 18:00:40,383:INFO:create_model() successfully completed......................................
2025-12-10 18:00:40,502:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:40,502:INFO:Creating metrics dataframe
2025-12-10 18:00:40,511:INFO:Initializing Ada Boost Classifier
2025-12-10 18:00:40,511:INFO:Total runtime is 0.09186131556828817 minutes
2025-12-10 18:00:40,517:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:40,518:INFO:Initializing create_model()
2025-12-10 18:00:40,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:40,519:INFO:Checking exceptions
2025-12-10 18:00:40,519:INFO:Importing libraries
2025-12-10 18:00:40,519:INFO:Copying training dataset
2025-12-10 18:00:40,528:INFO:Defining folds
2025-12-10 18:00:40,530:INFO:Declaring metric variables
2025-12-10 18:00:40,536:INFO:Importing untrained model
2025-12-10 18:00:40,540:INFO:Ada Boost Classifier Imported successfully
2025-12-10 18:00:40,550:INFO:Starting cross validation
2025-12-10 18:00:40,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:40,652:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,654:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,654:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,655:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,655:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,655:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,655:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,657:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,657:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:40,662:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:00:41,372:INFO:Calculating mean and std
2025-12-10 18:00:41,374:INFO:Creating metrics dataframe
2025-12-10 18:00:41,377:INFO:Uploading results into container
2025-12-10 18:00:41,377:INFO:Uploading model into container now
2025-12-10 18:00:41,379:INFO:_master_model_container: 9
2025-12-10 18:00:41,379:INFO:_display_container: 2
2025-12-10 18:00:41,379:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-10 18:00:41,379:INFO:create_model() successfully completed......................................
2025-12-10 18:00:41,500:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:41,500:INFO:Creating metrics dataframe
2025-12-10 18:00:41,511:INFO:Initializing Gradient Boosting Classifier
2025-12-10 18:00:41,512:INFO:Total runtime is 0.10851672887802125 minutes
2025-12-10 18:00:41,516:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:41,517:INFO:Initializing create_model()
2025-12-10 18:00:41,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:41,517:INFO:Checking exceptions
2025-12-10 18:00:41,517:INFO:Importing libraries
2025-12-10 18:00:41,517:INFO:Copying training dataset
2025-12-10 18:00:41,528:INFO:Defining folds
2025-12-10 18:00:41,528:INFO:Declaring metric variables
2025-12-10 18:00:41,532:INFO:Importing untrained model
2025-12-10 18:00:41,537:INFO:Gradient Boosting Classifier Imported successfully
2025-12-10 18:00:41,548:INFO:Starting cross validation
2025-12-10 18:00:41,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:43,623:INFO:Calculating mean and std
2025-12-10 18:00:43,625:INFO:Creating metrics dataframe
2025-12-10 18:00:43,626:INFO:Uploading results into container
2025-12-10 18:00:43,628:INFO:Uploading model into container now
2025-12-10 18:00:43,628:INFO:_master_model_container: 10
2025-12-10 18:00:43,628:INFO:_display_container: 2
2025-12-10 18:00:43,629:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-10 18:00:43,629:INFO:create_model() successfully completed......................................
2025-12-10 18:00:43,754:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:43,754:INFO:Creating metrics dataframe
2025-12-10 18:00:43,765:INFO:Initializing Linear Discriminant Analysis
2025-12-10 18:00:43,766:INFO:Total runtime is 0.1461138606071472 minutes
2025-12-10 18:00:43,771:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:43,772:INFO:Initializing create_model()
2025-12-10 18:00:43,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:43,773:INFO:Checking exceptions
2025-12-10 18:00:43,773:INFO:Importing libraries
2025-12-10 18:00:43,773:INFO:Copying training dataset
2025-12-10 18:00:43,783:INFO:Defining folds
2025-12-10 18:00:43,784:INFO:Declaring metric variables
2025-12-10 18:00:43,789:INFO:Importing untrained model
2025-12-10 18:00:43,796:INFO:Linear Discriminant Analysis Imported successfully
2025-12-10 18:00:43,804:INFO:Starting cross validation
2025-12-10 18:00:43,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:43,964:INFO:Calculating mean and std
2025-12-10 18:00:43,965:INFO:Creating metrics dataframe
2025-12-10 18:00:43,966:INFO:Uploading results into container
2025-12-10 18:00:43,968:INFO:Uploading model into container now
2025-12-10 18:00:43,968:INFO:_master_model_container: 11
2025-12-10 18:00:43,968:INFO:_display_container: 2
2025-12-10 18:00:43,968:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-10 18:00:43,969:INFO:create_model() successfully completed......................................
2025-12-10 18:00:44,119:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:44,119:INFO:Creating metrics dataframe
2025-12-10 18:00:44,131:INFO:Initializing Extra Trees Classifier
2025-12-10 18:00:44,132:INFO:Total runtime is 0.15220911502838133 minutes
2025-12-10 18:00:44,137:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:44,137:INFO:Initializing create_model()
2025-12-10 18:00:44,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:44,137:INFO:Checking exceptions
2025-12-10 18:00:44,137:INFO:Importing libraries
2025-12-10 18:00:44,137:INFO:Copying training dataset
2025-12-10 18:00:44,147:INFO:Defining folds
2025-12-10 18:00:44,147:INFO:Declaring metric variables
2025-12-10 18:00:44,154:INFO:Importing untrained model
2025-12-10 18:00:44,159:INFO:Extra Trees Classifier Imported successfully
2025-12-10 18:00:44,168:INFO:Starting cross validation
2025-12-10 18:00:44,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:45,404:INFO:Calculating mean and std
2025-12-10 18:00:45,407:INFO:Creating metrics dataframe
2025-12-10 18:00:45,409:INFO:Uploading results into container
2025-12-10 18:00:45,410:INFO:Uploading model into container now
2025-12-10 18:00:45,410:INFO:_master_model_container: 12
2025-12-10 18:00:45,410:INFO:_display_container: 2
2025-12-10 18:00:45,412:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-10 18:00:45,412:INFO:create_model() successfully completed......................................
2025-12-10 18:00:45,534:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:45,534:INFO:Creating metrics dataframe
2025-12-10 18:00:45,546:INFO:Initializing Light Gradient Boosting Machine
2025-12-10 18:00:45,547:INFO:Total runtime is 0.17578945954640704 minutes
2025-12-10 18:00:45,551:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:45,553:INFO:Initializing create_model()
2025-12-10 18:00:45,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:45,553:INFO:Checking exceptions
2025-12-10 18:00:45,553:INFO:Importing libraries
2025-12-10 18:00:45,553:INFO:Copying training dataset
2025-12-10 18:00:45,562:INFO:Defining folds
2025-12-10 18:00:45,563:INFO:Declaring metric variables
2025-12-10 18:00:45,569:INFO:Importing untrained model
2025-12-10 18:00:45,574:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:00:45,583:INFO:Starting cross validation
2025-12-10 18:00:45,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:47,546:INFO:Calculating mean and std
2025-12-10 18:00:47,547:INFO:Creating metrics dataframe
2025-12-10 18:00:47,552:INFO:Uploading results into container
2025-12-10 18:00:47,553:INFO:Uploading model into container now
2025-12-10 18:00:47,553:INFO:_master_model_container: 13
2025-12-10 18:00:47,555:INFO:_display_container: 2
2025-12-10 18:00:47,556:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:00:47,556:INFO:create_model() successfully completed......................................
2025-12-10 18:00:47,697:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:47,698:INFO:Creating metrics dataframe
2025-12-10 18:00:47,707:INFO:Initializing Dummy Classifier
2025-12-10 18:00:47,707:INFO:Total runtime is 0.21178994576136267 minutes
2025-12-10 18:00:47,713:INFO:SubProcess create_model() called ==================================
2025-12-10 18:00:47,714:INFO:Initializing create_model()
2025-12-10 18:00:47,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6D52C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:47,714:INFO:Checking exceptions
2025-12-10 18:00:47,714:INFO:Importing libraries
2025-12-10 18:00:47,714:INFO:Copying training dataset
2025-12-10 18:00:47,723:INFO:Defining folds
2025-12-10 18:00:47,723:INFO:Declaring metric variables
2025-12-10 18:00:47,729:INFO:Importing untrained model
2025-12-10 18:00:47,733:INFO:Dummy Classifier Imported successfully
2025-12-10 18:00:47,744:INFO:Starting cross validation
2025-12-10 18:00:47,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:00:47,849:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,851:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,853:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,855:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,866:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,868:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,871:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,872:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,878:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,883:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:00:47,900:INFO:Calculating mean and std
2025-12-10 18:00:47,901:INFO:Creating metrics dataframe
2025-12-10 18:00:47,905:INFO:Uploading results into container
2025-12-10 18:00:47,906:INFO:Uploading model into container now
2025-12-10 18:00:47,907:INFO:_master_model_container: 14
2025-12-10 18:00:47,907:INFO:_display_container: 2
2025-12-10 18:00:47,907:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-10 18:00:47,907:INFO:create_model() successfully completed......................................
2025-12-10 18:00:48,030:INFO:SubProcess create_model() end ==================================
2025-12-10 18:00:48,031:INFO:Creating metrics dataframe
2025-12-10 18:00:48,042:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-10 18:00:48,054:INFO:Initializing create_model()
2025-12-10 18:00:48,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:00:48,055:INFO:Checking exceptions
2025-12-10 18:00:48,056:INFO:Importing libraries
2025-12-10 18:00:48,057:INFO:Copying training dataset
2025-12-10 18:00:48,065:INFO:Defining folds
2025-12-10 18:00:48,065:INFO:Declaring metric variables
2025-12-10 18:00:48,065:INFO:Importing untrained model
2025-12-10 18:00:48,065:INFO:Declaring custom model
2025-12-10 18:00:48,067:INFO:Logistic Regression Imported successfully
2025-12-10 18:00:48,067:INFO:Cross validation set to False
2025-12-10 18:00:48,068:INFO:Fitting Model
2025-12-10 18:00:48,117:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] O sistema no pode encontrar o arquivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-12-10 18:00:48,121:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\joblib\externals\loky\backend\context.py", line 257, in _count_physical_cores
2025-12-10 18:00:48,121:WARNING:    cpu_info = subprocess.run(
2025-12-10 18:00:48,121:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 503, in run
2025-12-10 18:00:48,121:WARNING:    with Popen(*popenargs, **kwargs) as process:
2025-12-10 18:00:48,121:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 971, in __init__
2025-12-10 18:00:48,121:WARNING:    self._execute_child(args, executable, preexec_fn, close_fds,
2025-12-10 18:00:48,121:WARNING:  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\subprocess.py", line 1456, in _execute_child
2025-12-10 18:00:48,121:WARNING:    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
2025-12-10 18:00:48,976:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:00:48,976:INFO:create_model() successfully completed......................................
2025-12-10 18:00:49,175:INFO:_master_model_container: 14
2025-12-10 18:00:49,176:INFO:_display_container: 2
2025-12-10 18:00:49,177:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:00:49,177:INFO:compare_models() successfully completed......................................
2025-12-10 18:00:49,179:INFO:Initializing tune_model()
2025-12-10 18:00:49,179:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>)
2025-12-10 18:00:49,179:INFO:Checking exceptions
2025-12-10 18:00:49,202:INFO:Copying training dataset
2025-12-10 18:00:49,212:INFO:Checking base model
2025-12-10 18:00:49,212:INFO:Base model : Logistic Regression
2025-12-10 18:00:49,217:INFO:Declaring metric variables
2025-12-10 18:00:49,220:INFO:Defining Hyperparameters
2025-12-10 18:00:49,351:INFO:Tuning with n_jobs=-1
2025-12-10 18:00:49,351:INFO:Initializing RandomizedSearchCV
2025-12-10 18:00:54,151:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:00:54,228:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:01:00,647:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:01:01,571:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:01:01,582:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-10 18:01:01,584:INFO:Hyperparameter search completed
2025-12-10 18:01:01,584:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:01,585:INFO:Initializing create_model()
2025-12-10 18:01:01,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CA831C00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-10 18:01:01,586:INFO:Checking exceptions
2025-12-10 18:01:01,586:INFO:Importing libraries
2025-12-10 18:01:01,586:INFO:Copying training dataset
2025-12-10 18:01:01,596:INFO:Defining folds
2025-12-10 18:01:01,596:INFO:Declaring metric variables
2025-12-10 18:01:01,599:INFO:Importing untrained model
2025-12-10 18:01:01,601:INFO:Declaring custom model
2025-12-10 18:01:01,605:INFO:Logistic Regression Imported successfully
2025-12-10 18:01:01,616:INFO:Starting cross validation
2025-12-10 18:01:01,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:02,873:INFO:Calculating mean and std
2025-12-10 18:01:02,875:INFO:Creating metrics dataframe
2025-12-10 18:01:02,881:INFO:Finalizing model
2025-12-10 18:01:03,946:INFO:Uploading results into container
2025-12-10 18:01:03,946:INFO:Uploading model into container now
2025-12-10 18:01:03,948:INFO:_master_model_container: 15
2025-12-10 18:01:03,948:INFO:_display_container: 3
2025-12-10 18:01:03,949:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:01:03,949:INFO:create_model() successfully completed......................................
2025-12-10 18:01:04,094:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:04,094:INFO:choose_better activated
2025-12-10 18:01:04,099:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:04,099:INFO:Initializing create_model()
2025-12-10 18:01:04,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C77A4E50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:04,099:INFO:Checking exceptions
2025-12-10 18:01:04,103:INFO:Importing libraries
2025-12-10 18:01:04,103:INFO:Copying training dataset
2025-12-10 18:01:04,110:INFO:Defining folds
2025-12-10 18:01:04,110:INFO:Declaring metric variables
2025-12-10 18:01:04,111:INFO:Importing untrained model
2025-12-10 18:01:04,111:INFO:Declaring custom model
2025-12-10 18:01:04,111:INFO:Logistic Regression Imported successfully
2025-12-10 18:01:04,112:INFO:Starting cross validation
2025-12-10 18:01:04,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:05,192:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:01:05,218:INFO:Calculating mean and std
2025-12-10 18:01:05,219:INFO:Creating metrics dataframe
2025-12-10 18:01:05,222:INFO:Finalizing model
2025-12-10 18:01:06,081:INFO:Uploading results into container
2025-12-10 18:01:06,082:INFO:Uploading model into container now
2025-12-10 18:01:06,082:INFO:_master_model_container: 16
2025-12-10 18:01:06,082:INFO:_display_container: 4
2025-12-10 18:01:06,083:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:01:06,083:INFO:create_model() successfully completed......................................
2025-12-10 18:01:06,201:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:06,202:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-10 18:01:06,202:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-10 18:01:06,202:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-10 18:01:06,202:INFO:choose_better completed
2025-12-10 18:01:06,202:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-10 18:01:06,217:INFO:_master_model_container: 16
2025-12-10 18:01:06,217:INFO:_display_container: 3
2025-12-10 18:01:06,218:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:01:06,218:INFO:tune_model() successfully completed......................................
2025-12-10 18:01:21,194:INFO:PyCaret RegressionExperiment
2025-12-10 18:01:21,194:INFO:Logging name: reg-default-name
2025-12-10 18:01:21,194:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-10 18:01:21,194:INFO:version 3.3.2
2025-12-10 18:01:21,194:INFO:Initializing setup()
2025-12-10 18:01:21,194:INFO:self.USI: e941
2025-12-10 18:01:21,194:INFO:self._variable_keys: {'X', 'USI', 'log_plots_param', 'exp_id', 'html_param', 'y_test', 'y_train', '_ml_usecase', 'X_train', 'n_jobs_param', 'pipeline', 'memory', '_available_plots', 'gpu_param', 'X_test', 'idx', 'seed', 'logging_param', 'exp_name_log', 'data', 'y', 'transform_target_param', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-12-10 18:01:21,194:INFO:Checking environment
2025-12-10 18:01:21,194:INFO:python_version: 3.10.19
2025-12-10 18:01:21,194:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-10 18:01:21,194:INFO:machine: AMD64
2025-12-10 18:01:21,194:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-10 18:01:21,194:INFO:Memory: svmem(total=33699516416, available=16004493312, percent=52.5, used=17695023104, free=16004493312)
2025-12-10 18:01:21,194:INFO:Physical Core: 8
2025-12-10 18:01:21,195:INFO:Logical Core: 16
2025-12-10 18:01:21,195:INFO:Checking libraries
2025-12-10 18:01:21,195:INFO:System:
2025-12-10 18:01:21,195:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-10 18:01:21,195:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-10 18:01:21,195:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-10 18:01:21,195:INFO:PyCaret required dependencies:
2025-12-10 18:01:21,195:INFO:                 pip: 25.3
2025-12-10 18:01:21,195:INFO:          setuptools: 80.9.0
2025-12-10 18:01:21,196:INFO:             pycaret: 3.3.2
2025-12-10 18:01:21,196:INFO:             IPython: 8.37.0
2025-12-10 18:01:21,196:INFO:          ipywidgets: 8.1.8
2025-12-10 18:01:21,196:INFO:                tqdm: 4.67.1
2025-12-10 18:01:21,196:INFO:               numpy: 1.26.4
2025-12-10 18:01:21,196:INFO:              pandas: 2.1.4
2025-12-10 18:01:21,196:INFO:              jinja2: 3.1.6
2025-12-10 18:01:21,196:INFO:               scipy: 1.11.4
2025-12-10 18:01:21,196:INFO:              joblib: 1.3.2
2025-12-10 18:01:21,196:INFO:             sklearn: 1.4.2
2025-12-10 18:01:21,196:INFO:                pyod: 2.0.6
2025-12-10 18:01:21,196:INFO:            imblearn: 0.14.0
2025-12-10 18:01:21,196:INFO:   category_encoders: 2.7.0
2025-12-10 18:01:21,196:INFO:            lightgbm: 4.6.0
2025-12-10 18:01:21,196:INFO:               numba: 0.62.1
2025-12-10 18:01:21,196:INFO:            requests: 2.32.5
2025-12-10 18:01:21,196:INFO:          matplotlib: 3.7.5
2025-12-10 18:01:21,196:INFO:          scikitplot: 0.3.7
2025-12-10 18:01:21,196:INFO:         yellowbrick: 1.5
2025-12-10 18:01:21,196:INFO:              plotly: 6.5.0
2025-12-10 18:01:21,196:INFO:    plotly-resampler: Not installed
2025-12-10 18:01:21,196:INFO:             kaleido: 1.2.0
2025-12-10 18:01:21,197:INFO:           schemdraw: 0.15
2025-12-10 18:01:21,197:INFO:         statsmodels: 0.14.5
2025-12-10 18:01:21,197:INFO:              sktime: 0.26.0
2025-12-10 18:01:21,197:INFO:               tbats: 1.1.3
2025-12-10 18:01:21,197:INFO:            pmdarima: 2.0.4
2025-12-10 18:01:21,197:INFO:              psutil: 7.1.3
2025-12-10 18:01:21,197:INFO:          markupsafe: 3.0.3
2025-12-10 18:01:21,197:INFO:             pickle5: Not installed
2025-12-10 18:01:21,197:INFO:         cloudpickle: 3.1.2
2025-12-10 18:01:21,197:INFO:         deprecation: 2.1.0
2025-12-10 18:01:21,197:INFO:              xxhash: 3.6.0
2025-12-10 18:01:21,197:INFO:           wurlitzer: Not installed
2025-12-10 18:01:21,197:INFO:PyCaret optional dependencies:
2025-12-10 18:01:21,197:INFO:                shap: Not installed
2025-12-10 18:01:21,197:INFO:           interpret: Not installed
2025-12-10 18:01:21,197:INFO:                umap: Not installed
2025-12-10 18:01:21,197:INFO:     ydata_profiling: Not installed
2025-12-10 18:01:21,197:INFO:  explainerdashboard: Not installed
2025-12-10 18:01:21,197:INFO:             autoviz: Not installed
2025-12-10 18:01:21,197:INFO:           fairlearn: Not installed
2025-12-10 18:01:21,197:INFO:          deepchecks: Not installed
2025-12-10 18:01:21,197:INFO:             xgboost: Not installed
2025-12-10 18:01:21,197:INFO:            catboost: Not installed
2025-12-10 18:01:21,197:INFO:              kmodes: Not installed
2025-12-10 18:01:21,197:INFO:             mlxtend: Not installed
2025-12-10 18:01:21,197:INFO:       statsforecast: Not installed
2025-12-10 18:01:21,197:INFO:        tune_sklearn: Not installed
2025-12-10 18:01:21,197:INFO:                 ray: Not installed
2025-12-10 18:01:21,197:INFO:            hyperopt: Not installed
2025-12-10 18:01:21,197:INFO:              optuna: Not installed
2025-12-10 18:01:21,197:INFO:               skopt: Not installed
2025-12-10 18:01:21,197:INFO:              mlflow: Not installed
2025-12-10 18:01:21,197:INFO:              gradio: Not installed
2025-12-10 18:01:21,197:INFO:             fastapi: Not installed
2025-12-10 18:01:21,197:INFO:             uvicorn: Not installed
2025-12-10 18:01:21,198:INFO:              m2cgen: Not installed
2025-12-10 18:01:21,198:INFO:           evidently: Not installed
2025-12-10 18:01:21,198:INFO:               fugue: Not installed
2025-12-10 18:01:21,198:INFO:           streamlit: Not installed
2025-12-10 18:01:21,198:INFO:             prophet: Not installed
2025-12-10 18:01:21,198:INFO:None
2025-12-10 18:01:21,198:INFO:Set up data.
2025-12-10 18:01:21,208:INFO:Set up folding strategy.
2025-12-10 18:01:21,208:INFO:Set up train/test split.
2025-12-10 18:01:21,215:INFO:Set up index.
2025-12-10 18:01:21,216:INFO:Assigning column types.
2025-12-10 18:01:21,224:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-10 18:01:21,224:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,230:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,303:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,355:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,365:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,485:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-10 18:01:21,490:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,562:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,618:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,623:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,738:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,740:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-10 18:01:21,750:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,875:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:01:21,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:21,992:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-10 18:01:22,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:22,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:01:22,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:22,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:01:22,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,262:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-10 18:01:22,338:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:22,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,463:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:01:22,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,514:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-10 18:01:22,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:22,766:INFO:Preparing preprocessing pipeline...
2025-12-10 18:01:22,766:INFO:Set up simple imputation.
2025-12-10 18:01:22,766:INFO:Set up feature normalization.
2025-12-10 18:01:22,768:INFO:Set up column name cleaning.
2025-12-10 18:01:22,818:INFO:Finished creating preprocessing pipeline.
2025-12-10 18:01:22,824:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'transmission_encoded',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'ow...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-10 18:01:22,824:INFO:Creating final display dataframe.
2025-12-10 18:01:22,977:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 17)
4        Transformed data shape        (7906, 17)
5   Transformed train set shape        (5534, 17)
6    Transformed test set shape        (2372, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              e941
2025-12-10 18:01:23,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:23,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:23,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:23,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:01:23,234:INFO:setup() successfully completed in 2.05s...............
2025-12-10 18:01:23,236:INFO:Initializing compare_models()
2025-12-10 18:01:23,236:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-10 18:01:23,236:INFO:Checking exceptions
2025-12-10 18:01:23,240:INFO:Preparing display monitor
2025-12-10 18:01:23,270:INFO:Initializing Linear Regression
2025-12-10 18:01:23,271:INFO:Total runtime is 1.7122427622477213e-05 minutes
2025-12-10 18:01:23,277:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:23,277:INFO:Initializing create_model()
2025-12-10 18:01:23,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:23,278:INFO:Checking exceptions
2025-12-10 18:01:23,278:INFO:Importing libraries
2025-12-10 18:01:23,278:INFO:Copying training dataset
2025-12-10 18:01:23,287:INFO:Defining folds
2025-12-10 18:01:23,287:INFO:Declaring metric variables
2025-12-10 18:01:23,291:INFO:Importing untrained model
2025-12-10 18:01:23,296:INFO:Linear Regression Imported successfully
2025-12-10 18:01:23,307:INFO:Starting cross validation
2025-12-10 18:01:23,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:23,471:INFO:Calculating mean and std
2025-12-10 18:01:23,472:INFO:Creating metrics dataframe
2025-12-10 18:01:23,474:INFO:Uploading results into container
2025-12-10 18:01:23,475:INFO:Uploading model into container now
2025-12-10 18:01:23,475:INFO:_master_model_container: 1
2025-12-10 18:01:23,475:INFO:_display_container: 2
2025-12-10 18:01:23,475:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-12-10 18:01:23,475:INFO:create_model() successfully completed......................................
2025-12-10 18:01:23,619:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:23,619:INFO:Creating metrics dataframe
2025-12-10 18:01:23,628:INFO:Initializing Lasso Regression
2025-12-10 18:01:23,628:INFO:Total runtime is 0.0059726913770039875 minutes
2025-12-10 18:01:23,631:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:23,633:INFO:Initializing create_model()
2025-12-10 18:01:23,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:23,633:INFO:Checking exceptions
2025-12-10 18:01:23,633:INFO:Importing libraries
2025-12-10 18:01:23,633:INFO:Copying training dataset
2025-12-10 18:01:23,642:INFO:Defining folds
2025-12-10 18:01:23,642:INFO:Declaring metric variables
2025-12-10 18:01:23,645:INFO:Importing untrained model
2025-12-10 18:01:23,652:INFO:Lasso Regression Imported successfully
2025-12-10 18:01:23,661:INFO:Starting cross validation
2025-12-10 18:01:23,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:23,804:INFO:Calculating mean and std
2025-12-10 18:01:23,804:INFO:Creating metrics dataframe
2025-12-10 18:01:23,806:INFO:Uploading results into container
2025-12-10 18:01:23,808:INFO:Uploading model into container now
2025-12-10 18:01:23,808:INFO:_master_model_container: 2
2025-12-10 18:01:23,808:INFO:_display_container: 2
2025-12-10 18:01:23,808:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-12-10 18:01:23,808:INFO:create_model() successfully completed......................................
2025-12-10 18:01:23,960:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:23,961:INFO:Creating metrics dataframe
2025-12-10 18:01:23,969:INFO:Initializing Ridge Regression
2025-12-10 18:01:23,970:INFO:Total runtime is 0.011661350727081299 minutes
2025-12-10 18:01:23,975:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:23,975:INFO:Initializing create_model()
2025-12-10 18:01:23,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:23,975:INFO:Checking exceptions
2025-12-10 18:01:23,977:INFO:Importing libraries
2025-12-10 18:01:23,977:INFO:Copying training dataset
2025-12-10 18:01:23,983:INFO:Defining folds
2025-12-10 18:01:23,983:INFO:Declaring metric variables
2025-12-10 18:01:23,990:INFO:Importing untrained model
2025-12-10 18:01:23,995:INFO:Ridge Regression Imported successfully
2025-12-10 18:01:24,004:INFO:Starting cross validation
2025-12-10 18:01:24,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:24,140:INFO:Calculating mean and std
2025-12-10 18:01:24,141:INFO:Creating metrics dataframe
2025-12-10 18:01:24,142:INFO:Uploading results into container
2025-12-10 18:01:24,143:INFO:Uploading model into container now
2025-12-10 18:01:24,143:INFO:_master_model_container: 3
2025-12-10 18:01:24,143:INFO:_display_container: 2
2025-12-10 18:01:24,143:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-12-10 18:01:24,143:INFO:create_model() successfully completed......................................
2025-12-10 18:01:24,281:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:24,281:INFO:Creating metrics dataframe
2025-12-10 18:01:24,290:INFO:Initializing Elastic Net
2025-12-10 18:01:24,290:INFO:Total runtime is 0.016995497544606525 minutes
2025-12-10 18:01:24,294:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:24,296:INFO:Initializing create_model()
2025-12-10 18:01:24,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:24,296:INFO:Checking exceptions
2025-12-10 18:01:24,296:INFO:Importing libraries
2025-12-10 18:01:24,296:INFO:Copying training dataset
2025-12-10 18:01:24,306:INFO:Defining folds
2025-12-10 18:01:24,306:INFO:Declaring metric variables
2025-12-10 18:01:24,311:INFO:Importing untrained model
2025-12-10 18:01:24,316:INFO:Elastic Net Imported successfully
2025-12-10 18:01:24,327:INFO:Starting cross validation
2025-12-10 18:01:24,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:24,474:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+12, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-10 18:01:24,485:INFO:Calculating mean and std
2025-12-10 18:01:24,486:INFO:Creating metrics dataframe
2025-12-10 18:01:24,489:INFO:Uploading results into container
2025-12-10 18:01:24,491:INFO:Uploading model into container now
2025-12-10 18:01:24,492:INFO:_master_model_container: 4
2025-12-10 18:01:24,493:INFO:_display_container: 2
2025-12-10 18:01:24,493:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-12-10 18:01:24,493:INFO:create_model() successfully completed......................................
2025-12-10 18:01:24,625:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:24,625:INFO:Creating metrics dataframe
2025-12-10 18:01:24,635:INFO:Initializing Least Angle Regression
2025-12-10 18:01:24,635:INFO:Total runtime is 0.02274588346481323 minutes
2025-12-10 18:01:24,640:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:24,641:INFO:Initializing create_model()
2025-12-10 18:01:24,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:24,642:INFO:Checking exceptions
2025-12-10 18:01:24,642:INFO:Importing libraries
2025-12-10 18:01:24,642:INFO:Copying training dataset
2025-12-10 18:01:24,651:INFO:Defining folds
2025-12-10 18:01:24,652:INFO:Declaring metric variables
2025-12-10 18:01:24,657:INFO:Importing untrained model
2025-12-10 18:01:24,663:INFO:Least Angle Regression Imported successfully
2025-12-10 18:01:24,674:INFO:Starting cross validation
2025-12-10 18:01:24,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:24,836:INFO:Calculating mean and std
2025-12-10 18:01:24,838:INFO:Creating metrics dataframe
2025-12-10 18:01:24,841:INFO:Uploading results into container
2025-12-10 18:01:24,842:INFO:Uploading model into container now
2025-12-10 18:01:24,842:INFO:_master_model_container: 5
2025-12-10 18:01:24,842:INFO:_display_container: 2
2025-12-10 18:01:24,842:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-12-10 18:01:24,844:INFO:create_model() successfully completed......................................
2025-12-10 18:01:24,976:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:24,976:INFO:Creating metrics dataframe
2025-12-10 18:01:24,983:INFO:Initializing Lasso Least Angle Regression
2025-12-10 18:01:24,984:INFO:Total runtime is 0.028572003046671547 minutes
2025-12-10 18:01:24,990:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:24,990:INFO:Initializing create_model()
2025-12-10 18:01:24,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:24,991:INFO:Checking exceptions
2025-12-10 18:01:24,991:INFO:Importing libraries
2025-12-10 18:01:24,991:INFO:Copying training dataset
2025-12-10 18:01:24,999:INFO:Defining folds
2025-12-10 18:01:24,999:INFO:Declaring metric variables
2025-12-10 18:01:25,006:INFO:Importing untrained model
2025-12-10 18:01:25,011:INFO:Lasso Least Angle Regression Imported successfully
2025-12-10 18:01:25,020:INFO:Starting cross validation
2025-12-10 18:01:25,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:25,149:INFO:Calculating mean and std
2025-12-10 18:01:25,151:INFO:Creating metrics dataframe
2025-12-10 18:01:25,155:INFO:Uploading results into container
2025-12-10 18:01:25,157:INFO:Uploading model into container now
2025-12-10 18:01:25,157:INFO:_master_model_container: 6
2025-12-10 18:01:25,157:INFO:_display_container: 2
2025-12-10 18:01:25,158:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-12-10 18:01:25,158:INFO:create_model() successfully completed......................................
2025-12-10 18:01:25,291:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:25,291:INFO:Creating metrics dataframe
2025-12-10 18:01:25,299:INFO:Initializing Orthogonal Matching Pursuit
2025-12-10 18:01:25,299:INFO:Total runtime is 0.03382180531819661 minutes
2025-12-10 18:01:25,305:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:25,305:INFO:Initializing create_model()
2025-12-10 18:01:25,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:25,306:INFO:Checking exceptions
2025-12-10 18:01:25,306:INFO:Importing libraries
2025-12-10 18:01:25,306:INFO:Copying training dataset
2025-12-10 18:01:25,315:INFO:Defining folds
2025-12-10 18:01:25,315:INFO:Declaring metric variables
2025-12-10 18:01:25,322:INFO:Importing untrained model
2025-12-10 18:01:25,328:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-10 18:01:25,338:INFO:Starting cross validation
2025-12-10 18:01:25,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:25,469:INFO:Calculating mean and std
2025-12-10 18:01:25,471:INFO:Creating metrics dataframe
2025-12-10 18:01:25,474:INFO:Uploading results into container
2025-12-10 18:01:25,475:INFO:Uploading model into container now
2025-12-10 18:01:25,476:INFO:_master_model_container: 7
2025-12-10 18:01:25,477:INFO:_display_container: 2
2025-12-10 18:01:25,477:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-12-10 18:01:25,478:INFO:create_model() successfully completed......................................
2025-12-10 18:01:25,602:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:25,602:INFO:Creating metrics dataframe
2025-12-10 18:01:25,612:INFO:Initializing Bayesian Ridge
2025-12-10 18:01:25,613:INFO:Total runtime is 0.039047213395436604 minutes
2025-12-10 18:01:25,616:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:25,617:INFO:Initializing create_model()
2025-12-10 18:01:25,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:25,618:INFO:Checking exceptions
2025-12-10 18:01:25,618:INFO:Importing libraries
2025-12-10 18:01:25,618:INFO:Copying training dataset
2025-12-10 18:01:25,628:INFO:Defining folds
2025-12-10 18:01:25,629:INFO:Declaring metric variables
2025-12-10 18:01:25,634:INFO:Importing untrained model
2025-12-10 18:01:25,641:INFO:Bayesian Ridge Imported successfully
2025-12-10 18:01:25,651:INFO:Starting cross validation
2025-12-10 18:01:25,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:25,788:INFO:Calculating mean and std
2025-12-10 18:01:25,790:INFO:Creating metrics dataframe
2025-12-10 18:01:25,793:INFO:Uploading results into container
2025-12-10 18:01:25,794:INFO:Uploading model into container now
2025-12-10 18:01:25,794:INFO:_master_model_container: 8
2025-12-10 18:01:25,794:INFO:_display_container: 2
2025-12-10 18:01:25,795:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-12-10 18:01:25,796:INFO:create_model() successfully completed......................................
2025-12-10 18:01:25,922:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:25,922:INFO:Creating metrics dataframe
2025-12-10 18:01:25,932:INFO:Initializing Passive Aggressive Regressor
2025-12-10 18:01:25,932:INFO:Total runtime is 0.04436558882395426 minutes
2025-12-10 18:01:25,937:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:25,937:INFO:Initializing create_model()
2025-12-10 18:01:25,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:25,937:INFO:Checking exceptions
2025-12-10 18:01:25,938:INFO:Importing libraries
2025-12-10 18:01:25,938:INFO:Copying training dataset
2025-12-10 18:01:25,947:INFO:Defining folds
2025-12-10 18:01:25,947:INFO:Declaring metric variables
2025-12-10 18:01:25,954:INFO:Importing untrained model
2025-12-10 18:01:25,959:INFO:Passive Aggressive Regressor Imported successfully
2025-12-10 18:01:25,968:INFO:Starting cross validation
2025-12-10 18:01:25,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:26,614:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,644:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,652:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,657:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,660:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,662:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,682:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,683:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,683:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:01:26,702:INFO:Calculating mean and std
2025-12-10 18:01:26,705:INFO:Creating metrics dataframe
2025-12-10 18:01:26,707:INFO:Uploading results into container
2025-12-10 18:01:26,709:INFO:Uploading model into container now
2025-12-10 18:01:26,709:INFO:_master_model_container: 9
2025-12-10 18:01:26,709:INFO:_display_container: 2
2025-12-10 18:01:26,711:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-10 18:01:26,711:INFO:create_model() successfully completed......................................
2025-12-10 18:01:26,837:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:26,837:INFO:Creating metrics dataframe
2025-12-10 18:01:26,849:INFO:Initializing Huber Regressor
2025-12-10 18:01:26,849:INFO:Total runtime is 0.05964829921722412 minutes
2025-12-10 18:01:26,856:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:26,856:INFO:Initializing create_model()
2025-12-10 18:01:26,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:26,856:INFO:Checking exceptions
2025-12-10 18:01:26,856:INFO:Importing libraries
2025-12-10 18:01:26,856:INFO:Copying training dataset
2025-12-10 18:01:26,865:INFO:Defining folds
2025-12-10 18:01:26,865:INFO:Declaring metric variables
2025-12-10 18:01:26,871:INFO:Importing untrained model
2025-12-10 18:01:26,877:INFO:Huber Regressor Imported successfully
2025-12-10 18:01:26,888:INFO:Starting cross validation
2025-12-10 18:01:26,889:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:27,166:INFO:Calculating mean and std
2025-12-10 18:01:27,186:INFO:Creating metrics dataframe
2025-12-10 18:01:27,190:INFO:Uploading results into container
2025-12-10 18:01:27,192:INFO:Uploading model into container now
2025-12-10 18:01:27,192:INFO:_master_model_container: 10
2025-12-10 18:01:27,192:INFO:_display_container: 2
2025-12-10 18:01:27,193:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-12-10 18:01:27,193:INFO:create_model() successfully completed......................................
2025-12-10 18:01:27,314:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:27,316:INFO:Creating metrics dataframe
2025-12-10 18:01:27,328:INFO:Initializing K Neighbors Regressor
2025-12-10 18:01:27,328:INFO:Total runtime is 0.06763474941253662 minutes
2025-12-10 18:01:27,332:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:27,333:INFO:Initializing create_model()
2025-12-10 18:01:27,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:27,334:INFO:Checking exceptions
2025-12-10 18:01:27,334:INFO:Importing libraries
2025-12-10 18:01:27,334:INFO:Copying training dataset
2025-12-10 18:01:27,346:INFO:Defining folds
2025-12-10 18:01:27,346:INFO:Declaring metric variables
2025-12-10 18:01:27,355:INFO:Importing untrained model
2025-12-10 18:01:27,362:INFO:K Neighbors Regressor Imported successfully
2025-12-10 18:01:27,375:INFO:Starting cross validation
2025-12-10 18:01:27,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:27,531:INFO:Calculating mean and std
2025-12-10 18:01:27,533:INFO:Creating metrics dataframe
2025-12-10 18:01:27,536:INFO:Uploading results into container
2025-12-10 18:01:27,536:INFO:Uploading model into container now
2025-12-10 18:01:27,537:INFO:_master_model_container: 11
2025-12-10 18:01:27,537:INFO:_display_container: 2
2025-12-10 18:01:27,538:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-12-10 18:01:27,538:INFO:create_model() successfully completed......................................
2025-12-10 18:01:27,665:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:27,665:INFO:Creating metrics dataframe
2025-12-10 18:01:27,675:INFO:Initializing Decision Tree Regressor
2025-12-10 18:01:27,677:INFO:Total runtime is 0.07344398895899455 minutes
2025-12-10 18:01:27,681:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:27,682:INFO:Initializing create_model()
2025-12-10 18:01:27,683:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:27,683:INFO:Checking exceptions
2025-12-10 18:01:27,683:INFO:Importing libraries
2025-12-10 18:01:27,683:INFO:Copying training dataset
2025-12-10 18:01:27,693:INFO:Defining folds
2025-12-10 18:01:27,693:INFO:Declaring metric variables
2025-12-10 18:01:27,698:INFO:Importing untrained model
2025-12-10 18:01:27,703:INFO:Decision Tree Regressor Imported successfully
2025-12-10 18:01:27,714:INFO:Starting cross validation
2025-12-10 18:01:27,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:27,857:INFO:Calculating mean and std
2025-12-10 18:01:27,858:INFO:Creating metrics dataframe
2025-12-10 18:01:27,862:INFO:Uploading results into container
2025-12-10 18:01:27,862:INFO:Uploading model into container now
2025-12-10 18:01:27,863:INFO:_master_model_container: 12
2025-12-10 18:01:27,863:INFO:_display_container: 2
2025-12-10 18:01:27,863:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-12-10 18:01:27,863:INFO:create_model() successfully completed......................................
2025-12-10 18:01:27,990:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:27,990:INFO:Creating metrics dataframe
2025-12-10 18:01:28,001:INFO:Initializing Random Forest Regressor
2025-12-10 18:01:28,001:INFO:Total runtime is 0.07885288794835409 minutes
2025-12-10 18:01:28,008:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:28,008:INFO:Initializing create_model()
2025-12-10 18:01:28,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:28,009:INFO:Checking exceptions
2025-12-10 18:01:28,009:INFO:Importing libraries
2025-12-10 18:01:28,009:INFO:Copying training dataset
2025-12-10 18:01:28,017:INFO:Defining folds
2025-12-10 18:01:28,018:INFO:Declaring metric variables
2025-12-10 18:01:28,025:INFO:Importing untrained model
2025-12-10 18:01:28,031:INFO:Random Forest Regressor Imported successfully
2025-12-10 18:01:28,041:INFO:Starting cross validation
2025-12-10 18:01:28,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:30,071:INFO:Calculating mean and std
2025-12-10 18:01:30,073:INFO:Creating metrics dataframe
2025-12-10 18:01:30,077:INFO:Uploading results into container
2025-12-10 18:01:30,079:INFO:Uploading model into container now
2025-12-10 18:01:30,079:INFO:_master_model_container: 13
2025-12-10 18:01:30,079:INFO:_display_container: 2
2025-12-10 18:01:30,080:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-12-10 18:01:30,080:INFO:create_model() successfully completed......................................
2025-12-10 18:01:30,251:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:30,251:INFO:Creating metrics dataframe
2025-12-10 18:01:30,266:INFO:Initializing Extra Trees Regressor
2025-12-10 18:01:30,266:INFO:Total runtime is 0.11659522056579591 minutes
2025-12-10 18:01:30,272:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:30,273:INFO:Initializing create_model()
2025-12-10 18:01:30,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:30,273:INFO:Checking exceptions
2025-12-10 18:01:30,273:INFO:Importing libraries
2025-12-10 18:01:30,273:INFO:Copying training dataset
2025-12-10 18:01:30,283:INFO:Defining folds
2025-12-10 18:01:30,283:INFO:Declaring metric variables
2025-12-10 18:01:30,290:INFO:Importing untrained model
2025-12-10 18:01:30,295:INFO:Extra Trees Regressor Imported successfully
2025-12-10 18:01:30,306:INFO:Starting cross validation
2025-12-10 18:01:30,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:31,888:INFO:Calculating mean and std
2025-12-10 18:01:31,890:INFO:Creating metrics dataframe
2025-12-10 18:01:31,892:INFO:Uploading results into container
2025-12-10 18:01:31,894:INFO:Uploading model into container now
2025-12-10 18:01:31,894:INFO:_master_model_container: 14
2025-12-10 18:01:31,894:INFO:_display_container: 2
2025-12-10 18:01:31,894:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-10 18:01:31,895:INFO:create_model() successfully completed......................................
2025-12-10 18:01:32,034:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:32,034:INFO:Creating metrics dataframe
2025-12-10 18:01:32,047:INFO:Initializing AdaBoost Regressor
2025-12-10 18:01:32,047:INFO:Total runtime is 0.14627883434295655 minutes
2025-12-10 18:01:32,051:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:32,052:INFO:Initializing create_model()
2025-12-10 18:01:32,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:32,053:INFO:Checking exceptions
2025-12-10 18:01:32,053:INFO:Importing libraries
2025-12-10 18:01:32,053:INFO:Copying training dataset
2025-12-10 18:01:32,061:INFO:Defining folds
2025-12-10 18:01:32,063:INFO:Declaring metric variables
2025-12-10 18:01:32,068:INFO:Importing untrained model
2025-12-10 18:01:32,075:INFO:AdaBoost Regressor Imported successfully
2025-12-10 18:01:32,089:INFO:Starting cross validation
2025-12-10 18:01:32,093:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:32,614:INFO:Calculating mean and std
2025-12-10 18:01:32,615:INFO:Creating metrics dataframe
2025-12-10 18:01:32,618:INFO:Uploading results into container
2025-12-10 18:01:32,618:INFO:Uploading model into container now
2025-12-10 18:01:32,620:INFO:_master_model_container: 15
2025-12-10 18:01:32,620:INFO:_display_container: 2
2025-12-10 18:01:32,620:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-12-10 18:01:32,620:INFO:create_model() successfully completed......................................
2025-12-10 18:01:32,741:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:32,741:INFO:Creating metrics dataframe
2025-12-10 18:01:32,756:INFO:Initializing Gradient Boosting Regressor
2025-12-10 18:01:32,757:INFO:Total runtime is 0.15811139742533367 minutes
2025-12-10 18:01:32,762:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:32,762:INFO:Initializing create_model()
2025-12-10 18:01:32,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:32,762:INFO:Checking exceptions
2025-12-10 18:01:32,762:INFO:Importing libraries
2025-12-10 18:01:32,762:INFO:Copying training dataset
2025-12-10 18:01:32,773:INFO:Defining folds
2025-12-10 18:01:32,774:INFO:Declaring metric variables
2025-12-10 18:01:32,778:INFO:Importing untrained model
2025-12-10 18:01:32,784:INFO:Gradient Boosting Regressor Imported successfully
2025-12-10 18:01:32,793:INFO:Starting cross validation
2025-12-10 18:01:32,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:33,578:INFO:Calculating mean and std
2025-12-10 18:01:33,579:INFO:Creating metrics dataframe
2025-12-10 18:01:33,582:INFO:Uploading results into container
2025-12-10 18:01:33,583:INFO:Uploading model into container now
2025-12-10 18:01:33,585:INFO:_master_model_container: 16
2025-12-10 18:01:33,585:INFO:_display_container: 2
2025-12-10 18:01:33,585:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-10 18:01:33,585:INFO:create_model() successfully completed......................................
2025-12-10 18:01:33,717:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:33,717:INFO:Creating metrics dataframe
2025-12-10 18:01:33,733:INFO:Initializing Light Gradient Boosting Machine
2025-12-10 18:01:33,734:INFO:Total runtime is 0.1743870735168457 minutes
2025-12-10 18:01:33,740:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:33,740:INFO:Initializing create_model()
2025-12-10 18:01:33,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:33,741:INFO:Checking exceptions
2025-12-10 18:01:33,741:INFO:Importing libraries
2025-12-10 18:01:33,741:INFO:Copying training dataset
2025-12-10 18:01:33,751:INFO:Defining folds
2025-12-10 18:01:33,751:INFO:Declaring metric variables
2025-12-10 18:01:33,757:INFO:Importing untrained model
2025-12-10 18:01:33,763:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:01:33,771:INFO:Starting cross validation
2025-12-10 18:01:33,774:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:35,201:INFO:Calculating mean and std
2025-12-10 18:01:35,203:INFO:Creating metrics dataframe
2025-12-10 18:01:35,206:INFO:Uploading results into container
2025-12-10 18:01:35,208:INFO:Uploading model into container now
2025-12-10 18:01:35,209:INFO:_master_model_container: 17
2025-12-10 18:01:35,209:INFO:_display_container: 2
2025-12-10 18:01:35,211:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:01:35,211:INFO:create_model() successfully completed......................................
2025-12-10 18:01:35,373:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:35,373:INFO:Creating metrics dataframe
2025-12-10 18:01:35,388:INFO:Initializing Dummy Regressor
2025-12-10 18:01:35,389:INFO:Total runtime is 0.20197925567626954 minutes
2025-12-10 18:01:35,395:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:35,395:INFO:Initializing create_model()
2025-12-10 18:01:35,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C779FD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:35,395:INFO:Checking exceptions
2025-12-10 18:01:35,395:INFO:Importing libraries
2025-12-10 18:01:35,397:INFO:Copying training dataset
2025-12-10 18:01:35,405:INFO:Defining folds
2025-12-10 18:01:35,405:INFO:Declaring metric variables
2025-12-10 18:01:35,412:INFO:Importing untrained model
2025-12-10 18:01:35,416:INFO:Dummy Regressor Imported successfully
2025-12-10 18:01:35,427:INFO:Starting cross validation
2025-12-10 18:01:35,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:35,556:INFO:Calculating mean and std
2025-12-10 18:01:35,557:INFO:Creating metrics dataframe
2025-12-10 18:01:35,560:INFO:Uploading results into container
2025-12-10 18:01:35,560:INFO:Uploading model into container now
2025-12-10 18:01:35,562:INFO:_master_model_container: 18
2025-12-10 18:01:35,562:INFO:_display_container: 2
2025-12-10 18:01:35,562:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-12-10 18:01:35,562:INFO:create_model() successfully completed......................................
2025-12-10 18:01:35,694:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:35,694:INFO:Creating metrics dataframe
2025-12-10 18:01:35,709:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-10 18:01:35,721:INFO:Initializing create_model()
2025-12-10 18:01:35,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:35,721:INFO:Checking exceptions
2025-12-10 18:01:35,725:INFO:Importing libraries
2025-12-10 18:01:35,725:INFO:Copying training dataset
2025-12-10 18:01:35,735:INFO:Defining folds
2025-12-10 18:01:35,735:INFO:Declaring metric variables
2025-12-10 18:01:35,735:INFO:Importing untrained model
2025-12-10 18:01:35,736:INFO:Declaring custom model
2025-12-10 18:01:35,737:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:01:35,737:INFO:Cross validation set to False
2025-12-10 18:01:35,737:INFO:Fitting Model
2025-12-10 18:01:35,762:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 18:01:35,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000600 seconds.
2025-12-10 18:01:35,763:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-10 18:01:35,763:INFO:[LightGBM] [Info] Total Bins 874
2025-12-10 18:01:35,763:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-10 18:01:35,763:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-10 18:01:35,881:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:01:35,881:INFO:create_model() successfully completed......................................
2025-12-10 18:01:36,072:INFO:_master_model_container: 18
2025-12-10 18:01:36,073:INFO:_display_container: 2
2025-12-10 18:01:36,073:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:01:36,073:INFO:compare_models() successfully completed......................................
2025-12-10 18:01:36,076:INFO:Initializing tune_model()
2025-12-10 18:01:36,076:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>)
2025-12-10 18:01:36,076:INFO:Checking exceptions
2025-12-10 18:01:36,098:INFO:Copying training dataset
2025-12-10 18:01:36,107:INFO:Checking base model
2025-12-10 18:01:36,107:INFO:Base model : Light Gradient Boosting Machine
2025-12-10 18:01:36,112:INFO:Declaring metric variables
2025-12-10 18:01:36,118:INFO:Defining Hyperparameters
2025-12-10 18:01:36,277:INFO:Tuning with n_jobs=-1
2025-12-10 18:01:36,277:INFO:Initializing RandomizedSearchCV
2025-12-10 18:01:56,886:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-10 18:01:56,887:INFO:Hyperparameter search completed
2025-12-10 18:01:56,889:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:56,890:INFO:Initializing create_model()
2025-12-10 18:01:56,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C77400D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-10 18:01:56,890:INFO:Checking exceptions
2025-12-10 18:01:56,892:INFO:Importing libraries
2025-12-10 18:01:56,892:INFO:Copying training dataset
2025-12-10 18:01:56,908:INFO:Defining folds
2025-12-10 18:01:56,908:INFO:Declaring metric variables
2025-12-10 18:01:56,915:INFO:Importing untrained model
2025-12-10 18:01:56,915:INFO:Declaring custom model
2025-12-10 18:01:56,927:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:01:56,945:INFO:Starting cross validation
2025-12-10 18:01:56,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:58,096:INFO:Calculating mean and std
2025-12-10 18:01:58,098:INFO:Creating metrics dataframe
2025-12-10 18:01:58,108:INFO:Finalizing model
2025-12-10 18:01:58,140:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-10 18:01:58,141:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-10 18:01:58,141:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-10 18:01:58,146:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 18:01:58,147:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-10 18:01:58,147:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-10 18:01:58,147:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-10 18:01:58,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-12-10 18:01:58,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 18:01:58,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 18:01:58,148:INFO:[LightGBM] [Info] Total Bins 874
2025-12-10 18:01:58,149:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-10 18:01:58,150:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-10 18:01:58,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 18:01:58,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 18:01:58,315:INFO:Uploading results into container
2025-12-10 18:01:58,317:INFO:Uploading model into container now
2025-12-10 18:01:58,318:INFO:_master_model_container: 19
2025-12-10 18:01:58,318:INFO:_display_container: 3
2025-12-10 18:01:58,321:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
              importance_type='split', learning_rate=0.4, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
              random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:01:58,321:INFO:create_model() successfully completed......................................
2025-12-10 18:01:58,499:INFO:SubProcess create_model() end ==================================
2025-12-10 18:01:58,499:INFO:choose_better activated
2025-12-10 18:01:58,505:INFO:SubProcess create_model() called ==================================
2025-12-10 18:01:58,507:INFO:Initializing create_model()
2025-12-10 18:01:58,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CE446D10>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:01:58,508:INFO:Checking exceptions
2025-12-10 18:01:58,511:INFO:Importing libraries
2025-12-10 18:01:58,511:INFO:Copying training dataset
2025-12-10 18:01:58,519:INFO:Defining folds
2025-12-10 18:01:58,520:INFO:Declaring metric variables
2025-12-10 18:01:58,520:INFO:Importing untrained model
2025-12-10 18:01:58,520:INFO:Declaring custom model
2025-12-10 18:01:58,522:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:01:58,522:INFO:Starting cross validation
2025-12-10 18:01:58,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:01:59,739:INFO:Calculating mean and std
2025-12-10 18:01:59,740:INFO:Creating metrics dataframe
2025-12-10 18:01:59,743:INFO:Finalizing model
2025-12-10 18:01:59,777:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 18:01:59,781:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.
2025-12-10 18:01:59,781:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-10 18:01:59,781:INFO:[LightGBM] [Info] Total Bins 874
2025-12-10 18:01:59,781:INFO:[LightGBM] [Info] Number of data points in the train set: 5534, number of used features: 15
2025-12-10 18:01:59,781:INFO:[LightGBM] [Info] Start training from score 642264.917058
2025-12-10 18:01:59,967:INFO:Uploading results into container
2025-12-10 18:01:59,968:INFO:Uploading model into container now
2025-12-10 18:01:59,969:INFO:_master_model_container: 20
2025-12-10 18:01:59,969:INFO:_display_container: 4
2025-12-10 18:01:59,970:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:01:59,970:INFO:create_model() successfully completed......................................
2025-12-10 18:02:00,136:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:00,136:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.9584
2025-12-10 18:02:00,138:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
              importance_type='split', learning_rate=0.4, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
              n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
              random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.9462
2025-12-10 18:02:00,139:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-10 18:02:00,139:INFO:choose_better completed
2025-12-10 18:02:00,140:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-10 18:02:00,158:INFO:_master_model_container: 20
2025-12-10 18:02:00,158:INFO:_display_container: 3
2025-12-10 18:02:00,160:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:02:00,160:INFO:tune_model() successfully completed......................................
2025-12-10 18:02:00,319:INFO:PyCaret ClassificationExperiment
2025-12-10 18:02:00,319:INFO:Logging name: clf-default-name
2025-12-10 18:02:00,319:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-10 18:02:00,319:INFO:version 3.3.2
2025-12-10 18:02:00,319:INFO:Initializing setup()
2025-12-10 18:02:00,319:INFO:self.USI: 1dc9
2025-12-10 18:02:00,319:INFO:self._variable_keys: {'X', 'USI', 'log_plots_param', 'exp_id', 'html_param', 'y_test', 'y_train', 'fix_imbalance', '_ml_usecase', 'X_train', 'n_jobs_param', 'pipeline', 'memory', '_available_plots', 'is_multiclass', 'gpu_param', 'X_test', 'idx', 'seed', 'logging_param', 'exp_name_log', 'data', 'y', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-12-10 18:02:00,320:INFO:Checking environment
2025-12-10 18:02:00,320:INFO:python_version: 3.10.19
2025-12-10 18:02:00,320:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-10 18:02:00,320:INFO:machine: AMD64
2025-12-10 18:02:00,320:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-10 18:02:00,320:INFO:Memory: svmem(total=33699516416, available=15899127808, percent=52.8, used=17800388608, free=15899127808)
2025-12-10 18:02:00,321:INFO:Physical Core: 8
2025-12-10 18:02:00,321:INFO:Logical Core: 16
2025-12-10 18:02:00,321:INFO:Checking libraries
2025-12-10 18:02:00,321:INFO:System:
2025-12-10 18:02:00,321:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-10 18:02:00,321:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-10 18:02:00,321:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-10 18:02:00,321:INFO:PyCaret required dependencies:
2025-12-10 18:02:00,322:INFO:                 pip: 25.3
2025-12-10 18:02:00,322:INFO:          setuptools: 80.9.0
2025-12-10 18:02:00,322:INFO:             pycaret: 3.3.2
2025-12-10 18:02:00,322:INFO:             IPython: 8.37.0
2025-12-10 18:02:00,322:INFO:          ipywidgets: 8.1.8
2025-12-10 18:02:00,322:INFO:                tqdm: 4.67.1
2025-12-10 18:02:00,322:INFO:               numpy: 1.26.4
2025-12-10 18:02:00,322:INFO:              pandas: 2.1.4
2025-12-10 18:02:00,322:INFO:              jinja2: 3.1.6
2025-12-10 18:02:00,322:INFO:               scipy: 1.11.4
2025-12-10 18:02:00,322:INFO:              joblib: 1.3.2
2025-12-10 18:02:00,322:INFO:             sklearn: 1.4.2
2025-12-10 18:02:00,322:INFO:                pyod: 2.0.6
2025-12-10 18:02:00,322:INFO:            imblearn: 0.14.0
2025-12-10 18:02:00,322:INFO:   category_encoders: 2.7.0
2025-12-10 18:02:00,322:INFO:            lightgbm: 4.6.0
2025-12-10 18:02:00,322:INFO:               numba: 0.62.1
2025-12-10 18:02:00,322:INFO:            requests: 2.32.5
2025-12-10 18:02:00,322:INFO:          matplotlib: 3.7.5
2025-12-10 18:02:00,322:INFO:          scikitplot: 0.3.7
2025-12-10 18:02:00,323:INFO:         yellowbrick: 1.5
2025-12-10 18:02:00,323:INFO:              plotly: 6.5.0
2025-12-10 18:02:00,323:INFO:    plotly-resampler: Not installed
2025-12-10 18:02:00,323:INFO:             kaleido: 1.2.0
2025-12-10 18:02:00,323:INFO:           schemdraw: 0.15
2025-12-10 18:02:00,323:INFO:         statsmodels: 0.14.5
2025-12-10 18:02:00,323:INFO:              sktime: 0.26.0
2025-12-10 18:02:00,323:INFO:               tbats: 1.1.3
2025-12-10 18:02:00,323:INFO:            pmdarima: 2.0.4
2025-12-10 18:02:00,323:INFO:              psutil: 7.1.3
2025-12-10 18:02:00,323:INFO:          markupsafe: 3.0.3
2025-12-10 18:02:00,324:INFO:             pickle5: Not installed
2025-12-10 18:02:00,324:INFO:         cloudpickle: 3.1.2
2025-12-10 18:02:00,324:INFO:         deprecation: 2.1.0
2025-12-10 18:02:00,324:INFO:              xxhash: 3.6.0
2025-12-10 18:02:00,324:INFO:           wurlitzer: Not installed
2025-12-10 18:02:00,324:INFO:PyCaret optional dependencies:
2025-12-10 18:02:00,324:INFO:                shap: Not installed
2025-12-10 18:02:00,325:INFO:           interpret: Not installed
2025-12-10 18:02:00,325:INFO:                umap: Not installed
2025-12-10 18:02:00,325:INFO:     ydata_profiling: Not installed
2025-12-10 18:02:00,325:INFO:  explainerdashboard: Not installed
2025-12-10 18:02:00,325:INFO:             autoviz: Not installed
2025-12-10 18:02:00,325:INFO:           fairlearn: Not installed
2025-12-10 18:02:00,325:INFO:          deepchecks: Not installed
2025-12-10 18:02:00,325:INFO:             xgboost: Not installed
2025-12-10 18:02:00,325:INFO:            catboost: Not installed
2025-12-10 18:02:00,325:INFO:              kmodes: Not installed
2025-12-10 18:02:00,325:INFO:             mlxtend: Not installed
2025-12-10 18:02:00,325:INFO:       statsforecast: Not installed
2025-12-10 18:02:00,325:INFO:        tune_sklearn: Not installed
2025-12-10 18:02:00,325:INFO:                 ray: Not installed
2025-12-10 18:02:00,325:INFO:            hyperopt: Not installed
2025-12-10 18:02:00,325:INFO:              optuna: Not installed
2025-12-10 18:02:00,325:INFO:               skopt: Not installed
2025-12-10 18:02:00,325:INFO:              mlflow: Not installed
2025-12-10 18:02:00,325:INFO:              gradio: Not installed
2025-12-10 18:02:00,325:INFO:             fastapi: Not installed
2025-12-10 18:02:00,325:INFO:             uvicorn: Not installed
2025-12-10 18:02:00,326:INFO:              m2cgen: Not installed
2025-12-10 18:02:00,326:INFO:           evidently: Not installed
2025-12-10 18:02:00,326:INFO:               fugue: Not installed
2025-12-10 18:02:00,326:INFO:           streamlit: Not installed
2025-12-10 18:02:00,326:INFO:             prophet: Not installed
2025-12-10 18:02:00,326:INFO:None
2025-12-10 18:02:00,326:INFO:Set up data.
2025-12-10 18:02:00,334:INFO:Set up folding strategy.
2025-12-10 18:02:00,334:INFO:Set up train/test split.
2025-12-10 18:02:00,349:INFO:Set up index.
2025-12-10 18:02:00,349:INFO:Assigning column types.
2025-12-10 18:02:00,360:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-10 18:02:00,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:02:00,415:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:02:00,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:02:00,501:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:02:00,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,539:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-10 18:02:00,592:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:02:00,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:02:00,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,723:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-10 18:02:00,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:00,911:INFO:Preparing preprocessing pipeline...
2025-12-10 18:02:00,913:INFO:Set up simple imputation.
2025-12-10 18:02:00,913:INFO:Set up imbalanced handling.
2025-12-10 18:02:00,915:INFO:Set up column name cleaning.
2025-12-10 18:02:00,966:INFO:Finished creating preprocessing pipeline.
2025-12-10 18:02:00,976:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'selling_price',
                                             'km_driven', 'mileage', 'engine',
                                             'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Sec...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-10 18:02:00,976:INFO:Creating final display dataframe.
2025-12-10 18:02:01,127:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 17)
4        Transformed data shape           (11982, 17)
5   Transformed train set shape            (9610, 17)
6    Transformed test set shape            (2372, 17)
7              Numeric features                    16
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                Fix imbalance                  True
13         Fix imbalance method                 SMOTE
14               Fold Generator       StratifiedKFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment                 False
19              Experiment Name      clf-default-name
20                          USI                  1dc9
2025-12-10 18:02:01,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:01,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:01,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:01,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:02:01,296:INFO:setup() successfully completed in 0.98s...............
2025-12-10 18:02:01,298:INFO:Initializing compare_models()
2025-12-10 18:02:01,298:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-10 18:02:01,298:INFO:Checking exceptions
2025-12-10 18:02:01,305:INFO:Preparing display monitor
2025-12-10 18:02:01,343:INFO:Initializing Logistic Regression
2025-12-10 18:02:01,344:INFO:Total runtime is 2.6698907216389974e-05 minutes
2025-12-10 18:02:01,350:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:01,352:INFO:Initializing create_model()
2025-12-10 18:02:01,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:01,352:INFO:Checking exceptions
2025-12-10 18:02:01,352:INFO:Importing libraries
2025-12-10 18:02:01,353:INFO:Copying training dataset
2025-12-10 18:02:01,366:INFO:Defining folds
2025-12-10 18:02:01,395:INFO:Declaring metric variables
2025-12-10 18:02:01,401:INFO:Importing untrained model
2025-12-10 18:02:01,409:INFO:Logistic Regression Imported successfully
2025-12-10 18:02:01,426:INFO:Starting cross validation
2025-12-10 18:02:01,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:02,703:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:02:02,747:INFO:Calculating mean and std
2025-12-10 18:02:02,748:INFO:Creating metrics dataframe
2025-12-10 18:02:02,750:INFO:Uploading results into container
2025-12-10 18:02:02,751:INFO:Uploading model into container now
2025-12-10 18:02:02,753:INFO:_master_model_container: 1
2025-12-10 18:02:02,753:INFO:_display_container: 2
2025-12-10 18:02:02,755:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:02:02,755:INFO:create_model() successfully completed......................................
2025-12-10 18:02:02,885:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:02,887:INFO:Creating metrics dataframe
2025-12-10 18:02:02,894:INFO:Initializing K Neighbors Classifier
2025-12-10 18:02:02,894:INFO:Total runtime is 0.025862614313761394 minutes
2025-12-10 18:02:02,901:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:02,901:INFO:Initializing create_model()
2025-12-10 18:02:02,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:02,901:INFO:Checking exceptions
2025-12-10 18:02:02,901:INFO:Importing libraries
2025-12-10 18:02:02,902:INFO:Copying training dataset
2025-12-10 18:02:02,912:INFO:Defining folds
2025-12-10 18:02:02,912:INFO:Declaring metric variables
2025-12-10 18:02:02,920:INFO:Importing untrained model
2025-12-10 18:02:02,927:INFO:K Neighbors Classifier Imported successfully
2025-12-10 18:02:02,938:INFO:Starting cross validation
2025-12-10 18:02:02,940:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:03,225:INFO:Calculating mean and std
2025-12-10 18:02:03,226:INFO:Creating metrics dataframe
2025-12-10 18:02:03,230:INFO:Uploading results into container
2025-12-10 18:02:03,230:INFO:Uploading model into container now
2025-12-10 18:02:03,231:INFO:_master_model_container: 2
2025-12-10 18:02:03,231:INFO:_display_container: 2
2025-12-10 18:02:03,231:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-10 18:02:03,231:INFO:create_model() successfully completed......................................
2025-12-10 18:02:03,356:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:03,357:INFO:Creating metrics dataframe
2025-12-10 18:02:03,366:INFO:Initializing Naive Bayes
2025-12-10 18:02:03,367:INFO:Total runtime is 0.033740007877349855 minutes
2025-12-10 18:02:03,373:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:03,374:INFO:Initializing create_model()
2025-12-10 18:02:03,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:03,375:INFO:Checking exceptions
2025-12-10 18:02:03,375:INFO:Importing libraries
2025-12-10 18:02:03,375:INFO:Copying training dataset
2025-12-10 18:02:03,386:INFO:Defining folds
2025-12-10 18:02:03,387:INFO:Declaring metric variables
2025-12-10 18:02:03,394:INFO:Importing untrained model
2025-12-10 18:02:03,399:INFO:Naive Bayes Imported successfully
2025-12-10 18:02:03,413:INFO:Starting cross validation
2025-12-10 18:02:03,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:03,586:INFO:Calculating mean and std
2025-12-10 18:02:03,587:INFO:Creating metrics dataframe
2025-12-10 18:02:03,592:INFO:Uploading results into container
2025-12-10 18:02:03,593:INFO:Uploading model into container now
2025-12-10 18:02:03,594:INFO:_master_model_container: 3
2025-12-10 18:02:03,594:INFO:_display_container: 2
2025-12-10 18:02:03,594:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-10 18:02:03,596:INFO:create_model() successfully completed......................................
2025-12-10 18:02:03,724:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:03,725:INFO:Creating metrics dataframe
2025-12-10 18:02:03,733:INFO:Initializing Decision Tree Classifier
2025-12-10 18:02:03,733:INFO:Total runtime is 0.039840304851531984 minutes
2025-12-10 18:02:03,740:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:03,740:INFO:Initializing create_model()
2025-12-10 18:02:03,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:03,742:INFO:Checking exceptions
2025-12-10 18:02:03,742:INFO:Importing libraries
2025-12-10 18:02:03,742:INFO:Copying training dataset
2025-12-10 18:02:03,751:INFO:Defining folds
2025-12-10 18:02:03,751:INFO:Declaring metric variables
2025-12-10 18:02:03,760:INFO:Importing untrained model
2025-12-10 18:02:03,766:INFO:Decision Tree Classifier Imported successfully
2025-12-10 18:02:03,778:INFO:Starting cross validation
2025-12-10 18:02:03,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:03,979:INFO:Calculating mean and std
2025-12-10 18:02:03,981:INFO:Creating metrics dataframe
2025-12-10 18:02:03,983:INFO:Uploading results into container
2025-12-10 18:02:03,984:INFO:Uploading model into container now
2025-12-10 18:02:03,985:INFO:_master_model_container: 4
2025-12-10 18:02:03,986:INFO:_display_container: 2
2025-12-10 18:02:03,987:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-10 18:02:03,988:INFO:create_model() successfully completed......................................
2025-12-10 18:02:04,113:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:04,113:INFO:Creating metrics dataframe
2025-12-10 18:02:04,124:INFO:Initializing SVM - Linear Kernel
2025-12-10 18:02:04,124:INFO:Total runtime is 0.04636327425638835 minutes
2025-12-10 18:02:04,129:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:04,131:INFO:Initializing create_model()
2025-12-10 18:02:04,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:04,131:INFO:Checking exceptions
2025-12-10 18:02:04,131:INFO:Importing libraries
2025-12-10 18:02:04,131:INFO:Copying training dataset
2025-12-10 18:02:04,145:INFO:Defining folds
2025-12-10 18:02:04,145:INFO:Declaring metric variables
2025-12-10 18:02:04,150:INFO:Importing untrained model
2025-12-10 18:02:04,159:INFO:SVM - Linear Kernel Imported successfully
2025-12-10 18:02:04,170:INFO:Starting cross validation
2025-12-10 18:02:04,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:04,466:INFO:Calculating mean and std
2025-12-10 18:02:04,468:INFO:Creating metrics dataframe
2025-12-10 18:02:04,470:INFO:Uploading results into container
2025-12-10 18:02:04,472:INFO:Uploading model into container now
2025-12-10 18:02:04,473:INFO:_master_model_container: 5
2025-12-10 18:02:04,473:INFO:_display_container: 2
2025-12-10 18:02:04,473:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-10 18:02:04,474:INFO:create_model() successfully completed......................................
2025-12-10 18:02:04,599:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:04,599:INFO:Creating metrics dataframe
2025-12-10 18:02:04,609:INFO:Initializing Ridge Classifier
2025-12-10 18:02:04,610:INFO:Total runtime is 0.0544542948404948 minutes
2025-12-10 18:02:04,615:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:04,616:INFO:Initializing create_model()
2025-12-10 18:02:04,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:04,616:INFO:Checking exceptions
2025-12-10 18:02:04,616:INFO:Importing libraries
2025-12-10 18:02:04,616:INFO:Copying training dataset
2025-12-10 18:02:04,627:INFO:Defining folds
2025-12-10 18:02:04,627:INFO:Declaring metric variables
2025-12-10 18:02:04,633:INFO:Importing untrained model
2025-12-10 18:02:04,642:INFO:Ridge Classifier Imported successfully
2025-12-10 18:02:04,659:INFO:Starting cross validation
2025-12-10 18:02:04,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:04,758:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.07985e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,765:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97415e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,772:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.12855e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,776:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.22879e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,780:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.76553e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,787:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.25459e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,790:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.97653e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,793:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.84536e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,795:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.18612e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,799:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.27127e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:02:04,842:INFO:Calculating mean and std
2025-12-10 18:02:04,843:INFO:Creating metrics dataframe
2025-12-10 18:02:04,846:INFO:Uploading results into container
2025-12-10 18:02:04,846:INFO:Uploading model into container now
2025-12-10 18:02:04,847:INFO:_master_model_container: 6
2025-12-10 18:02:04,847:INFO:_display_container: 2
2025-12-10 18:02:04,848:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-10 18:02:04,849:INFO:create_model() successfully completed......................................
2025-12-10 18:02:04,976:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:04,976:INFO:Creating metrics dataframe
2025-12-10 18:02:04,987:INFO:Initializing Random Forest Classifier
2025-12-10 18:02:04,987:INFO:Total runtime is 0.060738460222880056 minutes
2025-12-10 18:02:04,993:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:04,995:INFO:Initializing create_model()
2025-12-10 18:02:04,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:04,995:INFO:Checking exceptions
2025-12-10 18:02:04,995:INFO:Importing libraries
2025-12-10 18:02:04,995:INFO:Copying training dataset
2025-12-10 18:02:05,006:INFO:Defining folds
2025-12-10 18:02:05,006:INFO:Declaring metric variables
2025-12-10 18:02:05,014:INFO:Importing untrained model
2025-12-10 18:02:05,020:INFO:Random Forest Classifier Imported successfully
2025-12-10 18:02:05,033:INFO:Starting cross validation
2025-12-10 18:02:05,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:06,639:INFO:Calculating mean and std
2025-12-10 18:02:06,641:INFO:Creating metrics dataframe
2025-12-10 18:02:06,644:INFO:Uploading results into container
2025-12-10 18:02:06,644:INFO:Uploading model into container now
2025-12-10 18:02:06,646:INFO:_master_model_container: 7
2025-12-10 18:02:06,646:INFO:_display_container: 2
2025-12-10 18:02:06,647:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-10 18:02:06,647:INFO:create_model() successfully completed......................................
2025-12-10 18:02:06,783:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:06,783:INFO:Creating metrics dataframe
2025-12-10 18:02:06,794:INFO:Initializing Quadratic Discriminant Analysis
2025-12-10 18:02:06,794:INFO:Total runtime is 0.09085118373235068 minutes
2025-12-10 18:02:06,798:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:06,799:INFO:Initializing create_model()
2025-12-10 18:02:06,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:06,799:INFO:Checking exceptions
2025-12-10 18:02:06,799:INFO:Importing libraries
2025-12-10 18:02:06,799:INFO:Copying training dataset
2025-12-10 18:02:06,808:INFO:Defining folds
2025-12-10 18:02:06,810:INFO:Declaring metric variables
2025-12-10 18:02:06,817:INFO:Importing untrained model
2025-12-10 18:02:06,823:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-10 18:02:06,838:INFO:Starting cross validation
2025-12-10 18:02:06,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:06,954:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:06,960:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:06,960:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:06,963:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:06,971:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:06,973:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,974:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,975:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,978:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:06,978:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,978:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,978:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,979:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,979:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,979:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,979:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,981:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,981:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,981:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,983:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,983:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,983:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:06,984:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:06,986:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,986:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,986:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:06,986:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,987:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,987:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:06,987:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,989:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,994:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,994:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,995:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,996:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:06,997:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,997:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:06,997:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:06,997:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:06,998:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:07,001:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:07,001:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,002:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,002:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

 self.scalings_])

2025-12-10 18:02:07,002:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:07,003:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:07,003:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:02:07,005:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,006:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,006:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:07,006:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:07,007:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,008:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,009:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:07,010:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,010:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:07,010:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,011:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:07,012:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:07,013:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:07,015:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:07,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:07,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:07,019:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:07,020:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:07,023:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,023:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,023:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,024:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:02:07,024:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:07,024:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:02:07,028:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:07,031:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:07,031:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:02:07,036:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:07,039:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:07,055:INFO:Calculating mean and std
2025-12-10 18:02:07,056:INFO:Creating metrics dataframe
2025-12-10 18:02:07,059:INFO:Uploading results into container
2025-12-10 18:02:07,060:INFO:Uploading model into container now
2025-12-10 18:02:07,060:INFO:_master_model_container: 8
2025-12-10 18:02:07,060:INFO:_display_container: 2
2025-12-10 18:02:07,061:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-10 18:02:07,062:INFO:create_model() successfully completed......................................
2025-12-10 18:02:07,189:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:07,189:INFO:Creating metrics dataframe
2025-12-10 18:02:07,198:INFO:Initializing Ada Boost Classifier
2025-12-10 18:02:07,198:INFO:Total runtime is 0.09759335915247601 minutes
2025-12-10 18:02:07,205:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:07,206:INFO:Initializing create_model()
2025-12-10 18:02:07,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:07,206:INFO:Checking exceptions
2025-12-10 18:02:07,206:INFO:Importing libraries
2025-12-10 18:02:07,206:INFO:Copying training dataset
2025-12-10 18:02:07,216:INFO:Defining folds
2025-12-10 18:02:07,216:INFO:Declaring metric variables
2025-12-10 18:02:07,223:INFO:Importing untrained model
2025-12-10 18:02:07,229:INFO:Ada Boost Classifier Imported successfully
2025-12-10 18:02:07,242:INFO:Starting cross validation
2025-12-10 18:02:07,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:07,335:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,336:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,338:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,347:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,349:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,360:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,361:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,362:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,365:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:07,374:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:02:08,103:INFO:Calculating mean and std
2025-12-10 18:02:08,103:INFO:Creating metrics dataframe
2025-12-10 18:02:08,108:INFO:Uploading results into container
2025-12-10 18:02:08,110:INFO:Uploading model into container now
2025-12-10 18:02:08,111:INFO:_master_model_container: 9
2025-12-10 18:02:08,111:INFO:_display_container: 2
2025-12-10 18:02:08,112:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-10 18:02:08,112:INFO:create_model() successfully completed......................................
2025-12-10 18:02:08,256:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:08,256:INFO:Creating metrics dataframe
2025-12-10 18:02:08,268:INFO:Initializing Gradient Boosting Classifier
2025-12-10 18:02:08,268:INFO:Total runtime is 0.11541872421900433 minutes
2025-12-10 18:02:08,274:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:08,276:INFO:Initializing create_model()
2025-12-10 18:02:08,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:08,277:INFO:Checking exceptions
2025-12-10 18:02:08,277:INFO:Importing libraries
2025-12-10 18:02:08,277:INFO:Copying training dataset
2025-12-10 18:02:08,289:INFO:Defining folds
2025-12-10 18:02:08,291:INFO:Declaring metric variables
2025-12-10 18:02:08,299:INFO:Importing untrained model
2025-12-10 18:02:08,309:INFO:Gradient Boosting Classifier Imported successfully
2025-12-10 18:02:08,328:INFO:Starting cross validation
2025-12-10 18:02:08,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:10,507:INFO:Calculating mean and std
2025-12-10 18:02:10,509:INFO:Creating metrics dataframe
2025-12-10 18:02:10,511:INFO:Uploading results into container
2025-12-10 18:02:10,512:INFO:Uploading model into container now
2025-12-10 18:02:10,512:INFO:_master_model_container: 10
2025-12-10 18:02:10,512:INFO:_display_container: 2
2025-12-10 18:02:10,513:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-10 18:02:10,513:INFO:create_model() successfully completed......................................
2025-12-10 18:02:10,640:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:10,640:INFO:Creating metrics dataframe
2025-12-10 18:02:10,653:INFO:Initializing Linear Discriminant Analysis
2025-12-10 18:02:10,654:INFO:Total runtime is 0.15518173774083457 minutes
2025-12-10 18:02:10,659:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:10,659:INFO:Initializing create_model()
2025-12-10 18:02:10,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:10,660:INFO:Checking exceptions
2025-12-10 18:02:10,660:INFO:Importing libraries
2025-12-10 18:02:10,660:INFO:Copying training dataset
2025-12-10 18:02:10,670:INFO:Defining folds
2025-12-10 18:02:10,671:INFO:Declaring metric variables
2025-12-10 18:02:10,676:INFO:Importing untrained model
2025-12-10 18:02:10,684:INFO:Linear Discriminant Analysis Imported successfully
2025-12-10 18:02:10,699:INFO:Starting cross validation
2025-12-10 18:02:10,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:10,899:INFO:Calculating mean and std
2025-12-10 18:02:10,900:INFO:Creating metrics dataframe
2025-12-10 18:02:10,903:INFO:Uploading results into container
2025-12-10 18:02:10,904:INFO:Uploading model into container now
2025-12-10 18:02:10,904:INFO:_master_model_container: 11
2025-12-10 18:02:10,904:INFO:_display_container: 2
2025-12-10 18:02:10,906:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-10 18:02:10,906:INFO:create_model() successfully completed......................................
2025-12-10 18:02:11,033:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:11,034:INFO:Creating metrics dataframe
2025-12-10 18:02:11,046:INFO:Initializing Extra Trees Classifier
2025-12-10 18:02:11,046:INFO:Total runtime is 0.16172176599502566 minutes
2025-12-10 18:02:11,053:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:11,054:INFO:Initializing create_model()
2025-12-10 18:02:11,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:11,054:INFO:Checking exceptions
2025-12-10 18:02:11,054:INFO:Importing libraries
2025-12-10 18:02:11,054:INFO:Copying training dataset
2025-12-10 18:02:11,063:INFO:Defining folds
2025-12-10 18:02:11,063:INFO:Declaring metric variables
2025-12-10 18:02:11,069:INFO:Importing untrained model
2025-12-10 18:02:11,077:INFO:Extra Trees Classifier Imported successfully
2025-12-10 18:02:11,092:INFO:Starting cross validation
2025-12-10 18:02:11,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:12,420:INFO:Calculating mean and std
2025-12-10 18:02:12,421:INFO:Creating metrics dataframe
2025-12-10 18:02:12,424:INFO:Uploading results into container
2025-12-10 18:02:12,424:INFO:Uploading model into container now
2025-12-10 18:02:12,426:INFO:_master_model_container: 12
2025-12-10 18:02:12,426:INFO:_display_container: 2
2025-12-10 18:02:12,427:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-10 18:02:12,427:INFO:create_model() successfully completed......................................
2025-12-10 18:02:12,584:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:12,584:INFO:Creating metrics dataframe
2025-12-10 18:02:12,596:INFO:Initializing Light Gradient Boosting Machine
2025-12-10 18:02:12,598:INFO:Total runtime is 0.1875908732414246 minutes
2025-12-10 18:02:12,604:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:12,604:INFO:Initializing create_model()
2025-12-10 18:02:12,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:12,605:INFO:Checking exceptions
2025-12-10 18:02:12,605:INFO:Importing libraries
2025-12-10 18:02:12,605:INFO:Copying training dataset
2025-12-10 18:02:12,617:INFO:Defining folds
2025-12-10 18:02:12,617:INFO:Declaring metric variables
2025-12-10 18:02:12,625:INFO:Importing untrained model
2025-12-10 18:02:12,630:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:02:12,644:INFO:Starting cross validation
2025-12-10 18:02:12,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:14,284:INFO:Calculating mean and std
2025-12-10 18:02:14,287:INFO:Creating metrics dataframe
2025-12-10 18:02:14,291:INFO:Uploading results into container
2025-12-10 18:02:14,293:INFO:Uploading model into container now
2025-12-10 18:02:14,293:INFO:_master_model_container: 13
2025-12-10 18:02:14,295:INFO:_display_container: 2
2025-12-10 18:02:14,296:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:02:14,296:INFO:create_model() successfully completed......................................
2025-12-10 18:02:14,443:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:14,443:INFO:Creating metrics dataframe
2025-12-10 18:02:14,458:INFO:Initializing Dummy Classifier
2025-12-10 18:02:14,458:INFO:Total runtime is 0.21858560244242353 minutes
2025-12-10 18:02:14,462:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:14,464:INFO:Initializing create_model()
2025-12-10 18:02:14,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7724BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:14,464:INFO:Checking exceptions
2025-12-10 18:02:14,464:INFO:Importing libraries
2025-12-10 18:02:14,464:INFO:Copying training dataset
2025-12-10 18:02:14,474:INFO:Defining folds
2025-12-10 18:02:14,474:INFO:Declaring metric variables
2025-12-10 18:02:14,481:INFO:Importing untrained model
2025-12-10 18:02:14,487:INFO:Dummy Classifier Imported successfully
2025-12-10 18:02:14,501:INFO:Starting cross validation
2025-12-10 18:02:14,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:14,614:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,616:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,619:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,623:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,627:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,628:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,637:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,642:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,648:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,653:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:02:14,677:INFO:Calculating mean and std
2025-12-10 18:02:14,679:INFO:Creating metrics dataframe
2025-12-10 18:02:14,681:INFO:Uploading results into container
2025-12-10 18:02:14,682:INFO:Uploading model into container now
2025-12-10 18:02:14,682:INFO:_master_model_container: 14
2025-12-10 18:02:14,682:INFO:_display_container: 2
2025-12-10 18:02:14,684:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-10 18:02:14,684:INFO:create_model() successfully completed......................................
2025-12-10 18:02:14,811:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:14,812:INFO:Creating metrics dataframe
2025-12-10 18:02:14,826:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-10 18:02:14,841:INFO:Initializing create_model()
2025-12-10 18:02:14,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:14,843:INFO:Checking exceptions
2025-12-10 18:02:14,845:INFO:Importing libraries
2025-12-10 18:02:14,845:INFO:Copying training dataset
2025-12-10 18:02:14,854:INFO:Defining folds
2025-12-10 18:02:14,854:INFO:Declaring metric variables
2025-12-10 18:02:14,854:INFO:Importing untrained model
2025-12-10 18:02:14,855:INFO:Declaring custom model
2025-12-10 18:02:14,855:INFO:Logistic Regression Imported successfully
2025-12-10 18:02:14,857:INFO:Cross validation set to False
2025-12-10 18:02:14,857:INFO:Fitting Model
2025-12-10 18:02:16,001:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:02:16,002:INFO:create_model() successfully completed......................................
2025-12-10 18:02:16,215:INFO:_master_model_container: 14
2025-12-10 18:02:16,217:INFO:_display_container: 2
2025-12-10 18:02:16,217:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:02:16,217:INFO:compare_models() successfully completed......................................
2025-12-10 18:02:16,219:INFO:Initializing tune_model()
2025-12-10 18:02:16,220:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>)
2025-12-10 18:02:16,220:INFO:Checking exceptions
2025-12-10 18:02:16,246:INFO:Copying training dataset
2025-12-10 18:02:16,255:INFO:Checking base model
2025-12-10 18:02:16,255:INFO:Base model : Logistic Regression
2025-12-10 18:02:16,264:INFO:Declaring metric variables
2025-12-10 18:02:16,271:INFO:Defining Hyperparameters
2025-12-10 18:02:16,413:INFO:Tuning with n_jobs=-1
2025-12-10 18:02:16,413:INFO:Initializing RandomizedSearchCV
2025-12-10 18:02:21,394:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:02:21,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:02:27,922:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:02:28,499:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:02:28,515:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-10 18:02:28,516:INFO:Hyperparameter search completed
2025-12-10 18:02:28,516:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:28,518:INFO:Initializing create_model()
2025-12-10 18:02:28,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7DB3E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-10 18:02:28,518:INFO:Checking exceptions
2025-12-10 18:02:28,518:INFO:Importing libraries
2025-12-10 18:02:28,518:INFO:Copying training dataset
2025-12-10 18:02:28,530:INFO:Defining folds
2025-12-10 18:02:28,530:INFO:Declaring metric variables
2025-12-10 18:02:28,534:INFO:Importing untrained model
2025-12-10 18:02:28,534:INFO:Declaring custom model
2025-12-10 18:02:28,541:INFO:Logistic Regression Imported successfully
2025-12-10 18:02:28,551:INFO:Starting cross validation
2025-12-10 18:02:28,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:30,035:INFO:Calculating mean and std
2025-12-10 18:02:30,037:INFO:Creating metrics dataframe
2025-12-10 18:02:30,045:INFO:Finalizing model
2025-12-10 18:02:31,499:INFO:Uploading results into container
2025-12-10 18:02:31,499:INFO:Uploading model into container now
2025-12-10 18:02:31,501:INFO:_master_model_container: 15
2025-12-10 18:02:31,501:INFO:_display_container: 3
2025-12-10 18:02:31,502:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:02:31,502:INFO:create_model() successfully completed......................................
2025-12-10 18:02:31,633:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:31,633:INFO:choose_better activated
2025-12-10 18:02:31,637:INFO:SubProcess create_model() called ==================================
2025-12-10 18:02:31,638:INFO:Initializing create_model()
2025-12-10 18:02:31,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6C7951450>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:02:31,639:INFO:Checking exceptions
2025-12-10 18:02:31,642:INFO:Importing libraries
2025-12-10 18:02:31,642:INFO:Copying training dataset
2025-12-10 18:02:31,649:INFO:Defining folds
2025-12-10 18:02:31,651:INFO:Declaring metric variables
2025-12-10 18:02:31,651:INFO:Importing untrained model
2025-12-10 18:02:31,651:INFO:Declaring custom model
2025-12-10 18:02:31,652:INFO:Logistic Regression Imported successfully
2025-12-10 18:02:31,653:INFO:Starting cross validation
2025-12-10 18:02:31,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:02:32,951:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:02:32,973:INFO:Calculating mean and std
2025-12-10 18:02:32,974:INFO:Creating metrics dataframe
2025-12-10 18:02:32,975:INFO:Finalizing model
2025-12-10 18:02:34,109:INFO:Uploading results into container
2025-12-10 18:02:34,109:INFO:Uploading model into container now
2025-12-10 18:02:34,109:INFO:_master_model_container: 16
2025-12-10 18:02:34,109:INFO:_display_container: 4
2025-12-10 18:02:34,111:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:02:34,111:INFO:create_model() successfully completed......................................
2025-12-10 18:02:34,234:INFO:SubProcess create_model() end ==================================
2025-12-10 18:02:34,236:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-10 18:02:34,237:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8079
2025-12-10 18:02:34,237:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-10 18:02:34,237:INFO:choose_better completed
2025-12-10 18:02:34,237:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-10 18:02:34,252:INFO:_master_model_container: 16
2025-12-10 18:02:34,253:INFO:_display_container: 3
2025-12-10 18:02:34,253:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:02:34,253:INFO:tune_model() successfully completed......................................
2025-12-10 18:50:45,842:INFO:PyCaret RegressionExperiment
2025-12-10 18:50:45,842:INFO:Logging name: reg-default-name
2025-12-10 18:50:45,842:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-10 18:50:45,842:INFO:version 3.3.2
2025-12-10 18:50:45,842:INFO:Initializing setup()
2025-12-10 18:50:45,842:INFO:self.USI: ed6e
2025-12-10 18:50:45,842:INFO:self._variable_keys: {'X', 'USI', 'log_plots_param', 'exp_id', 'html_param', 'y_test', 'y_train', '_ml_usecase', 'X_train', 'n_jobs_param', 'pipeline', 'memory', '_available_plots', 'gpu_param', 'X_test', 'idx', 'seed', 'logging_param', 'exp_name_log', 'data', 'y', 'transform_target_param', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-12-10 18:50:45,842:INFO:Checking environment
2025-12-10 18:50:45,842:INFO:python_version: 3.10.19
2025-12-10 18:50:45,843:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-10 18:50:45,843:INFO:machine: AMD64
2025-12-10 18:50:45,843:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-10 18:50:45,843:INFO:Memory: svmem(total=33699516416, available=18075762688, percent=46.4, used=15623753728, free=18075762688)
2025-12-10 18:50:45,843:INFO:Physical Core: 8
2025-12-10 18:50:45,843:INFO:Logical Core: 16
2025-12-10 18:50:45,843:INFO:Checking libraries
2025-12-10 18:50:45,843:INFO:System:
2025-12-10 18:50:45,843:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-10 18:50:45,843:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-10 18:50:45,843:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-10 18:50:45,843:INFO:PyCaret required dependencies:
2025-12-10 18:50:45,843:INFO:                 pip: 25.3
2025-12-10 18:50:45,843:INFO:          setuptools: 80.9.0
2025-12-10 18:50:45,843:INFO:             pycaret: 3.3.2
2025-12-10 18:50:45,843:INFO:             IPython: 8.37.0
2025-12-10 18:50:45,843:INFO:          ipywidgets: 8.1.8
2025-12-10 18:50:45,843:INFO:                tqdm: 4.67.1
2025-12-10 18:50:45,843:INFO:               numpy: 1.26.4
2025-12-10 18:50:45,843:INFO:              pandas: 2.1.4
2025-12-10 18:50:45,843:INFO:              jinja2: 3.1.6
2025-12-10 18:50:45,843:INFO:               scipy: 1.11.4
2025-12-10 18:50:45,843:INFO:              joblib: 1.3.2
2025-12-10 18:50:45,843:INFO:             sklearn: 1.4.2
2025-12-10 18:50:45,844:INFO:                pyod: 2.0.6
2025-12-10 18:50:45,844:INFO:            imblearn: 0.14.0
2025-12-10 18:50:45,844:INFO:   category_encoders: 2.7.0
2025-12-10 18:50:45,844:INFO:            lightgbm: 4.6.0
2025-12-10 18:50:45,844:INFO:               numba: 0.62.1
2025-12-10 18:50:45,844:INFO:            requests: 2.32.5
2025-12-10 18:50:45,844:INFO:          matplotlib: 3.7.5
2025-12-10 18:50:45,844:INFO:          scikitplot: 0.3.7
2025-12-10 18:50:45,844:INFO:         yellowbrick: 1.5
2025-12-10 18:50:45,844:INFO:              plotly: 6.5.0
2025-12-10 18:50:45,844:INFO:    plotly-resampler: Not installed
2025-12-10 18:50:45,844:INFO:             kaleido: 1.2.0
2025-12-10 18:50:45,844:INFO:           schemdraw: 0.15
2025-12-10 18:50:45,844:INFO:         statsmodels: 0.14.5
2025-12-10 18:50:45,844:INFO:              sktime: 0.26.0
2025-12-10 18:50:45,844:INFO:               tbats: 1.1.3
2025-12-10 18:50:45,844:INFO:            pmdarima: 2.0.4
2025-12-10 18:50:45,844:INFO:              psutil: 7.1.3
2025-12-10 18:50:45,844:INFO:          markupsafe: 3.0.3
2025-12-10 18:50:45,844:INFO:             pickle5: Not installed
2025-12-10 18:50:45,844:INFO:         cloudpickle: 3.1.2
2025-12-10 18:50:45,844:INFO:         deprecation: 2.1.0
2025-12-10 18:50:45,844:INFO:              xxhash: 3.6.0
2025-12-10 18:50:45,844:INFO:           wurlitzer: Not installed
2025-12-10 18:50:45,844:INFO:PyCaret optional dependencies:
2025-12-10 18:50:45,844:INFO:                shap: Not installed
2025-12-10 18:50:45,844:INFO:           interpret: Not installed
2025-12-10 18:50:45,844:INFO:                umap: Not installed
2025-12-10 18:50:45,844:INFO:     ydata_profiling: Not installed
2025-12-10 18:50:45,844:INFO:  explainerdashboard: Not installed
2025-12-10 18:50:45,844:INFO:             autoviz: Not installed
2025-12-10 18:50:45,844:INFO:           fairlearn: Not installed
2025-12-10 18:50:45,844:INFO:          deepchecks: Not installed
2025-12-10 18:50:45,844:INFO:             xgboost: Not installed
2025-12-10 18:50:45,844:INFO:            catboost: Not installed
2025-12-10 18:50:45,846:INFO:              kmodes: Not installed
2025-12-10 18:50:45,846:INFO:             mlxtend: Not installed
2025-12-10 18:50:45,846:INFO:       statsforecast: Not installed
2025-12-10 18:50:45,846:INFO:        tune_sklearn: Not installed
2025-12-10 18:50:45,846:INFO:                 ray: Not installed
2025-12-10 18:50:45,846:INFO:            hyperopt: Not installed
2025-12-10 18:50:45,846:INFO:              optuna: Not installed
2025-12-10 18:50:45,846:INFO:               skopt: Not installed
2025-12-10 18:50:45,847:INFO:              mlflow: Not installed
2025-12-10 18:50:45,847:INFO:              gradio: Not installed
2025-12-10 18:50:45,847:INFO:             fastapi: Not installed
2025-12-10 18:50:45,847:INFO:             uvicorn: Not installed
2025-12-10 18:50:45,847:INFO:              m2cgen: Not installed
2025-12-10 18:50:45,847:INFO:           evidently: Not installed
2025-12-10 18:50:45,847:INFO:               fugue: Not installed
2025-12-10 18:50:45,847:INFO:           streamlit: Not installed
2025-12-10 18:50:45,847:INFO:             prophet: Not installed
2025-12-10 18:50:45,847:INFO:None
2025-12-10 18:50:45,847:INFO:Set up data.
2025-12-10 18:50:45,858:INFO:Set up folding strategy.
2025-12-10 18:50:45,858:INFO:Set up train/test split.
2025-12-10 18:50:45,864:INFO:Set up index.
2025-12-10 18:50:45,865:INFO:Assigning column types.
2025-12-10 18:50:45,873:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-10 18:50:45,873:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-10 18:50:45,878:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:50:45,883:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:50:45,947:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:45,994:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:50:45,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:45,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:45,996:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,074:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,122:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,123:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-10 18:50:46,128:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,135:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,256:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,261:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,326:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,375:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-10 18:50:46,386:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,503:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,514:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,625:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,626:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-10 18:50:46,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,898:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:50:46,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:46,899:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-10 18:50:46,972:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:47,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:47,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:47,098:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:50:47,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:47,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:47,147:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-10 18:50:47,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:47,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:47,397:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:47,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:50:47,400:INFO:Preparing preprocessing pipeline...
2025-12-10 18:50:47,400:INFO:Set up target transformation.
2025-12-10 18:50:47,400:INFO:Set up simple imputation.
2025-12-10 18:50:47,400:INFO:Set up feature normalization.
2025-12-10 18:50:47,401:INFO:Set up column name cleaning.
2025-12-10 18:50:47,468:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\preprocessing\_data.py:3408: RuntimeWarning: overflow encountered in power
  out[pos] = (np.power(x[pos] + 1, lmbda) - 1) / lmbda

2025-12-10 18:52:37,374:INFO:PyCaret RegressionExperiment
2025-12-10 18:52:37,374:INFO:Logging name: reg-default-name
2025-12-10 18:52:37,374:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-10 18:52:37,374:INFO:version 3.3.2
2025-12-10 18:52:37,374:INFO:Initializing setup()
2025-12-10 18:52:37,374:INFO:self.USI: 3968
2025-12-10 18:52:37,374:INFO:self._variable_keys: {'X', 'USI', 'log_plots_param', 'exp_id', 'html_param', 'y_test', 'y_train', '_ml_usecase', 'X_train', 'n_jobs_param', 'pipeline', 'memory', '_available_plots', 'gpu_param', 'X_test', 'idx', 'seed', 'logging_param', 'exp_name_log', 'data', 'y', 'transform_target_param', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-12-10 18:52:37,374:INFO:Checking environment
2025-12-10 18:52:37,374:INFO:python_version: 3.10.19
2025-12-10 18:52:37,374:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-10 18:52:37,374:INFO:machine: AMD64
2025-12-10 18:52:37,374:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-10 18:52:37,375:INFO:Memory: svmem(total=33699516416, available=17900974080, percent=46.9, used=15798542336, free=17900974080)
2025-12-10 18:52:37,375:INFO:Physical Core: 8
2025-12-10 18:52:37,375:INFO:Logical Core: 16
2025-12-10 18:52:37,375:INFO:Checking libraries
2025-12-10 18:52:37,376:INFO:System:
2025-12-10 18:52:37,376:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-10 18:52:37,376:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-10 18:52:37,376:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-10 18:52:37,376:INFO:PyCaret required dependencies:
2025-12-10 18:52:37,376:INFO:                 pip: 25.3
2025-12-10 18:52:37,376:INFO:          setuptools: 80.9.0
2025-12-10 18:52:37,376:INFO:             pycaret: 3.3.2
2025-12-10 18:52:37,376:INFO:             IPython: 8.37.0
2025-12-10 18:52:37,376:INFO:          ipywidgets: 8.1.8
2025-12-10 18:52:37,376:INFO:                tqdm: 4.67.1
2025-12-10 18:52:37,376:INFO:               numpy: 1.26.4
2025-12-10 18:52:37,376:INFO:              pandas: 2.1.4
2025-12-10 18:52:37,376:INFO:              jinja2: 3.1.6
2025-12-10 18:52:37,376:INFO:               scipy: 1.11.4
2025-12-10 18:52:37,376:INFO:              joblib: 1.3.2
2025-12-10 18:52:37,376:INFO:             sklearn: 1.4.2
2025-12-10 18:52:37,376:INFO:                pyod: 2.0.6
2025-12-10 18:52:37,376:INFO:            imblearn: 0.14.0
2025-12-10 18:52:37,376:INFO:   category_encoders: 2.7.0
2025-12-10 18:52:37,376:INFO:            lightgbm: 4.6.0
2025-12-10 18:52:37,376:INFO:               numba: 0.62.1
2025-12-10 18:52:37,377:INFO:            requests: 2.32.5
2025-12-10 18:52:37,377:INFO:          matplotlib: 3.7.5
2025-12-10 18:52:37,377:INFO:          scikitplot: 0.3.7
2025-12-10 18:52:37,377:INFO:         yellowbrick: 1.5
2025-12-10 18:52:37,377:INFO:              plotly: 6.5.0
2025-12-10 18:52:37,377:INFO:    plotly-resampler: Not installed
2025-12-10 18:52:37,377:INFO:             kaleido: 1.2.0
2025-12-10 18:52:37,377:INFO:           schemdraw: 0.15
2025-12-10 18:52:37,377:INFO:         statsmodels: 0.14.5
2025-12-10 18:52:37,377:INFO:              sktime: 0.26.0
2025-12-10 18:52:37,377:INFO:               tbats: 1.1.3
2025-12-10 18:52:37,377:INFO:            pmdarima: 2.0.4
2025-12-10 18:52:37,377:INFO:              psutil: 7.1.3
2025-12-10 18:52:37,377:INFO:          markupsafe: 3.0.3
2025-12-10 18:52:37,377:INFO:             pickle5: Not installed
2025-12-10 18:52:37,377:INFO:         cloudpickle: 3.1.2
2025-12-10 18:52:37,377:INFO:         deprecation: 2.1.0
2025-12-10 18:52:37,377:INFO:              xxhash: 3.6.0
2025-12-10 18:52:37,377:INFO:           wurlitzer: Not installed
2025-12-10 18:52:37,377:INFO:PyCaret optional dependencies:
2025-12-10 18:52:37,377:INFO:                shap: Not installed
2025-12-10 18:52:37,377:INFO:           interpret: Not installed
2025-12-10 18:52:37,377:INFO:                umap: Not installed
2025-12-10 18:52:37,377:INFO:     ydata_profiling: Not installed
2025-12-10 18:52:37,377:INFO:  explainerdashboard: Not installed
2025-12-10 18:52:37,377:INFO:             autoviz: Not installed
2025-12-10 18:52:37,377:INFO:           fairlearn: Not installed
2025-12-10 18:52:37,377:INFO:          deepchecks: Not installed
2025-12-10 18:52:37,377:INFO:             xgboost: Not installed
2025-12-10 18:52:37,377:INFO:            catboost: Not installed
2025-12-10 18:52:37,377:INFO:              kmodes: Not installed
2025-12-10 18:52:37,377:INFO:             mlxtend: Not installed
2025-12-10 18:52:37,377:INFO:       statsforecast: Not installed
2025-12-10 18:52:37,377:INFO:        tune_sklearn: Not installed
2025-12-10 18:52:37,378:INFO:                 ray: Not installed
2025-12-10 18:52:37,378:INFO:            hyperopt: Not installed
2025-12-10 18:52:37,378:INFO:              optuna: Not installed
2025-12-10 18:52:37,378:INFO:               skopt: Not installed
2025-12-10 18:52:37,378:INFO:              mlflow: Not installed
2025-12-10 18:52:37,378:INFO:              gradio: Not installed
2025-12-10 18:52:37,378:INFO:             fastapi: Not installed
2025-12-10 18:52:37,378:INFO:             uvicorn: Not installed
2025-12-10 18:52:37,378:INFO:              m2cgen: Not installed
2025-12-10 18:52:37,378:INFO:           evidently: Not installed
2025-12-10 18:52:37,378:INFO:               fugue: Not installed
2025-12-10 18:52:37,378:INFO:           streamlit: Not installed
2025-12-10 18:52:37,378:INFO:             prophet: Not installed
2025-12-10 18:52:37,378:INFO:None
2025-12-10 18:52:37,378:INFO:Set up data.
2025-12-10 18:52:37,390:INFO:Set up folding strategy.
2025-12-10 18:52:37,390:INFO:Set up train/test split.
2025-12-10 18:52:37,396:INFO:Set up index.
2025-12-10 18:52:37,397:INFO:Assigning column types.
2025-12-10 18:52:37,404:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-10 18:52:37,404:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,415:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,481:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:37,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:37,531:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,536:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,541:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:37,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:37,657:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-10 18:52:37,662:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,734:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,782:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:37,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:37,788:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,792:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:37,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:37,905:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-10 18:52:37,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:52:37,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,151:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,152:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-10 18:52:38,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,275:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,398:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-10 18:52:38,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,603:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-10 18:52:38,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,652:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-10 18:52:38,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:38,911:INFO:Preparing preprocessing pipeline...
2025-12-10 18:52:38,911:INFO:Set up simple imputation.
2025-12-10 18:52:38,911:INFO:Set up feature normalization.
2025-12-10 18:52:38,913:INFO:Set up column name cleaning.
2025-12-10 18:52:38,960:INFO:Finished creating preprocessing pipeline.
2025-12-10 18:52:38,967:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-10 18:52:38,967:INFO:Creating final display dataframe.
2025-12-10 18:52:39,110:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 18)
4        Transformed data shape        (7906, 16)
5   Transformed train set shape        (5534, 16)
6    Transformed test set shape        (2372, 16)
7               Ignore features                 2
8              Numeric features                15
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              3968
2025-12-10 18:52:39,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:39,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:39,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:39,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:52:39,353:INFO:setup() successfully completed in 1.98s...............
2025-12-10 18:52:39,354:INFO:Initializing compare_models()
2025-12-10 18:52:39,354:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-10 18:52:39,354:INFO:Checking exceptions
2025-12-10 18:52:39,357:INFO:Preparing display monitor
2025-12-10 18:52:39,387:INFO:Initializing Linear Regression
2025-12-10 18:52:39,388:INFO:Total runtime is 8.503595987955729e-06 minutes
2025-12-10 18:52:39,393:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:39,393:INFO:Initializing create_model()
2025-12-10 18:52:39,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:39,394:INFO:Checking exceptions
2025-12-10 18:52:39,394:INFO:Importing libraries
2025-12-10 18:52:39,394:INFO:Copying training dataset
2025-12-10 18:52:39,404:INFO:Defining folds
2025-12-10 18:52:39,404:INFO:Declaring metric variables
2025-12-10 18:52:39,409:INFO:Importing untrained model
2025-12-10 18:52:39,415:INFO:Linear Regression Imported successfully
2025-12-10 18:52:39,427:INFO:Starting cross validation
2025-12-10 18:52:39,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:45,565:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,568:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,568:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,573:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,575:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,576:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,578:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,579:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,581:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:45,600:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:46,025:INFO:Calculating mean and std
2025-12-10 18:52:46,027:INFO:Creating metrics dataframe
2025-12-10 18:52:46,032:INFO:Uploading results into container
2025-12-10 18:52:46,034:INFO:Uploading model into container now
2025-12-10 18:52:46,035:INFO:_master_model_container: 1
2025-12-10 18:52:46,035:INFO:_display_container: 2
2025-12-10 18:52:46,036:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-12-10 18:52:46,036:INFO:create_model() successfully completed......................................
2025-12-10 18:52:46,309:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:46,310:INFO:Creating metrics dataframe
2025-12-10 18:52:46,320:INFO:Initializing Lasso Regression
2025-12-10 18:52:46,320:INFO:Total runtime is 0.11553506056467693 minutes
2025-12-10 18:52:46,324:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:46,325:INFO:Initializing create_model()
2025-12-10 18:52:46,325:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:46,326:INFO:Checking exceptions
2025-12-10 18:52:46,326:INFO:Importing libraries
2025-12-10 18:52:46,326:INFO:Copying training dataset
2025-12-10 18:52:46,336:INFO:Defining folds
2025-12-10 18:52:46,336:INFO:Declaring metric variables
2025-12-10 18:52:46,342:INFO:Importing untrained model
2025-12-10 18:52:46,347:INFO:Lasso Regression Imported successfully
2025-12-10 18:52:46,358:INFO:Starting cross validation
2025-12-10 18:52:46,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:46,520:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.296e+11, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-10 18:52:46,527:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e+11, tolerance: 3.109e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-10 18:52:50,778:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:50,791:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:50,794:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:50,796:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:50,808:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:50,834:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 18:52:51,109:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.119e+11, tolerance: 3.154e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-10 18:52:51,160:INFO:Calculating mean and std
2025-12-10 18:52:51,161:INFO:Creating metrics dataframe
2025-12-10 18:52:51,166:INFO:Uploading results into container
2025-12-10 18:52:51,168:INFO:Uploading model into container now
2025-12-10 18:52:51,170:INFO:_master_model_container: 2
2025-12-10 18:52:51,170:INFO:_display_container: 2
2025-12-10 18:52:51,171:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-12-10 18:52:51,171:INFO:create_model() successfully completed......................................
2025-12-10 18:52:51,342:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:51,342:INFO:Creating metrics dataframe
2025-12-10 18:52:51,349:INFO:Initializing Ridge Regression
2025-12-10 18:52:51,349:INFO:Total runtime is 0.1993679165840149 minutes
2025-12-10 18:52:51,353:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:51,353:INFO:Initializing create_model()
2025-12-10 18:52:51,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:51,354:INFO:Checking exceptions
2025-12-10 18:52:51,354:INFO:Importing libraries
2025-12-10 18:52:51,354:INFO:Copying training dataset
2025-12-10 18:52:51,364:INFO:Defining folds
2025-12-10 18:52:51,364:INFO:Declaring metric variables
2025-12-10 18:52:51,371:INFO:Importing untrained model
2025-12-10 18:52:51,377:INFO:Ridge Regression Imported successfully
2025-12-10 18:52:51,389:INFO:Starting cross validation
2025-12-10 18:52:51,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:51,517:INFO:Calculating mean and std
2025-12-10 18:52:51,518:INFO:Creating metrics dataframe
2025-12-10 18:52:51,521:INFO:Uploading results into container
2025-12-10 18:52:51,523:INFO:Uploading model into container now
2025-12-10 18:52:51,523:INFO:_master_model_container: 3
2025-12-10 18:52:51,523:INFO:_display_container: 2
2025-12-10 18:52:51,524:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-12-10 18:52:51,524:INFO:create_model() successfully completed......................................
2025-12-10 18:52:51,678:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:51,678:INFO:Creating metrics dataframe
2025-12-10 18:52:51,688:INFO:Initializing Elastic Net
2025-12-10 18:52:51,688:INFO:Total runtime is 0.20501715739568074 minutes
2025-12-10 18:52:51,692:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:51,692:INFO:Initializing create_model()
2025-12-10 18:52:51,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:51,692:INFO:Checking exceptions
2025-12-10 18:52:51,692:INFO:Importing libraries
2025-12-10 18:52:51,692:INFO:Copying training dataset
2025-12-10 18:52:51,704:INFO:Defining folds
2025-12-10 18:52:51,704:INFO:Declaring metric variables
2025-12-10 18:52:51,709:INFO:Importing untrained model
2025-12-10 18:52:51,714:INFO:Elastic Net Imported successfully
2025-12-10 18:52:51,724:INFO:Starting cross validation
2025-12-10 18:52:51,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:51,853:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e+12, tolerance: 3.109e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-10 18:52:51,867:INFO:Calculating mean and std
2025-12-10 18:52:51,869:INFO:Creating metrics dataframe
2025-12-10 18:52:51,872:INFO:Uploading results into container
2025-12-10 18:52:51,873:INFO:Uploading model into container now
2025-12-10 18:52:51,874:INFO:_master_model_container: 4
2025-12-10 18:52:51,874:INFO:_display_container: 2
2025-12-10 18:52:51,875:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-12-10 18:52:51,875:INFO:create_model() successfully completed......................................
2025-12-10 18:52:52,030:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:52,030:INFO:Creating metrics dataframe
2025-12-10 18:52:52,041:INFO:Initializing Least Angle Regression
2025-12-10 18:52:52,041:INFO:Total runtime is 0.21088502009709675 minutes
2025-12-10 18:52:52,045:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:52,047:INFO:Initializing create_model()
2025-12-10 18:52:52,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:52,047:INFO:Checking exceptions
2025-12-10 18:52:52,047:INFO:Importing libraries
2025-12-10 18:52:52,047:INFO:Copying training dataset
2025-12-10 18:52:52,058:INFO:Defining folds
2025-12-10 18:52:52,058:INFO:Declaring metric variables
2025-12-10 18:52:52,061:INFO:Importing untrained model
2025-12-10 18:52:52,070:INFO:Least Angle Regression Imported successfully
2025-12-10 18:52:52,077:INFO:Starting cross validation
2025-12-10 18:52:52,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:52,195:INFO:Calculating mean and std
2025-12-10 18:52:52,197:INFO:Creating metrics dataframe
2025-12-10 18:52:52,199:INFO:Uploading results into container
2025-12-10 18:52:52,201:INFO:Uploading model into container now
2025-12-10 18:52:52,201:INFO:_master_model_container: 5
2025-12-10 18:52:52,202:INFO:_display_container: 2
2025-12-10 18:52:52,202:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-12-10 18:52:52,202:INFO:create_model() successfully completed......................................
2025-12-10 18:52:52,358:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:52,358:INFO:Creating metrics dataframe
2025-12-10 18:52:52,367:INFO:Initializing Lasso Least Angle Regression
2025-12-10 18:52:52,367:INFO:Total runtime is 0.21632450421651203 minutes
2025-12-10 18:52:52,372:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:52,373:INFO:Initializing create_model()
2025-12-10 18:52:52,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:52,373:INFO:Checking exceptions
2025-12-10 18:52:52,373:INFO:Importing libraries
2025-12-10 18:52:52,373:INFO:Copying training dataset
2025-12-10 18:52:52,383:INFO:Defining folds
2025-12-10 18:52:52,383:INFO:Declaring metric variables
2025-12-10 18:52:52,389:INFO:Importing untrained model
2025-12-10 18:52:52,394:INFO:Lasso Least Angle Regression Imported successfully
2025-12-10 18:52:52,407:INFO:Starting cross validation
2025-12-10 18:52:52,407:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:52,528:INFO:Calculating mean and std
2025-12-10 18:52:52,529:INFO:Creating metrics dataframe
2025-12-10 18:52:52,533:INFO:Uploading results into container
2025-12-10 18:52:52,535:INFO:Uploading model into container now
2025-12-10 18:52:52,535:INFO:_master_model_container: 6
2025-12-10 18:52:52,535:INFO:_display_container: 2
2025-12-10 18:52:52,535:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-12-10 18:52:52,537:INFO:create_model() successfully completed......................................
2025-12-10 18:52:52,693:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:52,693:INFO:Creating metrics dataframe
2025-12-10 18:52:52,703:INFO:Initializing Orthogonal Matching Pursuit
2025-12-10 18:52:52,703:INFO:Total runtime is 0.22191946109135943 minutes
2025-12-10 18:52:52,709:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:52,709:INFO:Initializing create_model()
2025-12-10 18:52:52,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:52,709:INFO:Checking exceptions
2025-12-10 18:52:52,709:INFO:Importing libraries
2025-12-10 18:52:52,709:INFO:Copying training dataset
2025-12-10 18:52:52,718:INFO:Defining folds
2025-12-10 18:52:52,720:INFO:Declaring metric variables
2025-12-10 18:52:52,727:INFO:Importing untrained model
2025-12-10 18:52:52,737:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-10 18:52:52,752:INFO:Starting cross validation
2025-12-10 18:52:52,755:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:52,891:INFO:Calculating mean and std
2025-12-10 18:52:52,893:INFO:Creating metrics dataframe
2025-12-10 18:52:52,895:INFO:Uploading results into container
2025-12-10 18:52:52,896:INFO:Uploading model into container now
2025-12-10 18:52:52,897:INFO:_master_model_container: 7
2025-12-10 18:52:52,898:INFO:_display_container: 2
2025-12-10 18:52:52,898:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-12-10 18:52:52,898:INFO:create_model() successfully completed......................................
2025-12-10 18:52:53,057:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:53,057:INFO:Creating metrics dataframe
2025-12-10 18:52:53,068:INFO:Initializing Bayesian Ridge
2025-12-10 18:52:53,068:INFO:Total runtime is 0.22800241708755492 minutes
2025-12-10 18:52:53,074:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:53,075:INFO:Initializing create_model()
2025-12-10 18:52:53,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:53,075:INFO:Checking exceptions
2025-12-10 18:52:53,075:INFO:Importing libraries
2025-12-10 18:52:53,075:INFO:Copying training dataset
2025-12-10 18:52:53,085:INFO:Defining folds
2025-12-10 18:52:53,085:INFO:Declaring metric variables
2025-12-10 18:52:53,091:INFO:Importing untrained model
2025-12-10 18:52:53,097:INFO:Bayesian Ridge Imported successfully
2025-12-10 18:52:53,110:INFO:Starting cross validation
2025-12-10 18:52:53,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:53,244:INFO:Calculating mean and std
2025-12-10 18:52:53,245:INFO:Creating metrics dataframe
2025-12-10 18:52:53,249:INFO:Uploading results into container
2025-12-10 18:52:53,249:INFO:Uploading model into container now
2025-12-10 18:52:53,250:INFO:_master_model_container: 8
2025-12-10 18:52:53,250:INFO:_display_container: 2
2025-12-10 18:52:53,250:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-12-10 18:52:53,251:INFO:create_model() successfully completed......................................
2025-12-10 18:52:53,407:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:53,407:INFO:Creating metrics dataframe
2025-12-10 18:52:53,417:INFO:Initializing Passive Aggressive Regressor
2025-12-10 18:52:53,418:INFO:Total runtime is 0.23384480079015094 minutes
2025-12-10 18:52:53,421:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:53,422:INFO:Initializing create_model()
2025-12-10 18:52:53,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:53,423:INFO:Checking exceptions
2025-12-10 18:52:53,423:INFO:Importing libraries
2025-12-10 18:52:53,423:INFO:Copying training dataset
2025-12-10 18:52:53,432:INFO:Defining folds
2025-12-10 18:52:53,432:INFO:Declaring metric variables
2025-12-10 18:52:53,439:INFO:Importing untrained model
2025-12-10 18:52:53,444:INFO:Passive Aggressive Regressor Imported successfully
2025-12-10 18:52:53,454:INFO:Starting cross validation
2025-12-10 18:52:53,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:54,047:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:52:54,056:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:52:54,061:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:52:54,062:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:52:54,094:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:52:54,099:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:52:54,117:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:52:54,126:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-10 18:52:54,147:INFO:Calculating mean and std
2025-12-10 18:52:54,148:INFO:Creating metrics dataframe
2025-12-10 18:52:54,149:INFO:Uploading results into container
2025-12-10 18:52:54,151:INFO:Uploading model into container now
2025-12-10 18:52:54,152:INFO:_master_model_container: 9
2025-12-10 18:52:54,152:INFO:_display_container: 2
2025-12-10 18:52:54,153:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-10 18:52:54,153:INFO:create_model() successfully completed......................................
2025-12-10 18:52:54,305:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:54,305:INFO:Creating metrics dataframe
2025-12-10 18:52:54,317:INFO:Initializing Huber Regressor
2025-12-10 18:52:54,317:INFO:Total runtime is 0.24882208903630573 minutes
2025-12-10 18:52:54,323:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:54,323:INFO:Initializing create_model()
2025-12-10 18:52:54,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:54,323:INFO:Checking exceptions
2025-12-10 18:52:54,323:INFO:Importing libraries
2025-12-10 18:52:54,323:INFO:Copying training dataset
2025-12-10 18:52:54,333:INFO:Defining folds
2025-12-10 18:52:54,333:INFO:Declaring metric variables
2025-12-10 18:52:54,338:INFO:Importing untrained model
2025-12-10 18:52:54,343:INFO:Huber Regressor Imported successfully
2025-12-10 18:52:54,353:INFO:Starting cross validation
2025-12-10 18:52:54,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:54,564:INFO:Calculating mean and std
2025-12-10 18:52:54,566:INFO:Creating metrics dataframe
2025-12-10 18:52:54,569:INFO:Uploading results into container
2025-12-10 18:52:54,570:INFO:Uploading model into container now
2025-12-10 18:52:54,570:INFO:_master_model_container: 10
2025-12-10 18:52:54,571:INFO:_display_container: 2
2025-12-10 18:52:54,571:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-12-10 18:52:54,571:INFO:create_model() successfully completed......................................
2025-12-10 18:52:54,735:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:54,735:INFO:Creating metrics dataframe
2025-12-10 18:52:54,747:INFO:Initializing K Neighbors Regressor
2025-12-10 18:52:54,748:INFO:Total runtime is 0.256013290087382 minutes
2025-12-10 18:52:54,755:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:54,755:INFO:Initializing create_model()
2025-12-10 18:52:54,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:54,757:INFO:Checking exceptions
2025-12-10 18:52:54,757:INFO:Importing libraries
2025-12-10 18:52:54,757:INFO:Copying training dataset
2025-12-10 18:52:54,771:INFO:Defining folds
2025-12-10 18:52:54,772:INFO:Declaring metric variables
2025-12-10 18:52:54,776:INFO:Importing untrained model
2025-12-10 18:52:54,783:INFO:K Neighbors Regressor Imported successfully
2025-12-10 18:52:54,793:INFO:Starting cross validation
2025-12-10 18:52:54,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:55,098:INFO:Calculating mean and std
2025-12-10 18:52:55,101:INFO:Creating metrics dataframe
2025-12-10 18:52:55,103:INFO:Uploading results into container
2025-12-10 18:52:55,104:INFO:Uploading model into container now
2025-12-10 18:52:55,106:INFO:_master_model_container: 11
2025-12-10 18:52:55,106:INFO:_display_container: 2
2025-12-10 18:52:55,106:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-12-10 18:52:55,107:INFO:create_model() successfully completed......................................
2025-12-10 18:52:55,284:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:55,284:INFO:Creating metrics dataframe
2025-12-10 18:52:55,295:INFO:Initializing Decision Tree Regressor
2025-12-10 18:52:55,295:INFO:Total runtime is 0.2651306509971619 minutes
2025-12-10 18:52:55,302:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:55,303:INFO:Initializing create_model()
2025-12-10 18:52:55,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:55,303:INFO:Checking exceptions
2025-12-10 18:52:55,303:INFO:Importing libraries
2025-12-10 18:52:55,303:INFO:Copying training dataset
2025-12-10 18:52:55,315:INFO:Defining folds
2025-12-10 18:52:55,317:INFO:Declaring metric variables
2025-12-10 18:52:55,327:INFO:Importing untrained model
2025-12-10 18:52:55,337:INFO:Decision Tree Regressor Imported successfully
2025-12-10 18:52:55,354:INFO:Starting cross validation
2025-12-10 18:52:55,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:55,513:INFO:Calculating mean and std
2025-12-10 18:52:55,515:INFO:Creating metrics dataframe
2025-12-10 18:52:55,517:INFO:Uploading results into container
2025-12-10 18:52:55,518:INFO:Uploading model into container now
2025-12-10 18:52:55,518:INFO:_master_model_container: 12
2025-12-10 18:52:55,518:INFO:_display_container: 2
2025-12-10 18:52:55,520:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-12-10 18:52:55,520:INFO:create_model() successfully completed......................................
2025-12-10 18:52:55,677:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:55,678:INFO:Creating metrics dataframe
2025-12-10 18:52:55,690:INFO:Initializing Random Forest Regressor
2025-12-10 18:52:55,690:INFO:Total runtime is 0.2717127323150635 minutes
2025-12-10 18:52:55,695:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:55,696:INFO:Initializing create_model()
2025-12-10 18:52:55,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:55,696:INFO:Checking exceptions
2025-12-10 18:52:55,697:INFO:Importing libraries
2025-12-10 18:52:55,697:INFO:Copying training dataset
2025-12-10 18:52:55,706:INFO:Defining folds
2025-12-10 18:52:55,707:INFO:Declaring metric variables
2025-12-10 18:52:55,714:INFO:Importing untrained model
2025-12-10 18:52:55,720:INFO:Random Forest Regressor Imported successfully
2025-12-10 18:52:55,730:INFO:Starting cross validation
2025-12-10 18:52:55,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:57,753:INFO:Calculating mean and std
2025-12-10 18:52:57,754:INFO:Creating metrics dataframe
2025-12-10 18:52:57,757:INFO:Uploading results into container
2025-12-10 18:52:57,758:INFO:Uploading model into container now
2025-12-10 18:52:57,758:INFO:_master_model_container: 13
2025-12-10 18:52:57,759:INFO:_display_container: 2
2025-12-10 18:52:57,760:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-12-10 18:52:57,760:INFO:create_model() successfully completed......................................
2025-12-10 18:52:57,914:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:57,914:INFO:Creating metrics dataframe
2025-12-10 18:52:57,925:INFO:Initializing Extra Trees Regressor
2025-12-10 18:52:57,927:INFO:Total runtime is 0.30899155934651695 minutes
2025-12-10 18:52:57,932:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:57,932:INFO:Initializing create_model()
2025-12-10 18:52:57,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:57,933:INFO:Checking exceptions
2025-12-10 18:52:57,933:INFO:Importing libraries
2025-12-10 18:52:57,934:INFO:Copying training dataset
2025-12-10 18:52:57,942:INFO:Defining folds
2025-12-10 18:52:57,943:INFO:Declaring metric variables
2025-12-10 18:52:57,948:INFO:Importing untrained model
2025-12-10 18:52:57,955:INFO:Extra Trees Regressor Imported successfully
2025-12-10 18:52:57,965:INFO:Starting cross validation
2025-12-10 18:52:57,968:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:52:59,467:INFO:Calculating mean and std
2025-12-10 18:52:59,468:INFO:Creating metrics dataframe
2025-12-10 18:52:59,472:INFO:Uploading results into container
2025-12-10 18:52:59,473:INFO:Uploading model into container now
2025-12-10 18:52:59,475:INFO:_master_model_container: 14
2025-12-10 18:52:59,475:INFO:_display_container: 2
2025-12-10 18:52:59,475:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-10 18:52:59,475:INFO:create_model() successfully completed......................................
2025-12-10 18:52:59,648:INFO:SubProcess create_model() end ==================================
2025-12-10 18:52:59,648:INFO:Creating metrics dataframe
2025-12-10 18:52:59,659:INFO:Initializing AdaBoost Regressor
2025-12-10 18:52:59,659:INFO:Total runtime is 0.33786570231119795 minutes
2025-12-10 18:52:59,663:INFO:SubProcess create_model() called ==================================
2025-12-10 18:52:59,665:INFO:Initializing create_model()
2025-12-10 18:52:59,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:52:59,665:INFO:Checking exceptions
2025-12-10 18:52:59,665:INFO:Importing libraries
2025-12-10 18:52:59,666:INFO:Copying training dataset
2025-12-10 18:52:59,674:INFO:Defining folds
2025-12-10 18:52:59,674:INFO:Declaring metric variables
2025-12-10 18:52:59,680:INFO:Importing untrained model
2025-12-10 18:52:59,686:INFO:AdaBoost Regressor Imported successfully
2025-12-10 18:52:59,697:INFO:Starting cross validation
2025-12-10 18:52:59,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:00,199:INFO:Calculating mean and std
2025-12-10 18:53:00,200:INFO:Creating metrics dataframe
2025-12-10 18:53:00,203:INFO:Uploading results into container
2025-12-10 18:53:00,205:INFO:Uploading model into container now
2025-12-10 18:53:00,205:INFO:_master_model_container: 15
2025-12-10 18:53:00,206:INFO:_display_container: 2
2025-12-10 18:53:00,207:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-12-10 18:53:00,207:INFO:create_model() successfully completed......................................
2025-12-10 18:53:00,364:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:00,364:INFO:Creating metrics dataframe
2025-12-10 18:53:00,376:INFO:Initializing Gradient Boosting Regressor
2025-12-10 18:53:00,376:INFO:Total runtime is 0.3498039762179057 minutes
2025-12-10 18:53:00,381:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:00,381:INFO:Initializing create_model()
2025-12-10 18:53:00,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:00,383:INFO:Checking exceptions
2025-12-10 18:53:00,383:INFO:Importing libraries
2025-12-10 18:53:00,383:INFO:Copying training dataset
2025-12-10 18:53:00,392:INFO:Defining folds
2025-12-10 18:53:00,392:INFO:Declaring metric variables
2025-12-10 18:53:00,397:INFO:Importing untrained model
2025-12-10 18:53:00,403:INFO:Gradient Boosting Regressor Imported successfully
2025-12-10 18:53:00,412:INFO:Starting cross validation
2025-12-10 18:53:00,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:01,125:INFO:Calculating mean and std
2025-12-10 18:53:01,126:INFO:Creating metrics dataframe
2025-12-10 18:53:01,129:INFO:Uploading results into container
2025-12-10 18:53:01,130:INFO:Uploading model into container now
2025-12-10 18:53:01,130:INFO:_master_model_container: 16
2025-12-10 18:53:01,132:INFO:_display_container: 2
2025-12-10 18:53:01,132:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-10 18:53:01,132:INFO:create_model() successfully completed......................................
2025-12-10 18:53:01,290:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:01,290:INFO:Creating metrics dataframe
2025-12-10 18:53:01,303:INFO:Initializing Light Gradient Boosting Machine
2025-12-10 18:53:01,303:INFO:Total runtime is 0.3652516523996989 minutes
2025-12-10 18:53:01,307:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:01,307:INFO:Initializing create_model()
2025-12-10 18:53:01,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:01,308:INFO:Checking exceptions
2025-12-10 18:53:01,309:INFO:Importing libraries
2025-12-10 18:53:01,309:INFO:Copying training dataset
2025-12-10 18:53:01,318:INFO:Defining folds
2025-12-10 18:53:01,318:INFO:Declaring metric variables
2025-12-10 18:53:01,323:INFO:Importing untrained model
2025-12-10 18:53:01,331:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:53:01,341:INFO:Starting cross validation
2025-12-10 18:53:01,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:02,509:INFO:Calculating mean and std
2025-12-10 18:53:02,511:INFO:Creating metrics dataframe
2025-12-10 18:53:02,517:INFO:Uploading results into container
2025-12-10 18:53:02,517:INFO:Uploading model into container now
2025-12-10 18:53:02,519:INFO:_master_model_container: 17
2025-12-10 18:53:02,519:INFO:_display_container: 2
2025-12-10 18:53:02,520:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:53:02,520:INFO:create_model() successfully completed......................................
2025-12-10 18:53:02,724:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:02,724:INFO:Creating metrics dataframe
2025-12-10 18:53:02,737:INFO:Initializing Dummy Regressor
2025-12-10 18:53:02,737:INFO:Total runtime is 0.38916233380635584 minutes
2025-12-10 18:53:02,743:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:02,743:INFO:Initializing create_model()
2025-12-10 18:53:02,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CE4476A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:02,743:INFO:Checking exceptions
2025-12-10 18:53:02,743:INFO:Importing libraries
2025-12-10 18:53:02,743:INFO:Copying training dataset
2025-12-10 18:53:02,754:INFO:Defining folds
2025-12-10 18:53:02,754:INFO:Declaring metric variables
2025-12-10 18:53:02,759:INFO:Importing untrained model
2025-12-10 18:53:02,765:INFO:Dummy Regressor Imported successfully
2025-12-10 18:53:02,775:INFO:Starting cross validation
2025-12-10 18:53:02,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:02,896:INFO:Calculating mean and std
2025-12-10 18:53:02,899:INFO:Creating metrics dataframe
2025-12-10 18:53:02,900:INFO:Uploading results into container
2025-12-10 18:53:02,902:INFO:Uploading model into container now
2025-12-10 18:53:02,902:INFO:_master_model_container: 18
2025-12-10 18:53:02,902:INFO:_display_container: 2
2025-12-10 18:53:02,903:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-12-10 18:53:02,903:INFO:create_model() successfully completed......................................
2025-12-10 18:53:03,059:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:03,059:INFO:Creating metrics dataframe
2025-12-10 18:53:03,074:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-10 18:53:03,087:INFO:Initializing create_model()
2025-12-10 18:53:03,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:03,088:INFO:Checking exceptions
2025-12-10 18:53:03,091:INFO:Importing libraries
2025-12-10 18:53:03,091:INFO:Copying training dataset
2025-12-10 18:53:03,100:INFO:Defining folds
2025-12-10 18:53:03,100:INFO:Declaring metric variables
2025-12-10 18:53:03,101:INFO:Importing untrained model
2025-12-10 18:53:03,101:INFO:Declaring custom model
2025-12-10 18:53:03,102:INFO:Extra Trees Regressor Imported successfully
2025-12-10 18:53:03,103:INFO:Cross validation set to False
2025-12-10 18:53:03,103:INFO:Fitting Model
2025-12-10 18:53:03,319:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-10 18:53:03,319:INFO:create_model() successfully completed......................................
2025-12-10 18:53:03,516:INFO:_master_model_container: 18
2025-12-10 18:53:03,516:INFO:_display_container: 2
2025-12-10 18:53:03,517:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-10 18:53:03,517:INFO:compare_models() successfully completed......................................
2025-12-10 18:53:03,519:INFO:Initializing tune_model()
2025-12-10 18:53:03,519:INFO:tune_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>)
2025-12-10 18:53:03,519:INFO:Checking exceptions
2025-12-10 18:53:03,545:INFO:Copying training dataset
2025-12-10 18:53:03,552:INFO:Checking base model
2025-12-10 18:53:03,553:INFO:Base model : Extra Trees Regressor
2025-12-10 18:53:03,558:INFO:Declaring metric variables
2025-12-10 18:53:03,563:INFO:Defining Hyperparameters
2025-12-10 18:53:03,770:INFO:Tuning with n_jobs=-1
2025-12-10 18:53:03,770:INFO:Initializing RandomizedSearchCV
2025-12-10 18:53:37,939:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2025-12-10 18:53:37,941:INFO:Hyperparameter search completed
2025-12-10 18:53:37,941:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:37,942:INFO:Initializing create_model()
2025-12-10 18:53:37,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6CA86B8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2025-12-10 18:53:37,943:INFO:Checking exceptions
2025-12-10 18:53:37,943:INFO:Importing libraries
2025-12-10 18:53:37,944:INFO:Copying training dataset
2025-12-10 18:53:37,956:INFO:Defining folds
2025-12-10 18:53:37,956:INFO:Declaring metric variables
2025-12-10 18:53:37,961:INFO:Importing untrained model
2025-12-10 18:53:37,961:INFO:Declaring custom model
2025-12-10 18:53:37,969:INFO:Extra Trees Regressor Imported successfully
2025-12-10 18:53:37,982:INFO:Starting cross validation
2025-12-10 18:53:37,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:38,957:INFO:Calculating mean and std
2025-12-10 18:53:38,959:INFO:Creating metrics dataframe
2025-12-10 18:53:38,969:INFO:Finalizing model
2025-12-10 18:53:39,240:INFO:Uploading results into container
2025-12-10 18:53:39,241:INFO:Uploading model into container now
2025-12-10 18:53:39,242:INFO:_master_model_container: 19
2025-12-10 18:53:39,242:INFO:_display_container: 3
2025-12-10 18:53:39,243:INFO:ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=9, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-10 18:53:39,243:INFO:create_model() successfully completed......................................
2025-12-10 18:53:39,429:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:39,429:INFO:choose_better activated
2025-12-10 18:53:39,435:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:39,436:INFO:Initializing create_model()
2025-12-10 18:53:39,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:39,436:INFO:Checking exceptions
2025-12-10 18:53:39,441:INFO:Importing libraries
2025-12-10 18:53:39,441:INFO:Copying training dataset
2025-12-10 18:53:39,453:INFO:Defining folds
2025-12-10 18:53:39,453:INFO:Declaring metric variables
2025-12-10 18:53:39,453:INFO:Importing untrained model
2025-12-10 18:53:39,453:INFO:Declaring custom model
2025-12-10 18:53:39,454:INFO:Extra Trees Regressor Imported successfully
2025-12-10 18:53:39,454:INFO:Starting cross validation
2025-12-10 18:53:39,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:40,999:INFO:Calculating mean and std
2025-12-10 18:53:41,000:INFO:Creating metrics dataframe
2025-12-10 18:53:41,001:INFO:Finalizing model
2025-12-10 18:53:41,219:INFO:Uploading results into container
2025-12-10 18:53:41,220:INFO:Uploading model into container now
2025-12-10 18:53:41,221:INFO:_master_model_container: 20
2025-12-10 18:53:41,221:INFO:_display_container: 4
2025-12-10 18:53:41,221:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-10 18:53:41,221:INFO:create_model() successfully completed......................................
2025-12-10 18:53:41,375:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:41,375:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) result for R2 is 0.9575
2025-12-10 18:53:41,376:INFO:ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=9, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) result for R2 is 0.9305
2025-12-10 18:53:41,376:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) is best model
2025-12-10 18:53:41,376:INFO:choose_better completed
2025-12-10 18:53:41,376:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-10 18:53:41,392:INFO:_master_model_container: 20
2025-12-10 18:53:41,392:INFO:_display_container: 3
2025-12-10 18:53:41,392:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-10 18:53:41,393:INFO:tune_model() successfully completed......................................
2025-12-10 18:53:41,579:INFO:PyCaret ClassificationExperiment
2025-12-10 18:53:41,579:INFO:Logging name: clf-default-name
2025-12-10 18:53:41,580:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-10 18:53:41,580:INFO:version 3.3.2
2025-12-10 18:53:41,580:INFO:Initializing setup()
2025-12-10 18:53:41,580:INFO:self.USI: fa08
2025-12-10 18:53:41,580:INFO:self._variable_keys: {'X', 'USI', 'log_plots_param', 'exp_id', 'html_param', 'y_test', 'y_train', 'fix_imbalance', '_ml_usecase', 'X_train', 'n_jobs_param', 'pipeline', 'memory', '_available_plots', 'is_multiclass', 'gpu_param', 'X_test', 'idx', 'seed', 'logging_param', 'exp_name_log', 'data', 'y', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-12-10 18:53:41,580:INFO:Checking environment
2025-12-10 18:53:41,580:INFO:python_version: 3.10.19
2025-12-10 18:53:41,580:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-10 18:53:41,580:INFO:machine: AMD64
2025-12-10 18:53:41,580:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-10 18:53:41,580:INFO:Memory: svmem(total=33699516416, available=16093634560, percent=52.2, used=17605881856, free=16093634560)
2025-12-10 18:53:41,580:INFO:Physical Core: 8
2025-12-10 18:53:41,580:INFO:Logical Core: 16
2025-12-10 18:53:41,580:INFO:Checking libraries
2025-12-10 18:53:41,580:INFO:System:
2025-12-10 18:53:41,582:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-10 18:53:41,582:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-10 18:53:41,582:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-10 18:53:41,582:INFO:PyCaret required dependencies:
2025-12-10 18:53:41,582:INFO:                 pip: 25.3
2025-12-10 18:53:41,582:INFO:          setuptools: 80.9.0
2025-12-10 18:53:41,582:INFO:             pycaret: 3.3.2
2025-12-10 18:53:41,582:INFO:             IPython: 8.37.0
2025-12-10 18:53:41,582:INFO:          ipywidgets: 8.1.8
2025-12-10 18:53:41,582:INFO:                tqdm: 4.67.1
2025-12-10 18:53:41,583:INFO:               numpy: 1.26.4
2025-12-10 18:53:41,583:INFO:              pandas: 2.1.4
2025-12-10 18:53:41,583:INFO:              jinja2: 3.1.6
2025-12-10 18:53:41,583:INFO:               scipy: 1.11.4
2025-12-10 18:53:41,583:INFO:              joblib: 1.3.2
2025-12-10 18:53:41,583:INFO:             sklearn: 1.4.2
2025-12-10 18:53:41,583:INFO:                pyod: 2.0.6
2025-12-10 18:53:41,583:INFO:            imblearn: 0.14.0
2025-12-10 18:53:41,583:INFO:   category_encoders: 2.7.0
2025-12-10 18:53:41,583:INFO:            lightgbm: 4.6.0
2025-12-10 18:53:41,583:INFO:               numba: 0.62.1
2025-12-10 18:53:41,583:INFO:            requests: 2.32.5
2025-12-10 18:53:41,583:INFO:          matplotlib: 3.7.5
2025-12-10 18:53:41,583:INFO:          scikitplot: 0.3.7
2025-12-10 18:53:41,583:INFO:         yellowbrick: 1.5
2025-12-10 18:53:41,583:INFO:              plotly: 6.5.0
2025-12-10 18:53:41,583:INFO:    plotly-resampler: Not installed
2025-12-10 18:53:41,583:INFO:             kaleido: 1.2.0
2025-12-10 18:53:41,583:INFO:           schemdraw: 0.15
2025-12-10 18:53:41,583:INFO:         statsmodels: 0.14.5
2025-12-10 18:53:41,583:INFO:              sktime: 0.26.0
2025-12-10 18:53:41,583:INFO:               tbats: 1.1.3
2025-12-10 18:53:41,583:INFO:            pmdarima: 2.0.4
2025-12-10 18:53:41,583:INFO:              psutil: 7.1.3
2025-12-10 18:53:41,583:INFO:          markupsafe: 3.0.3
2025-12-10 18:53:41,584:INFO:             pickle5: Not installed
2025-12-10 18:53:41,584:INFO:         cloudpickle: 3.1.2
2025-12-10 18:53:41,584:INFO:         deprecation: 2.1.0
2025-12-10 18:53:41,584:INFO:              xxhash: 3.6.0
2025-12-10 18:53:41,584:INFO:           wurlitzer: Not installed
2025-12-10 18:53:41,584:INFO:PyCaret optional dependencies:
2025-12-10 18:53:41,584:INFO:                shap: Not installed
2025-12-10 18:53:41,584:INFO:           interpret: Not installed
2025-12-10 18:53:41,584:INFO:                umap: Not installed
2025-12-10 18:53:41,584:INFO:     ydata_profiling: Not installed
2025-12-10 18:53:41,584:INFO:  explainerdashboard: Not installed
2025-12-10 18:53:41,584:INFO:             autoviz: Not installed
2025-12-10 18:53:41,584:INFO:           fairlearn: Not installed
2025-12-10 18:53:41,584:INFO:          deepchecks: Not installed
2025-12-10 18:53:41,584:INFO:             xgboost: Not installed
2025-12-10 18:53:41,584:INFO:            catboost: Not installed
2025-12-10 18:53:41,584:INFO:              kmodes: Not installed
2025-12-10 18:53:41,584:INFO:             mlxtend: Not installed
2025-12-10 18:53:41,584:INFO:       statsforecast: Not installed
2025-12-10 18:53:41,584:INFO:        tune_sklearn: Not installed
2025-12-10 18:53:41,584:INFO:                 ray: Not installed
2025-12-10 18:53:41,584:INFO:            hyperopt: Not installed
2025-12-10 18:53:41,584:INFO:              optuna: Not installed
2025-12-10 18:53:41,584:INFO:               skopt: Not installed
2025-12-10 18:53:41,585:INFO:              mlflow: Not installed
2025-12-10 18:53:41,585:INFO:              gradio: Not installed
2025-12-10 18:53:41,585:INFO:             fastapi: Not installed
2025-12-10 18:53:41,585:INFO:             uvicorn: Not installed
2025-12-10 18:53:41,585:INFO:              m2cgen: Not installed
2025-12-10 18:53:41,585:INFO:           evidently: Not installed
2025-12-10 18:53:41,585:INFO:               fugue: Not installed
2025-12-10 18:53:41,585:INFO:           streamlit: Not installed
2025-12-10 18:53:41,585:INFO:             prophet: Not installed
2025-12-10 18:53:41,585:INFO:None
2025-12-10 18:53:41,585:INFO:Set up data.
2025-12-10 18:53:41,593:INFO:Set up folding strategy.
2025-12-10 18:53:41,593:INFO:Set up train/test split.
2025-12-10 18:53:41,606:INFO:Set up index.
2025-12-10 18:53:41,606:INFO:Assigning column types.
2025-12-10 18:53:41,618:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-10 18:53:41,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:53:41,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:53:41,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:41,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:41,753:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-10 18:53:41,755:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:53:41,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:41,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:41,788:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-10 18:53:41,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:53:41,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:41,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:41,930:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-10 18:53:41,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:41,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:41,963:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-10 18:53:42,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:42,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:42,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:42,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:42,131:INFO:Preparing preprocessing pipeline...
2025-12-10 18:53:42,135:INFO:Set up simple imputation.
2025-12-10 18:53:42,135:INFO:Set up imbalanced handling.
2025-12-10 18:53:42,135:INFO:Set up column name cleaning.
2025-12-10 18:53:42,221:INFO:Finished creating preprocessing pipeline.
2025-12-10 18:53:42,228:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-10 18:53:42,228:INFO:Creating final display dataframe.
2025-12-10 18:53:42,454:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 18)
4        Transformed data shape           (11982, 16)
5   Transformed train set shape            (9610, 16)
6    Transformed test set shape            (2372, 16)
7               Ignore features                     2
8              Numeric features                    15
9                    Preprocess                  True
10              Imputation type                simple
11           Numeric imputation                  mean
12       Categorical imputation                  mode
13                Fix imbalance                  True
14         Fix imbalance method                 SMOTE
15               Fold Generator       StratifiedKFold
16                  Fold Number                    10
17                     CPU Jobs                    -1
18                      Use GPU                 False
19               Log Experiment                 False
20              Experiment Name      clf-default-name
21                          USI                  fa08
2025-12-10 18:53:42,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:42,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:42,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:42,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-10 18:53:42,626:INFO:setup() successfully completed in 1.05s...............
2025-12-10 18:53:42,629:INFO:Initializing compare_models()
2025-12-10 18:53:42,629:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-10 18:53:42,629:INFO:Checking exceptions
2025-12-10 18:53:42,635:INFO:Preparing display monitor
2025-12-10 18:53:42,676:INFO:Initializing Logistic Regression
2025-12-10 18:53:42,676:INFO:Total runtime is 0.0 minutes
2025-12-10 18:53:42,684:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:42,684:INFO:Initializing create_model()
2025-12-10 18:53:42,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:42,685:INFO:Checking exceptions
2025-12-10 18:53:42,685:INFO:Importing libraries
2025-12-10 18:53:42,685:INFO:Copying training dataset
2025-12-10 18:53:42,697:INFO:Defining folds
2025-12-10 18:53:42,698:INFO:Declaring metric variables
2025-12-10 18:53:42,703:INFO:Importing untrained model
2025-12-10 18:53:42,710:INFO:Logistic Regression Imported successfully
2025-12-10 18:53:42,725:INFO:Starting cross validation
2025-12-10 18:53:42,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:44,662:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:44,691:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:44,723:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:44,725:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:44,742:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:44,769:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:44,775:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:44,800:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:44,823:INFO:Calculating mean and std
2025-12-10 18:53:44,825:INFO:Creating metrics dataframe
2025-12-10 18:53:44,829:INFO:Uploading results into container
2025-12-10 18:53:44,831:INFO:Uploading model into container now
2025-12-10 18:53:44,831:INFO:_master_model_container: 1
2025-12-10 18:53:44,832:INFO:_display_container: 2
2025-12-10 18:53:44,833:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:53:44,833:INFO:create_model() successfully completed......................................
2025-12-10 18:53:44,993:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:44,995:INFO:Creating metrics dataframe
2025-12-10 18:53:45,003:INFO:Initializing K Neighbors Classifier
2025-12-10 18:53:45,003:INFO:Total runtime is 0.0387939453125 minutes
2025-12-10 18:53:45,008:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:45,008:INFO:Initializing create_model()
2025-12-10 18:53:45,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:45,010:INFO:Checking exceptions
2025-12-10 18:53:45,010:INFO:Importing libraries
2025-12-10 18:53:45,010:INFO:Copying training dataset
2025-12-10 18:53:45,019:INFO:Defining folds
2025-12-10 18:53:45,019:INFO:Declaring metric variables
2025-12-10 18:53:45,025:INFO:Importing untrained model
2025-12-10 18:53:45,034:INFO:K Neighbors Classifier Imported successfully
2025-12-10 18:53:45,048:INFO:Starting cross validation
2025-12-10 18:53:45,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:45,387:INFO:Calculating mean and std
2025-12-10 18:53:45,389:INFO:Creating metrics dataframe
2025-12-10 18:53:45,392:INFO:Uploading results into container
2025-12-10 18:53:45,394:INFO:Uploading model into container now
2025-12-10 18:53:45,394:INFO:_master_model_container: 2
2025-12-10 18:53:45,395:INFO:_display_container: 2
2025-12-10 18:53:45,396:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-10 18:53:45,397:INFO:create_model() successfully completed......................................
2025-12-10 18:53:45,556:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:45,556:INFO:Creating metrics dataframe
2025-12-10 18:53:45,566:INFO:Initializing Naive Bayes
2025-12-10 18:53:45,566:INFO:Total runtime is 0.0481699546178182 minutes
2025-12-10 18:53:45,572:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:45,601:INFO:Initializing create_model()
2025-12-10 18:53:45,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:45,601:INFO:Checking exceptions
2025-12-10 18:53:45,601:INFO:Importing libraries
2025-12-10 18:53:45,601:INFO:Copying training dataset
2025-12-10 18:53:45,613:INFO:Defining folds
2025-12-10 18:53:45,614:INFO:Declaring metric variables
2025-12-10 18:53:45,620:INFO:Importing untrained model
2025-12-10 18:53:45,625:INFO:Naive Bayes Imported successfully
2025-12-10 18:53:45,637:INFO:Starting cross validation
2025-12-10 18:53:45,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:45,800:INFO:Calculating mean and std
2025-12-10 18:53:45,801:INFO:Creating metrics dataframe
2025-12-10 18:53:45,805:INFO:Uploading results into container
2025-12-10 18:53:45,805:INFO:Uploading model into container now
2025-12-10 18:53:45,805:INFO:_master_model_container: 3
2025-12-10 18:53:45,805:INFO:_display_container: 2
2025-12-10 18:53:45,806:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-10 18:53:45,806:INFO:create_model() successfully completed......................................
2025-12-10 18:53:45,969:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:45,969:INFO:Creating metrics dataframe
2025-12-10 18:53:45,977:INFO:Initializing Decision Tree Classifier
2025-12-10 18:53:45,977:INFO:Total runtime is 0.05501893361409506 minutes
2025-12-10 18:53:45,982:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:45,984:INFO:Initializing create_model()
2025-12-10 18:53:45,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:45,984:INFO:Checking exceptions
2025-12-10 18:53:45,985:INFO:Importing libraries
2025-12-10 18:53:45,985:INFO:Copying training dataset
2025-12-10 18:53:45,997:INFO:Defining folds
2025-12-10 18:53:45,997:INFO:Declaring metric variables
2025-12-10 18:53:46,004:INFO:Importing untrained model
2025-12-10 18:53:46,009:INFO:Decision Tree Classifier Imported successfully
2025-12-10 18:53:46,022:INFO:Starting cross validation
2025-12-10 18:53:46,025:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:46,226:INFO:Calculating mean and std
2025-12-10 18:53:46,227:INFO:Creating metrics dataframe
2025-12-10 18:53:46,232:INFO:Uploading results into container
2025-12-10 18:53:46,234:INFO:Uploading model into container now
2025-12-10 18:53:46,234:INFO:_master_model_container: 4
2025-12-10 18:53:46,234:INFO:_display_container: 2
2025-12-10 18:53:46,236:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-10 18:53:46,236:INFO:create_model() successfully completed......................................
2025-12-10 18:53:46,397:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:46,397:INFO:Creating metrics dataframe
2025-12-10 18:53:46,407:INFO:Initializing SVM - Linear Kernel
2025-12-10 18:53:46,408:INFO:Total runtime is 0.06220226287841797 minutes
2025-12-10 18:53:46,412:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:46,413:INFO:Initializing create_model()
2025-12-10 18:53:46,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:46,414:INFO:Checking exceptions
2025-12-10 18:53:46,414:INFO:Importing libraries
2025-12-10 18:53:46,414:INFO:Copying training dataset
2025-12-10 18:53:46,424:INFO:Defining folds
2025-12-10 18:53:46,425:INFO:Declaring metric variables
2025-12-10 18:53:46,431:INFO:Importing untrained model
2025-12-10 18:53:46,440:INFO:SVM - Linear Kernel Imported successfully
2025-12-10 18:53:46,455:INFO:Starting cross validation
2025-12-10 18:53:46,457:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:46,717:INFO:Calculating mean and std
2025-12-10 18:53:46,719:INFO:Creating metrics dataframe
2025-12-10 18:53:46,722:INFO:Uploading results into container
2025-12-10 18:53:46,723:INFO:Uploading model into container now
2025-12-10 18:53:46,724:INFO:_master_model_container: 5
2025-12-10 18:53:46,724:INFO:_display_container: 2
2025-12-10 18:53:46,725:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-10 18:53:46,725:INFO:create_model() successfully completed......................................
2025-12-10 18:53:46,887:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:46,888:INFO:Creating metrics dataframe
2025-12-10 18:53:46,898:INFO:Initializing Ridge Classifier
2025-12-10 18:53:46,898:INFO:Total runtime is 0.07037080923716227 minutes
2025-12-10 18:53:46,904:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:46,904:INFO:Initializing create_model()
2025-12-10 18:53:46,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:46,905:INFO:Checking exceptions
2025-12-10 18:53:46,905:INFO:Importing libraries
2025-12-10 18:53:46,905:INFO:Copying training dataset
2025-12-10 18:53:46,915:INFO:Defining folds
2025-12-10 18:53:46,916:INFO:Declaring metric variables
2025-12-10 18:53:46,921:INFO:Importing untrained model
2025-12-10 18:53:46,959:INFO:Ridge Classifier Imported successfully
2025-12-10 18:53:46,975:INFO:Starting cross validation
2025-12-10 18:53:46,978:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:47,069:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.37492e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,073:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.17074e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,078:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.88649e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,084:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.28373e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,090:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.01165e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,097:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.12804e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,097:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.28724e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,102:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.19698e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,107:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.31499e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,110:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.1424e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-10 18:53:47,150:INFO:Calculating mean and std
2025-12-10 18:53:47,151:INFO:Creating metrics dataframe
2025-12-10 18:53:47,153:INFO:Uploading results into container
2025-12-10 18:53:47,154:INFO:Uploading model into container now
2025-12-10 18:53:47,154:INFO:_master_model_container: 6
2025-12-10 18:53:47,154:INFO:_display_container: 2
2025-12-10 18:53:47,154:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-10 18:53:47,156:INFO:create_model() successfully completed......................................
2025-12-10 18:53:47,315:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:47,315:INFO:Creating metrics dataframe
2025-12-10 18:53:47,325:INFO:Initializing Random Forest Classifier
2025-12-10 18:53:47,325:INFO:Total runtime is 0.07749724785486857 minutes
2025-12-10 18:53:47,332:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:47,332:INFO:Initializing create_model()
2025-12-10 18:53:47,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:47,333:INFO:Checking exceptions
2025-12-10 18:53:47,333:INFO:Importing libraries
2025-12-10 18:53:47,333:INFO:Copying training dataset
2025-12-10 18:53:47,344:INFO:Defining folds
2025-12-10 18:53:47,344:INFO:Declaring metric variables
2025-12-10 18:53:47,351:INFO:Importing untrained model
2025-12-10 18:53:47,356:INFO:Random Forest Classifier Imported successfully
2025-12-10 18:53:47,370:INFO:Starting cross validation
2025-12-10 18:53:47,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:48,812:INFO:Calculating mean and std
2025-12-10 18:53:48,815:INFO:Creating metrics dataframe
2025-12-10 18:53:48,816:INFO:Uploading results into container
2025-12-10 18:53:48,818:INFO:Uploading model into container now
2025-12-10 18:53:48,818:INFO:_master_model_container: 7
2025-12-10 18:53:48,818:INFO:_display_container: 2
2025-12-10 18:53:48,820:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-10 18:53:48,820:INFO:create_model() successfully completed......................................
2025-12-10 18:53:49,020:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:49,021:INFO:Creating metrics dataframe
2025-12-10 18:53:49,033:INFO:Initializing Quadratic Discriminant Analysis
2025-12-10 18:53:49,033:INFO:Total runtime is 0.10596181551615397 minutes
2025-12-10 18:53:49,040:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:49,040:INFO:Initializing create_model()
2025-12-10 18:53:49,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:49,041:INFO:Checking exceptions
2025-12-10 18:53:49,041:INFO:Importing libraries
2025-12-10 18:53:49,041:INFO:Copying training dataset
2025-12-10 18:53:49,053:INFO:Defining folds
2025-12-10 18:53:49,053:INFO:Declaring metric variables
2025-12-10 18:53:49,059:INFO:Importing untrained model
2025-12-10 18:53:49,065:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-10 18:53:49,078:INFO:Starting cross validation
2025-12-10 18:53:49,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:49,166:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,179:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,181:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,182:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,183:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,183:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,185:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,186:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,190:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,191:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,191:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,195:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,195:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,195:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,196:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,198:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,198:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,198:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,200:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,200:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,200:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,200:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,202:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,202:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,202:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,202:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,203:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,203:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,204:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,204:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,205:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,205:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,205:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,205:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,205:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,205:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,208:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,210:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,210:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,211:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,211:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-10 18:53:49,214:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,217:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,217:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,217:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,217:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,219:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,220:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,220:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,221:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,222:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,222:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,222:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,222:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,223:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,225:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:961: RuntimeWarning: overflow encountered in square
  norm2.append(np.sum(X2**2, axis=1))

2025-12-10 18:53:49,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,226:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,230:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,231:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,231:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:961: RuntimeWarning: overflow encountered in square
  norm2.append(np.sum(X2**2, axis=1))



2025-12-10 18:53:49,232:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,232:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,234:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-10 18:53:49,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-10 18:53:49,238:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,238:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,240:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2025-12-10 18:53:49,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,246:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-10 18:53:49,248:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,256:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:49,277:INFO:Calculating mean and std
2025-12-10 18:53:49,280:INFO:Creating metrics dataframe
2025-12-10 18:53:49,284:INFO:Uploading results into container
2025-12-10 18:53:49,284:INFO:Uploading model into container now
2025-12-10 18:53:49,284:INFO:_master_model_container: 8
2025-12-10 18:53:49,285:INFO:_display_container: 2
2025-12-10 18:53:49,285:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-10 18:53:49,285:INFO:create_model() successfully completed......................................
2025-12-10 18:53:49,447:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:49,447:INFO:Creating metrics dataframe
2025-12-10 18:53:49,458:INFO:Initializing Ada Boost Classifier
2025-12-10 18:53:49,458:INFO:Total runtime is 0.11303168137868246 minutes
2025-12-10 18:53:49,465:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:49,465:INFO:Initializing create_model()
2025-12-10 18:53:49,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:49,466:INFO:Checking exceptions
2025-12-10 18:53:49,466:INFO:Importing libraries
2025-12-10 18:53:49,466:INFO:Copying training dataset
2025-12-10 18:53:49,475:INFO:Defining folds
2025-12-10 18:53:49,475:INFO:Declaring metric variables
2025-12-10 18:53:49,483:INFO:Importing untrained model
2025-12-10 18:53:49,490:INFO:Ada Boost Classifier Imported successfully
2025-12-10 18:53:49,503:INFO:Starting cross validation
2025-12-10 18:53:49,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:49,592:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,596:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,600:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,611:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,611:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,612:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,623:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,624:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,627:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:49,628:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-10 18:53:50,291:INFO:Calculating mean and std
2025-12-10 18:53:50,292:INFO:Creating metrics dataframe
2025-12-10 18:53:50,295:INFO:Uploading results into container
2025-12-10 18:53:50,296:INFO:Uploading model into container now
2025-12-10 18:53:50,296:INFO:_master_model_container: 9
2025-12-10 18:53:50,298:INFO:_display_container: 2
2025-12-10 18:53:50,298:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-10 18:53:50,298:INFO:create_model() successfully completed......................................
2025-12-10 18:53:50,461:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:50,461:INFO:Creating metrics dataframe
2025-12-10 18:53:50,472:INFO:Initializing Gradient Boosting Classifier
2025-12-10 18:53:50,474:INFO:Total runtime is 0.12997442483901978 minutes
2025-12-10 18:53:50,479:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:50,481:INFO:Initializing create_model()
2025-12-10 18:53:50,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:50,481:INFO:Checking exceptions
2025-12-10 18:53:50,481:INFO:Importing libraries
2025-12-10 18:53:50,481:INFO:Copying training dataset
2025-12-10 18:53:50,489:INFO:Defining folds
2025-12-10 18:53:50,489:INFO:Declaring metric variables
2025-12-10 18:53:50,497:INFO:Importing untrained model
2025-12-10 18:53:50,502:INFO:Gradient Boosting Classifier Imported successfully
2025-12-10 18:53:50,516:INFO:Starting cross validation
2025-12-10 18:53:50,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:52,381:INFO:Calculating mean and std
2025-12-10 18:53:52,382:INFO:Creating metrics dataframe
2025-12-10 18:53:52,385:INFO:Uploading results into container
2025-12-10 18:53:52,387:INFO:Uploading model into container now
2025-12-10 18:53:52,387:INFO:_master_model_container: 10
2025-12-10 18:53:52,388:INFO:_display_container: 2
2025-12-10 18:53:52,389:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-10 18:53:52,389:INFO:create_model() successfully completed......................................
2025-12-10 18:53:52,547:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:52,547:INFO:Creating metrics dataframe
2025-12-10 18:53:52,560:INFO:Initializing Linear Discriminant Analysis
2025-12-10 18:53:52,560:INFO:Total runtime is 0.16474241415659585 minutes
2025-12-10 18:53:52,567:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:52,567:INFO:Initializing create_model()
2025-12-10 18:53:52,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:52,567:INFO:Checking exceptions
2025-12-10 18:53:52,567:INFO:Importing libraries
2025-12-10 18:53:52,567:INFO:Copying training dataset
2025-12-10 18:53:52,578:INFO:Defining folds
2025-12-10 18:53:52,578:INFO:Declaring metric variables
2025-12-10 18:53:52,586:INFO:Importing untrained model
2025-12-10 18:53:52,591:INFO:Linear Discriminant Analysis Imported successfully
2025-12-10 18:53:52,604:INFO:Starting cross validation
2025-12-10 18:53:52,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:52,781:INFO:Calculating mean and std
2025-12-10 18:53:52,783:INFO:Creating metrics dataframe
2025-12-10 18:53:52,786:INFO:Uploading results into container
2025-12-10 18:53:52,787:INFO:Uploading model into container now
2025-12-10 18:53:52,787:INFO:_master_model_container: 11
2025-12-10 18:53:52,787:INFO:_display_container: 2
2025-12-10 18:53:52,788:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-10 18:53:52,788:INFO:create_model() successfully completed......................................
2025-12-10 18:53:52,948:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:52,948:INFO:Creating metrics dataframe
2025-12-10 18:53:52,961:INFO:Initializing Extra Trees Classifier
2025-12-10 18:53:52,962:INFO:Total runtime is 0.17143690188725788 minutes
2025-12-10 18:53:52,968:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:52,969:INFO:Initializing create_model()
2025-12-10 18:53:52,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:52,969:INFO:Checking exceptions
2025-12-10 18:53:52,970:INFO:Importing libraries
2025-12-10 18:53:52,970:INFO:Copying training dataset
2025-12-10 18:53:52,980:INFO:Defining folds
2025-12-10 18:53:52,982:INFO:Declaring metric variables
2025-12-10 18:53:52,990:INFO:Importing untrained model
2025-12-10 18:53:52,997:INFO:Extra Trees Classifier Imported successfully
2025-12-10 18:53:53,008:INFO:Starting cross validation
2025-12-10 18:53:53,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:54,245:INFO:Calculating mean and std
2025-12-10 18:53:54,246:INFO:Creating metrics dataframe
2025-12-10 18:53:54,249:INFO:Uploading results into container
2025-12-10 18:53:54,251:INFO:Uploading model into container now
2025-12-10 18:53:54,253:INFO:_master_model_container: 12
2025-12-10 18:53:54,253:INFO:_display_container: 2
2025-12-10 18:53:54,253:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-10 18:53:54,253:INFO:create_model() successfully completed......................................
2025-12-10 18:53:54,413:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:54,413:INFO:Creating metrics dataframe
2025-12-10 18:53:54,426:INFO:Initializing Light Gradient Boosting Machine
2025-12-10 18:53:54,426:INFO:Total runtime is 0.1958401560783386 minutes
2025-12-10 18:53:54,434:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:54,434:INFO:Initializing create_model()
2025-12-10 18:53:54,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:54,435:INFO:Checking exceptions
2025-12-10 18:53:54,435:INFO:Importing libraries
2025-12-10 18:53:54,435:INFO:Copying training dataset
2025-12-10 18:53:54,444:INFO:Defining folds
2025-12-10 18:53:54,444:INFO:Declaring metric variables
2025-12-10 18:53:54,451:INFO:Importing untrained model
2025-12-10 18:53:54,457:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 18:53:54,473:INFO:Starting cross validation
2025-12-10 18:53:54,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:56,024:INFO:Calculating mean and std
2025-12-10 18:53:56,025:INFO:Creating metrics dataframe
2025-12-10 18:53:56,030:INFO:Uploading results into container
2025-12-10 18:53:56,032:INFO:Uploading model into container now
2025-12-10 18:53:56,032:INFO:_master_model_container: 13
2025-12-10 18:53:56,033:INFO:_display_container: 2
2025-12-10 18:53:56,035:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 18:53:56,035:INFO:create_model() successfully completed......................................
2025-12-10 18:53:56,211:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:56,211:INFO:Creating metrics dataframe
2025-12-10 18:53:56,224:INFO:Initializing Dummy Classifier
2025-12-10 18:53:56,224:INFO:Total runtime is 0.2258109172185262 minutes
2025-12-10 18:53:56,232:INFO:SubProcess create_model() called ==================================
2025-12-10 18:53:56,232:INFO:Initializing create_model()
2025-12-10 18:53:56,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:56,232:INFO:Checking exceptions
2025-12-10 18:53:56,232:INFO:Importing libraries
2025-12-10 18:53:56,232:INFO:Copying training dataset
2025-12-10 18:53:56,242:INFO:Defining folds
2025-12-10 18:53:56,242:INFO:Declaring metric variables
2025-12-10 18:53:56,251:INFO:Importing untrained model
2025-12-10 18:53:56,258:INFO:Dummy Classifier Imported successfully
2025-12-10 18:53:56,273:INFO:Starting cross validation
2025-12-10 18:53:56,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:53:56,379:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,382:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,383:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,383:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,390:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,393:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,401:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,402:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,404:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 18:53:56,433:INFO:Calculating mean and std
2025-12-10 18:53:56,435:INFO:Creating metrics dataframe
2025-12-10 18:53:56,438:INFO:Uploading results into container
2025-12-10 18:53:56,439:INFO:Uploading model into container now
2025-12-10 18:53:56,441:INFO:_master_model_container: 14
2025-12-10 18:53:56,441:INFO:_display_container: 2
2025-12-10 18:53:56,441:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-10 18:53:56,443:INFO:create_model() successfully completed......................................
2025-12-10 18:53:56,602:INFO:SubProcess create_model() end ==================================
2025-12-10 18:53:56,602:INFO:Creating metrics dataframe
2025-12-10 18:53:56,617:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-10 18:53:56,633:INFO:Initializing create_model()
2025-12-10 18:53:56,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:53:56,633:INFO:Checking exceptions
2025-12-10 18:53:56,636:INFO:Importing libraries
2025-12-10 18:53:56,636:INFO:Copying training dataset
2025-12-10 18:53:56,648:INFO:Defining folds
2025-12-10 18:53:56,648:INFO:Declaring metric variables
2025-12-10 18:53:56,648:INFO:Importing untrained model
2025-12-10 18:53:56,648:INFO:Declaring custom model
2025-12-10 18:53:56,649:INFO:Logistic Regression Imported successfully
2025-12-10 18:53:56,652:INFO:Cross validation set to False
2025-12-10 18:53:56,652:INFO:Fitting Model
2025-12-10 18:53:58,097:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:53:58,098:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:53:58,098:INFO:create_model() successfully completed......................................
2025-12-10 18:53:58,301:INFO:_master_model_container: 14
2025-12-10 18:53:58,301:INFO:_display_container: 2
2025-12-10 18:53:58,302:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:53:58,302:INFO:compare_models() successfully completed......................................
2025-12-10 18:53:58,303:INFO:Initializing tune_model()
2025-12-10 18:53:58,303:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>)
2025-12-10 18:53:58,303:INFO:Checking exceptions
2025-12-10 18:53:58,329:INFO:Copying training dataset
2025-12-10 18:53:58,343:INFO:Checking base model
2025-12-10 18:53:58,343:INFO:Base model : Logistic Regression
2025-12-10 18:53:58,350:INFO:Declaring metric variables
2025-12-10 18:53:58,357:INFO:Defining Hyperparameters
2025-12-10 18:53:58,540:INFO:Tuning with n_jobs=-1
2025-12-10 18:53:58,540:INFO:Initializing RandomizedSearchCV
2025-12-10 18:54:01,903:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:01,990:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:02,015:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:02,056:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:02,085:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:02,225:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:02,459:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:03,718:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:03,885:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:04,332:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:04,336:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:04,481:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:04,796:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:05,340:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:05,487:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:05,512:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:05,541:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:05,597:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:05,636:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:05,825:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:05,930:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:06,136:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:07,221:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:07,686:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:07,986:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:08,103:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:08,233:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:08,579:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:08,628:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:08,674:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:08,712:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:08,901:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:08,950:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:09,189:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:09,635:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:10,389:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:10,662:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:10,910:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:11,982:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:12,119:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:12,143:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:12,486:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:12,618:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:12,875:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:13,066:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:13,515:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:13,539:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:13,829:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:13,842:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:14,043:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:14,585:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:14,754:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:14,914:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:15,159:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:15,351:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:15,354:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:15,354:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:15,804:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:15,927:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:16,146:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:16,156:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:16,678:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:16,741:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:16,939:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,140:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,475:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,516:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,576:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,660:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,728:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,748:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,757:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,758:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,878:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:17,890:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-10 18:54:17,891:INFO:Hyperparameter search completed
2025-12-10 18:54:17,891:INFO:SubProcess create_model() called ==================================
2025-12-10 18:54:17,891:INFO:Initializing create_model()
2025-12-10 18:54:17,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6C7925480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-10 18:54:17,891:INFO:Checking exceptions
2025-12-10 18:54:17,893:INFO:Importing libraries
2025-12-10 18:54:17,893:INFO:Copying training dataset
2025-12-10 18:54:17,904:INFO:Defining folds
2025-12-10 18:54:17,904:INFO:Declaring metric variables
2025-12-10 18:54:17,909:INFO:Importing untrained model
2025-12-10 18:54:17,909:INFO:Declaring custom model
2025-12-10 18:54:17,916:INFO:Logistic Regression Imported successfully
2025-12-10 18:54:17,926:INFO:Starting cross validation
2025-12-10 18:54:17,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:54:19,362:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:19,387:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:19,414:INFO:Calculating mean and std
2025-12-10 18:54:19,417:INFO:Creating metrics dataframe
2025-12-10 18:54:19,423:INFO:Finalizing model
2025-12-10 18:54:20,332:INFO:Uploading results into container
2025-12-10 18:54:20,333:INFO:Uploading model into container now
2025-12-10 18:54:20,334:INFO:_master_model_container: 15
2025-12-10 18:54:20,335:INFO:_display_container: 3
2025-12-10 18:54:20,336:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:54:20,336:INFO:create_model() successfully completed......................................
2025-12-10 18:54:20,493:INFO:SubProcess create_model() end ==================================
2025-12-10 18:54:20,493:INFO:choose_better activated
2025-12-10 18:54:20,497:INFO:SubProcess create_model() called ==================================
2025-12-10 18:54:20,499:INFO:Initializing create_model()
2025-12-10 18:54:20,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 18:54:20,499:INFO:Checking exceptions
2025-12-10 18:54:20,501:INFO:Importing libraries
2025-12-10 18:54:20,501:INFO:Copying training dataset
2025-12-10 18:54:20,509:INFO:Defining folds
2025-12-10 18:54:20,509:INFO:Declaring metric variables
2025-12-10 18:54:20,509:INFO:Importing untrained model
2025-12-10 18:54:20,509:INFO:Declaring custom model
2025-12-10 18:54:20,509:INFO:Logistic Regression Imported successfully
2025-12-10 18:54:20,510:INFO:Starting cross validation
2025-12-10 18:54:20,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 18:54:22,210:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:22,234:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:22,245:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:22,252:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:22,277:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:22,282:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:22,293:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:22,296:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:22,330:INFO:Calculating mean and std
2025-12-10 18:54:22,330:INFO:Creating metrics dataframe
2025-12-10 18:54:22,333:INFO:Finalizing model
2025-12-10 18:54:23,419:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-10 18:54:23,419:INFO:Uploading results into container
2025-12-10 18:54:23,420:INFO:Uploading model into container now
2025-12-10 18:54:23,420:INFO:_master_model_container: 16
2025-12-10 18:54:23,420:INFO:_display_container: 4
2025-12-10 18:54:23,420:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:54:23,420:INFO:create_model() successfully completed......................................
2025-12-10 18:54:23,571:INFO:SubProcess create_model() end ==================================
2025-12-10 18:54:23,572:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.7982
2025-12-10 18:54:23,572:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.7996
2025-12-10 18:54:23,572:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-10 18:54:23,573:INFO:choose_better completed
2025-12-10 18:54:23,586:INFO:_master_model_container: 16
2025-12-10 18:54:23,586:INFO:_display_container: 3
2025-12-10 18:54:23,587:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-10 18:54:23,587:INFO:tune_model() successfully completed......................................
2025-12-10 19:04:12,079:INFO:Initializing plot_model()
2025-12-10 19:04:12,080:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, system=True)
2025-12-10 19:04:12,080:INFO:Checking exceptions
2025-12-10 19:04:12,126:INFO:Preloading libraries
2025-12-10 19:04:12,200:INFO:Copying training dataset
2025-12-10 19:04:12,200:INFO:Plot type: error
2025-12-10 19:04:12,384:INFO:Fitting Model
2025-12-10 19:04:12,384:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2025-12-10 19:04:12,384:INFO:Scoring test/hold-out set
2025-12-10 19:04:13,009:INFO:Visual Rendered Successfully
2025-12-10 19:04:13,185:INFO:plot_model() successfully completed......................................
2025-12-10 19:04:13,194:INFO:Initializing plot_model()
2025-12-10 19:04:13,194:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, system=True)
2025-12-10 19:04:13,194:INFO:Checking exceptions
2025-12-10 19:04:13,267:INFO:Preloading libraries
2025-12-10 19:04:13,343:INFO:Copying training dataset
2025-12-10 19:04:13,344:INFO:Plot type: feature
2025-12-10 19:04:13,344:WARNING:No coef_ found. Trying feature_importances_
2025-12-10 19:04:13,651:INFO:Visual Rendered Successfully
2025-12-10 19:04:13,826:INFO:plot_model() successfully completed......................................
2025-12-10 19:04:13,838:INFO:Initializing plot_model()
2025-12-10 19:04:13,838:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, system=True)
2025-12-10 19:04:13,838:INFO:Checking exceptions
2025-12-10 19:04:13,846:INFO:Preloading libraries
2025-12-10 19:04:13,847:INFO:Copying training dataset
2025-12-10 19:04:13,847:INFO:Plot type: confusion_matrix
2025-12-10 19:04:14,054:INFO:Fitting Model
2025-12-10 19:04:14,054:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-12-10 19:04:14,054:INFO:Scoring test/hold-out set
2025-12-10 19:04:14,214:INFO:Visual Rendered Successfully
2025-12-10 19:04:14,370:INFO:plot_model() successfully completed......................................
2025-12-10 19:04:14,372:INFO:Initializing plot_model()
2025-12-10 19:04:14,372:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, system=True)
2025-12-10 19:04:14,372:INFO:Checking exceptions
2025-12-10 19:04:14,377:INFO:Preloading libraries
2025-12-10 19:04:14,378:INFO:Copying training dataset
2025-12-10 19:04:14,378:INFO:Plot type: feature
2025-12-10 19:04:14,711:INFO:Visual Rendered Successfully
2025-12-10 19:04:14,868:INFO:plot_model() successfully completed......................................
2025-12-10 19:12:41,964:INFO:Initializing plot_model()
2025-12-10 19:12:41,965:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F6CA560700>, system=True)
2025-12-10 19:12:41,965:INFO:Checking exceptions
2025-12-10 19:12:42,030:INFO:Preloading libraries
2025-12-10 19:12:42,102:INFO:Copying training dataset
2025-12-10 19:12:42,102:INFO:Plot type: error
2025-12-10 19:12:42,257:INFO:Fitting Model
2025-12-10 19:12:42,257:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2025-12-10 19:12:42,257:INFO:Scoring test/hold-out set
2025-12-10 19:12:42,709:INFO:Visual Rendered Successfully
2025-12-10 19:12:42,866:INFO:plot_model() successfully completed......................................
2025-12-10 19:12:42,876:INFO:Initializing plot_model()
2025-12-10 19:12:42,876:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6D537D960>, system=True)
2025-12-10 19:12:42,876:INFO:Checking exceptions
2025-12-10 19:12:42,885:INFO:Preloading libraries
2025-12-10 19:12:42,886:INFO:Copying training dataset
2025-12-10 19:12:42,886:INFO:Plot type: confusion_matrix
2025-12-10 19:12:43,061:INFO:Fitting Model
2025-12-10 19:12:43,061:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-12-10 19:12:43,061:INFO:Scoring test/hold-out set
2025-12-10 19:12:43,203:INFO:Visual Rendered Successfully
2025-12-10 19:12:43,356:INFO:plot_model() successfully completed......................................
2025-12-10 19:33:52,851:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names
  warnings.warn(

2025-12-11 15:14:09,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-11 15:14:09,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-11 15:14:09,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-11 15:14:09,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-11 15:14:10,405:INFO:PyCaret RegressionExperiment
2025-12-11 15:14:10,405:INFO:Logging name: reg-default-name
2025-12-11 15:14:10,405:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-11 15:14:10,405:INFO:version 3.3.2
2025-12-11 15:14:10,405:INFO:Initializing setup()
2025-12-11 15:14:10,405:INFO:self.USI: c365
2025-12-11 15:14:10,405:INFO:self._variable_keys: {'gpu_param', 'fold_shuffle_param', '_ml_usecase', 'memory', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'exp_name_log', 'X', '_available_plots', 'fold_generator', 'exp_id', 'transform_target_param', 'X_train', 'data', 'X_test', 'USI', 'y_test', 'target_param', 'y', 'idx', 'fold_groups_param', 'y_train', 'html_param', 'pipeline', 'n_jobs_param', 'logging_param'}
2025-12-11 15:14:10,405:INFO:Checking environment
2025-12-11 15:14:10,405:INFO:python_version: 3.10.19
2025-12-11 15:14:10,405:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-11 15:14:10,405:INFO:machine: AMD64
2025-12-11 15:14:10,406:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-11 15:14:10,406:INFO:Memory: svmem(total=33699516416, available=17140543488, percent=49.1, used=16558972928, free=17140543488)
2025-12-11 15:14:10,407:INFO:Physical Core: 8
2025-12-11 15:14:10,407:INFO:Logical Core: 16
2025-12-11 15:14:10,407:INFO:Checking libraries
2025-12-11 15:14:10,407:INFO:System:
2025-12-11 15:14:10,407:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-11 15:14:10,407:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-11 15:14:10,407:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-11 15:14:10,407:INFO:PyCaret required dependencies:
2025-12-11 15:14:10,409:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:10,464:INFO:                 pip: 25.3
2025-12-11 15:14:10,464:INFO:          setuptools: 80.9.0
2025-12-11 15:14:10,464:INFO:             pycaret: 3.3.2
2025-12-11 15:14:10,464:INFO:             IPython: 8.37.0
2025-12-11 15:14:10,464:INFO:          ipywidgets: 8.1.8
2025-12-11 15:14:10,464:INFO:                tqdm: 4.67.1
2025-12-11 15:14:10,464:INFO:               numpy: 1.26.4
2025-12-11 15:14:10,464:INFO:              pandas: 2.1.4
2025-12-11 15:14:10,464:INFO:              jinja2: 3.1.6
2025-12-11 15:14:10,464:INFO:               scipy: 1.11.4
2025-12-11 15:14:10,464:INFO:              joblib: 1.3.2
2025-12-11 15:14:10,464:INFO:             sklearn: 1.4.2
2025-12-11 15:14:10,466:INFO:                pyod: 2.0.6
2025-12-11 15:14:10,466:INFO:            imblearn: 0.14.0
2025-12-11 15:14:10,466:INFO:   category_encoders: 2.7.0
2025-12-11 15:14:10,466:INFO:            lightgbm: 4.6.0
2025-12-11 15:14:10,466:INFO:               numba: 0.62.1
2025-12-11 15:14:10,466:INFO:            requests: 2.32.5
2025-12-11 15:14:10,466:INFO:          matplotlib: 3.7.5
2025-12-11 15:14:10,466:INFO:          scikitplot: 0.3.7
2025-12-11 15:14:10,466:INFO:         yellowbrick: 1.5
2025-12-11 15:14:10,466:INFO:              plotly: 6.5.0
2025-12-11 15:14:10,466:INFO:    plotly-resampler: Not installed
2025-12-11 15:14:10,466:INFO:             kaleido: 1.2.0
2025-12-11 15:14:10,466:INFO:           schemdraw: 0.15
2025-12-11 15:14:10,466:INFO:         statsmodels: 0.14.5
2025-12-11 15:14:10,466:INFO:              sktime: 0.26.0
2025-12-11 15:14:10,466:INFO:               tbats: 1.1.3
2025-12-11 15:14:10,466:INFO:            pmdarima: 2.0.4
2025-12-11 15:14:10,466:INFO:              psutil: 7.1.3
2025-12-11 15:14:10,466:INFO:          markupsafe: 3.0.3
2025-12-11 15:14:10,466:INFO:             pickle5: Not installed
2025-12-11 15:14:10,466:INFO:         cloudpickle: 3.1.2
2025-12-11 15:14:10,466:INFO:         deprecation: 2.1.0
2025-12-11 15:14:10,466:INFO:              xxhash: 3.6.0
2025-12-11 15:14:10,466:INFO:           wurlitzer: Not installed
2025-12-11 15:14:10,466:INFO:PyCaret optional dependencies:
2025-12-11 15:14:10,477:INFO:                shap: Not installed
2025-12-11 15:14:10,477:INFO:           interpret: Not installed
2025-12-11 15:14:10,477:INFO:                umap: Not installed
2025-12-11 15:14:10,477:INFO:     ydata_profiling: Not installed
2025-12-11 15:14:10,477:INFO:  explainerdashboard: Not installed
2025-12-11 15:14:10,477:INFO:             autoviz: Not installed
2025-12-11 15:14:10,477:INFO:           fairlearn: Not installed
2025-12-11 15:14:10,477:INFO:          deepchecks: Not installed
2025-12-11 15:14:10,477:INFO:             xgboost: Not installed
2025-12-11 15:14:10,477:INFO:            catboost: Not installed
2025-12-11 15:14:10,478:INFO:              kmodes: Not installed
2025-12-11 15:14:10,478:INFO:             mlxtend: Not installed
2025-12-11 15:14:10,478:INFO:       statsforecast: Not installed
2025-12-11 15:14:10,478:INFO:        tune_sklearn: Not installed
2025-12-11 15:14:10,478:INFO:                 ray: Not installed
2025-12-11 15:14:10,478:INFO:            hyperopt: Not installed
2025-12-11 15:14:10,478:INFO:              optuna: Not installed
2025-12-11 15:14:10,478:INFO:               skopt: Not installed
2025-12-11 15:14:10,478:INFO:              mlflow: Not installed
2025-12-11 15:14:10,478:INFO:              gradio: Not installed
2025-12-11 15:14:10,478:INFO:             fastapi: Not installed
2025-12-11 15:14:10,478:INFO:             uvicorn: Not installed
2025-12-11 15:14:10,479:INFO:              m2cgen: Not installed
2025-12-11 15:14:10,479:INFO:           evidently: Not installed
2025-12-11 15:14:10,479:INFO:               fugue: Not installed
2025-12-11 15:14:10,479:INFO:           streamlit: Not installed
2025-12-11 15:14:10,479:INFO:             prophet: Not installed
2025-12-11 15:14:10,479:INFO:None
2025-12-11 15:14:10,479:INFO:Set up data.
2025-12-11 15:14:10,491:INFO:Set up folding strategy.
2025-12-11 15:14:10,492:INFO:Set up train/test split.
2025-12-11 15:14:10,498:INFO:Set up index.
2025-12-11 15:14:10,498:INFO:Assigning column types.
2025-12-11 15:14:10,504:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-11 15:14:10,506:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,510:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,516:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:10,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:10,645:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,650:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,656:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,724:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,774:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:10,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:10,776:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-11 15:14:10,781:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,786:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:10,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:10,910:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:14:10,981:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,033:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-11 15:14:11,044:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,111:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,173:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,323:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-11 15:14:11,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,529:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,580:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-11 15:14:11,657:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:14:11,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,846:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-11 15:14:11,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:11,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:12,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:12,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:12,102:INFO:Preparing preprocessing pipeline...
2025-12-11 15:14:12,102:INFO:Set up simple imputation.
2025-12-11 15:14:12,102:INFO:Set up feature normalization.
2025-12-11 15:14:12,104:INFO:Set up column name cleaning.
2025-12-11 15:14:12,215:INFO:Finished creating preprocessing pipeline.
2025-12-11 15:14:12,223:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner_Test Drive Car',
                                             'owner_Third Owner'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-12-11 15:14:12,223:INFO:Creating final display dataframe.
2025-12-11 15:14:12,369:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 18)
4        Transformed data shape        (7906, 16)
5   Transformed train set shape        (5534, 16)
6    Transformed test set shape        (2372, 16)
7               Ignore features                 2
8              Numeric features                15
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              c365
2025-12-11 15:14:12,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:12,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:12,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:12,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:14:12,625:INFO:setup() successfully completed in 2.23s...............
2025-12-11 15:14:12,626:INFO:Initializing compare_models()
2025-12-11 15:14:12,626:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-11 15:14:12,626:INFO:Checking exceptions
2025-12-11 15:14:12,629:INFO:Preparing display monitor
2025-12-11 15:14:12,658:INFO:Initializing Linear Regression
2025-12-11 15:14:12,688:INFO:Total runtime is 0.0004997094472249349 minutes
2025-12-11 15:14:12,693:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:12,693:INFO:Initializing create_model()
2025-12-11 15:14:12,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:12,695:INFO:Checking exceptions
2025-12-11 15:14:12,695:INFO:Importing libraries
2025-12-11 15:14:12,695:INFO:Copying training dataset
2025-12-11 15:14:12,705:INFO:Defining folds
2025-12-11 15:14:12,705:INFO:Declaring metric variables
2025-12-11 15:14:12,710:INFO:Importing untrained model
2025-12-11 15:14:12,714:INFO:Linear Regression Imported successfully
2025-12-11 15:14:12,725:INFO:Starting cross validation
2025-12-11 15:14:12,737:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:18,731:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,752:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,754:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,754:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,768:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,771:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,775:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,779:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,785:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:18,797:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:19,191:INFO:Calculating mean and std
2025-12-11 15:14:19,195:INFO:Creating metrics dataframe
2025-12-11 15:14:19,199:INFO:Uploading results into container
2025-12-11 15:14:19,201:INFO:Uploading model into container now
2025-12-11 15:14:19,202:INFO:_master_model_container: 1
2025-12-11 15:14:19,203:INFO:_display_container: 2
2025-12-11 15:14:19,203:INFO:LinearRegression(n_jobs=-1)
2025-12-11 15:14:19,203:INFO:create_model() successfully completed......................................
2025-12-11 15:14:19,393:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:19,394:INFO:Creating metrics dataframe
2025-12-11 15:14:19,402:INFO:Initializing Lasso Regression
2025-12-11 15:14:19,402:INFO:Total runtime is 0.11239041487375896 minutes
2025-12-11 15:14:19,407:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:19,407:INFO:Initializing create_model()
2025-12-11 15:14:19,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:19,407:INFO:Checking exceptions
2025-12-11 15:14:19,407:INFO:Importing libraries
2025-12-11 15:14:19,407:INFO:Copying training dataset
2025-12-11 15:14:19,417:INFO:Defining folds
2025-12-11 15:14:19,417:INFO:Declaring metric variables
2025-12-11 15:14:19,423:INFO:Importing untrained model
2025-12-11 15:14:19,429:INFO:Lasso Regression Imported successfully
2025-12-11 15:14:19,440:INFO:Starting cross validation
2025-12-11 15:14:19,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:19,584:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.296e+11, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-11 15:14:19,587:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e+11, tolerance: 3.109e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-11 15:14:23,163:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:23,165:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:23,179:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:23,187:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:23,204:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:23,224:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-11 15:14:23,460:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.119e+11, tolerance: 3.154e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-11 15:14:23,541:INFO:Calculating mean and std
2025-12-11 15:14:23,543:INFO:Creating metrics dataframe
2025-12-11 15:14:23,546:INFO:Uploading results into container
2025-12-11 15:14:23,547:INFO:Uploading model into container now
2025-12-11 15:14:23,548:INFO:_master_model_container: 2
2025-12-11 15:14:23,548:INFO:_display_container: 2
2025-12-11 15:14:23,548:INFO:Lasso(random_state=123)
2025-12-11 15:14:23,549:INFO:create_model() successfully completed......................................
2025-12-11 15:14:23,660:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:23,660:INFO:Creating metrics dataframe
2025-12-11 15:14:23,668:INFO:Initializing Ridge Regression
2025-12-11 15:14:23,668:INFO:Total runtime is 0.18350219329198203 minutes
2025-12-11 15:14:23,674:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:23,675:INFO:Initializing create_model()
2025-12-11 15:14:23,675:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:23,675:INFO:Checking exceptions
2025-12-11 15:14:23,675:INFO:Importing libraries
2025-12-11 15:14:23,675:INFO:Copying training dataset
2025-12-11 15:14:23,682:INFO:Defining folds
2025-12-11 15:14:23,682:INFO:Declaring metric variables
2025-12-11 15:14:23,688:INFO:Importing untrained model
2025-12-11 15:14:23,695:INFO:Ridge Regression Imported successfully
2025-12-11 15:14:23,704:INFO:Starting cross validation
2025-12-11 15:14:23,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:23,825:INFO:Calculating mean and std
2025-12-11 15:14:23,826:INFO:Creating metrics dataframe
2025-12-11 15:14:23,829:INFO:Uploading results into container
2025-12-11 15:14:23,829:INFO:Uploading model into container now
2025-12-11 15:14:23,830:INFO:_master_model_container: 3
2025-12-11 15:14:23,831:INFO:_display_container: 2
2025-12-11 15:14:23,831:INFO:Ridge(random_state=123)
2025-12-11 15:14:23,831:INFO:create_model() successfully completed......................................
2025-12-11 15:14:23,929:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:23,930:INFO:Creating metrics dataframe
2025-12-11 15:14:23,938:INFO:Initializing Elastic Net
2025-12-11 15:14:23,939:INFO:Total runtime is 0.1880070408185323 minutes
2025-12-11 15:14:23,943:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:23,945:INFO:Initializing create_model()
2025-12-11 15:14:23,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:23,945:INFO:Checking exceptions
2025-12-11 15:14:23,945:INFO:Importing libraries
2025-12-11 15:14:23,945:INFO:Copying training dataset
2025-12-11 15:14:23,952:INFO:Defining folds
2025-12-11 15:14:23,952:INFO:Declaring metric variables
2025-12-11 15:14:23,959:INFO:Importing untrained model
2025-12-11 15:14:23,964:INFO:Elastic Net Imported successfully
2025-12-11 15:14:23,973:INFO:Starting cross validation
2025-12-11 15:14:23,975:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:24,096:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e+12, tolerance: 3.109e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-11 15:14:24,125:INFO:Calculating mean and std
2025-12-11 15:14:24,128:INFO:Creating metrics dataframe
2025-12-11 15:14:24,129:INFO:Uploading results into container
2025-12-11 15:14:24,129:INFO:Uploading model into container now
2025-12-11 15:14:24,131:INFO:_master_model_container: 4
2025-12-11 15:14:24,131:INFO:_display_container: 2
2025-12-11 15:14:24,131:INFO:ElasticNet(random_state=123)
2025-12-11 15:14:24,131:INFO:create_model() successfully completed......................................
2025-12-11 15:14:24,227:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:24,227:INFO:Creating metrics dataframe
2025-12-11 15:14:24,240:INFO:Initializing Least Angle Regression
2025-12-11 15:14:24,240:INFO:Total runtime is 0.19302688042322794 minutes
2025-12-11 15:14:24,245:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:24,246:INFO:Initializing create_model()
2025-12-11 15:14:24,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:24,246:INFO:Checking exceptions
2025-12-11 15:14:24,246:INFO:Importing libraries
2025-12-11 15:14:24,246:INFO:Copying training dataset
2025-12-11 15:14:24,254:INFO:Defining folds
2025-12-11 15:14:24,254:INFO:Declaring metric variables
2025-12-11 15:14:24,260:INFO:Importing untrained model
2025-12-11 15:14:24,264:INFO:Least Angle Regression Imported successfully
2025-12-11 15:14:24,275:INFO:Starting cross validation
2025-12-11 15:14:24,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:24,390:INFO:Calculating mean and std
2025-12-11 15:14:24,392:INFO:Creating metrics dataframe
2025-12-11 15:14:24,395:INFO:Uploading results into container
2025-12-11 15:14:24,395:INFO:Uploading model into container now
2025-12-11 15:14:24,395:INFO:_master_model_container: 5
2025-12-11 15:14:24,395:INFO:_display_container: 2
2025-12-11 15:14:24,397:INFO:Lars(random_state=123)
2025-12-11 15:14:24,397:INFO:create_model() successfully completed......................................
2025-12-11 15:14:24,496:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:24,496:INFO:Creating metrics dataframe
2025-12-11 15:14:24,506:INFO:Initializing Lasso Least Angle Regression
2025-12-11 15:14:24,507:INFO:Total runtime is 0.19747767051060994 minutes
2025-12-11 15:14:24,512:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:24,512:INFO:Initializing create_model()
2025-12-11 15:14:24,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:24,512:INFO:Checking exceptions
2025-12-11 15:14:24,512:INFO:Importing libraries
2025-12-11 15:14:24,512:INFO:Copying training dataset
2025-12-11 15:14:24,520:INFO:Defining folds
2025-12-11 15:14:24,520:INFO:Declaring metric variables
2025-12-11 15:14:24,528:INFO:Importing untrained model
2025-12-11 15:14:24,533:INFO:Lasso Least Angle Regression Imported successfully
2025-12-11 15:14:24,543:INFO:Starting cross validation
2025-12-11 15:14:24,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:24,658:INFO:Calculating mean and std
2025-12-11 15:14:24,660:INFO:Creating metrics dataframe
2025-12-11 15:14:24,663:INFO:Uploading results into container
2025-12-11 15:14:24,664:INFO:Uploading model into container now
2025-12-11 15:14:24,665:INFO:_master_model_container: 6
2025-12-11 15:14:24,665:INFO:_display_container: 2
2025-12-11 15:14:24,666:INFO:LassoLars(random_state=123)
2025-12-11 15:14:24,666:INFO:create_model() successfully completed......................................
2025-12-11 15:14:24,763:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:24,763:INFO:Creating metrics dataframe
2025-12-11 15:14:24,772:INFO:Initializing Orthogonal Matching Pursuit
2025-12-11 15:14:24,774:INFO:Total runtime is 0.2018996755282084 minutes
2025-12-11 15:14:24,778:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:24,780:INFO:Initializing create_model()
2025-12-11 15:14:24,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:24,780:INFO:Checking exceptions
2025-12-11 15:14:24,780:INFO:Importing libraries
2025-12-11 15:14:24,780:INFO:Copying training dataset
2025-12-11 15:14:24,789:INFO:Defining folds
2025-12-11 15:14:24,790:INFO:Declaring metric variables
2025-12-11 15:14:24,794:INFO:Importing untrained model
2025-12-11 15:14:24,800:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-11 15:14:24,809:INFO:Starting cross validation
2025-12-11 15:14:24,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:24,922:INFO:Calculating mean and std
2025-12-11 15:14:24,956:INFO:Creating metrics dataframe
2025-12-11 15:14:24,960:INFO:Uploading results into container
2025-12-11 15:14:24,961:INFO:Uploading model into container now
2025-12-11 15:14:24,962:INFO:_master_model_container: 7
2025-12-11 15:14:24,962:INFO:_display_container: 2
2025-12-11 15:14:24,962:INFO:OrthogonalMatchingPursuit()
2025-12-11 15:14:24,963:INFO:create_model() successfully completed......................................
2025-12-11 15:14:25,060:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:25,060:INFO:Creating metrics dataframe
2025-12-11 15:14:25,069:INFO:Initializing Bayesian Ridge
2025-12-11 15:14:25,070:INFO:Total runtime is 0.20686814387639363 minutes
2025-12-11 15:14:25,074:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:25,076:INFO:Initializing create_model()
2025-12-11 15:14:25,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:25,076:INFO:Checking exceptions
2025-12-11 15:14:25,076:INFO:Importing libraries
2025-12-11 15:14:25,076:INFO:Copying training dataset
2025-12-11 15:14:25,085:INFO:Defining folds
2025-12-11 15:14:25,086:INFO:Declaring metric variables
2025-12-11 15:14:25,090:INFO:Importing untrained model
2025-12-11 15:14:25,096:INFO:Bayesian Ridge Imported successfully
2025-12-11 15:14:25,106:INFO:Starting cross validation
2025-12-11 15:14:25,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:25,226:INFO:Calculating mean and std
2025-12-11 15:14:25,227:INFO:Creating metrics dataframe
2025-12-11 15:14:25,230:INFO:Uploading results into container
2025-12-11 15:14:25,231:INFO:Uploading model into container now
2025-12-11 15:14:25,232:INFO:_master_model_container: 8
2025-12-11 15:14:25,233:INFO:_display_container: 2
2025-12-11 15:14:25,233:INFO:BayesianRidge()
2025-12-11 15:14:25,233:INFO:create_model() successfully completed......................................
2025-12-11 15:14:25,330:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:25,330:INFO:Creating metrics dataframe
2025-12-11 15:14:25,338:INFO:Initializing Passive Aggressive Regressor
2025-12-11 15:14:25,338:INFO:Total runtime is 0.21132824818293253 minutes
2025-12-11 15:14:25,344:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:25,344:INFO:Initializing create_model()
2025-12-11 15:14:25,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:25,344:INFO:Checking exceptions
2025-12-11 15:14:25,344:INFO:Importing libraries
2025-12-11 15:14:25,344:INFO:Copying training dataset
2025-12-11 15:14:25,352:INFO:Defining folds
2025-12-11 15:14:25,352:INFO:Declaring metric variables
2025-12-11 15:14:25,358:INFO:Importing untrained model
2025-12-11 15:14:25,363:INFO:Passive Aggressive Regressor Imported successfully
2025-12-11 15:14:25,375:INFO:Starting cross validation
2025-12-11 15:14:25,377:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:26,022:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:14:26,023:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:14:26,023:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:14:26,024:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:14:26,024:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:14:26,024:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:14:26,136:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:14:26,186:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:14:26,306:INFO:Calculating mean and std
2025-12-11 15:14:26,308:INFO:Creating metrics dataframe
2025-12-11 15:14:26,311:INFO:Uploading results into container
2025-12-11 15:14:26,312:INFO:Uploading model into container now
2025-12-11 15:14:26,313:INFO:_master_model_container: 9
2025-12-11 15:14:26,313:INFO:_display_container: 2
2025-12-11 15:14:26,313:INFO:PassiveAggressiveRegressor(random_state=123)
2025-12-11 15:14:26,314:INFO:create_model() successfully completed......................................
2025-12-11 15:14:26,409:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:26,409:INFO:Creating metrics dataframe
2025-12-11 15:14:26,420:INFO:Initializing Huber Regressor
2025-12-11 15:14:26,420:INFO:Total runtime is 0.22937132120132445 minutes
2025-12-11 15:14:26,427:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:26,427:INFO:Initializing create_model()
2025-12-11 15:14:26,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:26,427:INFO:Checking exceptions
2025-12-11 15:14:26,427:INFO:Importing libraries
2025-12-11 15:14:26,427:INFO:Copying training dataset
2025-12-11 15:14:26,437:INFO:Defining folds
2025-12-11 15:14:26,437:INFO:Declaring metric variables
2025-12-11 15:14:26,446:INFO:Importing untrained model
2025-12-11 15:14:26,454:INFO:Huber Regressor Imported successfully
2025-12-11 15:14:26,467:INFO:Starting cross validation
2025-12-11 15:14:26,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:26,674:INFO:Calculating mean and std
2025-12-11 15:14:26,676:INFO:Creating metrics dataframe
2025-12-11 15:14:26,678:INFO:Uploading results into container
2025-12-11 15:14:26,679:INFO:Uploading model into container now
2025-12-11 15:14:26,679:INFO:_master_model_container: 10
2025-12-11 15:14:26,679:INFO:_display_container: 2
2025-12-11 15:14:26,680:INFO:HuberRegressor()
2025-12-11 15:14:26,680:INFO:create_model() successfully completed......................................
2025-12-11 15:14:26,776:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:26,776:INFO:Creating metrics dataframe
2025-12-11 15:14:26,786:INFO:Initializing K Neighbors Regressor
2025-12-11 15:14:26,786:INFO:Total runtime is 0.23546641270319618 minutes
2025-12-11 15:14:26,791:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:26,792:INFO:Initializing create_model()
2025-12-11 15:14:26,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:26,793:INFO:Checking exceptions
2025-12-11 15:14:26,793:INFO:Importing libraries
2025-12-11 15:14:26,793:INFO:Copying training dataset
2025-12-11 15:14:26,801:INFO:Defining folds
2025-12-11 15:14:26,801:INFO:Declaring metric variables
2025-12-11 15:14:26,804:INFO:Importing untrained model
2025-12-11 15:14:26,812:INFO:K Neighbors Regressor Imported successfully
2025-12-11 15:14:26,821:INFO:Starting cross validation
2025-12-11 15:14:26,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:27,090:INFO:Calculating mean and std
2025-12-11 15:14:27,091:INFO:Creating metrics dataframe
2025-12-11 15:14:27,094:INFO:Uploading results into container
2025-12-11 15:14:27,095:INFO:Uploading model into container now
2025-12-11 15:14:27,095:INFO:_master_model_container: 11
2025-12-11 15:14:27,095:INFO:_display_container: 2
2025-12-11 15:14:27,095:INFO:KNeighborsRegressor(n_jobs=-1)
2025-12-11 15:14:27,095:INFO:create_model() successfully completed......................................
2025-12-11 15:14:27,192:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:27,192:INFO:Creating metrics dataframe
2025-12-11 15:14:27,205:INFO:Initializing Decision Tree Regressor
2025-12-11 15:14:27,205:INFO:Total runtime is 0.2424503405888875 minutes
2025-12-11 15:14:27,210:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:27,210:INFO:Initializing create_model()
2025-12-11 15:14:27,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:27,211:INFO:Checking exceptions
2025-12-11 15:14:27,211:INFO:Importing libraries
2025-12-11 15:14:27,211:INFO:Copying training dataset
2025-12-11 15:14:27,220:INFO:Defining folds
2025-12-11 15:14:27,220:INFO:Declaring metric variables
2025-12-11 15:14:27,225:INFO:Importing untrained model
2025-12-11 15:14:27,231:INFO:Decision Tree Regressor Imported successfully
2025-12-11 15:14:27,240:INFO:Starting cross validation
2025-12-11 15:14:27,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:27,388:INFO:Calculating mean and std
2025-12-11 15:14:27,390:INFO:Creating metrics dataframe
2025-12-11 15:14:27,391:INFO:Uploading results into container
2025-12-11 15:14:27,393:INFO:Uploading model into container now
2025-12-11 15:14:27,394:INFO:_master_model_container: 12
2025-12-11 15:14:27,394:INFO:_display_container: 2
2025-12-11 15:14:27,394:INFO:DecisionTreeRegressor(random_state=123)
2025-12-11 15:14:27,394:INFO:create_model() successfully completed......................................
2025-12-11 15:14:27,488:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:27,488:INFO:Creating metrics dataframe
2025-12-11 15:14:27,503:INFO:Initializing Random Forest Regressor
2025-12-11 15:14:27,503:INFO:Total runtime is 0.2474166711171468 minutes
2025-12-11 15:14:27,508:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:27,509:INFO:Initializing create_model()
2025-12-11 15:14:27,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:27,510:INFO:Checking exceptions
2025-12-11 15:14:27,510:INFO:Importing libraries
2025-12-11 15:14:27,510:INFO:Copying training dataset
2025-12-11 15:14:27,517:INFO:Defining folds
2025-12-11 15:14:27,518:INFO:Declaring metric variables
2025-12-11 15:14:27,522:INFO:Importing untrained model
2025-12-11 15:14:27,529:INFO:Random Forest Regressor Imported successfully
2025-12-11 15:14:27,538:INFO:Starting cross validation
2025-12-11 15:14:27,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:29,495:INFO:Calculating mean and std
2025-12-11 15:14:29,497:INFO:Creating metrics dataframe
2025-12-11 15:14:29,499:INFO:Uploading results into container
2025-12-11 15:14:29,500:INFO:Uploading model into container now
2025-12-11 15:14:29,501:INFO:_master_model_container: 13
2025-12-11 15:14:29,501:INFO:_display_container: 2
2025-12-11 15:14:29,501:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-12-11 15:14:29,502:INFO:create_model() successfully completed......................................
2025-12-11 15:14:29,597:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:29,597:INFO:Creating metrics dataframe
2025-12-11 15:14:29,609:INFO:Initializing Extra Trees Regressor
2025-12-11 15:14:29,610:INFO:Total runtime is 0.2825079202651977 minutes
2025-12-11 15:14:29,615:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:29,615:INFO:Initializing create_model()
2025-12-11 15:14:29,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:29,615:INFO:Checking exceptions
2025-12-11 15:14:29,616:INFO:Importing libraries
2025-12-11 15:14:29,616:INFO:Copying training dataset
2025-12-11 15:14:29,624:INFO:Defining folds
2025-12-11 15:14:29,624:INFO:Declaring metric variables
2025-12-11 15:14:29,631:INFO:Importing untrained model
2025-12-11 15:14:29,636:INFO:Extra Trees Regressor Imported successfully
2025-12-11 15:14:29,647:INFO:Starting cross validation
2025-12-11 15:14:29,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:31,115:INFO:Calculating mean and std
2025-12-11 15:14:31,118:INFO:Creating metrics dataframe
2025-12-11 15:14:31,123:INFO:Uploading results into container
2025-12-11 15:14:31,125:INFO:Uploading model into container now
2025-12-11 15:14:31,127:INFO:_master_model_container: 14
2025-12-11 15:14:31,127:INFO:_display_container: 2
2025-12-11 15:14:31,128:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-11 15:14:31,128:INFO:create_model() successfully completed......................................
2025-12-11 15:14:31,235:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:31,235:INFO:Creating metrics dataframe
2025-12-11 15:14:31,247:INFO:Initializing AdaBoost Regressor
2025-12-11 15:14:31,247:INFO:Total runtime is 0.3098218242327372 minutes
2025-12-11 15:14:31,252:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:31,252:INFO:Initializing create_model()
2025-12-11 15:14:31,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:31,254:INFO:Checking exceptions
2025-12-11 15:14:31,254:INFO:Importing libraries
2025-12-11 15:14:31,254:INFO:Copying training dataset
2025-12-11 15:14:31,262:INFO:Defining folds
2025-12-11 15:14:31,262:INFO:Declaring metric variables
2025-12-11 15:14:31,268:INFO:Importing untrained model
2025-12-11 15:14:31,273:INFO:AdaBoost Regressor Imported successfully
2025-12-11 15:14:31,283:INFO:Starting cross validation
2025-12-11 15:14:31,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:31,760:INFO:Calculating mean and std
2025-12-11 15:14:31,761:INFO:Creating metrics dataframe
2025-12-11 15:14:31,765:INFO:Uploading results into container
2025-12-11 15:14:31,766:INFO:Uploading model into container now
2025-12-11 15:14:31,766:INFO:_master_model_container: 15
2025-12-11 15:14:31,766:INFO:_display_container: 2
2025-12-11 15:14:31,767:INFO:AdaBoostRegressor(random_state=123)
2025-12-11 15:14:31,767:INFO:create_model() successfully completed......................................
2025-12-11 15:14:31,863:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:31,863:INFO:Creating metrics dataframe
2025-12-11 15:14:31,874:INFO:Initializing Gradient Boosting Regressor
2025-12-11 15:14:31,874:INFO:Total runtime is 0.32027259270350134 minutes
2025-12-11 15:14:31,880:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:31,881:INFO:Initializing create_model()
2025-12-11 15:14:31,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:31,881:INFO:Checking exceptions
2025-12-11 15:14:31,881:INFO:Importing libraries
2025-12-11 15:14:31,881:INFO:Copying training dataset
2025-12-11 15:14:31,892:INFO:Defining folds
2025-12-11 15:14:31,893:INFO:Declaring metric variables
2025-12-11 15:14:31,897:INFO:Importing untrained model
2025-12-11 15:14:31,904:INFO:Gradient Boosting Regressor Imported successfully
2025-12-11 15:14:31,913:INFO:Starting cross validation
2025-12-11 15:14:31,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:32,612:INFO:Calculating mean and std
2025-12-11 15:14:32,613:INFO:Creating metrics dataframe
2025-12-11 15:14:32,614:INFO:Uploading results into container
2025-12-11 15:14:32,614:INFO:Uploading model into container now
2025-12-11 15:14:32,616:INFO:_master_model_container: 16
2025-12-11 15:14:32,617:INFO:_display_container: 2
2025-12-11 15:14:32,618:INFO:GradientBoostingRegressor(random_state=123)
2025-12-11 15:14:32,618:INFO:create_model() successfully completed......................................
2025-12-11 15:14:32,713:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:32,713:INFO:Creating metrics dataframe
2025-12-11 15:14:32,724:INFO:Initializing Light Gradient Boosting Machine
2025-12-11 15:14:32,724:INFO:Total runtime is 0.33443211714426674 minutes
2025-12-11 15:14:32,731:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:32,731:INFO:Initializing create_model()
2025-12-11 15:14:32,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:32,732:INFO:Checking exceptions
2025-12-11 15:14:32,732:INFO:Importing libraries
2025-12-11 15:14:32,732:INFO:Copying training dataset
2025-12-11 15:14:32,739:INFO:Defining folds
2025-12-11 15:14:32,740:INFO:Declaring metric variables
2025-12-11 15:14:32,745:INFO:Importing untrained model
2025-12-11 15:14:32,752:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-11 15:14:32,761:INFO:Starting cross validation
2025-12-11 15:14:32,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:33,828:INFO:Calculating mean and std
2025-12-11 15:14:33,831:INFO:Creating metrics dataframe
2025-12-11 15:14:33,835:INFO:Uploading results into container
2025-12-11 15:14:33,836:INFO:Uploading model into container now
2025-12-11 15:14:33,837:INFO:_master_model_container: 17
2025-12-11 15:14:33,837:INFO:_display_container: 2
2025-12-11 15:14:33,839:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-12-11 15:14:33,839:INFO:create_model() successfully completed......................................
2025-12-11 15:14:33,955:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:33,955:INFO:Creating metrics dataframe
2025-12-11 15:14:33,970:INFO:Initializing Dummy Regressor
2025-12-11 15:14:33,970:INFO:Total runtime is 0.3552014589309692 minutes
2025-12-11 15:14:33,975:INFO:SubProcess create_model() called ==================================
2025-12-11 15:14:33,975:INFO:Initializing create_model()
2025-12-11 15:14:33,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F5BF6A70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:33,976:INFO:Checking exceptions
2025-12-11 15:14:33,976:INFO:Importing libraries
2025-12-11 15:14:33,976:INFO:Copying training dataset
2025-12-11 15:14:33,984:INFO:Defining folds
2025-12-11 15:14:33,984:INFO:Declaring metric variables
2025-12-11 15:14:33,992:INFO:Importing untrained model
2025-12-11 15:14:33,996:INFO:Dummy Regressor Imported successfully
2025-12-11 15:14:34,005:INFO:Starting cross validation
2025-12-11 15:14:34,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:14:34,141:INFO:Calculating mean and std
2025-12-11 15:14:34,142:INFO:Creating metrics dataframe
2025-12-11 15:14:34,144:INFO:Uploading results into container
2025-12-11 15:14:34,145:INFO:Uploading model into container now
2025-12-11 15:14:34,146:INFO:_master_model_container: 18
2025-12-11 15:14:34,146:INFO:_display_container: 2
2025-12-11 15:14:34,146:INFO:DummyRegressor()
2025-12-11 15:14:34,146:INFO:create_model() successfully completed......................................
2025-12-11 15:14:34,242:INFO:SubProcess create_model() end ==================================
2025-12-11 15:14:34,242:INFO:Creating metrics dataframe
2025-12-11 15:14:34,260:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-11 15:14:34,270:INFO:Initializing create_model()
2025-12-11 15:14:34,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:14:34,271:INFO:Checking exceptions
2025-12-11 15:14:34,274:INFO:Importing libraries
2025-12-11 15:14:34,274:INFO:Copying training dataset
2025-12-11 15:14:34,281:INFO:Defining folds
2025-12-11 15:14:34,282:INFO:Declaring metric variables
2025-12-11 15:14:34,282:INFO:Importing untrained model
2025-12-11 15:14:34,282:INFO:Declaring custom model
2025-12-11 15:14:34,284:INFO:Extra Trees Regressor Imported successfully
2025-12-11 15:14:34,284:INFO:Cross validation set to False
2025-12-11 15:14:34,284:INFO:Fitting Model
2025-12-11 15:14:34,511:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-11 15:14:34,511:INFO:create_model() successfully completed......................................
2025-12-11 15:14:34,645:INFO:_master_model_container: 18
2025-12-11 15:14:34,645:INFO:_display_container: 2
2025-12-11 15:14:34,645:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-11 15:14:34,645:INFO:compare_models() successfully completed......................................
2025-12-11 15:14:34,647:INFO:Initializing tune_model()
2025-12-11 15:14:34,647:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>)
2025-12-11 15:14:34,648:INFO:Checking exceptions
2025-12-11 15:14:34,672:INFO:Copying training dataset
2025-12-11 15:14:34,679:INFO:Checking base model
2025-12-11 15:14:34,680:INFO:Base model : Extra Trees Regressor
2025-12-11 15:14:34,685:INFO:Declaring metric variables
2025-12-11 15:14:34,720:INFO:Defining Hyperparameters
2025-12-11 15:14:34,825:INFO:Tuning with n_jobs=-1
2025-12-11 15:14:34,825:INFO:Initializing RandomizedSearchCV
2025-12-11 15:15:09,527:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2025-12-11 15:15:09,528:INFO:Hyperparameter search completed
2025-12-11 15:15:09,529:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:09,530:INFO:Initializing create_model()
2025-12-11 15:15:09,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F18EA650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2025-12-11 15:15:09,531:INFO:Checking exceptions
2025-12-11 15:15:09,532:INFO:Importing libraries
2025-12-11 15:15:09,532:INFO:Copying training dataset
2025-12-11 15:15:09,543:INFO:Defining folds
2025-12-11 15:15:09,543:INFO:Declaring metric variables
2025-12-11 15:15:09,548:INFO:Importing untrained model
2025-12-11 15:15:09,548:INFO:Declaring custom model
2025-12-11 15:15:09,555:INFO:Extra Trees Regressor Imported successfully
2025-12-11 15:15:09,567:INFO:Starting cross validation
2025-12-11 15:15:09,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:10,400:INFO:Calculating mean and std
2025-12-11 15:15:10,401:INFO:Creating metrics dataframe
2025-12-11 15:15:10,408:INFO:Finalizing model
2025-12-11 15:15:10,649:INFO:Uploading results into container
2025-12-11 15:15:10,651:INFO:Uploading model into container now
2025-12-11 15:15:10,651:INFO:_master_model_container: 19
2025-12-11 15:15:10,652:INFO:_display_container: 3
2025-12-11 15:15:10,652:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2025-12-11 15:15:10,653:INFO:create_model() successfully completed......................................
2025-12-11 15:15:10,753:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:10,753:INFO:choose_better activated
2025-12-11 15:15:10,758:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:10,759:INFO:Initializing create_model()
2025-12-11 15:15:10,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:10,759:INFO:Checking exceptions
2025-12-11 15:15:10,761:INFO:Importing libraries
2025-12-11 15:15:10,761:INFO:Copying training dataset
2025-12-11 15:15:10,770:INFO:Defining folds
2025-12-11 15:15:10,770:INFO:Declaring metric variables
2025-12-11 15:15:10,770:INFO:Importing untrained model
2025-12-11 15:15:10,770:INFO:Declaring custom model
2025-12-11 15:15:10,771:INFO:Extra Trees Regressor Imported successfully
2025-12-11 15:15:10,771:INFO:Starting cross validation
2025-12-11 15:15:10,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:12,267:INFO:Calculating mean and std
2025-12-11 15:15:12,268:INFO:Creating metrics dataframe
2025-12-11 15:15:12,271:INFO:Finalizing model
2025-12-11 15:15:12,503:INFO:Uploading results into container
2025-12-11 15:15:12,503:INFO:Uploading model into container now
2025-12-11 15:15:12,505:INFO:_master_model_container: 20
2025-12-11 15:15:12,505:INFO:_display_container: 4
2025-12-11 15:15:12,505:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-11 15:15:12,505:INFO:create_model() successfully completed......................................
2025-12-11 15:15:12,603:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:12,605:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9575
2025-12-11 15:15:12,605:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.9305
2025-12-11 15:15:12,605:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2025-12-11 15:15:12,605:INFO:choose_better completed
2025-12-11 15:15:12,605:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-11 15:15:12,620:INFO:_master_model_container: 20
2025-12-11 15:15:12,620:INFO:_display_container: 3
2025-12-11 15:15:12,622:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-12-11 15:15:12,622:INFO:tune_model() successfully completed......................................
2025-12-11 15:15:12,769:INFO:PyCaret ClassificationExperiment
2025-12-11 15:15:12,771:INFO:Logging name: clf-default-name
2025-12-11 15:15:12,771:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-11 15:15:12,771:INFO:version 3.3.2
2025-12-11 15:15:12,771:INFO:Initializing setup()
2025-12-11 15:15:12,771:INFO:self.USI: 9d85
2025-12-11 15:15:12,771:INFO:self._variable_keys: {'gpu_param', 'fold_shuffle_param', '_ml_usecase', 'memory', 'gpu_n_jobs_param', 'is_multiclass', 'seed', 'log_plots_param', 'exp_name_log', 'X', '_available_plots', 'fold_generator', 'exp_id', 'X_train', 'data', 'X_test', 'USI', 'y_test', 'target_param', 'fix_imbalance', 'y', 'idx', 'fold_groups_param', 'y_train', 'html_param', 'pipeline', 'n_jobs_param', 'logging_param'}
2025-12-11 15:15:12,771:INFO:Checking environment
2025-12-11 15:15:12,771:INFO:python_version: 3.10.19
2025-12-11 15:15:12,771:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-11 15:15:12,771:INFO:machine: AMD64
2025-12-11 15:15:12,771:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-11 15:15:12,772:INFO:Memory: svmem(total=33699516416, available=15081721856, percent=55.2, used=18617794560, free=15081721856)
2025-12-11 15:15:12,772:INFO:Physical Core: 8
2025-12-11 15:15:12,772:INFO:Logical Core: 16
2025-12-11 15:15:12,772:INFO:Checking libraries
2025-12-11 15:15:12,772:INFO:System:
2025-12-11 15:15:12,772:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-11 15:15:12,772:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-11 15:15:12,772:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-11 15:15:12,772:INFO:PyCaret required dependencies:
2025-12-11 15:15:12,772:INFO:                 pip: 25.3
2025-12-11 15:15:12,772:INFO:          setuptools: 80.9.0
2025-12-11 15:15:12,772:INFO:             pycaret: 3.3.2
2025-12-11 15:15:12,772:INFO:             IPython: 8.37.0
2025-12-11 15:15:12,772:INFO:          ipywidgets: 8.1.8
2025-12-11 15:15:12,772:INFO:                tqdm: 4.67.1
2025-12-11 15:15:12,772:INFO:               numpy: 1.26.4
2025-12-11 15:15:12,772:INFO:              pandas: 2.1.4
2025-12-11 15:15:12,772:INFO:              jinja2: 3.1.6
2025-12-11 15:15:12,772:INFO:               scipy: 1.11.4
2025-12-11 15:15:12,772:INFO:              joblib: 1.3.2
2025-12-11 15:15:12,772:INFO:             sklearn: 1.4.2
2025-12-11 15:15:12,772:INFO:                pyod: 2.0.6
2025-12-11 15:15:12,772:INFO:            imblearn: 0.14.0
2025-12-11 15:15:12,772:INFO:   category_encoders: 2.7.0
2025-12-11 15:15:12,772:INFO:            lightgbm: 4.6.0
2025-12-11 15:15:12,772:INFO:               numba: 0.62.1
2025-12-11 15:15:12,772:INFO:            requests: 2.32.5
2025-12-11 15:15:12,772:INFO:          matplotlib: 3.7.5
2025-12-11 15:15:12,772:INFO:          scikitplot: 0.3.7
2025-12-11 15:15:12,772:INFO:         yellowbrick: 1.5
2025-12-11 15:15:12,772:INFO:              plotly: 6.5.0
2025-12-11 15:15:12,772:INFO:    plotly-resampler: Not installed
2025-12-11 15:15:12,774:INFO:             kaleido: 1.2.0
2025-12-11 15:15:12,774:INFO:           schemdraw: 0.15
2025-12-11 15:15:12,774:INFO:         statsmodels: 0.14.5
2025-12-11 15:15:12,774:INFO:              sktime: 0.26.0
2025-12-11 15:15:12,774:INFO:               tbats: 1.1.3
2025-12-11 15:15:12,774:INFO:            pmdarima: 2.0.4
2025-12-11 15:15:12,774:INFO:              psutil: 7.1.3
2025-12-11 15:15:12,774:INFO:          markupsafe: 3.0.3
2025-12-11 15:15:12,774:INFO:             pickle5: Not installed
2025-12-11 15:15:12,774:INFO:         cloudpickle: 3.1.2
2025-12-11 15:15:12,774:INFO:         deprecation: 2.1.0
2025-12-11 15:15:12,774:INFO:              xxhash: 3.6.0
2025-12-11 15:15:12,774:INFO:           wurlitzer: Not installed
2025-12-11 15:15:12,774:INFO:PyCaret optional dependencies:
2025-12-11 15:15:12,774:INFO:                shap: Not installed
2025-12-11 15:15:12,774:INFO:           interpret: Not installed
2025-12-11 15:15:12,774:INFO:                umap: Not installed
2025-12-11 15:15:12,774:INFO:     ydata_profiling: Not installed
2025-12-11 15:15:12,774:INFO:  explainerdashboard: Not installed
2025-12-11 15:15:12,774:INFO:             autoviz: Not installed
2025-12-11 15:15:12,774:INFO:           fairlearn: Not installed
2025-12-11 15:15:12,774:INFO:          deepchecks: Not installed
2025-12-11 15:15:12,774:INFO:             xgboost: Not installed
2025-12-11 15:15:12,774:INFO:            catboost: Not installed
2025-12-11 15:15:12,774:INFO:              kmodes: Not installed
2025-12-11 15:15:12,774:INFO:             mlxtend: Not installed
2025-12-11 15:15:12,774:INFO:       statsforecast: Not installed
2025-12-11 15:15:12,774:INFO:        tune_sklearn: Not installed
2025-12-11 15:15:12,774:INFO:                 ray: Not installed
2025-12-11 15:15:12,774:INFO:            hyperopt: Not installed
2025-12-11 15:15:12,774:INFO:              optuna: Not installed
2025-12-11 15:15:12,774:INFO:               skopt: Not installed
2025-12-11 15:15:12,774:INFO:              mlflow: Not installed
2025-12-11 15:15:12,774:INFO:              gradio: Not installed
2025-12-11 15:15:12,776:INFO:             fastapi: Not installed
2025-12-11 15:15:12,776:INFO:             uvicorn: Not installed
2025-12-11 15:15:12,776:INFO:              m2cgen: Not installed
2025-12-11 15:15:12,776:INFO:           evidently: Not installed
2025-12-11 15:15:12,776:INFO:               fugue: Not installed
2025-12-11 15:15:12,776:INFO:           streamlit: Not installed
2025-12-11 15:15:12,776:INFO:             prophet: Not installed
2025-12-11 15:15:12,776:INFO:None
2025-12-11 15:15:12,776:INFO:Set up data.
2025-12-11 15:15:12,788:INFO:Set up folding strategy.
2025-12-11 15:15:12,788:INFO:Set up train/test split.
2025-12-11 15:15:12,798:INFO:Set up index.
2025-12-11 15:15:12,800:INFO:Assigning column types.
2025-12-11 15:15:12,808:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-11 15:15:12,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:15:12,869:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-11 15:15:12,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:12,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:12,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:15:12,965:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-11 15:15:12,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:12,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:12,998:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-11 15:15:13,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-11 15:15:13,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-11 15:15:13,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,174:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-11 15:15:13,262:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,349:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,351:INFO:Preparing preprocessing pipeline...
2025-12-11 15:15:13,352:INFO:Set up simple imputation.
2025-12-11 15:15:13,353:INFO:Set up imbalanced handling.
2025-12-11 15:15:13,354:INFO:Set up column name cleaning.
2025-12-11 15:15:13,453:INFO:Finished creating preprocessing pipeline.
2025-12-11 15:15:13,462:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-11 15:15:13,462:INFO:Creating final display dataframe.
2025-12-11 15:15:13,639:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 18)
4        Transformed data shape           (11982, 16)
5   Transformed train set shape            (9610, 16)
6    Transformed test set shape            (2372, 16)
7               Ignore features                     2
8              Numeric features                    15
9                    Preprocess                  True
10              Imputation type                simple
11           Numeric imputation                  mean
12       Categorical imputation                  mode
13                Fix imbalance                  True
14         Fix imbalance method                 SMOTE
15               Fold Generator       StratifiedKFold
16                  Fold Number                    10
17                     CPU Jobs                    -1
18                      Use GPU                 False
19               Log Experiment                 False
20              Experiment Name      clf-default-name
21                          USI                  9d85
2025-12-11 15:15:13,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:15:13,817:INFO:setup() successfully completed in 1.05s...............
2025-12-11 15:15:13,817:INFO:Initializing compare_models()
2025-12-11 15:15:13,817:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-11 15:15:13,817:INFO:Checking exceptions
2025-12-11 15:15:13,823:INFO:Preparing display monitor
2025-12-11 15:15:13,862:INFO:Initializing Logistic Regression
2025-12-11 15:15:13,862:INFO:Total runtime is 0.0 minutes
2025-12-11 15:15:13,871:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:13,871:INFO:Initializing create_model()
2025-12-11 15:15:13,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:13,871:INFO:Checking exceptions
2025-12-11 15:15:13,871:INFO:Importing libraries
2025-12-11 15:15:13,872:INFO:Copying training dataset
2025-12-11 15:15:13,883:INFO:Defining folds
2025-12-11 15:15:13,883:INFO:Declaring metric variables
2025-12-11 15:15:13,887:INFO:Importing untrained model
2025-12-11 15:15:13,894:INFO:Logistic Regression Imported successfully
2025-12-11 15:15:13,905:INFO:Starting cross validation
2025-12-11 15:15:13,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:15,402:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:15,534:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:15,579:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:15,602:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:15,605:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:15,630:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:15,639:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:15,639:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:15,685:INFO:Calculating mean and std
2025-12-11 15:15:15,688:INFO:Creating metrics dataframe
2025-12-11 15:15:15,690:INFO:Uploading results into container
2025-12-11 15:15:15,691:INFO:Uploading model into container now
2025-12-11 15:15:15,692:INFO:_master_model_container: 1
2025-12-11 15:15:15,693:INFO:_display_container: 2
2025-12-11 15:15:15,693:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-11 15:15:15,694:INFO:create_model() successfully completed......................................
2025-12-11 15:15:15,796:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:15,796:INFO:Creating metrics dataframe
2025-12-11 15:15:15,802:INFO:Initializing K Neighbors Classifier
2025-12-11 15:15:15,803:INFO:Total runtime is 0.03234548568725586 minutes
2025-12-11 15:15:15,808:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:15,809:INFO:Initializing create_model()
2025-12-11 15:15:15,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:15,809:INFO:Checking exceptions
2025-12-11 15:15:15,809:INFO:Importing libraries
2025-12-11 15:15:15,809:INFO:Copying training dataset
2025-12-11 15:15:15,819:INFO:Defining folds
2025-12-11 15:15:15,819:INFO:Declaring metric variables
2025-12-11 15:15:15,824:INFO:Importing untrained model
2025-12-11 15:15:15,832:INFO:K Neighbors Classifier Imported successfully
2025-12-11 15:15:15,842:INFO:Starting cross validation
2025-12-11 15:15:15,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:16,169:INFO:Calculating mean and std
2025-12-11 15:15:16,170:INFO:Creating metrics dataframe
2025-12-11 15:15:16,175:INFO:Uploading results into container
2025-12-11 15:15:16,178:INFO:Uploading model into container now
2025-12-11 15:15:16,179:INFO:_master_model_container: 2
2025-12-11 15:15:16,179:INFO:_display_container: 2
2025-12-11 15:15:16,179:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-11 15:15:16,180:INFO:create_model() successfully completed......................................
2025-12-11 15:15:16,278:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:16,289:INFO:Creating metrics dataframe
2025-12-11 15:15:16,298:INFO:Initializing Naive Bayes
2025-12-11 15:15:16,298:INFO:Total runtime is 0.0406015674273173 minutes
2025-12-11 15:15:16,305:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:16,305:INFO:Initializing create_model()
2025-12-11 15:15:16,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:16,305:INFO:Checking exceptions
2025-12-11 15:15:16,305:INFO:Importing libraries
2025-12-11 15:15:16,306:INFO:Copying training dataset
2025-12-11 15:15:16,316:INFO:Defining folds
2025-12-11 15:15:16,316:INFO:Declaring metric variables
2025-12-11 15:15:16,322:INFO:Importing untrained model
2025-12-11 15:15:16,329:INFO:Naive Bayes Imported successfully
2025-12-11 15:15:16,340:INFO:Starting cross validation
2025-12-11 15:15:16,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:16,503:INFO:Calculating mean and std
2025-12-11 15:15:16,505:INFO:Creating metrics dataframe
2025-12-11 15:15:16,507:INFO:Uploading results into container
2025-12-11 15:15:16,509:INFO:Uploading model into container now
2025-12-11 15:15:16,509:INFO:_master_model_container: 3
2025-12-11 15:15:16,510:INFO:_display_container: 2
2025-12-11 15:15:16,510:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-11 15:15:16,510:INFO:create_model() successfully completed......................................
2025-12-11 15:15:16,611:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:16,611:INFO:Creating metrics dataframe
2025-12-11 15:15:16,622:INFO:Initializing Decision Tree Classifier
2025-12-11 15:15:16,622:INFO:Total runtime is 0.04599732160568237 minutes
2025-12-11 15:15:16,627:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:16,628:INFO:Initializing create_model()
2025-12-11 15:15:16,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:16,628:INFO:Checking exceptions
2025-12-11 15:15:16,628:INFO:Importing libraries
2025-12-11 15:15:16,628:INFO:Copying training dataset
2025-12-11 15:15:16,638:INFO:Defining folds
2025-12-11 15:15:16,638:INFO:Declaring metric variables
2025-12-11 15:15:16,646:INFO:Importing untrained model
2025-12-11 15:15:16,653:INFO:Decision Tree Classifier Imported successfully
2025-12-11 15:15:16,663:INFO:Starting cross validation
2025-12-11 15:15:16,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:16,850:INFO:Calculating mean and std
2025-12-11 15:15:16,851:INFO:Creating metrics dataframe
2025-12-11 15:15:16,854:INFO:Uploading results into container
2025-12-11 15:15:16,856:INFO:Uploading model into container now
2025-12-11 15:15:16,856:INFO:_master_model_container: 4
2025-12-11 15:15:16,857:INFO:_display_container: 2
2025-12-11 15:15:16,857:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-11 15:15:16,857:INFO:create_model() successfully completed......................................
2025-12-11 15:15:16,960:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:16,960:INFO:Creating metrics dataframe
2025-12-11 15:15:16,969:INFO:Initializing SVM - Linear Kernel
2025-12-11 15:15:16,970:INFO:Total runtime is 0.05178780158360799 minutes
2025-12-11 15:15:16,975:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:16,976:INFO:Initializing create_model()
2025-12-11 15:15:16,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:16,976:INFO:Checking exceptions
2025-12-11 15:15:16,976:INFO:Importing libraries
2025-12-11 15:15:16,976:INFO:Copying training dataset
2025-12-11 15:15:16,987:INFO:Defining folds
2025-12-11 15:15:16,987:INFO:Declaring metric variables
2025-12-11 15:15:16,993:INFO:Importing untrained model
2025-12-11 15:15:16,999:INFO:SVM - Linear Kernel Imported successfully
2025-12-11 15:15:17,008:INFO:Starting cross validation
2025-12-11 15:15:17,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:17,257:INFO:Calculating mean and std
2025-12-11 15:15:17,259:INFO:Creating metrics dataframe
2025-12-11 15:15:17,261:INFO:Uploading results into container
2025-12-11 15:15:17,263:INFO:Uploading model into container now
2025-12-11 15:15:17,263:INFO:_master_model_container: 5
2025-12-11 15:15:17,263:INFO:_display_container: 2
2025-12-11 15:15:17,264:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-11 15:15:17,264:INFO:create_model() successfully completed......................................
2025-12-11 15:15:17,367:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:17,367:INFO:Creating metrics dataframe
2025-12-11 15:15:17,377:INFO:Initializing Ridge Classifier
2025-12-11 15:15:17,377:INFO:Total runtime is 0.058578924338022864 minutes
2025-12-11 15:15:17,381:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:17,382:INFO:Initializing create_model()
2025-12-11 15:15:17,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:17,382:INFO:Checking exceptions
2025-12-11 15:15:17,382:INFO:Importing libraries
2025-12-11 15:15:17,382:INFO:Copying training dataset
2025-12-11 15:15:17,393:INFO:Defining folds
2025-12-11 15:15:17,393:INFO:Declaring metric variables
2025-12-11 15:15:17,398:INFO:Importing untrained model
2025-12-11 15:15:17,405:INFO:Ridge Classifier Imported successfully
2025-12-11 15:15:17,420:INFO:Starting cross validation
2025-12-11 15:15:17,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:17,519:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.37492e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,519:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.17074e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,520:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.88649e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,520:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.12804e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,520:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.01165e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,522:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.28373e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,524:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.28724e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,528:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.1424e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,532:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.19698e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,538:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.31499e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:15:17,585:INFO:Calculating mean and std
2025-12-11 15:15:17,586:INFO:Creating metrics dataframe
2025-12-11 15:15:17,590:INFO:Uploading results into container
2025-12-11 15:15:17,591:INFO:Uploading model into container now
2025-12-11 15:15:17,592:INFO:_master_model_container: 6
2025-12-11 15:15:17,592:INFO:_display_container: 2
2025-12-11 15:15:17,592:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-11 15:15:17,592:INFO:create_model() successfully completed......................................
2025-12-11 15:15:17,693:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:17,693:INFO:Creating metrics dataframe
2025-12-11 15:15:17,703:INFO:Initializing Random Forest Classifier
2025-12-11 15:15:17,703:INFO:Total runtime is 0.0640071948369344 minutes
2025-12-11 15:15:17,709:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:17,709:INFO:Initializing create_model()
2025-12-11 15:15:17,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:17,709:INFO:Checking exceptions
2025-12-11 15:15:17,709:INFO:Importing libraries
2025-12-11 15:15:17,709:INFO:Copying training dataset
2025-12-11 15:15:17,719:INFO:Defining folds
2025-12-11 15:15:17,719:INFO:Declaring metric variables
2025-12-11 15:15:17,727:INFO:Importing untrained model
2025-12-11 15:15:17,733:INFO:Random Forest Classifier Imported successfully
2025-12-11 15:15:17,745:INFO:Starting cross validation
2025-12-11 15:15:17,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:19,122:INFO:Calculating mean and std
2025-12-11 15:15:19,125:INFO:Creating metrics dataframe
2025-12-11 15:15:19,129:INFO:Uploading results into container
2025-12-11 15:15:19,131:INFO:Uploading model into container now
2025-12-11 15:15:19,131:INFO:_master_model_container: 7
2025-12-11 15:15:19,132:INFO:_display_container: 2
2025-12-11 15:15:19,132:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-11 15:15:19,132:INFO:create_model() successfully completed......................................
2025-12-11 15:15:19,232:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:19,232:INFO:Creating metrics dataframe
2025-12-11 15:15:19,242:INFO:Initializing Quadratic Discriminant Analysis
2025-12-11 15:15:19,242:INFO:Total runtime is 0.08966600497563679 minutes
2025-12-11 15:15:19,249:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:19,249:INFO:Initializing create_model()
2025-12-11 15:15:19,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:19,251:INFO:Checking exceptions
2025-12-11 15:15:19,251:INFO:Importing libraries
2025-12-11 15:15:19,251:INFO:Copying training dataset
2025-12-11 15:15:19,262:INFO:Defining folds
2025-12-11 15:15:19,262:INFO:Declaring metric variables
2025-12-11 15:15:19,268:INFO:Importing untrained model
2025-12-11 15:15:19,275:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-11 15:15:19,287:INFO:Starting cross validation
2025-12-11 15:15:19,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:19,397:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,399:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,399:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,399:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,399:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,401:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,401:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,401:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,402:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,402:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:15:19,413:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,414:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,416:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,416:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

in self.scalings_])

2025-12-11 15:15:19,416:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:961: RuntimeWarning: overflow encountered in square
  norm2.append(np.sum(X2**2, axis=1))

2025-12-11 15:15:19,416:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,416:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

in self.scalings_])

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,417:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,419:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,419:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,419:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,419:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,420:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,420:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:961: RuntimeWarning: overflow encountered in square
  norm2.append(np.sum(X2**2, axis=1))

2025-12-11 15:15:19,420:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,421:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,421:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,421:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,421:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,421:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,422:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,422:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,422:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,422:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,422:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,422:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,424:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,424:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,424:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,424:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,425:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:15:19,425:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:15:19,433:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,433:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,433:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2025-12-11 15:15:19,433:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,433:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,433:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,435:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,435:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,435:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,435:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:15:19,445:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,446:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,448:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,449:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,449:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,449:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,450:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:19,465:INFO:Calculating mean and std
2025-12-11 15:15:19,468:INFO:Creating metrics dataframe
2025-12-11 15:15:19,470:INFO:Uploading results into container
2025-12-11 15:15:19,470:INFO:Uploading model into container now
2025-12-11 15:15:19,471:INFO:_master_model_container: 8
2025-12-11 15:15:19,471:INFO:_display_container: 2
2025-12-11 15:15:19,471:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-11 15:15:19,471:INFO:create_model() successfully completed......................................
2025-12-11 15:15:19,573:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:19,573:INFO:Creating metrics dataframe
2025-12-11 15:15:19,586:INFO:Initializing Ada Boost Classifier
2025-12-11 15:15:19,586:INFO:Total runtime is 0.09539088408152262 minutes
2025-12-11 15:15:19,591:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:19,592:INFO:Initializing create_model()
2025-12-11 15:15:19,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:19,592:INFO:Checking exceptions
2025-12-11 15:15:19,592:INFO:Importing libraries
2025-12-11 15:15:19,592:INFO:Copying training dataset
2025-12-11 15:15:19,602:INFO:Defining folds
2025-12-11 15:15:19,602:INFO:Declaring metric variables
2025-12-11 15:15:19,609:INFO:Importing untrained model
2025-12-11 15:15:19,616:INFO:Ada Boost Classifier Imported successfully
2025-12-11 15:15:19,628:INFO:Starting cross validation
2025-12-11 15:15:19,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:19,746:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,746:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,746:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,746:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,748:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,748:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,748:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,748:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,748:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:19,749:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:15:20,394:INFO:Calculating mean and std
2025-12-11 15:15:20,395:INFO:Creating metrics dataframe
2025-12-11 15:15:20,400:INFO:Uploading results into container
2025-12-11 15:15:20,401:INFO:Uploading model into container now
2025-12-11 15:15:20,402:INFO:_master_model_container: 9
2025-12-11 15:15:20,402:INFO:_display_container: 2
2025-12-11 15:15:20,402:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-11 15:15:20,403:INFO:create_model() successfully completed......................................
2025-12-11 15:15:20,504:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:20,504:INFO:Creating metrics dataframe
2025-12-11 15:15:20,515:INFO:Initializing Gradient Boosting Classifier
2025-12-11 15:15:20,515:INFO:Total runtime is 0.11087276538213094 minutes
2025-12-11 15:15:20,521:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:20,521:INFO:Initializing create_model()
2025-12-11 15:15:20,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:20,521:INFO:Checking exceptions
2025-12-11 15:15:20,523:INFO:Importing libraries
2025-12-11 15:15:20,523:INFO:Copying training dataset
2025-12-11 15:15:20,532:INFO:Defining folds
2025-12-11 15:15:20,532:INFO:Declaring metric variables
2025-12-11 15:15:20,537:INFO:Importing untrained model
2025-12-11 15:15:20,545:INFO:Gradient Boosting Classifier Imported successfully
2025-12-11 15:15:20,554:INFO:Starting cross validation
2025-12-11 15:15:20,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:22,368:INFO:Calculating mean and std
2025-12-11 15:15:22,370:INFO:Creating metrics dataframe
2025-12-11 15:15:22,372:INFO:Uploading results into container
2025-12-11 15:15:22,374:INFO:Uploading model into container now
2025-12-11 15:15:22,374:INFO:_master_model_container: 10
2025-12-11 15:15:22,375:INFO:_display_container: 2
2025-12-11 15:15:22,376:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-11 15:15:22,376:INFO:create_model() successfully completed......................................
2025-12-11 15:15:22,474:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:22,474:INFO:Creating metrics dataframe
2025-12-11 15:15:22,486:INFO:Initializing Linear Discriminant Analysis
2025-12-11 15:15:22,486:INFO:Total runtime is 0.1437286893526713 minutes
2025-12-11 15:15:22,494:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:22,494:INFO:Initializing create_model()
2025-12-11 15:15:22,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:22,495:INFO:Checking exceptions
2025-12-11 15:15:22,495:INFO:Importing libraries
2025-12-11 15:15:22,495:INFO:Copying training dataset
2025-12-11 15:15:22,505:INFO:Defining folds
2025-12-11 15:15:22,505:INFO:Declaring metric variables
2025-12-11 15:15:22,510:INFO:Importing untrained model
2025-12-11 15:15:22,517:INFO:Linear Discriminant Analysis Imported successfully
2025-12-11 15:15:22,529:INFO:Starting cross validation
2025-12-11 15:15:22,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:22,688:INFO:Calculating mean and std
2025-12-11 15:15:22,689:INFO:Creating metrics dataframe
2025-12-11 15:15:22,692:INFO:Uploading results into container
2025-12-11 15:15:22,692:INFO:Uploading model into container now
2025-12-11 15:15:22,693:INFO:_master_model_container: 11
2025-12-11 15:15:22,693:INFO:_display_container: 2
2025-12-11 15:15:22,693:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-11 15:15:22,693:INFO:create_model() successfully completed......................................
2025-12-11 15:15:22,796:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:22,796:INFO:Creating metrics dataframe
2025-12-11 15:15:22,808:INFO:Initializing Extra Trees Classifier
2025-12-11 15:15:22,809:INFO:Total runtime is 0.14911721547444662 minutes
2025-12-11 15:15:22,815:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:22,815:INFO:Initializing create_model()
2025-12-11 15:15:22,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:22,816:INFO:Checking exceptions
2025-12-11 15:15:22,816:INFO:Importing libraries
2025-12-11 15:15:22,816:INFO:Copying training dataset
2025-12-11 15:15:22,827:INFO:Defining folds
2025-12-11 15:15:22,827:INFO:Declaring metric variables
2025-12-11 15:15:22,832:INFO:Importing untrained model
2025-12-11 15:15:22,840:INFO:Extra Trees Classifier Imported successfully
2025-12-11 15:15:22,853:INFO:Starting cross validation
2025-12-11 15:15:22,855:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:23,969:INFO:Calculating mean and std
2025-12-11 15:15:23,971:INFO:Creating metrics dataframe
2025-12-11 15:15:23,977:INFO:Uploading results into container
2025-12-11 15:15:23,978:INFO:Uploading model into container now
2025-12-11 15:15:23,979:INFO:_master_model_container: 12
2025-12-11 15:15:23,979:INFO:_display_container: 2
2025-12-11 15:15:23,981:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-11 15:15:23,981:INFO:create_model() successfully completed......................................
2025-12-11 15:15:24,094:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:24,094:INFO:Creating metrics dataframe
2025-12-11 15:15:24,104:INFO:Initializing Light Gradient Boosting Machine
2025-12-11 15:15:24,104:INFO:Total runtime is 0.17070293823877972 minutes
2025-12-11 15:15:24,110:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:24,110:INFO:Initializing create_model()
2025-12-11 15:15:24,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:24,112:INFO:Checking exceptions
2025-12-11 15:15:24,112:INFO:Importing libraries
2025-12-11 15:15:24,112:INFO:Copying training dataset
2025-12-11 15:15:24,122:INFO:Defining folds
2025-12-11 15:15:24,123:INFO:Declaring metric variables
2025-12-11 15:15:24,129:INFO:Importing untrained model
2025-12-11 15:15:24,139:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-11 15:15:24,151:INFO:Starting cross validation
2025-12-11 15:15:24,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:25,595:INFO:Calculating mean and std
2025-12-11 15:15:25,596:INFO:Creating metrics dataframe
2025-12-11 15:15:25,601:INFO:Uploading results into container
2025-12-11 15:15:25,601:INFO:Uploading model into container now
2025-12-11 15:15:25,603:INFO:_master_model_container: 13
2025-12-11 15:15:25,603:INFO:_display_container: 2
2025-12-11 15:15:25,604:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-11 15:15:25,604:INFO:create_model() successfully completed......................................
2025-12-11 15:15:25,728:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:25,728:INFO:Creating metrics dataframe
2025-12-11 15:15:25,739:INFO:Initializing Dummy Classifier
2025-12-11 15:15:25,740:INFO:Total runtime is 0.1979677716890971 minutes
2025-12-11 15:15:25,744:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:25,746:INFO:Initializing create_model()
2025-12-11 15:15:25,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F70946D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:25,746:INFO:Checking exceptions
2025-12-11 15:15:25,746:INFO:Importing libraries
2025-12-11 15:15:25,746:INFO:Copying training dataset
2025-12-11 15:15:25,756:INFO:Defining folds
2025-12-11 15:15:25,757:INFO:Declaring metric variables
2025-12-11 15:15:25,764:INFO:Importing untrained model
2025-12-11 15:15:25,769:INFO:Dummy Classifier Imported successfully
2025-12-11 15:15:25,782:INFO:Starting cross validation
2025-12-11 15:15:25,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:25,869:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,888:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,891:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,891:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,897:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,901:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,901:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,903:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,909:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,911:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:15:25,934:INFO:Calculating mean and std
2025-12-11 15:15:25,935:INFO:Creating metrics dataframe
2025-12-11 15:15:25,939:INFO:Uploading results into container
2025-12-11 15:15:25,941:INFO:Uploading model into container now
2025-12-11 15:15:25,941:INFO:_master_model_container: 14
2025-12-11 15:15:25,942:INFO:_display_container: 2
2025-12-11 15:15:25,942:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-11 15:15:25,942:INFO:create_model() successfully completed......................................
2025-12-11 15:15:26,044:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:26,044:INFO:Creating metrics dataframe
2025-12-11 15:15:26,056:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-11 15:15:26,070:INFO:Initializing create_model()
2025-12-11 15:15:26,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:26,071:INFO:Checking exceptions
2025-12-11 15:15:26,072:INFO:Importing libraries
2025-12-11 15:15:26,074:INFO:Copying training dataset
2025-12-11 15:15:26,083:INFO:Defining folds
2025-12-11 15:15:26,083:INFO:Declaring metric variables
2025-12-11 15:15:26,083:INFO:Importing untrained model
2025-12-11 15:15:26,084:INFO:Declaring custom model
2025-12-11 15:15:26,084:INFO:Logistic Regression Imported successfully
2025-12-11 15:15:26,085:INFO:Cross validation set to False
2025-12-11 15:15:26,085:INFO:Fitting Model
2025-12-11 15:15:27,444:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:27,444:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-11 15:15:27,444:INFO:create_model() successfully completed......................................
2025-12-11 15:15:27,588:INFO:_master_model_container: 14
2025-12-11 15:15:27,588:INFO:_display_container: 2
2025-12-11 15:15:27,589:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-11 15:15:27,589:INFO:compare_models() successfully completed......................................
2025-12-11 15:15:27,592:INFO:Initializing tune_model()
2025-12-11 15:15:27,592:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>)
2025-12-11 15:15:27,592:INFO:Checking exceptions
2025-12-11 15:15:27,619:INFO:Copying training dataset
2025-12-11 15:15:27,629:INFO:Checking base model
2025-12-11 15:15:27,630:INFO:Base model : Logistic Regression
2025-12-11 15:15:27,636:INFO:Declaring metric variables
2025-12-11 15:15:27,642:INFO:Defining Hyperparameters
2025-12-11 15:15:27,754:INFO:Tuning with n_jobs=-1
2025-12-11 15:15:27,754:INFO:Initializing RandomizedSearchCV
2025-12-11 15:15:30,721:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:30,833:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:30,997:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:31,054:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:31,077:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:31,299:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:31,302:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:32,568:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:32,612:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:32,699:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:33,162:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:33,841:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:33,844:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:33,849:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:33,900:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:34,235:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:34,325:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:34,358:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:34,522:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:34,620:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:34,622:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:34,698:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:35,530:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:35,829:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:36,222:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:36,379:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:36,889:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:37,076:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:37,426:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:37,468:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:37,513:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:37,722:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:37,765:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:38,062:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:38,172:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:38,389:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:39,717:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:39,979:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:40,367:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:40,834:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:41,239:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:41,305:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:41,382:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:41,848:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:41,893:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:41,977:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:42,144:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:42,300:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:42,433:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:43,281:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:43,338:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:43,343:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:43,548:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:43,837:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:44,050:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:44,293:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:44,515:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:44,633:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:44,691:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:45,111:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:45,160:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:45,300:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:45,576:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:45,618:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,130:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,178:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,339:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,369:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,447:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,472:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,544:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,546:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,577:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,650:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:46,672:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2025-12-11 15:15:46,674:INFO:Hyperparameter search completed
2025-12-11 15:15:46,674:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:46,675:INFO:Initializing create_model()
2025-12-11 15:15:46,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F7247E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 0.049})
2025-12-11 15:15:46,676:INFO:Checking exceptions
2025-12-11 15:15:46,676:INFO:Importing libraries
2025-12-11 15:15:46,676:INFO:Copying training dataset
2025-12-11 15:15:46,685:INFO:Defining folds
2025-12-11 15:15:46,685:INFO:Declaring metric variables
2025-12-11 15:15:46,690:INFO:Importing untrained model
2025-12-11 15:15:46,690:INFO:Declaring custom model
2025-12-11 15:15:46,699:INFO:Logistic Regression Imported successfully
2025-12-11 15:15:46,709:INFO:Starting cross validation
2025-12-11 15:15:46,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:48,236:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:48,253:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:48,286:INFO:Calculating mean and std
2025-12-11 15:15:48,288:INFO:Creating metrics dataframe
2025-12-11 15:15:48,294:INFO:Finalizing model
2025-12-11 15:15:49,466:INFO:Uploading results into container
2025-12-11 15:15:49,467:INFO:Uploading model into container now
2025-12-11 15:15:49,468:INFO:_master_model_container: 15
2025-12-11 15:15:49,468:INFO:_display_container: 3
2025-12-11 15:15:49,468:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-11 15:15:49,469:INFO:create_model() successfully completed......................................
2025-12-11 15:15:49,585:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:49,585:INFO:choose_better activated
2025-12-11 15:15:49,591:INFO:SubProcess create_model() called ==================================
2025-12-11 15:15:49,593:INFO:Initializing create_model()
2025-12-11 15:15:49,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:15:49,593:INFO:Checking exceptions
2025-12-11 15:15:49,596:INFO:Importing libraries
2025-12-11 15:15:49,596:INFO:Copying training dataset
2025-12-11 15:15:49,606:INFO:Defining folds
2025-12-11 15:15:49,606:INFO:Declaring metric variables
2025-12-11 15:15:49,607:INFO:Importing untrained model
2025-12-11 15:15:49,607:INFO:Declaring custom model
2025-12-11 15:15:49,608:INFO:Logistic Regression Imported successfully
2025-12-11 15:15:49,608:INFO:Starting cross validation
2025-12-11 15:15:49,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:15:51,515:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:51,549:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:51,555:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:51,558:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:51,578:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:51,583:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:51,598:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:51,633:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:51,656:INFO:Calculating mean and std
2025-12-11 15:15:51,658:INFO:Creating metrics dataframe
2025-12-11 15:15:51,659:INFO:Finalizing model
2025-12-11 15:15:52,735:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:15:52,735:INFO:Uploading results into container
2025-12-11 15:15:52,737:INFO:Uploading model into container now
2025-12-11 15:15:52,737:INFO:_master_model_container: 16
2025-12-11 15:15:52,737:INFO:_display_container: 4
2025-12-11 15:15:52,737:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-11 15:15:52,737:INFO:create_model() successfully completed......................................
2025-12-11 15:15:52,833:INFO:SubProcess create_model() end ==================================
2025-12-11 15:15:52,834:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.7982
2025-12-11 15:15:52,834:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.7996
2025-12-11 15:15:52,834:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-11 15:15:52,834:INFO:choose_better completed
2025-12-11 15:15:52,849:INFO:_master_model_container: 16
2025-12-11 15:15:52,850:INFO:_display_container: 3
2025-12-11 15:15:52,850:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-11 15:15:52,850:INFO:tune_model() successfully completed......................................
2025-12-11 15:15:52,998:INFO:Initializing plot_model()
2025-12-11 15:15:52,998:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F8620C40>, system=True)
2025-12-11 15:15:52,998:INFO:Checking exceptions
2025-12-11 15:15:53,052:INFO:Preloading libraries
2025-12-11 15:15:53,120:INFO:Copying training dataset
2025-12-11 15:15:53,121:INFO:Plot type: error
2025-12-11 15:15:53,298:INFO:Fitting Model
2025-12-11 15:15:53,298:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2025-12-11 15:15:53,298:INFO:Scoring test/hold-out set
2025-12-11 15:15:53,849:INFO:Visual Rendered Successfully
2025-12-11 15:15:53,949:INFO:plot_model() successfully completed......................................
2025-12-11 15:15:53,960:INFO:Initializing plot_model()
2025-12-11 15:15:53,960:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F167ACE0>, system=True)
2025-12-11 15:15:53,960:INFO:Checking exceptions
2025-12-11 15:15:53,967:INFO:Preloading libraries
2025-12-11 15:15:53,969:INFO:Copying training dataset
2025-12-11 15:15:53,969:INFO:Plot type: confusion_matrix
2025-12-11 15:15:54,134:INFO:Fitting Model
2025-12-11 15:15:54,134:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-12-11 15:15:54,134:INFO:Scoring test/hold-out set
2025-12-11 15:15:54,256:INFO:Visual Rendered Successfully
2025-12-11 15:15:54,354:INFO:plot_model() successfully completed......................................
2025-12-11 15:16:58,926:INFO:PyCaret RegressionExperiment
2025-12-11 15:16:58,927:INFO:Logging name: reg-default-name
2025-12-11 15:16:58,927:INFO:ML Usecase: MLUsecase.REGRESSION
2025-12-11 15:16:58,927:INFO:version 3.3.2
2025-12-11 15:16:58,927:INFO:Initializing setup()
2025-12-11 15:16:58,927:INFO:self.USI: e36c
2025-12-11 15:16:58,927:INFO:self._variable_keys: {'gpu_param', 'fold_shuffle_param', '_ml_usecase', 'memory', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'exp_name_log', 'X', '_available_plots', 'fold_generator', 'exp_id', 'transform_target_param', 'X_train', 'data', 'X_test', 'USI', 'y_test', 'target_param', 'y', 'idx', 'fold_groups_param', 'y_train', 'html_param', 'pipeline', 'n_jobs_param', 'logging_param'}
2025-12-11 15:16:58,927:INFO:Checking environment
2025-12-11 15:16:58,927:INFO:python_version: 3.10.19
2025-12-11 15:16:58,928:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-11 15:16:58,928:INFO:machine: AMD64
2025-12-11 15:16:58,928:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-11 15:16:58,928:INFO:Memory: svmem(total=33699516416, available=14753337344, percent=56.2, used=18946179072, free=14753337344)
2025-12-11 15:16:58,928:INFO:Physical Core: 8
2025-12-11 15:16:58,928:INFO:Logical Core: 16
2025-12-11 15:16:58,928:INFO:Checking libraries
2025-12-11 15:16:58,928:INFO:System:
2025-12-11 15:16:58,928:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-11 15:16:58,929:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-11 15:16:58,929:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-11 15:16:58,929:INFO:PyCaret required dependencies:
2025-12-11 15:16:58,929:INFO:                 pip: 25.3
2025-12-11 15:16:58,929:INFO:          setuptools: 80.9.0
2025-12-11 15:16:58,929:INFO:             pycaret: 3.3.2
2025-12-11 15:16:58,929:INFO:             IPython: 8.37.0
2025-12-11 15:16:58,929:INFO:          ipywidgets: 8.1.8
2025-12-11 15:16:58,929:INFO:                tqdm: 4.67.1
2025-12-11 15:16:58,929:INFO:               numpy: 1.26.4
2025-12-11 15:16:58,930:INFO:              pandas: 2.1.4
2025-12-11 15:16:58,930:INFO:              jinja2: 3.1.6
2025-12-11 15:16:58,930:INFO:               scipy: 1.11.4
2025-12-11 15:16:58,930:INFO:              joblib: 1.3.2
2025-12-11 15:16:58,930:INFO:             sklearn: 1.4.2
2025-12-11 15:16:58,930:INFO:                pyod: 2.0.6
2025-12-11 15:16:58,930:INFO:            imblearn: 0.14.0
2025-12-11 15:16:58,930:INFO:   category_encoders: 2.7.0
2025-12-11 15:16:58,930:INFO:            lightgbm: 4.6.0
2025-12-11 15:16:58,930:INFO:               numba: 0.62.1
2025-12-11 15:16:58,930:INFO:            requests: 2.32.5
2025-12-11 15:16:58,930:INFO:          matplotlib: 3.7.5
2025-12-11 15:16:58,930:INFO:          scikitplot: 0.3.7
2025-12-11 15:16:58,930:INFO:         yellowbrick: 1.5
2025-12-11 15:16:58,930:INFO:              plotly: 6.5.0
2025-12-11 15:16:58,930:INFO:    plotly-resampler: Not installed
2025-12-11 15:16:58,930:INFO:             kaleido: 1.2.0
2025-12-11 15:16:58,930:INFO:           schemdraw: 0.15
2025-12-11 15:16:58,930:INFO:         statsmodels: 0.14.5
2025-12-11 15:16:58,930:INFO:              sktime: 0.26.0
2025-12-11 15:16:58,930:INFO:               tbats: 1.1.3
2025-12-11 15:16:58,930:INFO:            pmdarima: 2.0.4
2025-12-11 15:16:58,930:INFO:              psutil: 7.1.3
2025-12-11 15:16:58,930:INFO:          markupsafe: 3.0.3
2025-12-11 15:16:58,930:INFO:             pickle5: Not installed
2025-12-11 15:16:58,930:INFO:         cloudpickle: 3.1.2
2025-12-11 15:16:58,930:INFO:         deprecation: 2.1.0
2025-12-11 15:16:58,930:INFO:              xxhash: 3.6.0
2025-12-11 15:16:58,930:INFO:           wurlitzer: Not installed
2025-12-11 15:16:58,930:INFO:PyCaret optional dependencies:
2025-12-11 15:16:58,930:INFO:                shap: Not installed
2025-12-11 15:16:58,930:INFO:           interpret: Not installed
2025-12-11 15:16:58,930:INFO:                umap: Not installed
2025-12-11 15:16:58,930:INFO:     ydata_profiling: Not installed
2025-12-11 15:16:58,931:INFO:  explainerdashboard: Not installed
2025-12-11 15:16:58,931:INFO:             autoviz: Not installed
2025-12-11 15:16:58,931:INFO:           fairlearn: Not installed
2025-12-11 15:16:58,931:INFO:          deepchecks: Not installed
2025-12-11 15:16:58,931:INFO:             xgboost: Not installed
2025-12-11 15:16:58,931:INFO:            catboost: Not installed
2025-12-11 15:16:58,931:INFO:              kmodes: Not installed
2025-12-11 15:16:58,931:INFO:             mlxtend: Not installed
2025-12-11 15:16:58,931:INFO:       statsforecast: Not installed
2025-12-11 15:16:58,931:INFO:        tune_sklearn: Not installed
2025-12-11 15:16:58,931:INFO:                 ray: Not installed
2025-12-11 15:16:58,931:INFO:            hyperopt: Not installed
2025-12-11 15:16:58,931:INFO:              optuna: Not installed
2025-12-11 15:16:58,932:INFO:               skopt: Not installed
2025-12-11 15:16:58,932:INFO:              mlflow: Not installed
2025-12-11 15:16:58,932:INFO:              gradio: Not installed
2025-12-11 15:16:58,932:INFO:             fastapi: Not installed
2025-12-11 15:16:58,932:INFO:             uvicorn: Not installed
2025-12-11 15:16:58,932:INFO:              m2cgen: Not installed
2025-12-11 15:16:58,932:INFO:           evidently: Not installed
2025-12-11 15:16:58,932:INFO:               fugue: Not installed
2025-12-11 15:16:58,932:INFO:           streamlit: Not installed
2025-12-11 15:16:58,932:INFO:             prophet: Not installed
2025-12-11 15:16:58,932:INFO:None
2025-12-11 15:16:58,932:INFO:Set up data.
2025-12-11 15:16:58,942:INFO:Set up folding strategy.
2025-12-11 15:16:58,943:INFO:Set up train/test split.
2025-12-11 15:16:58,949:INFO:Set up index.
2025-12-11 15:16:58,950:INFO:Assigning column types.
2025-12-11 15:16:58,957:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-11 15:16:58,957:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-11 15:16:58,962:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-11 15:16:58,967:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,035:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,086:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,092:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,097:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,220:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-12-11 15:16:59,225:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,302:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,351:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,391:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,465:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,516:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-12-11 15:16:59,526:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,659:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,777:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-12-11 15:16:59,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,907:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:16:59,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:16:59,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:17:00,036:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:17:00,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,038:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-11 15:17:00,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:17:00,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-12-11 15:17:00,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,299:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-12-11 15:17:00,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,570:INFO:Preparing preprocessing pipeline...
2025-12-11 15:17:00,570:INFO:Set up simple imputation.
2025-12-11 15:17:00,571:INFO:Set up feature normalization.
2025-12-11 15:17:00,572:INFO:Set up column name cleaning.
2025-12-11 15:17:00,616:INFO:Finished creating preprocessing pipeline.
2025-12-11 15:17:00,623:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-11 15:17:00,623:INFO:Creating final display dataframe.
2025-12-11 15:17:00,761:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     selling_price
2                   Target type        Regression
3           Original data shape        (7906, 18)
4        Transformed data shape        (7906, 16)
5   Transformed train set shape        (5534, 16)
6    Transformed test set shape        (2372, 16)
7               Ignore features                 2
8              Numeric features                15
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              e36c
2025-12-11 15:17:00,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:00,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:01,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:01,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:01,017:INFO:setup() successfully completed in 2.09s...............
2025-12-11 15:17:01,020:INFO:Initializing compare_models()
2025-12-11 15:17:01,020:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-12-11 15:17:01,020:INFO:Checking exceptions
2025-12-11 15:17:01,024:INFO:Preparing display monitor
2025-12-11 15:17:01,051:INFO:Initializing Linear Regression
2025-12-11 15:17:01,051:INFO:Total runtime is 0.0 minutes
2025-12-11 15:17:01,059:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:01,059:INFO:Initializing create_model()
2025-12-11 15:17:01,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:01,059:INFO:Checking exceptions
2025-12-11 15:17:01,059:INFO:Importing libraries
2025-12-11 15:17:01,059:INFO:Copying training dataset
2025-12-11 15:17:01,068:INFO:Defining folds
2025-12-11 15:17:01,068:INFO:Declaring metric variables
2025-12-11 15:17:01,072:INFO:Importing untrained model
2025-12-11 15:17:01,079:INFO:Linear Regression Imported successfully
2025-12-11 15:17:01,089:INFO:Starting cross validation
2025-12-11 15:17:01,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:01,220:INFO:Calculating mean and std
2025-12-11 15:17:01,221:INFO:Creating metrics dataframe
2025-12-11 15:17:01,223:INFO:Uploading results into container
2025-12-11 15:17:01,223:INFO:Uploading model into container now
2025-12-11 15:17:01,224:INFO:_master_model_container: 1
2025-12-11 15:17:01,224:INFO:_display_container: 2
2025-12-11 15:17:01,224:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-12-11 15:17:01,224:INFO:create_model() successfully completed......................................
2025-12-11 15:17:01,326:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:01,326:INFO:Creating metrics dataframe
2025-12-11 15:17:01,335:INFO:Initializing Lasso Regression
2025-12-11 15:17:01,335:INFO:Total runtime is 0.004717588424682617 minutes
2025-12-11 15:17:01,340:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:01,341:INFO:Initializing create_model()
2025-12-11 15:17:01,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:01,341:INFO:Checking exceptions
2025-12-11 15:17:01,341:INFO:Importing libraries
2025-12-11 15:17:01,341:INFO:Copying training dataset
2025-12-11 15:17:01,349:INFO:Defining folds
2025-12-11 15:17:01,349:INFO:Declaring metric variables
2025-12-11 15:17:01,353:INFO:Importing untrained model
2025-12-11 15:17:01,360:INFO:Lasso Regression Imported successfully
2025-12-11 15:17:01,368:INFO:Starting cross validation
2025-12-11 15:17:01,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:01,470:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.119e+11, tolerance: 3.154e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-11 15:17:01,496:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.296e+11, tolerance: 3.151e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-11 15:17:01,506:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e+11, tolerance: 3.109e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-11 15:17:01,521:INFO:Calculating mean and std
2025-12-11 15:17:01,522:INFO:Creating metrics dataframe
2025-12-11 15:17:01,524:INFO:Uploading results into container
2025-12-11 15:17:01,524:INFO:Uploading model into container now
2025-12-11 15:17:01,524:INFO:_master_model_container: 2
2025-12-11 15:17:01,524:INFO:_display_container: 2
2025-12-11 15:17:01,524:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-12-11 15:17:01,524:INFO:create_model() successfully completed......................................
2025-12-11 15:17:01,624:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:01,625:INFO:Creating metrics dataframe
2025-12-11 15:17:01,632:INFO:Initializing Ridge Regression
2025-12-11 15:17:01,633:INFO:Total runtime is 0.00969305435816447 minutes
2025-12-11 15:17:01,639:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:01,639:INFO:Initializing create_model()
2025-12-11 15:17:01,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:01,639:INFO:Checking exceptions
2025-12-11 15:17:01,639:INFO:Importing libraries
2025-12-11 15:17:01,639:INFO:Copying training dataset
2025-12-11 15:17:01,648:INFO:Defining folds
2025-12-11 15:17:01,648:INFO:Declaring metric variables
2025-12-11 15:17:01,652:INFO:Importing untrained model
2025-12-11 15:17:01,657:INFO:Ridge Regression Imported successfully
2025-12-11 15:17:01,667:INFO:Starting cross validation
2025-12-11 15:17:01,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:01,788:INFO:Calculating mean and std
2025-12-11 15:17:01,788:INFO:Creating metrics dataframe
2025-12-11 15:17:01,790:INFO:Uploading results into container
2025-12-11 15:17:01,790:INFO:Uploading model into container now
2025-12-11 15:17:01,791:INFO:_master_model_container: 3
2025-12-11 15:17:01,791:INFO:_display_container: 2
2025-12-11 15:17:01,792:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-12-11 15:17:01,792:INFO:create_model() successfully completed......................................
2025-12-11 15:17:01,888:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:01,888:INFO:Creating metrics dataframe
2025-12-11 15:17:01,896:INFO:Initializing Elastic Net
2025-12-11 15:17:01,897:INFO:Total runtime is 0.014100289344787598 minutes
2025-12-11 15:17:01,902:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:01,902:INFO:Initializing create_model()
2025-12-11 15:17:01,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:01,902:INFO:Checking exceptions
2025-12-11 15:17:01,902:INFO:Importing libraries
2025-12-11 15:17:01,902:INFO:Copying training dataset
2025-12-11 15:17:01,913:INFO:Defining folds
2025-12-11 15:17:01,913:INFO:Declaring metric variables
2025-12-11 15:17:01,917:INFO:Importing untrained model
2025-12-11 15:17:01,923:INFO:Elastic Net Imported successfully
2025-12-11 15:17:01,933:INFO:Starting cross validation
2025-12-11 15:17:01,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:02,060:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e+12, tolerance: 3.109e+11
  model = cd_fast.enet_coordinate_descent(

2025-12-11 15:17:02,086:INFO:Calculating mean and std
2025-12-11 15:17:02,120:INFO:Creating metrics dataframe
2025-12-11 15:17:02,124:INFO:Uploading results into container
2025-12-11 15:17:02,124:INFO:Uploading model into container now
2025-12-11 15:17:02,125:INFO:_master_model_container: 4
2025-12-11 15:17:02,125:INFO:_display_container: 2
2025-12-11 15:17:02,126:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-12-11 15:17:02,126:INFO:create_model() successfully completed......................................
2025-12-11 15:17:02,224:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:02,224:INFO:Creating metrics dataframe
2025-12-11 15:17:02,235:INFO:Initializing Least Angle Regression
2025-12-11 15:17:02,235:INFO:Total runtime is 0.019722950458526612 minutes
2025-12-11 15:17:02,239:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:02,240:INFO:Initializing create_model()
2025-12-11 15:17:02,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:02,240:INFO:Checking exceptions
2025-12-11 15:17:02,240:INFO:Importing libraries
2025-12-11 15:17:02,241:INFO:Copying training dataset
2025-12-11 15:17:02,248:INFO:Defining folds
2025-12-11 15:17:02,250:INFO:Declaring metric variables
2025-12-11 15:17:02,255:INFO:Importing untrained model
2025-12-11 15:17:02,261:INFO:Least Angle Regression Imported successfully
2025-12-11 15:17:02,271:INFO:Starting cross validation
2025-12-11 15:17:02,273:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:02,416:INFO:Calculating mean and std
2025-12-11 15:17:02,418:INFO:Creating metrics dataframe
2025-12-11 15:17:02,420:INFO:Uploading results into container
2025-12-11 15:17:02,422:INFO:Uploading model into container now
2025-12-11 15:17:02,423:INFO:_master_model_container: 5
2025-12-11 15:17:02,423:INFO:_display_container: 2
2025-12-11 15:17:02,423:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-12-11 15:17:02,424:INFO:create_model() successfully completed......................................
2025-12-11 15:17:02,523:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:02,523:INFO:Creating metrics dataframe
2025-12-11 15:17:02,533:INFO:Initializing Lasso Least Angle Regression
2025-12-11 15:17:02,533:INFO:Total runtime is 0.024684182802836102 minutes
2025-12-11 15:17:02,538:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:02,538:INFO:Initializing create_model()
2025-12-11 15:17:02,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:02,540:INFO:Checking exceptions
2025-12-11 15:17:02,540:INFO:Importing libraries
2025-12-11 15:17:02,540:INFO:Copying training dataset
2025-12-11 15:17:02,548:INFO:Defining folds
2025-12-11 15:17:02,548:INFO:Declaring metric variables
2025-12-11 15:17:02,556:INFO:Importing untrained model
2025-12-11 15:17:02,560:INFO:Lasso Least Angle Regression Imported successfully
2025-12-11 15:17:02,570:INFO:Starting cross validation
2025-12-11 15:17:02,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:02,686:INFO:Calculating mean and std
2025-12-11 15:17:02,688:INFO:Creating metrics dataframe
2025-12-11 15:17:02,691:INFO:Uploading results into container
2025-12-11 15:17:02,692:INFO:Uploading model into container now
2025-12-11 15:17:02,693:INFO:_master_model_container: 6
2025-12-11 15:17:02,693:INFO:_display_container: 2
2025-12-11 15:17:02,693:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-12-11 15:17:02,693:INFO:create_model() successfully completed......................................
2025-12-11 15:17:02,793:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:02,793:INFO:Creating metrics dataframe
2025-12-11 15:17:02,803:INFO:Initializing Orthogonal Matching Pursuit
2025-12-11 15:17:02,804:INFO:Total runtime is 0.029203530152638754 minutes
2025-12-11 15:17:02,809:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:02,810:INFO:Initializing create_model()
2025-12-11 15:17:02,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:02,811:INFO:Checking exceptions
2025-12-11 15:17:02,811:INFO:Importing libraries
2025-12-11 15:17:02,811:INFO:Copying training dataset
2025-12-11 15:17:02,819:INFO:Defining folds
2025-12-11 15:17:02,819:INFO:Declaring metric variables
2025-12-11 15:17:02,825:INFO:Importing untrained model
2025-12-11 15:17:02,830:INFO:Orthogonal Matching Pursuit Imported successfully
2025-12-11 15:17:02,843:INFO:Starting cross validation
2025-12-11 15:17:02,844:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:02,953:INFO:Calculating mean and std
2025-12-11 15:17:02,956:INFO:Creating metrics dataframe
2025-12-11 15:17:02,958:INFO:Uploading results into container
2025-12-11 15:17:02,958:INFO:Uploading model into container now
2025-12-11 15:17:02,960:INFO:_master_model_container: 7
2025-12-11 15:17:02,960:INFO:_display_container: 2
2025-12-11 15:17:02,960:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-12-11 15:17:02,961:INFO:create_model() successfully completed......................................
2025-12-11 15:17:03,067:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:03,067:INFO:Creating metrics dataframe
2025-12-11 15:17:03,076:INFO:Initializing Bayesian Ridge
2025-12-11 15:17:03,076:INFO:Total runtime is 0.03374980688095093 minutes
2025-12-11 15:17:03,081:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:03,081:INFO:Initializing create_model()
2025-12-11 15:17:03,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:03,081:INFO:Checking exceptions
2025-12-11 15:17:03,081:INFO:Importing libraries
2025-12-11 15:17:03,081:INFO:Copying training dataset
2025-12-11 15:17:03,092:INFO:Defining folds
2025-12-11 15:17:03,092:INFO:Declaring metric variables
2025-12-11 15:17:03,098:INFO:Importing untrained model
2025-12-11 15:17:03,102:INFO:Bayesian Ridge Imported successfully
2025-12-11 15:17:03,112:INFO:Starting cross validation
2025-12-11 15:17:03,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:03,236:INFO:Calculating mean and std
2025-12-11 15:17:03,238:INFO:Creating metrics dataframe
2025-12-11 15:17:03,241:INFO:Uploading results into container
2025-12-11 15:17:03,242:INFO:Uploading model into container now
2025-12-11 15:17:03,243:INFO:_master_model_container: 8
2025-12-11 15:17:03,243:INFO:_display_container: 2
2025-12-11 15:17:03,244:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-12-11 15:17:03,245:INFO:create_model() successfully completed......................................
2025-12-11 15:17:03,343:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:03,343:INFO:Creating metrics dataframe
2025-12-11 15:17:03,352:INFO:Initializing Passive Aggressive Regressor
2025-12-11 15:17:03,352:INFO:Total runtime is 0.03834969600041708 minutes
2025-12-11 15:17:03,359:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:03,359:INFO:Initializing create_model()
2025-12-11 15:17:03,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:03,361:INFO:Checking exceptions
2025-12-11 15:17:03,361:INFO:Importing libraries
2025-12-11 15:17:03,361:INFO:Copying training dataset
2025-12-11 15:17:03,368:INFO:Defining folds
2025-12-11 15:17:03,368:INFO:Declaring metric variables
2025-12-11 15:17:03,374:INFO:Importing untrained model
2025-12-11 15:17:03,379:INFO:Passive Aggressive Regressor Imported successfully
2025-12-11 15:17:03,391:INFO:Starting cross validation
2025-12-11 15:17:03,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:03,949:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:17:03,968:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:17:03,984:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:17:03,988:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:17:04,012:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:17:04,017:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:17:04,021:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:17:04,025:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-12-11 15:17:04,040:INFO:Calculating mean and std
2025-12-11 15:17:04,041:INFO:Creating metrics dataframe
2025-12-11 15:17:04,045:INFO:Uploading results into container
2025-12-11 15:17:04,046:INFO:Uploading model into container now
2025-12-11 15:17:04,046:INFO:_master_model_container: 9
2025-12-11 15:17:04,046:INFO:_display_container: 2
2025-12-11 15:17:04,048:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-11 15:17:04,048:INFO:create_model() successfully completed......................................
2025-12-11 15:17:04,146:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:04,146:INFO:Creating metrics dataframe
2025-12-11 15:17:04,157:INFO:Initializing Huber Regressor
2025-12-11 15:17:04,158:INFO:Total runtime is 0.0517512321472168 minutes
2025-12-11 15:17:04,161:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:04,163:INFO:Initializing create_model()
2025-12-11 15:17:04,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:04,163:INFO:Checking exceptions
2025-12-11 15:17:04,163:INFO:Importing libraries
2025-12-11 15:17:04,163:INFO:Copying training dataset
2025-12-11 15:17:04,172:INFO:Defining folds
2025-12-11 15:17:04,172:INFO:Declaring metric variables
2025-12-11 15:17:04,178:INFO:Importing untrained model
2025-12-11 15:17:04,182:INFO:Huber Regressor Imported successfully
2025-12-11 15:17:04,193:INFO:Starting cross validation
2025-12-11 15:17:04,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:04,407:INFO:Calculating mean and std
2025-12-11 15:17:04,408:INFO:Creating metrics dataframe
2025-12-11 15:17:04,409:INFO:Uploading results into container
2025-12-11 15:17:04,411:INFO:Uploading model into container now
2025-12-11 15:17:04,411:INFO:_master_model_container: 10
2025-12-11 15:17:04,411:INFO:_display_container: 2
2025-12-11 15:17:04,411:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-12-11 15:17:04,411:INFO:create_model() successfully completed......................................
2025-12-11 15:17:04,510:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:04,510:INFO:Creating metrics dataframe
2025-12-11 15:17:04,522:INFO:Initializing K Neighbors Regressor
2025-12-11 15:17:04,522:INFO:Total runtime is 0.05784291823705038 minutes
2025-12-11 15:17:04,527:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:04,527:INFO:Initializing create_model()
2025-12-11 15:17:04,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:04,527:INFO:Checking exceptions
2025-12-11 15:17:04,528:INFO:Importing libraries
2025-12-11 15:17:04,529:INFO:Copying training dataset
2025-12-11 15:17:04,538:INFO:Defining folds
2025-12-11 15:17:04,538:INFO:Declaring metric variables
2025-12-11 15:17:04,544:INFO:Importing untrained model
2025-12-11 15:17:04,550:INFO:K Neighbors Regressor Imported successfully
2025-12-11 15:17:04,560:INFO:Starting cross validation
2025-12-11 15:17:04,562:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:04,803:INFO:Calculating mean and std
2025-12-11 15:17:04,804:INFO:Creating metrics dataframe
2025-12-11 15:17:04,806:INFO:Uploading results into container
2025-12-11 15:17:04,806:INFO:Uploading model into container now
2025-12-11 15:17:04,806:INFO:_master_model_container: 11
2025-12-11 15:17:04,808:INFO:_display_container: 2
2025-12-11 15:17:04,808:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-12-11 15:17:04,808:INFO:create_model() successfully completed......................................
2025-12-11 15:17:04,912:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:04,913:INFO:Creating metrics dataframe
2025-12-11 15:17:04,924:INFO:Initializing Decision Tree Regressor
2025-12-11 15:17:04,924:INFO:Total runtime is 0.06453607082366944 minutes
2025-12-11 15:17:04,929:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:04,930:INFO:Initializing create_model()
2025-12-11 15:17:04,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:04,930:INFO:Checking exceptions
2025-12-11 15:17:04,930:INFO:Importing libraries
2025-12-11 15:17:04,930:INFO:Copying training dataset
2025-12-11 15:17:04,938:INFO:Defining folds
2025-12-11 15:17:04,939:INFO:Declaring metric variables
2025-12-11 15:17:04,943:INFO:Importing untrained model
2025-12-11 15:17:04,949:INFO:Decision Tree Regressor Imported successfully
2025-12-11 15:17:04,958:INFO:Starting cross validation
2025-12-11 15:17:04,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:05,120:INFO:Calculating mean and std
2025-12-11 15:17:05,122:INFO:Creating metrics dataframe
2025-12-11 15:17:05,125:INFO:Uploading results into container
2025-12-11 15:17:05,126:INFO:Uploading model into container now
2025-12-11 15:17:05,126:INFO:_master_model_container: 12
2025-12-11 15:17:05,127:INFO:_display_container: 2
2025-12-11 15:17:05,127:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-12-11 15:17:05,128:INFO:create_model() successfully completed......................................
2025-12-11 15:17:05,228:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:05,228:INFO:Creating metrics dataframe
2025-12-11 15:17:05,240:INFO:Initializing Random Forest Regressor
2025-12-11 15:17:05,240:INFO:Total runtime is 0.06980065107345582 minutes
2025-12-11 15:17:05,245:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:05,246:INFO:Initializing create_model()
2025-12-11 15:17:05,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:05,246:INFO:Checking exceptions
2025-12-11 15:17:05,246:INFO:Importing libraries
2025-12-11 15:17:05,246:INFO:Copying training dataset
2025-12-11 15:17:05,255:INFO:Defining folds
2025-12-11 15:17:05,256:INFO:Declaring metric variables
2025-12-11 15:17:05,261:INFO:Importing untrained model
2025-12-11 15:17:05,264:INFO:Random Forest Regressor Imported successfully
2025-12-11 15:17:05,277:INFO:Starting cross validation
2025-12-11 15:17:05,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:07,191:INFO:Calculating mean and std
2025-12-11 15:17:07,192:INFO:Creating metrics dataframe
2025-12-11 15:17:07,195:INFO:Uploading results into container
2025-12-11 15:17:07,197:INFO:Uploading model into container now
2025-12-11 15:17:07,197:INFO:_master_model_container: 13
2025-12-11 15:17:07,198:INFO:_display_container: 2
2025-12-11 15:17:07,198:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-12-11 15:17:07,198:INFO:create_model() successfully completed......................................
2025-12-11 15:17:07,312:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:07,312:INFO:Creating metrics dataframe
2025-12-11 15:17:07,325:INFO:Initializing Extra Trees Regressor
2025-12-11 15:17:07,327:INFO:Total runtime is 0.10459273656209311 minutes
2025-12-11 15:17:07,330:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:07,332:INFO:Initializing create_model()
2025-12-11 15:17:07,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:07,333:INFO:Checking exceptions
2025-12-11 15:17:07,333:INFO:Importing libraries
2025-12-11 15:17:07,333:INFO:Copying training dataset
2025-12-11 15:17:07,342:INFO:Defining folds
2025-12-11 15:17:07,343:INFO:Declaring metric variables
2025-12-11 15:17:07,348:INFO:Importing untrained model
2025-12-11 15:17:07,355:INFO:Extra Trees Regressor Imported successfully
2025-12-11 15:17:07,367:INFO:Starting cross validation
2025-12-11 15:17:07,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:08,808:INFO:Calculating mean and std
2025-12-11 15:17:08,811:INFO:Creating metrics dataframe
2025-12-11 15:17:08,813:INFO:Uploading results into container
2025-12-11 15:17:08,815:INFO:Uploading model into container now
2025-12-11 15:17:08,816:INFO:_master_model_container: 14
2025-12-11 15:17:08,816:INFO:_display_container: 2
2025-12-11 15:17:08,816:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-11 15:17:08,816:INFO:create_model() successfully completed......................................
2025-12-11 15:17:08,934:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:08,935:INFO:Creating metrics dataframe
2025-12-11 15:17:08,949:INFO:Initializing AdaBoost Regressor
2025-12-11 15:17:08,949:INFO:Total runtime is 0.1316182573636373 minutes
2025-12-11 15:17:08,954:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:08,955:INFO:Initializing create_model()
2025-12-11 15:17:08,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:08,955:INFO:Checking exceptions
2025-12-11 15:17:08,956:INFO:Importing libraries
2025-12-11 15:17:08,956:INFO:Copying training dataset
2025-12-11 15:17:08,964:INFO:Defining folds
2025-12-11 15:17:08,964:INFO:Declaring metric variables
2025-12-11 15:17:08,972:INFO:Importing untrained model
2025-12-11 15:17:08,978:INFO:AdaBoost Regressor Imported successfully
2025-12-11 15:17:08,989:INFO:Starting cross validation
2025-12-11 15:17:08,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:09,541:INFO:Calculating mean and std
2025-12-11 15:17:09,541:INFO:Creating metrics dataframe
2025-12-11 15:17:09,544:INFO:Uploading results into container
2025-12-11 15:17:09,546:INFO:Uploading model into container now
2025-12-11 15:17:09,546:INFO:_master_model_container: 15
2025-12-11 15:17:09,546:INFO:_display_container: 2
2025-12-11 15:17:09,546:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-12-11 15:17:09,547:INFO:create_model() successfully completed......................................
2025-12-11 15:17:09,654:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:09,654:INFO:Creating metrics dataframe
2025-12-11 15:17:09,668:INFO:Initializing Gradient Boosting Regressor
2025-12-11 15:17:09,669:INFO:Total runtime is 0.1436187267303467 minutes
2025-12-11 15:17:09,675:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:09,676:INFO:Initializing create_model()
2025-12-11 15:17:09,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:09,676:INFO:Checking exceptions
2025-12-11 15:17:09,676:INFO:Importing libraries
2025-12-11 15:17:09,676:INFO:Copying training dataset
2025-12-11 15:17:09,686:INFO:Defining folds
2025-12-11 15:17:09,686:INFO:Declaring metric variables
2025-12-11 15:17:09,693:INFO:Importing untrained model
2025-12-11 15:17:09,698:INFO:Gradient Boosting Regressor Imported successfully
2025-12-11 15:17:09,709:INFO:Starting cross validation
2025-12-11 15:17:09,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:10,476:INFO:Calculating mean and std
2025-12-11 15:17:10,477:INFO:Creating metrics dataframe
2025-12-11 15:17:10,480:INFO:Uploading results into container
2025-12-11 15:17:10,480:INFO:Uploading model into container now
2025-12-11 15:17:10,480:INFO:_master_model_container: 16
2025-12-11 15:17:10,480:INFO:_display_container: 2
2025-12-11 15:17:10,481:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-11 15:17:10,483:INFO:create_model() successfully completed......................................
2025-12-11 15:17:10,589:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:10,589:INFO:Creating metrics dataframe
2025-12-11 15:17:10,603:INFO:Initializing Light Gradient Boosting Machine
2025-12-11 15:17:10,603:INFO:Total runtime is 0.15919303894042972 minutes
2025-12-11 15:17:10,608:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:10,608:INFO:Initializing create_model()
2025-12-11 15:17:10,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:10,609:INFO:Checking exceptions
2025-12-11 15:17:10,609:INFO:Importing libraries
2025-12-11 15:17:10,609:INFO:Copying training dataset
2025-12-11 15:17:10,620:INFO:Defining folds
2025-12-11 15:17:10,621:INFO:Declaring metric variables
2025-12-11 15:17:10,627:INFO:Importing untrained model
2025-12-11 15:17:10,633:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-11 15:17:10,644:INFO:Starting cross validation
2025-12-11 15:17:10,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:11,954:INFO:Calculating mean and std
2025-12-11 15:17:11,955:INFO:Creating metrics dataframe
2025-12-11 15:17:11,960:INFO:Uploading results into container
2025-12-11 15:17:11,961:INFO:Uploading model into container now
2025-12-11 15:17:11,961:INFO:_master_model_container: 17
2025-12-11 15:17:11,962:INFO:_display_container: 2
2025-12-11 15:17:11,964:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-12-11 15:17:11,964:INFO:create_model() successfully completed......................................
2025-12-11 15:17:12,094:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:12,094:INFO:Creating metrics dataframe
2025-12-11 15:17:12,106:INFO:Initializing Dummy Regressor
2025-12-11 15:17:12,106:INFO:Total runtime is 0.1842470169067383 minutes
2025-12-11 15:17:12,110:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:12,112:INFO:Initializing create_model()
2025-12-11 15:17:12,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F00DD4B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:12,112:INFO:Checking exceptions
2025-12-11 15:17:12,112:INFO:Importing libraries
2025-12-11 15:17:12,112:INFO:Copying training dataset
2025-12-11 15:17:12,124:INFO:Defining folds
2025-12-11 15:17:12,124:INFO:Declaring metric variables
2025-12-11 15:17:12,129:INFO:Importing untrained model
2025-12-11 15:17:12,134:INFO:Dummy Regressor Imported successfully
2025-12-11 15:17:12,147:INFO:Starting cross validation
2025-12-11 15:17:12,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:12,270:INFO:Calculating mean and std
2025-12-11 15:17:12,272:INFO:Creating metrics dataframe
2025-12-11 15:17:12,276:INFO:Uploading results into container
2025-12-11 15:17:12,277:INFO:Uploading model into container now
2025-12-11 15:17:12,278:INFO:_master_model_container: 18
2025-12-11 15:17:12,278:INFO:_display_container: 2
2025-12-11 15:17:12,278:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-12-11 15:17:12,278:INFO:create_model() successfully completed......................................
2025-12-11 15:17:12,390:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:12,390:INFO:Creating metrics dataframe
2025-12-11 15:17:12,405:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-11 15:17:12,417:INFO:Initializing create_model()
2025-12-11 15:17:12,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:12,419:INFO:Checking exceptions
2025-12-11 15:17:12,420:INFO:Importing libraries
2025-12-11 15:17:12,420:INFO:Copying training dataset
2025-12-11 15:17:12,430:INFO:Defining folds
2025-12-11 15:17:12,430:INFO:Declaring metric variables
2025-12-11 15:17:12,430:INFO:Importing untrained model
2025-12-11 15:17:12,430:INFO:Declaring custom model
2025-12-11 15:17:12,430:INFO:Extra Trees Regressor Imported successfully
2025-12-11 15:17:12,431:INFO:Cross validation set to False
2025-12-11 15:17:12,431:INFO:Fitting Model
2025-12-11 15:17:12,676:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-11 15:17:12,676:INFO:create_model() successfully completed......................................
2025-12-11 15:17:12,825:INFO:_master_model_container: 18
2025-12-11 15:17:12,825:INFO:_display_container: 2
2025-12-11 15:17:12,827:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-11 15:17:12,828:INFO:compare_models() successfully completed......................................
2025-12-11 15:17:12,835:INFO:Initializing tune_model()
2025-12-11 15:17:12,836:INFO:tune_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>)
2025-12-11 15:17:12,836:INFO:Checking exceptions
2025-12-11 15:17:12,862:INFO:Copying training dataset
2025-12-11 15:17:12,872:INFO:Checking base model
2025-12-11 15:17:12,872:INFO:Base model : Extra Trees Regressor
2025-12-11 15:17:12,879:INFO:Declaring metric variables
2025-12-11 15:17:12,885:INFO:Defining Hyperparameters
2025-12-11 15:17:13,011:INFO:Tuning with n_jobs=-1
2025-12-11 15:17:13,024:INFO:Initializing RandomizedSearchCV
2025-12-11 15:17:46,855:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2025-12-11 15:17:46,855:INFO:Hyperparameter search completed
2025-12-11 15:17:46,856:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:46,857:INFO:Initializing create_model()
2025-12-11 15:17:46,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249CC677D00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2025-12-11 15:17:46,857:INFO:Checking exceptions
2025-12-11 15:17:46,858:INFO:Importing libraries
2025-12-11 15:17:46,858:INFO:Copying training dataset
2025-12-11 15:17:46,868:INFO:Defining folds
2025-12-11 15:17:46,868:INFO:Declaring metric variables
2025-12-11 15:17:46,873:INFO:Importing untrained model
2025-12-11 15:17:46,874:INFO:Declaring custom model
2025-12-11 15:17:46,880:INFO:Extra Trees Regressor Imported successfully
2025-12-11 15:17:46,890:INFO:Starting cross validation
2025-12-11 15:17:46,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:47,685:INFO:Calculating mean and std
2025-12-11 15:17:47,687:INFO:Creating metrics dataframe
2025-12-11 15:17:47,694:INFO:Finalizing model
2025-12-11 15:17:47,944:INFO:Uploading results into container
2025-12-11 15:17:47,946:INFO:Uploading model into container now
2025-12-11 15:17:47,946:INFO:_master_model_container: 19
2025-12-11 15:17:47,947:INFO:_display_container: 3
2025-12-11 15:17:47,947:INFO:ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=9, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-11 15:17:47,947:INFO:create_model() successfully completed......................................
2025-12-11 15:17:48,057:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:48,057:INFO:choose_better activated
2025-12-11 15:17:48,060:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:48,062:INFO:Initializing create_model()
2025-12-11 15:17:48,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:48,062:INFO:Checking exceptions
2025-12-11 15:17:48,065:INFO:Importing libraries
2025-12-11 15:17:48,065:INFO:Copying training dataset
2025-12-11 15:17:48,073:INFO:Defining folds
2025-12-11 15:17:48,073:INFO:Declaring metric variables
2025-12-11 15:17:48,073:INFO:Importing untrained model
2025-12-11 15:17:48,073:INFO:Declaring custom model
2025-12-11 15:17:48,073:INFO:Extra Trees Regressor Imported successfully
2025-12-11 15:17:48,075:INFO:Starting cross validation
2025-12-11 15:17:48,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:49,571:INFO:Calculating mean and std
2025-12-11 15:17:49,571:INFO:Creating metrics dataframe
2025-12-11 15:17:49,573:INFO:Finalizing model
2025-12-11 15:17:49,801:INFO:Uploading results into container
2025-12-11 15:17:49,803:INFO:Uploading model into container now
2025-12-11 15:17:49,804:INFO:_master_model_container: 20
2025-12-11 15:17:49,804:INFO:_display_container: 4
2025-12-11 15:17:49,804:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-11 15:17:49,804:INFO:create_model() successfully completed......................................
2025-12-11 15:17:49,904:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:49,904:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) result for R2 is 0.9575
2025-12-11 15:17:49,904:INFO:ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=9, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) result for R2 is 0.9305
2025-12-11 15:17:49,904:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) is best model
2025-12-11 15:17:49,904:INFO:choose_better completed
2025-12-11 15:17:49,904:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-11 15:17:49,920:INFO:_master_model_container: 20
2025-12-11 15:17:49,920:INFO:_display_container: 3
2025-12-11 15:17:49,921:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-12-11 15:17:49,921:INFO:tune_model() successfully completed......................................
2025-12-11 15:17:50,042:INFO:PyCaret ClassificationExperiment
2025-12-11 15:17:50,042:INFO:Logging name: clf-default-name
2025-12-11 15:17:50,042:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-11 15:17:50,042:INFO:version 3.3.2
2025-12-11 15:17:50,042:INFO:Initializing setup()
2025-12-11 15:17:50,042:INFO:self.USI: 8e39
2025-12-11 15:17:50,042:INFO:self._variable_keys: {'gpu_param', 'fold_shuffle_param', '_ml_usecase', 'memory', 'gpu_n_jobs_param', 'is_multiclass', 'seed', 'log_plots_param', 'exp_name_log', 'X', '_available_plots', 'fold_generator', 'exp_id', 'X_train', 'data', 'X_test', 'USI', 'y_test', 'target_param', 'fix_imbalance', 'y', 'idx', 'fold_groups_param', 'y_train', 'html_param', 'pipeline', 'n_jobs_param', 'logging_param'}
2025-12-11 15:17:50,042:INFO:Checking environment
2025-12-11 15:17:50,042:INFO:python_version: 3.10.19
2025-12-11 15:17:50,042:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-11 15:17:50,042:INFO:machine: AMD64
2025-12-11 15:17:50,042:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-11 15:17:50,043:INFO:Memory: svmem(total=33699516416, available=16486989824, percent=51.1, used=17212526592, free=16486989824)
2025-12-11 15:17:50,043:INFO:Physical Core: 8
2025-12-11 15:17:50,043:INFO:Logical Core: 16
2025-12-11 15:17:50,043:INFO:Checking libraries
2025-12-11 15:17:50,043:INFO:System:
2025-12-11 15:17:50,043:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-11 15:17:50,043:INFO:executable: c:\Users\Davi\anaconda3\envs\projeto_regressao\python.exe
2025-12-11 15:17:50,043:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-11 15:17:50,043:INFO:PyCaret required dependencies:
2025-12-11 15:17:50,043:INFO:                 pip: 25.3
2025-12-11 15:17:50,043:INFO:          setuptools: 80.9.0
2025-12-11 15:17:50,043:INFO:             pycaret: 3.3.2
2025-12-11 15:17:50,043:INFO:             IPython: 8.37.0
2025-12-11 15:17:50,043:INFO:          ipywidgets: 8.1.8
2025-12-11 15:17:50,043:INFO:                tqdm: 4.67.1
2025-12-11 15:17:50,043:INFO:               numpy: 1.26.4
2025-12-11 15:17:50,043:INFO:              pandas: 2.1.4
2025-12-11 15:17:50,043:INFO:              jinja2: 3.1.6
2025-12-11 15:17:50,043:INFO:               scipy: 1.11.4
2025-12-11 15:17:50,043:INFO:              joblib: 1.3.2
2025-12-11 15:17:50,043:INFO:             sklearn: 1.4.2
2025-12-11 15:17:50,043:INFO:                pyod: 2.0.6
2025-12-11 15:17:50,043:INFO:            imblearn: 0.14.0
2025-12-11 15:17:50,043:INFO:   category_encoders: 2.7.0
2025-12-11 15:17:50,043:INFO:            lightgbm: 4.6.0
2025-12-11 15:17:50,043:INFO:               numba: 0.62.1
2025-12-11 15:17:50,043:INFO:            requests: 2.32.5
2025-12-11 15:17:50,043:INFO:          matplotlib: 3.7.5
2025-12-11 15:17:50,043:INFO:          scikitplot: 0.3.7
2025-12-11 15:17:50,043:INFO:         yellowbrick: 1.5
2025-12-11 15:17:50,045:INFO:              plotly: 6.5.0
2025-12-11 15:17:50,045:INFO:    plotly-resampler: Not installed
2025-12-11 15:17:50,045:INFO:             kaleido: 1.2.0
2025-12-11 15:17:50,045:INFO:           schemdraw: 0.15
2025-12-11 15:17:50,045:INFO:         statsmodels: 0.14.5
2025-12-11 15:17:50,045:INFO:              sktime: 0.26.0
2025-12-11 15:17:50,045:INFO:               tbats: 1.1.3
2025-12-11 15:17:50,045:INFO:            pmdarima: 2.0.4
2025-12-11 15:17:50,045:INFO:              psutil: 7.1.3
2025-12-11 15:17:50,045:INFO:          markupsafe: 3.0.3
2025-12-11 15:17:50,045:INFO:             pickle5: Not installed
2025-12-11 15:17:50,045:INFO:         cloudpickle: 3.1.2
2025-12-11 15:17:50,045:INFO:         deprecation: 2.1.0
2025-12-11 15:17:50,045:INFO:              xxhash: 3.6.0
2025-12-11 15:17:50,045:INFO:           wurlitzer: Not installed
2025-12-11 15:17:50,045:INFO:PyCaret optional dependencies:
2025-12-11 15:17:50,045:INFO:                shap: Not installed
2025-12-11 15:17:50,045:INFO:           interpret: Not installed
2025-12-11 15:17:50,045:INFO:                umap: Not installed
2025-12-11 15:17:50,045:INFO:     ydata_profiling: Not installed
2025-12-11 15:17:50,045:INFO:  explainerdashboard: Not installed
2025-12-11 15:17:50,045:INFO:             autoviz: Not installed
2025-12-11 15:17:50,045:INFO:           fairlearn: Not installed
2025-12-11 15:17:50,045:INFO:          deepchecks: Not installed
2025-12-11 15:17:50,045:INFO:             xgboost: Not installed
2025-12-11 15:17:50,045:INFO:            catboost: Not installed
2025-12-11 15:17:50,045:INFO:              kmodes: Not installed
2025-12-11 15:17:50,045:INFO:             mlxtend: Not installed
2025-12-11 15:17:50,045:INFO:       statsforecast: Not installed
2025-12-11 15:17:50,045:INFO:        tune_sklearn: Not installed
2025-12-11 15:17:50,045:INFO:                 ray: Not installed
2025-12-11 15:17:50,045:INFO:            hyperopt: Not installed
2025-12-11 15:17:50,045:INFO:              optuna: Not installed
2025-12-11 15:17:50,045:INFO:               skopt: Not installed
2025-12-11 15:17:50,045:INFO:              mlflow: Not installed
2025-12-11 15:17:50,045:INFO:              gradio: Not installed
2025-12-11 15:17:50,045:INFO:             fastapi: Not installed
2025-12-11 15:17:50,045:INFO:             uvicorn: Not installed
2025-12-11 15:17:50,047:INFO:              m2cgen: Not installed
2025-12-11 15:17:50,047:INFO:           evidently: Not installed
2025-12-11 15:17:50,047:INFO:               fugue: Not installed
2025-12-11 15:17:50,047:INFO:           streamlit: Not installed
2025-12-11 15:17:50,047:INFO:             prophet: Not installed
2025-12-11 15:17:50,047:INFO:None
2025-12-11 15:17:50,047:INFO:Set up data.
2025-12-11 15:17:50,056:INFO:Set up folding strategy.
2025-12-11 15:17:50,057:INFO:Set up train/test split.
2025-12-11 15:17:50,065:INFO:Set up index.
2025-12-11 15:17:50,067:INFO:Assigning column types.
2025-12-11 15:17:50,074:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-11 15:17:50,124:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:17:50,127:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-11 15:17:50,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-11 15:17:50,213:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-11 15:17:50,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-11 15:17:50,299:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-11 15:17:50,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,385:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-11 15:17:50,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,417:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-11 15:17:50,502:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,588:INFO:Preparing preprocessing pipeline...
2025-12-11 15:17:50,589:INFO:Set up simple imputation.
2025-12-11 15:17:50,589:INFO:Set up imbalanced handling.
2025-12-11 15:17:50,592:INFO:Set up column name cleaning.
2025-12-11 15:17:50,655:INFO:Finished creating preprocessing pipeline.
2025-12-11 15:17:50,661:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Davi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['year', 'km_driven', 'mileage',
                                             'engine', 'max_power', 'seats',
                                             'fuel_Diesel', 'fuel_LPG',
                                             'fuel_Petrol',
                                             'seller_type_Individual',
                                             'seller_type_Trustmark Dealer',
                                             'owner_Fourth & Above Owner',
                                             'owner_Second Owner',
                                             'owner...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-11 15:17:50,661:INFO:Creating final display dataframe.
2025-12-11 15:17:50,838:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target  transmission_encoded
2                   Target type                Binary
3           Original data shape            (7906, 18)
4        Transformed data shape           (11982, 16)
5   Transformed train set shape            (9610, 16)
6    Transformed test set shape            (2372, 16)
7               Ignore features                     2
8              Numeric features                    15
9                    Preprocess                  True
10              Imputation type                simple
11           Numeric imputation                  mean
12       Categorical imputation                  mode
13                Fix imbalance                  True
14         Fix imbalance method                 SMOTE
15               Fold Generator       StratifiedKFold
16                  Fold Number                    10
17                     CPU Jobs                    -1
18                      Use GPU                 False
19               Log Experiment                 False
20              Experiment Name      clf-default-name
21                          USI                  8e39
2025-12-11 15:17:50,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:50,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:51,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:51,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-11 15:17:51,008:INFO:setup() successfully completed in 0.97s...............
2025-12-11 15:17:51,009:INFO:Initializing compare_models()
2025-12-11 15:17:51,009:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-11 15:17:51,009:INFO:Checking exceptions
2025-12-11 15:17:51,016:INFO:Preparing display monitor
2025-12-11 15:17:51,048:INFO:Initializing Logistic Regression
2025-12-11 15:17:51,050:INFO:Total runtime is 2.9242038726806642e-05 minutes
2025-12-11 15:17:51,055:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:51,055:INFO:Initializing create_model()
2025-12-11 15:17:51,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:51,056:INFO:Checking exceptions
2025-12-11 15:17:51,056:INFO:Importing libraries
2025-12-11 15:17:51,056:INFO:Copying training dataset
2025-12-11 15:17:51,066:INFO:Defining folds
2025-12-11 15:17:51,066:INFO:Declaring metric variables
2025-12-11 15:17:51,072:INFO:Importing untrained model
2025-12-11 15:17:51,077:INFO:Logistic Regression Imported successfully
2025-12-11 15:17:51,088:INFO:Starting cross validation
2025-12-11 15:17:51,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:52,891:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:17:52,901:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:17:52,985:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:17:52,997:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:17:53,032:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:17:53,053:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:17:53,060:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:17:53,062:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-11 15:17:53,087:INFO:Calculating mean and std
2025-12-11 15:17:53,087:INFO:Creating metrics dataframe
2025-12-11 15:17:53,091:INFO:Uploading results into container
2025-12-11 15:17:53,092:INFO:Uploading model into container now
2025-12-11 15:17:53,093:INFO:_master_model_container: 1
2025-12-11 15:17:53,093:INFO:_display_container: 2
2025-12-11 15:17:53,094:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-11 15:17:53,094:INFO:create_model() successfully completed......................................
2025-12-11 15:17:53,195:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:53,196:INFO:Creating metrics dataframe
2025-12-11 15:17:53,203:INFO:Initializing K Neighbors Classifier
2025-12-11 15:17:53,203:INFO:Total runtime is 0.035916729768117266 minutes
2025-12-11 15:17:53,207:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:53,207:INFO:Initializing create_model()
2025-12-11 15:17:53,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:53,209:INFO:Checking exceptions
2025-12-11 15:17:53,209:INFO:Importing libraries
2025-12-11 15:17:53,209:INFO:Copying training dataset
2025-12-11 15:17:53,218:INFO:Defining folds
2025-12-11 15:17:53,218:INFO:Declaring metric variables
2025-12-11 15:17:53,224:INFO:Importing untrained model
2025-12-11 15:17:53,229:INFO:K Neighbors Classifier Imported successfully
2025-12-11 15:17:53,239:INFO:Starting cross validation
2025-12-11 15:17:53,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:53,535:INFO:Calculating mean and std
2025-12-11 15:17:53,538:INFO:Creating metrics dataframe
2025-12-11 15:17:53,540:INFO:Uploading results into container
2025-12-11 15:17:53,541:INFO:Uploading model into container now
2025-12-11 15:17:53,542:INFO:_master_model_container: 2
2025-12-11 15:17:53,542:INFO:_display_container: 2
2025-12-11 15:17:53,542:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-11 15:17:53,542:INFO:create_model() successfully completed......................................
2025-12-11 15:17:53,641:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:53,641:INFO:Creating metrics dataframe
2025-12-11 15:17:53,648:INFO:Initializing Naive Bayes
2025-12-11 15:17:53,648:INFO:Total runtime is 0.04332004785537719 minutes
2025-12-11 15:17:53,652:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:53,654:INFO:Initializing create_model()
2025-12-11 15:17:53,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:53,654:INFO:Checking exceptions
2025-12-11 15:17:53,654:INFO:Importing libraries
2025-12-11 15:17:53,654:INFO:Copying training dataset
2025-12-11 15:17:53,661:INFO:Defining folds
2025-12-11 15:17:53,663:INFO:Declaring metric variables
2025-12-11 15:17:53,668:INFO:Importing untrained model
2025-12-11 15:17:53,672:INFO:Naive Bayes Imported successfully
2025-12-11 15:17:53,681:INFO:Starting cross validation
2025-12-11 15:17:53,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:53,818:INFO:Calculating mean and std
2025-12-11 15:17:53,820:INFO:Creating metrics dataframe
2025-12-11 15:17:53,824:INFO:Uploading results into container
2025-12-11 15:17:53,825:INFO:Uploading model into container now
2025-12-11 15:17:53,825:INFO:_master_model_container: 3
2025-12-11 15:17:53,825:INFO:_display_container: 2
2025-12-11 15:17:53,826:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-11 15:17:53,826:INFO:create_model() successfully completed......................................
2025-12-11 15:17:53,926:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:53,927:INFO:Creating metrics dataframe
2025-12-11 15:17:53,934:INFO:Initializing Decision Tree Classifier
2025-12-11 15:17:53,966:INFO:Total runtime is 0.04862195253372192 minutes
2025-12-11 15:17:53,972:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:53,973:INFO:Initializing create_model()
2025-12-11 15:17:53,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:53,973:INFO:Checking exceptions
2025-12-11 15:17:53,973:INFO:Importing libraries
2025-12-11 15:17:53,973:INFO:Copying training dataset
2025-12-11 15:17:53,981:INFO:Defining folds
2025-12-11 15:17:53,981:INFO:Declaring metric variables
2025-12-11 15:17:53,986:INFO:Importing untrained model
2025-12-11 15:17:53,992:INFO:Decision Tree Classifier Imported successfully
2025-12-11 15:17:54,001:INFO:Starting cross validation
2025-12-11 15:17:54,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:54,185:INFO:Calculating mean and std
2025-12-11 15:17:54,187:INFO:Creating metrics dataframe
2025-12-11 15:17:54,190:INFO:Uploading results into container
2025-12-11 15:17:54,191:INFO:Uploading model into container now
2025-12-11 15:17:54,191:INFO:_master_model_container: 4
2025-12-11 15:17:54,191:INFO:_display_container: 2
2025-12-11 15:17:54,193:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-12-11 15:17:54,193:INFO:create_model() successfully completed......................................
2025-12-11 15:17:54,289:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:54,289:INFO:Creating metrics dataframe
2025-12-11 15:17:54,298:INFO:Initializing SVM - Linear Kernel
2025-12-11 15:17:54,300:INFO:Total runtime is 0.05416282018025716 minutes
2025-12-11 15:17:54,304:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:54,305:INFO:Initializing create_model()
2025-12-11 15:17:54,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:54,306:INFO:Checking exceptions
2025-12-11 15:17:54,306:INFO:Importing libraries
2025-12-11 15:17:54,306:INFO:Copying training dataset
2025-12-11 15:17:54,314:INFO:Defining folds
2025-12-11 15:17:54,314:INFO:Declaring metric variables
2025-12-11 15:17:54,320:INFO:Importing untrained model
2025-12-11 15:17:54,325:INFO:SVM - Linear Kernel Imported successfully
2025-12-11 15:17:54,335:INFO:Starting cross validation
2025-12-11 15:17:54,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:54,568:INFO:Calculating mean and std
2025-12-11 15:17:54,570:INFO:Creating metrics dataframe
2025-12-11 15:17:54,572:INFO:Uploading results into container
2025-12-11 15:17:54,572:INFO:Uploading model into container now
2025-12-11 15:17:54,574:INFO:_master_model_container: 5
2025-12-11 15:17:54,574:INFO:_display_container: 2
2025-12-11 15:17:54,574:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-11 15:17:54,574:INFO:create_model() successfully completed......................................
2025-12-11 15:17:54,675:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:54,676:INFO:Creating metrics dataframe
2025-12-11 15:17:54,687:INFO:Initializing Ridge Classifier
2025-12-11 15:17:54,687:INFO:Total runtime is 0.060647757848103834 minutes
2025-12-11 15:17:54,693:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:54,693:INFO:Initializing create_model()
2025-12-11 15:17:54,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:54,693:INFO:Checking exceptions
2025-12-11 15:17:54,693:INFO:Importing libraries
2025-12-11 15:17:54,693:INFO:Copying training dataset
2025-12-11 15:17:54,702:INFO:Defining folds
2025-12-11 15:17:54,704:INFO:Declaring metric variables
2025-12-11 15:17:54,709:INFO:Importing untrained model
2025-12-11 15:17:54,714:INFO:Ridge Classifier Imported successfully
2025-12-11 15:17:54,723:INFO:Starting cross validation
2025-12-11 15:17:54,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:54,802:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.17074e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,810:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.37492e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,812:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.88649e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,814:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.28373e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,822:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.01165e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,828:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.12804e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,831:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.19698e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,834:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.28724e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,837:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.1424e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,847:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.31499e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-12-11 15:17:54,886:INFO:Calculating mean and std
2025-12-11 15:17:54,887:INFO:Creating metrics dataframe
2025-12-11 15:17:54,890:INFO:Uploading results into container
2025-12-11 15:17:54,891:INFO:Uploading model into container now
2025-12-11 15:17:54,891:INFO:_master_model_container: 6
2025-12-11 15:17:54,891:INFO:_display_container: 2
2025-12-11 15:17:54,891:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-12-11 15:17:54,891:INFO:create_model() successfully completed......................................
2025-12-11 15:17:54,995:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:54,995:INFO:Creating metrics dataframe
2025-12-11 15:17:55,005:INFO:Initializing Random Forest Classifier
2025-12-11 15:17:55,006:INFO:Total runtime is 0.06596129337946573 minutes
2025-12-11 15:17:55,010:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:55,011:INFO:Initializing create_model()
2025-12-11 15:17:55,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:55,011:INFO:Checking exceptions
2025-12-11 15:17:55,011:INFO:Importing libraries
2025-12-11 15:17:55,012:INFO:Copying training dataset
2025-12-11 15:17:55,020:INFO:Defining folds
2025-12-11 15:17:55,022:INFO:Declaring metric variables
2025-12-11 15:17:55,026:INFO:Importing untrained model
2025-12-11 15:17:55,032:INFO:Random Forest Classifier Imported successfully
2025-12-11 15:17:55,043:INFO:Starting cross validation
2025-12-11 15:17:55,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:56,431:INFO:Calculating mean and std
2025-12-11 15:17:56,431:INFO:Creating metrics dataframe
2025-12-11 15:17:56,435:INFO:Uploading results into container
2025-12-11 15:17:56,436:INFO:Uploading model into container now
2025-12-11 15:17:56,437:INFO:_master_model_container: 7
2025-12-11 15:17:56,437:INFO:_display_container: 2
2025-12-11 15:17:56,437:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-11 15:17:56,438:INFO:create_model() successfully completed......................................
2025-12-11 15:17:56,539:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:56,539:INFO:Creating metrics dataframe
2025-12-11 15:17:56,548:INFO:Initializing Quadratic Discriminant Analysis
2025-12-11 15:17:56,550:INFO:Total runtime is 0.09168569246927896 minutes
2025-12-11 15:17:56,554:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:56,554:INFO:Initializing create_model()
2025-12-11 15:17:56,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:56,554:INFO:Checking exceptions
2025-12-11 15:17:56,554:INFO:Importing libraries
2025-12-11 15:17:56,554:INFO:Copying training dataset
2025-12-11 15:17:56,564:INFO:Defining folds
2025-12-11 15:17:56,564:INFO:Declaring metric variables
2025-12-11 15:17:56,568:INFO:Importing untrained model
2025-12-11 15:17:56,574:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-11 15:17:56,583:INFO:Starting cross validation
2025-12-11 15:17:56,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:56,653:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,661:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,664:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,669:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,669:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,670:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,670:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,675:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

)) for s in self.scalings_])

2025-12-11 15:17:56,676:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,678:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,681:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,681:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,681:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,681:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,681:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,683:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,683:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,683:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,683:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,683:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,685:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,688:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,688:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,688:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,689:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,689:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,689:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,689:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,689:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,689:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,691:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,691:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,691:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,691:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,692:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,692:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,692:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,694:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,694:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,694:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,694:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))


2025-12-11 15:17:56,694:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,696:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,696:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,696:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,696:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,696:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,697:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-11 15:17:56,697:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,697:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,699:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:961: RuntimeWarning: overflow encountered in square
  norm2.append(np.sum(X2**2, axis=1))

2025-12-11 15:17:56,699:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,700:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,700:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,700:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,702:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:961: RuntimeWarning: overflow encountered in square
  norm2.append(np.sum(X2**2, axis=1))

2025-12-11 15:17:56,705:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2025-12-11 15:17:56,705:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,707:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,708:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,708:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,708:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,708:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,710:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,710:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,711:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,711:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,711:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,711:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,711:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,711:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-12-11 15:17:56,711:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-12-11 15:17:56,713:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,714:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,716:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,720:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,720:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-12-11 15:17:56,728:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:17:56,737:INFO:Calculating mean and std
2025-12-11 15:17:56,738:INFO:Creating metrics dataframe
2025-12-11 15:17:56,741:INFO:Uploading results into container
2025-12-11 15:17:56,742:INFO:Uploading model into container now
2025-12-11 15:17:56,742:INFO:_master_model_container: 8
2025-12-11 15:17:56,742:INFO:_display_container: 2
2025-12-11 15:17:56,744:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-11 15:17:56,744:INFO:create_model() successfully completed......................................
2025-12-11 15:17:56,842:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:56,842:INFO:Creating metrics dataframe
2025-12-11 15:17:56,852:INFO:Initializing Ada Boost Classifier
2025-12-11 15:17:56,852:INFO:Total runtime is 0.09673336744308471 minutes
2025-12-11 15:17:56,856:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:56,857:INFO:Initializing create_model()
2025-12-11 15:17:56,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:56,857:INFO:Checking exceptions
2025-12-11 15:17:56,857:INFO:Importing libraries
2025-12-11 15:17:56,857:INFO:Copying training dataset
2025-12-11 15:17:56,866:INFO:Defining folds
2025-12-11 15:17:56,866:INFO:Declaring metric variables
2025-12-11 15:17:56,872:INFO:Importing untrained model
2025-12-11 15:17:56,877:INFO:Ada Boost Classifier Imported successfully
2025-12-11 15:17:56,885:INFO:Starting cross validation
2025-12-11 15:17:56,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:56,962:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,970:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,972:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,976:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,978:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,980:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,983:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,985:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,990:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:56,999:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-11 15:17:57,586:INFO:Calculating mean and std
2025-12-11 15:17:57,588:INFO:Creating metrics dataframe
2025-12-11 15:17:57,591:INFO:Uploading results into container
2025-12-11 15:17:57,592:INFO:Uploading model into container now
2025-12-11 15:17:57,593:INFO:_master_model_container: 9
2025-12-11 15:17:57,593:INFO:_display_container: 2
2025-12-11 15:17:57,593:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-12-11 15:17:57,593:INFO:create_model() successfully completed......................................
2025-12-11 15:17:57,690:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:57,690:INFO:Creating metrics dataframe
2025-12-11 15:17:57,702:INFO:Initializing Gradient Boosting Classifier
2025-12-11 15:17:57,703:INFO:Total runtime is 0.1109041412671407 minutes
2025-12-11 15:17:57,708:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:57,708:INFO:Initializing create_model()
2025-12-11 15:17:57,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:57,709:INFO:Checking exceptions
2025-12-11 15:17:57,709:INFO:Importing libraries
2025-12-11 15:17:57,709:INFO:Copying training dataset
2025-12-11 15:17:57,717:INFO:Defining folds
2025-12-11 15:17:57,718:INFO:Declaring metric variables
2025-12-11 15:17:57,725:INFO:Importing untrained model
2025-12-11 15:17:57,730:INFO:Gradient Boosting Classifier Imported successfully
2025-12-11 15:17:57,740:INFO:Starting cross validation
2025-12-11 15:17:57,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:59,487:INFO:Calculating mean and std
2025-12-11 15:17:59,489:INFO:Creating metrics dataframe
2025-12-11 15:17:59,492:INFO:Uploading results into container
2025-12-11 15:17:59,493:INFO:Uploading model into container now
2025-12-11 15:17:59,494:INFO:_master_model_container: 10
2025-12-11 15:17:59,494:INFO:_display_container: 2
2025-12-11 15:17:59,495:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-11 15:17:59,495:INFO:create_model() successfully completed......................................
2025-12-11 15:17:59,592:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:59,593:INFO:Creating metrics dataframe
2025-12-11 15:17:59,604:INFO:Initializing Linear Discriminant Analysis
2025-12-11 15:17:59,604:INFO:Total runtime is 0.14258437554041542 minutes
2025-12-11 15:17:59,608:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:59,609:INFO:Initializing create_model()
2025-12-11 15:17:59,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:59,609:INFO:Checking exceptions
2025-12-11 15:17:59,610:INFO:Importing libraries
2025-12-11 15:17:59,610:INFO:Copying training dataset
2025-12-11 15:17:59,618:INFO:Defining folds
2025-12-11 15:17:59,618:INFO:Declaring metric variables
2025-12-11 15:17:59,624:INFO:Importing untrained model
2025-12-11 15:17:59,629:INFO:Linear Discriminant Analysis Imported successfully
2025-12-11 15:17:59,639:INFO:Starting cross validation
2025-12-11 15:17:59,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:17:59,783:INFO:Calculating mean and std
2025-12-11 15:17:59,784:INFO:Creating metrics dataframe
2025-12-11 15:17:59,787:INFO:Uploading results into container
2025-12-11 15:17:59,788:INFO:Uploading model into container now
2025-12-11 15:17:59,789:INFO:_master_model_container: 11
2025-12-11 15:17:59,789:INFO:_display_container: 2
2025-12-11 15:17:59,790:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-11 15:17:59,790:INFO:create_model() successfully completed......................................
2025-12-11 15:17:59,892:INFO:SubProcess create_model() end ==================================
2025-12-11 15:17:59,892:INFO:Creating metrics dataframe
2025-12-11 15:17:59,904:INFO:Initializing Extra Trees Classifier
2025-12-11 15:17:59,904:INFO:Total runtime is 0.14759350220362344 minutes
2025-12-11 15:17:59,909:INFO:SubProcess create_model() called ==================================
2025-12-11 15:17:59,910:INFO:Initializing create_model()
2025-12-11 15:17:59,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:17:59,910:INFO:Checking exceptions
2025-12-11 15:17:59,910:INFO:Importing libraries
2025-12-11 15:17:59,911:INFO:Copying training dataset
2025-12-11 15:17:59,919:INFO:Defining folds
2025-12-11 15:17:59,920:INFO:Declaring metric variables
2025-12-11 15:17:59,926:INFO:Importing untrained model
2025-12-11 15:17:59,930:INFO:Extra Trees Classifier Imported successfully
2025-12-11 15:17:59,939:INFO:Starting cross validation
2025-12-11 15:17:59,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:18:01,006:INFO:Calculating mean and std
2025-12-11 15:18:01,007:INFO:Creating metrics dataframe
2025-12-11 15:18:01,011:INFO:Uploading results into container
2025-12-11 15:18:01,012:INFO:Uploading model into container now
2025-12-11 15:18:01,012:INFO:_master_model_container: 12
2025-12-11 15:18:01,013:INFO:_display_container: 2
2025-12-11 15:18:01,013:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-12-11 15:18:01,013:INFO:create_model() successfully completed......................................
2025-12-11 15:18:01,123:INFO:SubProcess create_model() end ==================================
2025-12-11 15:18:01,123:INFO:Creating metrics dataframe
2025-12-11 15:18:01,135:INFO:Initializing Light Gradient Boosting Machine
2025-12-11 15:18:01,135:INFO:Total runtime is 0.16810534795125323 minutes
2025-12-11 15:18:01,143:INFO:SubProcess create_model() called ==================================
2025-12-11 15:18:01,144:INFO:Initializing create_model()
2025-12-11 15:18:01,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:18:01,144:INFO:Checking exceptions
2025-12-11 15:18:01,144:INFO:Importing libraries
2025-12-11 15:18:01,144:INFO:Copying training dataset
2025-12-11 15:18:01,153:INFO:Defining folds
2025-12-11 15:18:01,154:INFO:Declaring metric variables
2025-12-11 15:18:01,160:INFO:Importing untrained model
2025-12-11 15:18:01,165:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-11 15:18:01,175:INFO:Starting cross validation
2025-12-11 15:18:01,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:18:02,604:INFO:Calculating mean and std
2025-12-11 15:18:02,606:INFO:Creating metrics dataframe
2025-12-11 15:18:02,610:INFO:Uploading results into container
2025-12-11 15:18:02,611:INFO:Uploading model into container now
2025-12-11 15:18:02,611:INFO:_master_model_container: 13
2025-12-11 15:18:02,611:INFO:_display_container: 2
2025-12-11 15:18:02,613:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-11 15:18:02,615:INFO:create_model() successfully completed......................................
2025-12-11 15:18:02,738:INFO:SubProcess create_model() end ==================================
2025-12-11 15:18:02,738:INFO:Creating metrics dataframe
2025-12-11 15:18:02,749:INFO:Initializing Dummy Classifier
2025-12-11 15:18:02,750:INFO:Total runtime is 0.1950268983840942 minutes
2025-12-11 15:18:02,754:INFO:SubProcess create_model() called ==================================
2025-12-11 15:18:02,754:INFO:Initializing create_model()
2025-12-11 15:18:02,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249EDDDA6E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:18:02,754:INFO:Checking exceptions
2025-12-11 15:18:02,754:INFO:Importing libraries
2025-12-11 15:18:02,756:INFO:Copying training dataset
2025-12-11 15:18:02,764:INFO:Defining folds
2025-12-11 15:18:02,764:INFO:Declaring metric variables
2025-12-11 15:18:02,770:INFO:Importing untrained model
2025-12-11 15:18:02,776:INFO:Dummy Classifier Imported successfully
2025-12-11 15:18:02,787:INFO:Starting cross validation
2025-12-11 15:18:02,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:18:02,876:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,880:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,884:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,892:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,896:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,896:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,899:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,899:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,907:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,907:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-11 15:18:02,918:INFO:Calculating mean and std
2025-12-11 15:18:02,921:INFO:Creating metrics dataframe
2025-12-11 15:18:02,923:INFO:Uploading results into container
2025-12-11 15:18:02,924:INFO:Uploading model into container now
2025-12-11 15:18:02,925:INFO:_master_model_container: 14
2025-12-11 15:18:02,925:INFO:_display_container: 2
2025-12-11 15:18:02,925:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-12-11 15:18:02,926:INFO:create_model() successfully completed......................................
2025-12-11 15:18:03,025:INFO:SubProcess create_model() end ==================================
2025-12-11 15:18:03,025:INFO:Creating metrics dataframe
2025-12-11 15:18:03,039:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-12-11 15:18:03,051:INFO:Initializing create_model()
2025-12-11 15:18:03,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:18:03,053:INFO:Checking exceptions
2025-12-11 15:18:03,056:INFO:Importing libraries
2025-12-11 15:18:03,056:INFO:Copying training dataset
2025-12-11 15:18:03,063:INFO:Defining folds
2025-12-11 15:18:03,063:INFO:Declaring metric variables
2025-12-11 15:18:03,063:INFO:Importing untrained model
2025-12-11 15:18:03,063:INFO:Declaring custom model
2025-12-11 15:18:03,063:INFO:Random Forest Classifier Imported successfully
2025-12-11 15:18:03,065:INFO:Cross validation set to False
2025-12-11 15:18:03,065:INFO:Fitting Model
2025-12-11 15:18:03,406:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-11 15:18:03,406:INFO:create_model() successfully completed......................................
2025-12-11 15:18:03,556:INFO:_master_model_container: 14
2025-12-11 15:18:03,557:INFO:_display_container: 2
2025-12-11 15:18:03,557:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-11 15:18:03,557:INFO:compare_models() successfully completed......................................
2025-12-11 15:18:03,558:INFO:Initializing tune_model()
2025-12-11 15:18:03,560:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>)
2025-12-11 15:18:03,560:INFO:Checking exceptions
2025-12-11 15:18:03,584:INFO:Copying training dataset
2025-12-11 15:18:03,591:INFO:Checking base model
2025-12-11 15:18:03,592:INFO:Base model : Random Forest Classifier
2025-12-11 15:18:03,597:INFO:Declaring metric variables
2025-12-11 15:18:03,602:INFO:Defining Hyperparameters
2025-12-11 15:18:03,711:INFO:Tuning with n_jobs=-1
2025-12-11 15:18:03,711:INFO:Initializing RandomizedSearchCV
2025-12-11 15:18:20,539:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2025-12-11 15:18:20,541:INFO:Hyperparameter search completed
2025-12-11 15:18:20,541:INFO:SubProcess create_model() called ==================================
2025-12-11 15:18:20,542:INFO:Initializing create_model()
2025-12-11 15:18:20,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000249F167ACE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2025-12-11 15:18:20,542:INFO:Checking exceptions
2025-12-11 15:18:20,542:INFO:Importing libraries
2025-12-11 15:18:20,543:INFO:Copying training dataset
2025-12-11 15:18:20,556:INFO:Defining folds
2025-12-11 15:18:20,556:INFO:Declaring metric variables
2025-12-11 15:18:20,560:INFO:Importing untrained model
2025-12-11 15:18:20,561:INFO:Declaring custom model
2025-12-11 15:18:20,565:INFO:Random Forest Classifier Imported successfully
2025-12-11 15:18:20,575:INFO:Starting cross validation
2025-12-11 15:18:20,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:18:22,303:INFO:Calculating mean and std
2025-12-11 15:18:22,305:INFO:Creating metrics dataframe
2025-12-11 15:18:22,313:INFO:Finalizing model
2025-12-11 15:18:22,762:INFO:Uploading results into container
2025-12-11 15:18:22,762:INFO:Uploading model into container now
2025-12-11 15:18:22,764:INFO:_master_model_container: 15
2025-12-11 15:18:22,764:INFO:_display_container: 3
2025-12-11 15:18:22,764:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=190, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2025-12-11 15:18:22,764:INFO:create_model() successfully completed......................................
2025-12-11 15:18:22,864:INFO:SubProcess create_model() end ==================================
2025-12-11 15:18:22,864:INFO:choose_better activated
2025-12-11 15:18:22,870:INFO:SubProcess create_model() called ==================================
2025-12-11 15:18:22,871:INFO:Initializing create_model()
2025-12-11 15:18:22,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-11 15:18:22,872:INFO:Checking exceptions
2025-12-11 15:18:22,874:INFO:Importing libraries
2025-12-11 15:18:22,874:INFO:Copying training dataset
2025-12-11 15:18:22,881:INFO:Defining folds
2025-12-11 15:18:22,881:INFO:Declaring metric variables
2025-12-11 15:18:22,881:INFO:Importing untrained model
2025-12-11 15:18:22,881:INFO:Declaring custom model
2025-12-11 15:18:22,883:INFO:Random Forest Classifier Imported successfully
2025-12-11 15:18:22,883:INFO:Starting cross validation
2025-12-11 15:18:22,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-11 15:18:24,219:INFO:Calculating mean and std
2025-12-11 15:18:24,219:INFO:Creating metrics dataframe
2025-12-11 15:18:24,221:INFO:Finalizing model
2025-12-11 15:18:24,553:INFO:Uploading results into container
2025-12-11 15:18:24,554:INFO:Uploading model into container now
2025-12-11 15:18:24,554:INFO:_master_model_container: 16
2025-12-11 15:18:24,554:INFO:_display_container: 4
2025-12-11 15:18:24,555:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-11 15:18:24,555:INFO:create_model() successfully completed......................................
2025-12-11 15:18:24,652:INFO:SubProcess create_model() end ==================================
2025-12-11 15:18:24,653:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for F1 is 0.7968
2025-12-11 15:18:24,653:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=190, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for F1 is 0.6715
2025-12-11 15:18:24,653:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2025-12-11 15:18:24,653:INFO:choose_better completed
2025-12-11 15:18:24,653:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-11 15:18:24,668:INFO:_master_model_container: 16
2025-12-11 15:18:24,668:INFO:_display_container: 3
2025-12-11 15:18:24,669:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-12-11 15:18:24,669:INFO:tune_model() successfully completed......................................
2025-12-11 15:18:29,750:INFO:Initializing plot_model()
2025-12-11 15:18:29,751:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000249F19FCF10>, system=True)
2025-12-11 15:18:29,751:INFO:Checking exceptions
2025-12-11 15:18:29,794:INFO:Preloading libraries
2025-12-11 15:18:29,868:INFO:Copying training dataset
2025-12-11 15:18:29,868:INFO:Plot type: error
2025-12-11 15:18:30,021:INFO:Fitting Model
2025-12-11 15:18:30,021:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2025-12-11 15:18:30,021:INFO:Scoring test/hold-out set
2025-12-11 15:18:30,386:INFO:Visual Rendered Successfully
2025-12-11 15:18:30,486:INFO:plot_model() successfully completed......................................
2025-12-11 15:18:30,495:INFO:Initializing plot_model()
2025-12-11 15:18:30,495:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249F711D690>, system=True)
2025-12-11 15:18:30,497:INFO:Checking exceptions
2025-12-11 15:18:30,543:INFO:Preloading libraries
2025-12-11 15:18:30,563:INFO:Copying training dataset
2025-12-11 15:18:30,563:INFO:Plot type: confusion_matrix
2025-12-11 15:18:30,739:INFO:Fitting Model
2025-12-11 15:18:30,769:WARNING:c:\Users\Davi\anaconda3\envs\projeto_regressao\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-12-11 15:18:30,770:INFO:Scoring test/hold-out set
2025-12-11 15:18:31,001:INFO:Visual Rendered Successfully
2025-12-11 15:18:31,111:INFO:plot_model() successfully completed......................................
